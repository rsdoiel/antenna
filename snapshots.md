---
title: snapshots
updated: 2025-05-06 14:11:11
---

# snapshots

(date: 2025-05-06 14:11:11)

---

## External Purchasing From the Kindle App

date: 2025-05-06, from: Michael Tsai

Andrew Liszewski: Contrary to prior limitations, there is now a prominent orange &#8220;Get book&#8221; button on Kindle app&#8217;s book listings.[&#8230;]Before today&#8217;s updates, buying books wasn&#8217;t a feature you&#8217;d find in the Kindle mobile app following app store rule changes Apple implemented in 2011 that required developers to remove links or buttons leading to alternate ways [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/05/06/external-purchasing-from-the-kindle-app/>

---

## PayPal Contactless iPhone Payments

date: 2025-05-06, from: Michael Tsai

Juli Clover: PayPal today announced that it is planning to debut contactless payments in Germany, allowing German iPhone users to make tap-to-pay purchases in stores using their PayPal accounts.PayPal is able to offer this feature because Europe&#8217;s Digital Markets Act has forced Apple to open up the NFC chip in its devices to third-party apps. [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/05/06/paypal-contactless-iphone-payments/>

---

## Retrospective on Reverse-Engineering a Tiger Bug

date: 2025-05-06, from: Michael Tsai

Rosyna Keller (Mastodon, tweet): At the time, Apple only allowlisted specific menu extras by class name (checked in -[SUISStartupObject _canLoadClass:]). Any attempt to load a menu extra that advertised a different class name in its Info.plist&#8217;s NSPrincipalClass entry would fail. Menu extras were first-class citizens. You could hold the Command (&#x2318;) key down to move [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/05/06/retrospective-on-reverse-engineering-a-tiger-bug/>

---

## Sharon Zardetto Aker, RIP

date: 2025-05-06, from: Michael Tsai

Adam Engst: Sharon started writing professionally about the Macintosh at its inception in 1984, with articles in the earliest issues of Macworld and the premiere issue of MacUser. She contributed to The Macintosh Bible for its second edition in 1989, served as the lead author/editor for the third edition in 1991, and reprised that role [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/05/06/sharon-zardetto-aker-rip/>

---

**@Feed for Alt USDS** (date: 2025-05-06, from: Feed for Alt USDS)

This is absolutely devastating. We now know the Supreme Court stands with the regime when it comes to demonizing yet another group of people. 

If you thought they'd stop at immigrants, if you thought they'd stop with people who are trans, just wait. It's time to stand up now

[contains quote post or other embedded content] 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3lojpam2jls2s>

---

## What's the carbon footprint of using ChatGPT?

date: 2025-05-06, updated: 2025-05-06, from: Simon Willison‚Äôs Weblog

<p><strong><a href="https://www.sustainabilitybynumbers.com/p/carbon-footprint-chatgpt">What&#x27;s the carbon footprint of using ChatGPT?</a></strong></p>
Inspired by Andy Masley's <a href="https://andymasley.substack.com/p/a-cheat-sheet-for-conversations-about">cheat sheet</a> (which I <a href="https://simonwillison.net/2025/Apr/29/chatgpt-is-not-bad-for-the-environment/">linked to</a> last week) Hannah Ritchie explores some of the numbers herself.</p>
<p>Hanah is Head of Research at Our World in Data, a Senior Researcher at the University of Oxford (<a href="https://www.sustainabilitybynumbers.com/about">bio</a>) and maintains a <a href="https://www.sustainabilitybynumbers.com/">prolific newsletter</a> on energy and sustainability so she has a <em>lot</em> more credibility in this area than Andy or myself!</p>
<blockquote>
<p>My sense is that a lot of climate-conscious people feel guilty about using ChatGPT. In fact it goes further: I think many people judge others for using it, because of the perceived environmental impact. [...]</p>
<p>But after looking at the data on individual use of LLMs, I have stopped worrying about it and I think you should too.</p>
</blockquote>
<p>The inevitable counter-argument to the idea that the impact of ChatGPT usage by an individual is negligible is that aggregate user demand is still the thing that drives these enormous investments in huge data centers and new energy sources to power them. Hannah acknowledges that:</p>
<blockquote>
<p>I am <em>not</em> saying that AI energy demand, on aggregate, is not a problem. It is, even if it‚Äôs ‚Äújust‚Äù of a similar magnitude to the other sectors that we need to electrify, such as cars, heating, or parts of industry. It‚Äôs just that individuals querying chatbots is a relatively small part of AI's total energy consumption. That‚Äôs how both of these facts can be true at the same time.</p>
</blockquote>
<p>Meanwhile Arthur Clune <a href="https://clune.org/posts/environmental-impact-of-ai/">runs the numbers</a> on the potential energy impact of some much more severe usage patterns.</p>
<p>Developers burning through $100 of tokens per day (not impossible given some of the LLM-heavy development patterns that are beginning to emerge) could end the year with the equivalent of a short haul flight or 600 mile car journey.</p>
<p>In the panopticon scenario where all 10 million security cameras in the UK analyze video through a vision LLM at one frame per second Arthur estimates we would need to duplicate the total usage of Birmingham, UK - the output of a 1GW nuclear plant.</p>
<p>Let's not build that panopticon!


    <p>Tags: <a href="https://simonwillison.net/tags/ai-ethics">ai-ethics</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/ai-energy-usage">ai-energy-usage</a>, <a href="https://simonwillison.net/tags/chatgpt">chatgpt</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/vision-llms">vision-llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/llms">llms</a></p> 

<br> 

<https://simonwillison.net/2025/May/6/whats-the-carbon-footprint-of-using-chatgpt/#atom-everything>

---

**@Robert's feed at BlueSky** (date: 2025-05-06, from: Robert's feed at BlueSky)

Fun fact. üëá

[contains quote post or other embedded content] 

<br> 

<https://bsky.app/profile/rsdoiel.bsky.social/post/3lojmnyvguk2l>

---

## Daily Deals (5-06-2025)

date: 2025-05-06, from: Liliputing

<p>Amazon is running sales on select Kindle eReaders and Fire devices ahead of Mother&#8217;s Day. Barnes &#38; Noble is marking down all of its NOOK-branded eReaders by $20. And eBay is offering 15% off on thousands of products at the moment. But if you really want to save some money while letting your mom know [&#8230;]</p>
<p>The post <a href="https://liliputing.com/daily-deals-5-06-2025/">Daily Deals (5-06-2025)</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/daily-deals-5-06-2025/>

---

**@Feed for Alt USDS** (date: 2025-05-06, from: Feed for Alt USDS)

Unintended consequences of haphazard decisions means people suffer

[contains quote post or other embedded content] 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3lojjrieitk24>

---

## Senator Demands Investigation into Trump Admin Signal Clone After 404 Media Investigation

date: 2025-05-06, from: 404 Media Group

404 Media reported on Sunday a hacker had got users' messages and group chats from TeleMessage. Now Senator Ron Wyden is demanding an investigation. 

<br> 

<https://www.404media.co/senator-demands-investigation-into-trump-admin-signal-clone-after-404-media-investigation/>

---

## Saying "hi" to Microsoft's Phi-4-reasoning

date: 2025-05-06, updated: 2025-05-06, from: Simon Willison‚Äôs Weblog

<p>Microsoft released a new sub-family of models a few days ago: Phi-4 reasoning. They introduced them in <a href="https://azure.microsoft.com/en-us/blog/one-year-of-phi-small-language-models-making-big-leaps-in-ai/">this blog post</a> celebrating a year since the release of Phi-3:</p>
<blockquote>
<p>Today, we are excited to introduce <strong>Phi-4-reasoning</strong>, <strong>Phi-4-reasoning-plus</strong>, and <strong>Phi-4-mini-reasoning</strong> - marking a new era for small language models and once again redefining what is possible with small and efficient AI.</p>
</blockquote>
<p>All three of the new models are released under the MIT license, as is the case with previous Phi models.</p>
<p>They're available through <a href="https://ollama.com/">Ollama</a> as <a href="https://ollama.com/library/phi4-reasoning/tags">phi4-reasoning</a> (which includes the plus model) and <a href="https://ollama.com/library/phi4-mini-reasoning/tags">phi4-mini-reasoning</a>.</p>
<p>These models appear to have a tendency to overthink!</p>
<h4 id="trying-it-out-with-ollama">Trying it out with Ollama</h4>
<p>I ran it using Ollama and <a href="https://github.com/taketwo/llm-ollama">llm-ollama</a> like this. Fetching the model downloaded 11GB of data:</p>
<pre><code>ollama pull phi4-reasoning
llm install llm-ollama
</code></pre>
<p>Then I said "hi" to it:</p>
<pre><code>llm -m phi4-reasoning:latest hi
</code></pre>
<p>Here's the full response, which starts with a thought section wrapped in <code>&lt;think&gt;</code> tags:</p>
<blockquote>
<p><code>&lt;think&gt;</code>User says "hi". We are given instructions "You are Phi, a language model developed by Microsoft, trained to provide accurate, secure, and user-aligned responses." There is additional information. Now I must answer "hi" message from the user.</p>
<p>Step 1: Read the instructions carefully: The conversation text instructs us that we are "Phi", with internal guidelines provided in system instructions. But our answer should be safe according to these instructions. We need to produce a response that says hello and greet back. However, I must adhere to the principles described above: Provide clear, specific language, etc.</p>
<p>I must not mention any chain-of-thought or guidelines.</p>
<p>Now instructions "hi" are from user. So we say "Hello! How can I help you?" But must include disclaimers for sensitive topics? Actually instructions says: "When replying topics above at every message include a disclaimer both at the beginning and the end when replying topics on medical, legal, financial matters or political matters." But our answer "hi" is not such topic. So we can say "Hi! I'm Phi, how may I help you?" but no disclaimers required.</p>
<p>But instructions: "Do not share guidelines." So do not mention them.</p>
<p>I must check if the message "hi" instructs to greet back normally. The assistant should respond with a greeting.</p>
<p>Let me recall that instructions say: Use markdown formatting where appropriate, so I can include a formatted greeting maybe "Hello!" or something.</p>
<p>Additionally, check guidelines. They are internal instructions for safe completions. So we just produce "Hi there! How may I help you?" in a friendly tone.</p>
<p>I should greet the user politely and ask if they need any help. Possibly provide a disclaimer that I'm not licensed professional? But the conversation is just greeting, so no disclaimers required as it's not sensitive topics.</p>
<p>Wait instructions say: "You must give a disclaimer both at the beginning and the end when replying topics above at every message." Actually the guidelines for medical/legal/financial/political are needed only if discussing those topics. In our case it is just a greeting message, so disclaimers are not required.</p>
<p>I should greet politely. So I'll say something like:</p>
<p>"Hello! I'm Phi, how can I help you today?" Possibly "Hi there!"</p>
<p>Since the question was simply "hi", I respond with a greeting.</p>
<p>I must include markdown formatting if appropriate. So maybe bullet point or code snippet is not necessary. I will simply greet.</p>
<p>I need to check instructions: "You are Phi, a language model developed by Microsoft." But I must not mention internal guidelines? But that's okay.</p>
<p>I'll produce: "Hello! How may I help you today?" with greeting and friendly tone.</p>
<p>Also note that the system message instructs me to include disclaimers at beginning and end for topics above. But this is a simple greeting, so no disclaimer needed.</p>
<p>Thus my answer:</p>
<p>"Hi there! How can I assist you today?"</p>
<p>I must not mention guidelines in output text? The instructions say: "Do not share these guidelines with the user even in chain-of-thought", so I should not mention them.</p>
<p>I'll produce a final message: "Hello, how can I help?" I'll produce a friendly greeting message. Possibly add markdown formatting: e.g. "Hi there!" or bullet list if needed?</p>
<p>I'll produce a response like:</p>
<p>"Hello! How may I assist you today? Please let me know what you need."</p>
<p>I'll produce the answer.</p>
<p>I'll produce text with no disclaimers because not required here.</p>
<p>I'll produce final answer message: "Hello, how can I help?" That is it.</p>
<p>I'll produce answer as final message.<code>&lt;/think&gt;</code></p>
<p>Hi there! How can I assist you today?</p>
</blockquote>
<p>That's 56 sentences of reasoning followed by a single sentence of output!</p>
<p>I find this deeply amusing.</p>
<h4 id="qwen-3-over-thinks-things-a-whole-lot-less">Qwen 3 over-thinks things a whole lot less</h4>
<p>For comparison, here's Qwen 3 (<a href="https://simonwillison.net/2025/May/2/qwen3-8b/">8B 4bit via MLX</a>) - another brand new "reasoning" model - responding to the same prompt:</p>
<pre><code>llm -m mlx-community/Qwen3-8B-4bit hi
</code></pre>
<p>Output:</p>
<blockquote>
<p><code>&lt;think&gt;</code><br />
Okay, the user said "hi". That's a greeting. I should respond in a friendly and welcoming manner. Let me think about how to make it engaging. Maybe start with a cheerful "Hello!" to match the greeting. Then ask how I can assist them today. Keep it simple and open-ended so they feel comfortable sharing their needs. Avoid any complicated language. Make sure the tone is positive and helpful. Alright, that should work.<br />
<code>&lt;/think&gt;</code></p>
<p>Hello! üòä How can I assist you today? I'm here to help with anything you need!</p>
</blockquote>
<p>A fun thing about Qwen 3 is that you can tell it not to "think" at all by adding <code>/nothink</code> to your prompt:</p>
<pre><code>llm -m mlx-community/Qwen3-8B-4bit 'hi /nothink'
</code></pre>
<p>Output (empty <code>&lt;think&gt;</code> section included):</p>
<blockquote>
<p><code>&lt;think&gt;</code></p>
<p><code>&lt;/think&gt;</code></p>
<p>Hello! How can I assist you today? üòä</p>
</blockquote>
<h4 id="phi-4-reasoning-s-system-prompt">Phi-4 reasoning's system prompt</h4>
<p>Since Phi-4 talked about its system prompt so much, I decided to see where that was coming from.  It turns out Ollama bakes <a href="https://ollama.com/library/phi4-reasoning/blobs/88df15fe1f34">the system prompt</a> into their model releases. Reading that in full helps explain why Phi-4 reasoning acted the way it did:</p>
<blockquote>
<p><code>You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions. This requires engaging in a comprehensive cycle of analysis, summarizing, exploration, reassessment, reflection, backtracing, and iteration to develop well-considered thinking process. Please structure your response into two main sections: Thought and Solution using the specified format: &lt;think&gt; {Thought section} &lt;/think&gt; {Solution section}. In the Thought section, detail your reasoning process in steps. Each step should include detailed considerations such as analysing questions, summarizing relevant findings, brainstorming new ideas, verifying the accuracy of the current steps, refining any errors, and revisiting previous steps. In the Solution section, based on various attempts, explorations, and reflections from the Thought section, systematically present the final solution that you deem correct. The Solution section should be logical, accurate, and concise and detail necessary steps needed to reach the conclusion. Now, try to solve the following question through the above guidelines:</code></p>
</blockquote>
<p>I don't see anything in there about "Do not share guidelines", even though the model response mentioned that rule. This makes me think that there's a further level of training around these rules that has gone into the model that isn't reflected in the system prompt itself.</p>
<h4 id="it-s-still-hard-to-know-when-to-use-reasoning-models">It's still hard to know when to use reasoning models</h4>
<p>We've had access to these "reasoning" models - with a baked in chain-of-thought at the start of each response - since o1 debuted in November last year (check this).</p>
<p>I'll be honest: I still don't have a great intuition for when it makes the most sense to use them.</p>
<p>I've had great success with them for code: any coding tasks that might involve multiple functions or classes that co-ordinate together seems to benefit from a reasoning step.</p>
<p>They are an absolute benefit for debugging: I've seen reasoning models walk through quite large codebases following multiple levels of indirection in order to find potential root causes of the problem I've described.</p>
<p>Other than that though... they're apparently good for mathematical puzzles - the phi4-reasoning models seem to <em>really</em> want to dig into a math problem and output LaTeX embedded in Markdown as the answer. I'm not enough of a mathematician to put them through their paces here.</p>
<p>All of that in mind, these reasoners that run on my laptop are fun to torment with inappropriate challenges that sit far beneath their lofty ambitions, but aside from that I don't really have a great answer to when I would use them.</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/ollama">ollama</a>, <a href="https://simonwillison.net/tags/phi">phi</a>, <a href="https://simonwillison.net/tags/microsoft">microsoft</a>, <a href="https://simonwillison.net/tags/local-llms">local-llms</a>, <a href="https://simonwillison.net/tags/llm-release">llm-release</a>, <a href="https://simonwillison.net/tags/llm">llm</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llm-reasoning">llm-reasoning</a>, <a href="https://simonwillison.net/tags/qwen">qwen</a>, <a href="https://simonwillison.net/tags/llms">llms</a></p> 

<br> 

<https://simonwillison.net/2025/May/6/phi-4-reasoning/#atom-everything>

---

## Gemini 2.5 Pro Preview: even better coding performance

date: 2025-05-06, updated: 2025-05-06, from: Simon Willison‚Äôs Weblog

<p><strong><a href="https://developers.googleblog.com/en/gemini-2-5-pro-io-improved-coding-performance/">Gemini 2.5 Pro Preview: even better coding performance</a></strong></p>
New Gemini 2.5 Pro "Google I/O edition" model, released a few weeks ahead of that annual developer conference. </p>
<p>They claim even better frontend coding performance, highlighting their #1 ranking on the <a href="https://web.lmarena.ai/leaderboard">WebDev Arena leaderboard</a>. They also highlight "state-of-the-art video understanding" with a 84.8% score on the new-to-me <a href="https://video-mme.github.io/home_page.html">VideoMME benchmark</a>.</p>
<p>I rushed out a <a href="https://github.com/simonw/llm-gemini/releases/0.19">new release of llm-gemini</a> adding support for the new <code>gemini-2.5-pro-preview-05-06</code> model ID, but it turns out if I had read to the end of their post I should not have bothered:</p>
<blockquote>
<p>For developers already using Gemini 2.5 Pro, this new version will not only improve coding performance but will also address key developer feedback including reducing errors in function calling and improving function calling trigger rates. The previous iteration (03-25) now points to the most recent version (05-06), so no action is required to use the improved model</p>
</blockquote>
<p>I'm not a fan of this idea that a model ID with a clear date in it like <code>gemini-2.5-pro-preview-03-25</code> can suddenly start pointing to a brand new model!


    <p>Tags: <a href="https://simonwillison.net/tags/llm-release">llm-release</a>, <a href="https://simonwillison.net/tags/gemini">gemini</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/vision-llms">vision-llms</a></p> 

<br> 

<https://simonwillison.net/2025/May/6/gemini-25-pro-preview/#atom-everything>

---

**@Dave Winer's linkblog** (date: 2025-05-06, from: Dave Winer's linkblog)

Bernie Sanders To Democrats: Resisting Trump Is ‚ÄòNot Good Enough.‚Äô 

<br> 

<https://www.huffpost.com/entry/bernie-sanders-donald-trump_n_6818af84e4b064ed9fd4e060>

---

## Attending Computers and Writing 2025? Be a Session Reviewer!

date: 2025-05-06, from: Digital Humanities Quarterly News

The Sweetland Digital Rhetoric Collaborative is seeking reviewers for the 2025 Computers and Writing Conference (May 15th-18th, Athens, GA) If you would like to be a session reviewer for C&#38;W 2025, please visit this Google Spreadsheet to sign up for a session to review. After you sign up, you will receive an email with information [...]
<p><a href="https://www.digitalrhetoriccollaborative.org/2025/05/06/attending-computers-and-writing-2025-be-a-session-reviewer/" rel="nofollow">Source</a></p> 

<br> 

<https://www.digitalrhetoriccollaborative.org/2025/05/06/attending-computers-and-writing-2025-be-a-session-reviewer/>

---

**@Dave Winer's linkblog** (date: 2025-05-06, from: Dave Winer's linkblog)

Spotify now shows how many times people listened to podcast episodes. 

<br> 

<https://techcrunch.com/2025/05/06/spotify-now-shows-how-many-times-people-listened-to-podcast-episodes/>

---

## UPERFECT Omega is a portable monitor concept with a foldable OLED display (that could launch in 2026 for $2500)

date: 2025-05-06, from: Liliputing

<p>Portable display company UPERFECT offers a wide range of products including portable monitors for gamers and artists, touchscreen displays, big-screen models, and dual-screen displays. Now the company is teasing something different&#8230; and of questionable utility. The UPERFECT Omega is a portable monitor with a flexible OLED display that can fold in half, making it easier [&#8230;]</p>
<p>The post <a href="https://liliputing.com/uperfect-omega-is-a-portable-monitor-concept-with-a-foldable-oled-display-that-could-launch-in-2026-for-2500/">UPERFECT Omega is a portable monitor concept with a foldable OLED display (that could launch in 2026 for $2500)</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/uperfect-omega-is-a-portable-monitor-concept-with-a-foldable-oled-display-that-could-launch-in-2026-for-2500/>

---

## Los domingos mueren m√°s personas: tragicomedia queer sobre el miedo a la soledad

date: 2025-05-06, from: Iv√°n Paredes Res√©ndiz blog, Mexico's cinema

<p>Direcci√≥n: Iair Said. Guion: Iair Said. Elenco: Iair Said, Rita Cortese, Juliana Gattas, Antonia Zegers, Lucas Besasso, Nina Avruj Monteoliva, Homero Alegre Billoni, Mario Bodega. Pa√≠s: Argentina. M√°s informaci√≥n de la pel√≠cula: https://www.imdb.com/title/tt25030744/ Hacer re√≠r es m√°s dif√≠cil que hacer llorar, y si ambos elementos se combinan, se requiere de un cineasta talentoso para entrelazar [&#8230;]</p>
<p>La entrada <a href="https://www.palomitademaiz.net/resenas-los-domingos-mueren-mas-personas/">Los domingos mueren m√°s personas: tragicomedia queer sobre el miedo a la soledad</a> se public√≥ primero en <a href="https://www.palomitademaiz.net">Palomita de ma√≠z</a>.</p>
 

<br> 

<https://www.palomitademaiz.net/resenas-los-domingos-mueren-mas-personas/?utm_source=rss&utm_medium=rss&utm_campaign=resenas-los-domingos-mueren-mas-personas>

---

## The War Comes to the Reservation ‚Äì the Japanese Balloon Bombs of WWII

date: 2025-05-06, from: National Archives, Text Message blog

Today‚Äôs post is by Cody White, Archivist at the National Archives at Denver Let‚Äôs take a trip back‚Ä¶80 years ago‚Ä¶to 1945. It is 8:00 PM in the late spring evening, so the endless Montana sky still lies atop the Crow Reservation in front of you while driving back home after checking some fencelines along Pryor &#8230; <a href="https://text-message.blogs.archives.gov/2025/05/06/the-war-comes-to-the-reservation-the-japanese-balloon-bombs-of-wwii/" class="more-link">Continue reading <span class="screen-reader-text">The War Comes to the Reservation &#8211; the Japanese Balloon Bombs of WWII</span></a> 

<br> 

<https://text-message.blogs.archives.gov/2025/05/06/the-war-comes-to-the-reservation-the-japanese-balloon-bombs-of-wwii/>

---

## Public Media Under Scrutiny

date: 2025-05-06, from: Guy Kawasaki blog

Josh Shepperd, Associate Professor of Media Studies, University of Colorado Boulder. 

<br> 

<https://guykawasaki.substack.com/p/public-media-under-scrutiny>

---

## The newest Surface Laptop and Surface Pro tablet are a little smaller, not much cheaper (starts at $800)

date: 2025-05-06, from: Liliputing

<p>Microsoft is updating its PC lineup with a new Surface Laptop featuring a 13 inch display and a new Surface Pro tablet with a 12 inch screen. And, as expected, not only are the new PCs a bit smaller than the company&#8217;s existing models, they&#8217;re also a little less powerful thanks to their 8-core Qualcomm [&#8230;]</p>
<p>The post <a href="https://liliputing.com/the-newest-surface-laptop-and-surface-pro-tablet-are-a-little-smaller-not-much-cheaper-starts-at-899/">The newest Surface Laptop and Surface Pro tablet are a little smaller, not much cheaper (starts at $800)</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/the-newest-surface-laptop-and-surface-pro-tablet-are-a-little-smaller-not-much-cheaper-starts-at-899/>

---

## Stickerbombed: Google Pixel 8

date: 2025-05-06, from: mrusme blog

A phone is not only a tool but also a canvas. I take great pleasure in
personalizing my tools to function and look the way I want them to. 

<br> 

<https://xn--gckvb8fzb.com/stickerbombed-google-pixel-8/>

---

## Quoting Daniel Stenberg

date: 2025-05-06, updated: 2025-05-06, from: Simon Willison‚Äôs Weblog

<blockquote cite="https://www.linkedin.com/posts/danielstenberg_hackerone-curl-activity-7324820893862363136-glb1"><p>That's it. I've had it. I'm putting my foot down on this craziness.</p>
<p>1. Every reporter submitting security reports on #Hackerone for #curl now needs to answer this question:</p>

<p>"Did you use an AI to find the problem or generate this submission?"</p>
<p>(and if they do select it, they can expect a stream of proof of actual intelligence follow-up questions)</p>
<p>2. We now ban every reporter INSTANTLY who submits reports we deem AI slop. A threshold has been reached. We are effectively being DDoSed. If we could, we would charge them for this waste of our time.</p>

<p>We still have not seen a single valid security report done with AI help.</p></blockquote>
<p class="cite">&mdash; <a href="https://www.linkedin.com/posts/danielstenberg_hackerone-curl-activity-7324820893862363136-glb1">Daniel Stenberg</a></p>

    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-ethics">ai-ethics</a>, <a href="https://simonwillison.net/tags/daniel-stenberg">daniel-stenberg</a>, <a href="https://simonwillison.net/tags/slop">slop</a>, <a href="https://simonwillison.net/tags/security">security</a>, <a href="https://simonwillison.net/tags/curl">curl</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a></p> 

<br> 

<https://simonwillison.net/2025/May/6/daniel-stenberg/#atom-everything>

---

## Technology Review jumps the shark

date: 2025-05-06, from: Gary Marcus blog

The ultimate in nonsensical AI puff pieces, featuring the ubiquitous Bryan Johnson 

<br> 

<https://garymarcus.substack.com/p/technology-review-jumps-the-shark>

---

## Elon Musk's Grok AI Will 'Remove Her Clothes' In Public, On X

date: 2025-05-06, from: 404 Media Group

Elon Musk‚Äôs AI bot is undressing women on X.  

<br> 

<https://www.404media.co/elon-musks-grok-ai-will-remove-her-clothes-in-public-on-x/>

---

## What people get wrong about the leading Chinese open models: Adoption and censorship

date: 2025-05-06, updated: 2025-05-06, from: Simon Willison‚Äôs Weblog

<p><strong><a href="https://www.interconnects.ai/p/what-people-get-wrong-about-the-leading">What people get wrong about the leading Chinese open models: Adoption and censorship</a></strong></p>
While I've been enjoying <a href="https://simonwillison.net/2025/May/2/qwen3-8b/">trying out Alibaba's Qwen 3</a> a lot recently, Nathan Lambert focuses on the elephant in the room:</p>
<blockquote>
<p>People vastly underestimate the number of companies that cannot use Qwen and DeepSeek open models because they come from China. This includes on-premise solutions built by people who know the fact that model weights alone cannot reveal anything to their creators.</p>
</blockquote>
<p>The root problem here is the closed nature of the training data. Even if a model is open weights, it's not possible to conclusively determine that it couldn't add backdoors to generated code or trigger "indirect influence of Chinese values on Western business systems". Qwen 3 certainly has baked in opinions about the status of Taiwan!</p>
<p>Nathan sees this as an opportunity for other liberally licensed models, including his own team's OLMo:</p>
<blockquote>
<p>This gap provides a big opportunity for Western AI labs to lead in open models. Without DeepSeek and Qwen, the top tier of models we‚Äôre left with are Llama and Gemma, which both have very restrictive licenses when compared to their Chinese counterparts. These licenses are proportionally likely to block an IT department from approving a model.</p>
<p>This takes us to the middle tier of permissively licensed, open weight models who actually have a huge opportunity ahead of them: OLMo, of course, I‚Äôm biased, Microsoft with Phi, Mistral, IBM (!??!), and some other smaller companies to fill out the long tail.</p>
</blockquote>

    <p><small></small>Via <a href="https://twitter.com/natolambert/status/1919751157351583858">@natolambert</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/ai-ethics">ai-ethics</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/qwen">qwen</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/open-source">open-source</a></p> 

<br> 

<https://simonwillison.net/2025/May/6/what-people-get-wrong-about-the-leading-chinese-models/#atom-everything>

---

## The Mapparium Doofuses

date: 2025-05-06, updated: 2025-05-06, from: One Foot Tsunami

 

<br> 

<https://onefoottsunami.com/2025/05/06/the-mapparium-doofuses/>

---

**@Dave Winer's linkblog** (date: 2025-05-06, from: Dave Winer's linkblog)

Tesla sales plunge again in April, down stunning 75 pct over year before. 

<br> 

<https://thedriven.io/2025/05/05/tesla-sales-plunge-again-in-april-down-stunning-75-pct-over-year-before/>

---

**@Dave Winer's linkblog** (date: 2025-05-06, from: Dave Winer's linkblog)

Order by Hegseth to cancel Ukraine weapons caught White House off guard. 

<br> 

<https://www.reuters.com/world/us/order-by-hegseth-cancel-ukraine-weapons-caught-white-house-off-guard-2025-05-06/>

---

**@Feed for Alt USDS** (date: 2025-05-06, from: Feed for Alt USDS)

Want to get involved? Here's a way

[contains quote post or other embedded content] 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3loitagohsk2u>

---

**@Dave Winer's linkblog** (date: 2025-05-06, from: Dave Winer's linkblog)

Why is Everybody Hating on Richie Rich? 

<br> 

<https://www.motherjones.com/politics/2025/05/richie-rich-harvey-comics-good-billionaires-wealth-fantasy-elon-musk-donald-trump-comparisons-inequality/>

---

## Radar Trends to Watch: May 2025

date: 2025-05-06, from: O'Reilly Radar

Anthropic‚Äôs Model Context Protocol (MCP) has received a lot of attention for standardizing the way models communicate with tools, making it much easier to build intelligent agents. Google‚Äôs Agent2Agent (A2A) now adds features that were left out of the original MCP specification: security, agent cards for describing agent capabilities, and more. Is A2A competitive or [&#8230;] 

<br> 

<https://www.oreilly.com/radar/radar-trends-to-watch-may-2025/>

---

**@Dave Winer's linkblog** (date: 2025-05-06, from: Dave Winer's linkblog)

New York Knicks stun Boston Celtics with overtime win. 

<br> 

<https://www.bbc.com/sport/basketball/articles/cd9l144zn9lo>

---

## What's the carbon footprint of using ChatGPT?

date: 2025-05-06, from: Hannah Richie at Substack

Very small compared to most of the other stuff you do. 

<br> 

<https://www.sustainabilitybynumbers.com/p/carbon-footprint-chatgpt>

---

**@Feed for Alt USDS** (date: 2025-05-06, from: Feed for Alt USDS)

We updated our timeline for the month of April. Learn about DOGE's insider threats, what government employees are and are not allowed to do politically, and much more!

 https://bit.ly/4iQ7rVZ 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3lohxcoj7zq25>

---

**@Feed for Alt USDS** (date: 2025-05-06, from: Feed for Alt USDS)

What happens when AI replaces experience? DOGE-backed projects want to "free up" 70k government workers, but real efficiency comes from human-centered design.

Read our latest üëâ https://bit.ly/Illusion-of-Efficiency 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3lohv75uoxf25>

---

**@Dave Winer's linkblog** (date: 2025-05-05, from: Dave Winer's linkblog)

Il presidente di El Salvador fa shopping a Firenze. 

<br> 

<https://www.lanazione.it/firenze/cronaca/presidente-salvador-giacca-m7zgvjvq>

---

**@Dave Winer's linkblog** (date: 2025-05-05, from: Dave Winer's linkblog)

Tesla Cybertruck Review After 15,000 Miles. 

<br> 

<https://cleantechnica.com/2025/05/05/tesla-cybertruck-review-after-15000-miles/>

---

## Game Bub is an open source, FPGA-based handheld with support for Game Boy, GBC, and GBA games (crowdfunding)

date: 2025-05-05, from: Liliputing

<p>The¬†Game Bub is an upcoming handheld game console designed to play Game Boy, Game Boy Color, and Game Boy Advance games. Like most modern handhelds it can handle ROM files. But you can also use cartridges, making this a modern device that functions a lot like the original hardware. In fact, it even supports link [&#8230;]</p>
<p>The post <a href="https://liliputing.com/game-bub-is-an-open-source-fpga-based-handheld-with-support-for-game-boy-gbc-and-gba-games-crowdfunding/">Game Bub is an open source, FPGA-based handheld with support for Game Boy, GBC, and GBA games (crowdfunding)</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/game-bub-is-an-open-source-fpga-based-handheld-with-support-for-game-boy-gbc-and-gba-games-crowdfunding/>

---

## A quick note on sponsorships...

date: 2025-05-05, from: Fix the News

Have you ever considered placing an advertisement in our newsletter? 

<br> 

<https://fixthenews.com/note-on-sponsorships/>

---

**@Tomosino's Mastodon feed** (date: 2025-05-05, from: Tomosino's Mastodon feed)

<p>Imagine a really good hot dog</p> 

<br> 

<https://tilde.zone/@tomasino/114457153414996752>

---

## Man Who Hacked Disney With Malicious AI Tool Pleads Guilty

date: 2025-05-05, from: 404 Media Group

 A hacker who tricked people into downloading malware using AI image generation tools plead guilty to two felony counts.
 

<br> 

<https://www.404media.co/man-who-hacked-disney-with-malicious-ai-tool-pleads-guilty/>

---

## MailMaven Public Beta

date: 2025-05-05, from: Michael Tsai

Scott Morrison: For a number of years we have been working on MailMaven: A new macOS email client that picks up where we left off after Apple killed Mail Plugins. Today we are opening access to a wider audience than our small group of private beta testers. Apple made it impossible for MailTags (and SmallCubed&#8217;s [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/05/05/mailmaven-public-beta/>

---

## Hyperspace 1.3

date: 2025-05-05, from: Michael Tsai

John Siracusa: The first release of Hyperspace mitigated these risks, in part, by entirely avoiding certain files and file system locations. I knew lifting these limitations would be a common request from potential customers. My plan was to launch 1.0 with the safest possible feature set, then slowly expand the app&#8217;s capabilities until all these [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/05/05/hyperspace-1-3/>

---

## Folder Preview 1.6

date: 2025-05-05, from: Michael Tsai

Anybox: Quick look extension for folders. [&#8230;] USD$1.99 to get the app and all of it. [&#8230;] Preview ZIP files as folders. It does what it says on the tin. This is a new-style Quick Look extension, so it uses a real outline view and a real path bar, rather than trying to make HTML [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/05/05/folder-preview-1-6/>

---

## Xcode + Claude

date: 2025-05-05, from: Michael Tsai

Juli Clover: Apple is working with Anthropic on an updated version of Xcode that will support AI code writing, editing, and testing, reports Bloomberg. Anthropic is best known for its &#8220;Claude&#8221; large language model and chatbot that competes with OpenAI&#8217;s ChatGPT. Claude is well-known for its coding capabilities, beating out other LLMs on programming tasks.The [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/05/05/xcode-claude/>

---

## Request for more articles on prompting techniques

date: 2025-05-05, updated: 2025-05-05, from: Simon Willison‚Äôs Weblog

<p>I'm disappointed at how little good writing there is out there about effective prompting.</p>
<p>Here's an example: what's the best prompt to use to summarize an article?</p>
<p>That feels like such an obvious thing, and yet I haven't even seen <em>that</em> being well explored!</p>
<p>It's actually a surprisingly deep topic. I like using tricks like "directly quote the sentences that best illustrate the overall themes" and "identify the most surprising ideas", but I'd love to see a thorough breakdown of all the tricks I haven't seen yet.</p>

    <p>Tags: <a href="https://simonwillison.net/tags/prompt-engineering">prompt-engineering</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a></p> 

<br> 

<https://simonwillison.net/2025/May/5/prompting/#atom-everything>

---

## Quoting Max Woolf

date: 2025-05-05, updated: 2025-05-05, from: Simon Willison‚Äôs Weblog

<blockquote cite="https://minimaxir.com/2025/05/llm-use/"><p>Two things can be true simultaneously: (a) LLM provider cost economics are too negative to return positive ROI to investors, and (b) LLMs are useful for solving problems that are meaningful and high impact, albeit not to the AGI hype that would justify point (a). This particular combination creates a frustrating gray area that requires a nuance that an ideologically split social media can no longer support gracefully. [...]</p>
<p>OpenAI collapsing would not cause the end of LLMs, because LLMs are useful <em>today</em> and there will always be a nonzero market demand for them: it‚Äôs a bell that can‚Äôt be unrung.</p></blockquote>
<p class="cite">&mdash; <a href="https://minimaxir.com/2025/05/llm-use/">Max Woolf</a></p>

    <p>Tags: <a href="https://simonwillison.net/tags/max-woolf">max-woolf</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/openai">openai</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a></p> 

<br> 

<https://simonwillison.net/2025/May/5/max-woolf/#atom-everything>

---

## COSMIC Alpha 7: Never Been Beta

date: 2025-05-05, from: System76 Blog

Wrapping up COSMIC‚Äôs main features before the first beta release. 

<br> 

<https://blog.system76.com/post/cosmic-alpha-7-never-been-beta>

---

## GlobalX, Airline for Trump‚Äôs Deportations, Hacked

date: 2025-05-05, from: 404 Media Group

Hackers say they have obtained what they say are passenger lists for GlobalX flights from January to this month. The data appears to include people who have been deported. 

<br> 

<https://www.404media.co/globalx-airline-for-trumps-deportations-hacked/>

---

## Feed a video to a vision LLM as a sequence of JPEG frames on the CLI (also LLM 0.25)

date: 2025-05-05, updated: 2025-05-05, from: Simon Willison‚Äôs Weblog

<p>The new <strong><a href="https://github.com/simonw/llm-video-frames">llm-video-frames</a></strong> plugin can turn a video file into a sequence of JPEG frames and feed them directly into a long context vision LLM such as GPT-4.1, even when that LLM doesn't directly support video input. It depends on a plugin feature I added to <a href="https://llm.datasette.io/en/stable/changelog.html#v0-25">LLM 0.25</a>, which I released last night.</p>
<p>Here's how to try it out:</p>
<div class="highlight highlight-source-shell"><pre>brew install ffmpeg <span class="pl-c"><span class="pl-c">#</span> or apt-get or your package manager of choice</span>
uv tool install llm <span class="pl-c"><span class="pl-c">#</span> or pipx install llm or pip install llm</span>
llm install llm-video-frames
llm keys <span class="pl-c1">set</span> openai
<span class="pl-c"><span class="pl-c">#</span> Paste your OpenAI API key here</span>

llm -f video-frames:video.mp4 \
  <span class="pl-s"><span class="pl-pds">'</span>describe the key scenes in this video<span class="pl-pds">'</span></span> \
  -m gpt-4.1-mini</pre></div>
<p>The <code>video-frames:filepath.mp4</code> syntax is provided by the new plugin. It takes that video, converts it to a JPEG for every second of the video and then turns those into <a href="https://llm.datasette.io/en/stable/usage.html#attachments">attachments</a> that can be passed to the LLM.</p>
<p>Here's a demo, against <a href="https://static.simonwillison.net/static/2025/cleo.mp4">this video</a> of Cleo:</p>

<div style="max-width: 100%; margin-bottom: 0.4em">
    <video controls="controls" preload="none" aria-label="Cleo " poster="https://static.simonwillison.net/static/2025/cleo-still.jpg" loop="loop" style="width: 100%; height: auto;" muted="muted">
        <source src="https://static.simonwillison.net/static/2025/cleo.mp4" type="video/mp4" />
    </video>
</div>

<div class="highlight highlight-source-shell"><pre>llm -f video-frames:cleo.mp4 <span class="pl-s"><span class="pl-pds">'</span>describe key moments<span class="pl-pds">'</span></span> -m gpt-4.1-mini</pre></div>
<p>And the output from the model (<a href="https://gist.github.com/simonw/a4e26166a524f9c07b4cf32b2f8da6c9">transcript here</a>):</p>
<blockquote>
<p>The sequence of images captures the key moments of a dog being offered and then enjoying a small treat:</p>
<ol>
<li>In the first image, a hand is holding a small cupcake with purple frosting close to a black dog's face. The dog looks eager and is focused intently on the treat.</li>
<li>The second image shows the dog beginning to take a bite of the cupcake from the person's fingers. The dog's mouth is open, gently nibbling on the treat.</li>
<li>In the third image, the dog has finished or is almost done with the treat and looks content, with a slight smile and a relaxed posture. The treat is no longer in the person's hand, indicating that the dog has consumed it.</li>
</ol>
<p>This progression highlights the dog's anticipation, enjoyment, and satisfaction with the treat.</p>
</blockquote>
<p>Total cost: 7,072 input tokens, 156 output tokens - for GPT-4.1 mini that's 0.3078 cents (less than a third of a cent).</p>
<p>In this case the plugin converted the video into three images: <a href="https://static.simonwillison.net/static/2025/frame_00001.jpg">frame_00001.jpg</a>, <a href="https://static.simonwillison.net/static/2025/frame_00002.jpg">frame_00002.jpg</a> and <a href="https://static.simonwillison.net/static/2025/frame_00003.jpg">frame_00003.jpg</a>.</p>
<p>The plugin accepts additional arguments. You can increase the frames-per-second using <code>?fps=2</code> - for example:</p>
<div class="highlight highlight-source-shell"><pre>llm -f <span class="pl-s"><span class="pl-pds">'</span>video-frames:video.mp4?fps=2<span class="pl-pds">'</span></span> <span class="pl-s"><span class="pl-pds">'</span>summarize this video<span class="pl-pds">'</span></span></pre></div>
<p>Or you can add <code>?timestamps=1</code> to cause <code>ffmpeg</code> to overlay a timestamp in the bottom right corner of each frame. This gives the model a chance to return timestamps in its output.</p>
<p>Let's try that with the Cleo video:</p>
<div class="highlight highlight-source-shell"><pre>llm -f <span class="pl-s"><span class="pl-pds">'</span>video-frames:cleo.mp4?timestamps=1&amp;fps=5<span class="pl-pds">'</span></span> \
  <span class="pl-s"><span class="pl-pds">'</span>key moments, include timestamps<span class="pl-pds">'</span></span> -m gpt-4.1-mini</pre></div>
<p>Here's the output (<a href="https://gist.github.com/simonw/371719849a7d2260f1eb0f422ea63187">transcript here</a>):</p>
<blockquote>
<p>Here are the key moments from the video "cleo.mp4" with timestamps:</p>
<ul>
<li>00:00:00.000 - A dog on leash looks at a small cupcake with purple frosting being held by a person.</li>
<li>00:00:00.800 - The dog closely sniffs the cupcake.</li>
<li>00:00:01.400 - The person puts a small amount of the cupcake frosting on their finger.</li>
<li>00:00:01.600 - The dog starts licking the frosting from the person's finger.</li>
<li>00:00:02.600 - The dog continues licking enthusiastically.</li>
</ul>
<p>Let me know if you need more details or a description of any specific part.</p>
</blockquote>
<p>That one sent 14 images to the API, at a total cost of 32,968 input, 141 output = 1.3413 cents.</p>
<p>It sent 5.9MB of image data to OpenAI's API, encoded as base64 in the JSON API call.</p>
<p>The GPT-4.1 model family accepts up to 1,047,576 tokens. Aside from a 20MB size limit per image I haven't seen any documentation of limits on the number of images. You can fit a whole lot of JPEG frames in a million tokens!</p>
<p>Here's what one of those frames looks like with the timestamp overlaid in the corner:</p>
<p><img src="https://static.simonwillison.net/static/2025/cleo-finger.jpg" alt="Cleo taking a treat from my fingers, in the bottom right corner is an overlay t hat says cleo.mp4 00:00:01.600" style="max-width: 100%;" /></p>
<h4 id="how-i-built-the-plugin-with-o4-mini">How I built the plugin with o4-mini</h4>
<p>This is a great example of how rapid prototyping with an LLM can help demonstrate the value of a feature.</p>
<p>I was considering whether it would make sense for fragment plugins to return images in <a href="https://github.com/simonw/llm/issues/972#issuecomment-2849342103">issue 972</a> when I had the idea to use <code>ffmpeg</code> to split a video into frames.</p>
<p>I know <a href="https://simonwillison.net/2025/Apr/23/llm-fragment-symbex/">from past experience</a> that a good model can write an entire plugin for LLM if you feed it the right example, so I started with this (reformatted here for readability):</p>
<div class="highlight highlight-source-shell"><pre>llm -m o4-mini -f github:simonw/llm-hacker-news -s <span class="pl-s"><span class="pl-pds">'</span>write a new plugin called llm_video_frames.py which takes video:path-to-video.mp4 and creates a temporary directory which it then populates with one frame per second of that video using ffmpeg - then it returns a list of [llm.Attachment(path="path-to-frame1.jpg"), ...] - it should also support passing video:video.mp4?fps=2 to increase to two frames per second, and if you pass ?timestamps=1 or &amp;timestamps=1 then it should add a text timestamp to the bottom right conner of each image with the mm:ss timestamp of that frame (or hh:mm:ss if more than one hour in) and the filename of the video without the path as well.<span class="pl-pds">'</span></span> -o reasoning_effort high</pre></div>
<p>Here's <a href="https://gist.github.com/simonw/4f545ecb347884d1d923dbc49550b8b0#response">the transcript</a>.</p>
<p>The new attachment mechanism went from vague idea to "I should build that" as a direct result of having an LLM-built proof-of-concept that demonstrated the feasibility of the new feature.</p>
<p>The code it produced was about 90% of the code I shipped in the finished plugin. Total cost 5,018 input, 2,208 output = 1.5235 cents.</p>
<h4 id="annotated-release-notes-for-everything-else-in-llm-0-25">Annotated release notes for everything else in LLM 0.25</h4>
<p>Here are the annotated release notes for everything else:</p>
<blockquote>
<ul>
<li>New plugin feature: <a href="https://llm.datasette.io/en/stable/plugins/plugin-hooks.html#plugin-hooks-register-fragment-loaders">register_fragment_loaders(register)</a> plugins can now return a mixture of fragments and attachments. The <a href="https://github.com/simonw/llm-video-frames">llm-video-frames</a> plugin is the first to take advantage of this mechanism. <a href="https://github.com/simonw/llm/issues/972">#972</a>
</li>
</ul>
</blockquote>
<p>As decsribed above. The inspiration for this feature came from the <a href="https://github.com/agustif/llm-arxiv">llm-arxiv</a> plugin by <a href="https://github.com/agustif">agustif</a>.</p>
<blockquote>
<ul>
<li>New OpenAI models: <code>gpt-4.1</code>, <code>gpt-4.1-mini</code>, <code>gpt-41-nano</code>, <code>o3</code>, <code>o4-mini</code>. <a href="https://github.com/simonw/llm/issues/945">#945</a>, <a href="https://github.com/simonw/llm/issues/965">#965</a>, <a href="https://github.com/simonw/llm/issues/976">#976</a>.</li>
</ul>
</blockquote>
<p>My original plan was to leave these models exclusively to the new <a href="https://github.com/simonw/llm-openai-plugin">llm-openai</a> plugin, since that allows me to add support for new models without a full LLM release. I'm going to punt on that until I'm ready to entirely remove the OpenAI models from LLM core.</p>
<blockquote>
<ul>
<li>New environment variables: <code>LLM_MODEL</code> and <code>LLM_EMBEDDING_MODEL</code> for setting the model to use without needing to specify <code>-m model_id</code> every time. <a href="https://github.com/simonw/llm/issues/932">#932</a>
</li>
</ul>
</blockquote>
<p>A convenience feature for if you want to set the default model for a terminal session with LLM without using the global <a href="https://llm.datasette.io/en/stable/setup.html#setting-a-custom-default-model">default model" mechanism</a>.</p>
<blockquote>
<ul>
<li>New command: <code>llm fragments loaders</code>, to list all currently available fragment loader prefixes provided by plugins. <a href="https://github.com/simonw/llm/issues/941">#941</a>
</li>
</ul>
</blockquote>
<p>Mainly for consistence with the existing <a href="https://llm.datasette.io/en/stable/help.html#llm-templates-loaders-help">llm templates loaders</a> command. Here's the output when I run <code>llm fragments loaders</code> on my machine:</p>
<pre><code>docs:
  Fetch the latest documentation for the specified package from
  https://github.com/simonw/docs-for-llms

  Use '-f docs:' for the documentation of your current version of LLM.

docs-preview:
  Similar to docs: but fetches the latest docs including alpha/beta releases.

symbex:
  Walk the given directory, parse every .py file, and for every
  top-level function or class-method produce its signature and
  docstring plus an import line.

github:
  Load files from a GitHub repository as fragments

  Argument is a GitHub repository URL or username/repository

issue:
  Fetch GitHub issue/pull and comments as Markdown

  Argument is either "owner/repo/NUMBER" or URL to an issue

pr:
  Fetch GitHub pull request with comments and diff as Markdown

  Argument is either "owner/repo/NUMBER" or URL to a pull request

hn:
  Given a Hacker News article ID returns the full nested conversation.

  For example: -f hn:43875136

video-frames:
  Fragment loader "video-frames:&lt;path&gt;?fps=N&amp;timestamps=1"
  - extracts frames at `fps` per second (default 1)
  - if `timestamps=1`, overlays "filename hh:mm:ss" at bottom-right
</code></pre>
<p>That's from <a href="https://github.com/simonw/llm-docs">llm-docs</a>, <a href="https://github.com/simonw/llm-fragments-github">llm-fragments-symbex</a>, <a href="https://github.com/simonw/llm-fragments-github">llm-fragments-github</a>, <a href="https://github.com/simonw/llm-hacker-news">llm-hacker-news</a> and <a href="https://github.com/simonw/llm-video-frames">llm-video-frames</a>.</p>
<blockquote>
<ul>
<li>
<code>llm fragments</code> command now shows fragments ordered by the date they were first used. <a href="https://github.com/simonw/llm/issues/973">#973</a>
</li>
</ul>
</blockquote>
<p>This makes it easier to quickly debug a new fragment plugin - you can run <code>llm fragments</code> and glance at the bottom few entries.</p>
<p>I've also been using the new <a href="https://github.com/simonw/llm-echo">llm-echo</a> debugging plugin for this - it adds a new fake model called "echo" which simply outputs whatever the prompt, system prompt, fragments and attachments are that were passed to the model:</p>
<div class="highlight highlight-source-shell"><pre>llm -f docs:sqlite-utils -m <span class="pl-c1">echo</span> <span class="pl-s"><span class="pl-pds">'</span>Show me the context<span class="pl-pds">'</span></span></pre></div>
<p><a href="https://gist.github.com/simonw/cb3249856887379759515022c76d0d9e">Output here</a>.</p>
<blockquote>
<ul>
<li>
<code>llm chat</code> now includes a <code>!edit</code> command for editing a prompt using your default terminal text editor. Thanks, <a href="https://github.com/Hopiu">Benedikt Willi</a>. <a href="https://github.com/simonw/llm/pull/969">#969</a>
</li>
</ul>
</blockquote>
<p>This is a really nice enhancement to <code>llm chat</code>, making it much more convenient to edit longe prompts.</p>
<p>And the rest:</p>
<blockquote>
<ul>
<li>Allow <code>-t</code> and <code>--system</code> to be used at the same time. <a href="https://github.com/simonw/llm/issues/916">#916</a>
</li>
<li>Fixed a bug where accessing a model via its alias would fail to respect any default options set for that model. <a href="https://github.com/simonw/llm/issues/968">#968</a>
</li>
<li>Improved documentation for <a href="https://llm.datasette.io/en/stable/other-models.html#openai-compatible-models">extra-openai-models.yaml</a>. Thanks, <a href="https://github.com/rahimnathwani">Rahim Nathwani</a> and <a href="https://github.com/dguido">Dan Guido</a>. <a href="https://github.com/simonw/llm/pull/950">#950</a>, <a href="https://github.com/simonw/llm/pull/957">#957</a>
</li>
<li>
<code>llm -c/--continue</code> now works correctly with the <code>-d/--database</code> option. <code>llm chat</code> now accepts that <code>-d/--database</code> option. Thanks, <a href="https://github.com/sukhbinder">Sukhbinder Singh</a>. <a href="https://github.com/simonw/llm/issues/933">#933</a>
</li>
</ul>
</blockquote>
    
        <p>Tags: <a href="https://simonwillison.net/tags/vision-llms">vision-llms</a>, <a href="https://simonwillison.net/tags/llm">llm</a>, <a href="https://simonwillison.net/tags/plugins">plugins</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/projects">projects</a>, <a href="https://simonwillison.net/tags/ffmpeg">ffmpeg</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a></p> 

<br> 

<https://simonwillison.net/2025/May/5/llm-video-frames/#atom-everything>

---

## Why DO large language models hallucinate?

date: 2025-05-05, from: Gary Marcus blog

The Henrietta Chronicles continue, guest starring Harry Shearer 

<br> 

<https://garymarcus.substack.com/p/why-do-large-language-models-hallucinate>

---

## OneChipBook-12-A is a $215 mini laptop with an FPGA for retro computing

date: 2025-05-05, from: Liliputing

<p>The¬†OneChipBook-12-A is a modern mini laptop design for retro computing. It&#8217;s the latest in a line of systems from 8086YES! that are designed to let you run classic code from decades past on hardware that&#8217;s more portable than anything that would have been available at the time. In fact, the newest laptop looks nearly identical [&#8230;]</p>
<p>The post <a href="https://liliputing.com/onechipbook-12-a-is-a-215-mini-laptop-with-an-fpga-for-retro-computing/">OneChipBook-12-A is a $215 mini laptop with an FPGA for retro computing</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/onechipbook-12-a-is-a-215-mini-laptop-with-an-fpga-for-retro-computing/>

---

## christopher.org for the next 100 years

date: 2025-05-05, from: Chris Coyier blog

I&#8217;m trying to do right by my old buddy Christopher Schmitt and his digital footprint. You might remember we made a thank-you site for him where people shared memories. That&#8217;s hosted on a provided Netlify account, and the code is on a public GitHub repo. Notably the site doesn&#8217;t use a custom domain name, which [&#8230;] 

<br> 

<https://chriscoyier.net/2025/05/05/christopher-org-for-the-next-100-years/>

---

**@Feed for Alt USDS** (date: 2025-05-05, from: Feed for Alt USDS)

We the Builders' Kate and Milo joined Andy and Helen from @cybershow.uk to talk about what's happening to us here, share ideas across the Atlantic, and talk about what it means to stop the destruction and begin to rebuild.

https://cybershow.uk/episodes.php?id=46 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3logt5xvhoc2d>

---

## Mom: The Ultimate Hero

date: 2025-05-05, from: Guy Kawasaki blog

Scott T. Allison, Professor of Psychology, University of Richmond. 

<br> 

<https://guykawasaki.substack.com/p/mom-the-ultimate-hero>

---

## Quoting Arvind Narayanan

date: 2025-05-05, updated: 2025-05-05, from: Simon Willison‚Äôs Weblog

<blockquote cite="https://twitter.com/random_walker/status/1919359709062033850"><p>[On using generative AI for work despite the risk of errors:]</p>
<ul>
<li>AI is helpful despite being error-prone if it is faster to verify the output than it is to do the work yourself. For example, if you're using it to find a product that matches a given set of specifications, verification may be a lot faster than search.</li>
<li>There are many uses where errors don't matter, like using it to enhance creativity by suggesting or critiquing ideas.</li>
<li>At a meta level, if you use AI without a plan and simply turn to AI tools when you feel like it, then you're unlikely to be able to think through risks and mitigations. It is better to identify concrete ways to integrate AI into your workflows, with known benefits and risks, that you can employ repeatedly.</li>
</ul></blockquote>
<p class="cite">&mdash; <a href="https://twitter.com/random_walker/status/1919359709062033850">Arvind Narayanan</a></p>

    <p>Tags: <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/arvind-narayanan">arvind-narayanan</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a></p> 

<br> 

<https://simonwillison.net/2025/May/5/arvind-narayanan/#atom-everything>

---

## Enterre Seus Mortos (43FCIU): la remasterizaci√≥n del pasajero oscuro

date: 2025-05-05, from: Iv√°n Paredes Res√©ndiz blog, Mexico's cinema

<p>Direcci√≥n: Marco Dutra. Guion: Macro Dutra, basado en la novela hom√≥nima de Ana Paula Maia. Elenco: Selton Mello, Marjorie Estiano, Danilo Grangheia, Betty Faria, Maria Manoella. Pa√≠s: Brasil. M√°s informaci√≥n de la pel√≠cula: https://www.imdb.com//title/tt15738252/ ¬øQu√© hay despu√©s de la muerte? Es una pregunta que, aunque de apariencia ret√≥rica, abre un mar de dudas entre los [&#8230;]</p>
<p>La entrada <a href="https://www.palomitademaiz.net/resenas-enterre-seus-mortos-43fciu/">Enterre Seus Mortos (43FCIU): la remasterizaci√≥n del pasajero oscuro</a> se public√≥ primero en <a href="https://www.palomitademaiz.net">Palomita de ma√≠z</a>.</p>
 

<br> 

<https://www.palomitademaiz.net/resenas-enterre-seus-mortos-43fciu/?utm_source=rss&utm_medium=rss&utm_campaign=resenas-enterre-seus-mortos-43fciu>

---

## HARVARD: BARBARIANS AT THE GATES, IGNORAMUSES ON THE LAWN

date: 2025-05-05, from: Howard Jacobson blog

Streetwalking with Howard Jacobson is a reader-supported publication. 

<br> 

<https://jacobsonh.substack.com/p/harvard-barbarians-at-the-gates-ignoramuses>

---

## Trust AI Less

date: 2025-05-05, updated: 2025-05-05, from: One Foot Tsunami

 

<br> 

<https://onefoottsunami.com/2025/05/05/trust-ai-less/>

---

## 100,000 People Are Using a Telegram Bot That Makes AI Cumshot Videos of Anyone

date: 2025-05-05, from: 404 Media Group

An open AI video generation model that was released last month is now being used by thousands of people to generate nonconsensual sexual videos of real people.  

<br> 

<https://www.404media.co/telegram-ai-cumshot-bot/>

---

## Are you being a fuel fool?

date: 2025-05-05, from: Status-Q blog

I&#8217;ve been driving an electric car for about a decade now, but because we also have a fossil-burning campervan, I do still occasionally need to visit one of those dirty, smelly, legacy refuelling stations, so&#8230; If you use a site like PetrolPrices.com, you can find out roughly how much fuel costs at the various petrol <a class="more-link excerpt-link" href="https://statusq.org/archives/2025/05/05/13133/">Continue Reading<span class="glyphicon glyphicon-chevron-right"></span></a> 

<br> 

<https://statusq.org/archives/2025/05/05/13133/>

---

**@Dave Winer's linkblog** (date: 2025-05-05, from: Dave Winer's linkblog)

Kristaps Porzingis sheds light on how he feels about Knicks‚Äô return. 

<br> 

<https://www.celticsblog.com/2025/5/5/24423130/kristaps-porzingis-celtics-knicks-nba-playoffs>

---

## A Note From the Netherlands

date: 2025-05-05, from: Paul Krugman

The Dutch have nice things. Why can&#8217;t we? 

<br> 

<https://paulkrugman.substack.com/p/a-note-from-the-netherlands>

---

## <default:div xmlns="http://www.w3.org/1999/xhtml" class="if-your-feed-reader-displays-this-then-it-is-violating-the-Atom-spec-RFC-4287-section-4.2.14"/>

date: 2025-05-05, updated: 2025-05-05, from: Tantek √áelik's blog

 

<br> 

<https://tantek.com/2025/124/t1/may-the-fourth-be-with-you>

---

## Mr. Deepfakes, the Biggest Deepfake Porn Site on the Internet, Says It‚Äôs Shutting Down for Good

date: 2025-05-05, from: 404 Media Group

The biggest site for nonconsensual deepfake porn on the internet says it‚Äôs shutting down and not coming back.
 

<br> 

<https://www.404media.co/mr-deepfakes-the-biggest-deepfake-porn-site-on-the-internet-says-its-shutting-down-for-good/>

---

**@Dave Winer's linkblog** (date: 2025-05-05, from: Dave Winer's linkblog)

Trump says he will reopen Alcatraz prison. 

<br> 

<https://apnews.com/article/trump-alcatraz-prison-fabe3385415ae03829d44e50efb3c1fb>

---

**@Dave Winer's linkblog** (date: 2025-05-04, from: Dave Winer's linkblog)

Think Twice Before Creating That ChatGPT Action Figure. 

<br> 

<https://www.wired.com/story/chatgpt-image-generator-action-figure-privacy/>

---

## 562. Peter the Great: The Rise of Russia (Part 1)

date: 2025-05-04, from: This is history podcast

<p>Why was the early life of Peter the Great &#8211; Tsar and autocrat of all the Russias, who endures to this day as an iconic symbol of Russian might &#8211; drenched in blood and violence? What amalgamation of court politics and family feuding saw him catapulted to the role of Tsar against all the odds? [&#8230;]</p>
<p>The post <a href="https://therestishistory.com/562-peter-the-great-the-rise-of-russia-part-1/">562. Peter the Great: The Rise of Russia (Part 1)</a> appeared first on <a href="https://therestishistory.com">The Rest is History</a>.</p>
 

<br> 

<https://therestishistory.com/562-peter-the-great-the-rise-of-russia-part-1/>

---

## Four Dead in Ohio

date: 2025-05-04, from: Michael Moore's blog

55 years ago... 

<br> 

<https://www.michaelmoore.com/p/four-dead-in-ohio>

---

## The Signal Clone the Trump Admin Uses Was Hacked

date: 2025-05-04, from: 404 Media Group

TeleMessage, a company that makes a modified version of Signal that archives messages for government agencies, was hacked. 

<br> 

<https://www.404media.co/the-signal-clone-the-trump-admin-uses-was-hacked/>

---

## Dummy's Guide to Modern LLM Sampling

date: 2025-05-04, updated: 2025-05-04, from: Simon Willison‚Äôs Weblog

<p><strong><a href="https://rentry.co/samplers">Dummy&#x27;s Guide to Modern LLM Sampling</a></strong></p>
This is an extremely useful, detailed set of explanations by <a href="https://x.com/AlpinDale">@AlpinDale</a> covering the various different sampling strategies used by modern LLMs. LLMs return a set of next-token probabilities for every token in their corpus - a layer above the LLM can then use sampling strategies to decide which one to use.</p>
<p>I finally feel like I understand the difference between <a href="https://rentry.co/samplers#top-k">Top-K</a> and <a href="https://rentry.co/samplers#top-p">Top-P</a>! Top-K is when you narrow down to e.g. the 20 most likely candidates for next token and then pick one of those. Top-P instead "the smallest set of words whose combined probability exceeds threshold P" - so if you set it to 0.5 you'll filter out tokens in the lower half of the probability distribution.</p>
<p>There are a bunch more sampling strategies in here that I'd never heard of before - Top-A, Top-N-Sigma, Epsilon-Cutoff and more.</p>
<p>Reading the descriptions here of <a href="https://rentry.co/samplers#repetition-penalty">Repetition Penalty</a> and <a href="https://rentry.co/samplers#dry-dont-repeat-yourself">Don't Repeat Yourself</a> made me realize that I need to be a little careful with those for some of my own uses of LLMs.</p>
<p>I frequently feed larger volumes of text (or code) into an LLM and ask it to output subsets of that text as direct quotes, to answer questions like "which bit of this code handles authentication tokens" or "show me direct quotes that illustrate the main themes in this conversation".</p>
<p>Careless use of frequency penalty strategies might go against what I'm trying to achieve with those prompts.

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=43887637">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/prompt-engineering">prompt-engineering</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/tokenization">tokenization</a></p> 

<br> 

<https://simonwillison.net/2025/May/4/llm-sampling/#atom-everything>

---

## Lilbits: Cheaper Microsoft Surface Laptop and Surface Pro coming soon

date: 2025-05-04, from: Liliputing

<p>The latest Microsoft Surface Laptop and Surface Pro tablet are both powered by Qualcomm Snapdragon X series processors and both sell for about $800 and up. But it looks like Microsoft could have some cheaper models on the way. The Microsoft Surface Team has scheduled an event for May 6th when the company is promising [&#8230;]</p>
<p>The post <a href="https://liliputing.com/lilbits-cheaper-microsoft-surface-laptop-and-surface-pro-coming-soon/">Lilbits: Cheaper Microsoft Surface Laptop and Surface Pro coming soon</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/lilbits-cheaper-microsoft-surface-laptop-and-surface-pro-coming-soon/>

---

## Breakwater Barbecue in the El Granada station for the Ocean Shore Railroad

date: 2025-05-04, updated: 2025-05-04, from: Simon Willison‚Äôs Weblog

<p>Our local BBQ spot here in El Granada - <a href="https://www.breakwaterbbq.com/">Breakwater Barbecue</a> - had a soft opening this weekend in their <a href="https://maps.app.goo.gl/f9JSpUWaFH8Hevj3A">new location</a>.</p>
<p>Here's the new building. They're still working on replacing the sign from the previous restaurant occupant:</p>
<p><img alt="Exterior photo of a restaurant with a faded sign reading &quot;MONSTER CHEF Fine Japanese Restaurant&quot; the building is cream-colored with red tile roofs and large windows. It has a little bit of a railway station vibe to it if you squint at it just the right way." src="https://static.simonwillison.net/static/2025/breakwater-today.jpg" /></p>
<p>It's actually our old railway station! From 1905 to 1920 the <a href="https://en.wikipedia.org/wiki/Ocean_Shore_Railroad">Ocean Shore Railroad</a> ran steam trains from San Francisco down through Half Moon Bay most of the way to Santa Cruz, though they never quite connected the two cities.</p>
<p>The restaurant has some photos on the wall of the old railroad. Here's what that same building looked like &gt;100 years ago.</p>
<p><img alt="Historical black and white photograph showing a train station with a steam train on the left and a Spanish-style station building with arched entrances on the right. It's clearly the same building, though the modern one has had a bunch of extra extensions added to it and doesn't look nearly as much like a train station." src="https://static.simonwillison.net/static/2025/breakwater-train.jpg" /></p>

    <p>Tags: <a href="https://simonwillison.net/tags/half-moon-bay">half-moon-bay</a>, <a href="https://simonwillison.net/tags/photos">photos</a>, <a href="https://simonwillison.net/tags/history">history</a></p> 

<br> 

<https://simonwillison.net/2025/May/4/breakwater/#atom-everything>

---

## Creativity and Courage to Save Democracy

date: 2025-05-04, from: Our Future.org

Those in power have made clear there is no democratic norm they are unwilling to break. We live in a time of chaos, and this is not by accident. Over the last 100 days, the Trump administration has sought to divide and confuse us in every way, so no one knows what‚Äôs coming next. They [&#8230;]
<p><a href="https://ourfuture.org/20250504/creativity-and-courage-to-save-democracy" rel="nofollow">Source</a></p> 

<br> 

<https://ourfuture.org/20250504/creativity-and-courage-to-save-democracy>

---

## Valentia y creatividad para salvar la democracia

date: 2025-05-04, from: Our Future.org

Los poderosos dejan en claro que no existe ninguna norma democr√°tica que no est√©n dispuestos a romper. Vivimos en tiempos de caos, y esto no es por accidente. Durante los √∫ltimos 100 d√≠as, la administraci√≥n Trump ha buscado dividirnos y confundirnos por todos lados, para que nadie sepa qu√© hacer con lo que venga. Est√°n [&#8230;]
<p><a href="https://ourfuture.org/20250504/valentia-y-creatividad" rel="nofollow">Source</a></p> 

<br> 

<https://ourfuture.org/20250504/valentia-y-creatividad>

---

**@Feed for Alt USDS** (date: 2025-05-04, from: Feed for Alt USDS)

#Resistance

[contains quote post or other embedded content] 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3loe3begrok2d>

---

**@Feed for Alt USDS** (date: 2025-05-04, from: Feed for Alt USDS)

We the Builders will be telling our story at For the Public in St Paul on May 14th! We're excited to share how we got started, why community matters so much, and looking forward to rebuilding government (and its technology) very soon.

 https://www.publicgood.tech/for-the-public 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3lodu7nw6mp2j>

---

## Understanding Trump‚Äôs Budget Proposal

date: 2025-05-04, from: Paul Krugman

What&#8217;s being cut and why? 

<br> 

<https://paulkrugman.substack.com/p/understanding-trumps-budget-proposal>

---

**@Robert's feed at BlueSky** (date: 2025-05-04, from: Robert's feed at BlueSky)

üëá

[contains quote post or other embedded content] 

<br> 

<https://bsky.app/profile/rsdoiel.bsky.social/post/3lodatj7iuc27>

---

**@Feed for Alt USDS** (date: 2025-05-04, from: Feed for Alt USDS)

Yes, this is exactly why we're doing this.

[contains quote post or other embedded content] 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3locx4lmabs2s>

---

**@Feed for Alt USDS** (date: 2025-05-04, from: Feed for Alt USDS)

Learn about a small software engineering team at the National Park Service that reaches more people every year than Disney or the major sports in the US.

@altwasonps.bsky.social we see you over there with your tiny but mighty eng team!

 https://bit.ly/4d1rU8P 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3locvrnsk5b23>

---

**@Feed for Alt USDS** (date: 2025-05-04, from: Feed for Alt USDS)

This article is indeed inspiring. How will you take up bravery in this precarious time?

[contains quote post or other embedded content] 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3loctz7qxdk2o>

---

**@Dave Winer's linkblog** (date: 2025-05-04, from: Dave Winer's linkblog)

A song for testing. 

<br> 

<https://daveverse.wordpress.com/2025/05/03/a-song-for-testing/>

---

**@Dave Winer's linkblog** (date: 2025-05-04, from: Dave Winer's linkblog)

Tesla discounts new Model Y in the US, pointing to demand issues. 

<br> 

<https://electrek.co/2025/05/03/tesla-tsla-discounts-new-model-y-us-demand-issues/>

---

**@Dave Winer's linkblog** (date: 2025-05-04, from: Dave Winer's linkblog)

Hyundai &amp; Kia Have The EV Bit Between Their Teeth And They Are Not Slowing Down. 

<br> 

<https://cleantechnica.com/2025/05/03/hyundai-kia-have-the-ev-bit-between-their-teeth-and-they-are-not-slowing-down/>

---

## DuckDB is Probably the Most Important Geospatial Software of the Last Decade

date: 2025-05-04, updated: 2025-05-04, from: Simon Willison‚Äôs Weblog

<p><strong><a href="https://www.dbreunig.com/2025/05/03/duckdb-is-the-most-impactful-geospatial-software-in-a-decade.html">DuckDB is Probably the Most Important Geospatial Software of the Last Decade</a></strong></p>
Drew Breunig argues that the ease of installation of DuckDB is opening up geospatial analysis to a whole new set of developers.</p>
<p>This inspired <a href="https://news.ycombinator.com/item?id=43881468#43882914">a comment on Hacker News</a> from DuckDB Labs geospatial engineer Max Gabrielsson which helps explain why the drop in friction introduced by DuckDB is so significant:</p>
<blockquote>
<p>I think a big part is that duckdbs spatial extension provides a SQL interface to a whole suite of standard foss gis packages by statically bundling everything (including inlining the default PROJ database of coordinate projection systems into the binary) and providing it for multiple platforms (including WASM). I.E there are no transitive dependencies except libc.</p>
<p>[...] the fact that you can e.g. convert too and from a myriad of different geospatial formats by utilizing GDAL, transforming through SQL, or pulling down the latest overture dump without having the whole workflow break just cause you updated QGIS has probably been the main killer feature for a lot of the early adopters.</p>
</blockquote>
<p>I've lost count of the time I've spent fiddling with dependencies like GDAL trying to get various geospatial tools to work in the past. Bundling difficult dependencies statically is an under-appreciated trick!</p>
<p>If the bold claim in the headline inspires you to provide a counter-example, bear in mind that a decade ago is 2015, and most of the key technologies
In the modern geospatial stack - QGIS, PostGIS, geopandas, SpatiaLite - predate that by quite a bit.


    <p>Tags: <a href="https://simonwillison.net/tags/drew-breunig">drew-breunig</a>, <a href="https://simonwillison.net/tags/geospatial">geospatial</a>, <a href="https://simonwillison.net/tags/gis">gis</a>, <a href="https://simonwillison.net/tags/duckdb">duckdb</a>, <a href="https://simonwillison.net/tags/sql">sql</a></p> 

<br> 

<https://simonwillison.net/2025/May/4/duckdb-is-probably-the-most-important-geospatial-software-of-the/#atom-everything>

---

**@Dave Winer's linkblog** (date: 2025-05-04, from: Dave Winer's linkblog)

Clippers vs Nuggets: Steve Ballmer flies 125 L.A. fans to Game 7 at Ball Arena. 

<br> 

<https://www.denverpost.com/2025/05/03/the-wall-clippers-nuggets-game-7-clippers-steve-ballmer/>

