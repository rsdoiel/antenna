---
title: snapshots
updated: 2025-05-06 06:10:30
---

# snapshots

(date: 2025-05-06 06:10:30)

---

**@Dave Winer's linkblog** (date: 2025-05-06, from: Dave Winer's linkblog)

Tesla sales plunge again in April, down stunning 75 pct over year before. 

<br> 

<https://thedriven.io/2025/05/05/tesla-sales-plunge-again-in-april-down-stunning-75-pct-over-year-before/>

---

**@Dave Winer's linkblog** (date: 2025-05-06, from: Dave Winer's linkblog)

Order by Hegseth to cancel Ukraine weapons caught White House off guard. 

<br> 

<https://www.reuters.com/world/us/order-by-hegseth-cancel-ukraine-weapons-caught-white-house-off-guard-2025-05-06/>

---

**@Feed for Alt USDS** (date: 2025-05-06, from: Feed for Alt USDS)

Want to get involved? Here's a way

[contains quote post or other embedded content] 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3loitagohsk2u>

---

**@Dave Winer's linkblog** (date: 2025-05-06, from: Dave Winer's linkblog)

Why is Everybody Hating on Richie Rich? 

<br> 

<https://www.motherjones.com/politics/2025/05/richie-rich-harvey-comics-good-billionaires-wealth-fantasy-elon-musk-donald-trump-comparisons-inequality/>

---

## Radar Trends to Watch: May 2025

date: 2025-05-06, from: O'Reilly Radar

Anthropicâ€™s Model Context Protocol (MCP) has received a lot of attention for standardizing the way models communicate with tools, making it much easier to build intelligent agents. Googleâ€™s Agent2Agent (A2A) now adds features that were left out of the original MCP specification: security, agent cards for describing agent capabilities, and more. Is A2A competitive or [&#8230;] 

<br> 

<https://www.oreilly.com/radar/radar-trends-to-watch-may-2025/>

---

**@Dave Winer's linkblog** (date: 2025-05-06, from: Dave Winer's linkblog)

New York Knicks stun Boston Celtics with overtime win. 

<br> 

<https://www.bbc.com/sport/basketball/articles/cd9l144zn9lo>

---

## What's the carbon footprint of using ChatGPT?

date: 2025-05-06, from: Hannah Richie at Substack

Very small compared to most of the other stuff you do. 

<br> 

<https://www.sustainabilitybynumbers.com/p/carbon-footprint-chatgpt>

---

**@Feed for Alt USDS** (date: 2025-05-06, from: Feed for Alt USDS)

We updated our timeline for the month of April. Learn about DOGE's insider threats, what government employees are and are not allowed to do politically, and much more!

 https://bit.ly/4iQ7rVZ 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3lohxcoj7zq25>

---

**@Feed for Alt USDS** (date: 2025-05-06, from: Feed for Alt USDS)

What happens when AI replaces experience? DOGE-backed projects want to "free up" 70k government workers, but real efficiency comes from human-centered design.

Read our latest ðŸ‘‰ https://bit.ly/Illusion-of-Efficiency 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3lohv75uoxf25>

---

**@Dave Winer's linkblog** (date: 2025-05-05, from: Dave Winer's linkblog)

Il presidente di El Salvador fa shopping a Firenze. 

<br> 

<https://www.lanazione.it/firenze/cronaca/presidente-salvador-giacca-m7zgvjvq>

---

**@Dave Winer's linkblog** (date: 2025-05-05, from: Dave Winer's linkblog)

Tesla Cybertruck Review After 15,000 Miles. 

<br> 

<https://cleantechnica.com/2025/05/05/tesla-cybertruck-review-after-15000-miles/>

---

## Game Bub is an open source, FPGA-based handheld with support for Game Boy, GBC, and GBA games (crowdfunding)

date: 2025-05-05, from: Liliputing

<p>TheÂ Game Bub is an upcoming handheld game console designed to play Game Boy, Game Boy Color, and Game Boy Advance games. Like most modern handhelds it can handle ROM files. But you can also use cartridges, making this a modern device that functions a lot like the original hardware. In fact, it even supports link [&#8230;]</p>
<p>The post <a href="https://liliputing.com/game-bub-is-an-open-source-fpga-based-handheld-with-support-for-game-boy-gbc-and-gba-games-crowdfunding/">Game Bub is an open source, FPGA-based handheld with support for Game Boy, GBC, and GBA games (crowdfunding)</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/game-bub-is-an-open-source-fpga-based-handheld-with-support-for-game-boy-gbc-and-gba-games-crowdfunding/>

---

## A quick note on sponsorships...

date: 2025-05-05, from: Fix the News

Have you ever considered placing an advertisement in our newsletter? 

<br> 

<https://fixthenews.com/note-on-sponsorships/>

---

**@Tomosino's Mastodon feed** (date: 2025-05-05, from: Tomosino's Mastodon feed)

<p>Imagine a really good hot dog</p> 

<br> 

<https://tilde.zone/@tomasino/114457153414996752>

---

## Man Who Hacked Disney With Malicious AI Tool Pleads Guilty

date: 2025-05-05, from: 404 Media Group

 A hacker who tricked people into downloading malware using AI image generation tools plead guilty to two felony counts.
 

<br> 

<https://www.404media.co/man-who-hacked-disney-with-malicious-ai-tool-pleads-guilty/>

---

## MailMaven Public Beta

date: 2025-05-05, from: Michael Tsai

Scott Morrison: For a number of years we have been working on MailMaven: A new macOS email client that picks up where we left off after Apple killed Mail Plugins. Today we are opening access to a wider audience than our small group of private beta testers. Apple made it impossible for MailTags (and SmallCubed&#8217;s [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/05/05/mailmaven-public-beta/>

---

## Hyperspace 1.3

date: 2025-05-05, from: Michael Tsai

John Siracusa: The first release of Hyperspace mitigated these risks, in part, by entirely avoiding certain files and file system locations. I knew lifting these limitations would be a common request from potential customers. My plan was to launch 1.0 with the safest possible feature set, then slowly expand the app&#8217;s capabilities until all these [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/05/05/hyperspace-1-3/>

---

## Folder Preview 1.6

date: 2025-05-05, from: Michael Tsai

Anybox: Quick look extension for folders. [&#8230;] USD$1.99 to get the app and all of it. [&#8230;] Preview ZIP files as folders. It does what it says on the tin. This is a new-style Quick Look extension, so it uses a real outline view and a real path bar, rather than trying to make HTML [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/05/05/folder-preview-1-6/>

---

## Xcode + Claude

date: 2025-05-05, from: Michael Tsai

Juli Clover: Apple is working with Anthropic on an updated version of Xcode that will support AI code writing, editing, and testing, reports Bloomberg. Anthropic is best known for its &#8220;Claude&#8221; large language model and chatbot that competes with OpenAI&#8217;s ChatGPT. Claude is well-known for its coding capabilities, beating out other LLMs on programming tasks.The [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/05/05/xcode-claude/>

---

## Request for more articles on prompting techniques

date: 2025-05-05, updated: 2025-05-05, from: Simon Willisonâ€™s Weblog

<p>I'm disappointed at how little good writing there is out there about effective prompting.</p>
<p>Here's an example: what's the best prompt to use to summarize an article?</p>
<p>That feels like such an obvious thing, and yet I haven't even seen <em>that</em> being well explored!</p>
<p>It's actually a surprisingly deep topic. I like using tricks like "directly quote the sentences that best illustrate the overall themes" and "identify the most surprising ideas", but I'd love to see a thorough breakdown of all the tricks I haven't seen yet.</p>

    <p>Tags: <a href="https://simonwillison.net/tags/prompt-engineering">prompt-engineering</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a></p> 

<br> 

<https://simonwillison.net/2025/May/5/prompting/#atom-everything>

---

## Quoting Max Woolf

date: 2025-05-05, updated: 2025-05-05, from: Simon Willisonâ€™s Weblog

<blockquote cite="https://minimaxir.com/2025/05/llm-use/"><p>Two things can be true simultaneously: (a) LLM provider cost economics are too negative to return positive ROI to investors, and (b) LLMs are useful for solving problems that are meaningful and high impact, albeit not to the AGI hype that would justify point (a). This particular combination creates a frustrating gray area that requires a nuance that an ideologically split social media can no longer support gracefully. [...]</p>
<p>OpenAI collapsing would not cause the end of LLMs, because LLMs are useful <em>today</em> and there will always be a nonzero market demand for them: itâ€™s a bell that canâ€™t be unrung.</p></blockquote>
<p class="cite">&mdash; <a href="https://minimaxir.com/2025/05/llm-use/">Max Woolf</a></p>

    <p>Tags: <a href="https://simonwillison.net/tags/max-woolf">max-woolf</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/openai">openai</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a></p> 

<br> 

<https://simonwillison.net/2025/May/5/max-woolf/#atom-everything>

---

## COSMIC Alpha 7: Never Been Beta

date: 2025-05-05, from: System76 Blog

Wrapping up COSMICâ€™s main features before the first beta release. 

<br> 

<https://blog.system76.com/post/cosmic-alpha-7-never-been-beta>

---

## GlobalX, Airline for Trumpâ€™s Deportations, Hacked

date: 2025-05-05, from: 404 Media Group

Hackers say they have obtained what they say are passenger lists for GlobalX flights from January to this month. The data appears to include people who have been deported. 

<br> 

<https://www.404media.co/globalx-airline-for-trumps-deportations-hacked/>

---

## Feed a video to a vision LLM as a sequence of JPEG frames on the CLI (also LLM 0.25)

date: 2025-05-05, updated: 2025-05-05, from: Simon Willisonâ€™s Weblog

<p>The new <strong><a href="https://github.com/simonw/llm-video-frames">llm-video-frames</a></strong> plugin can turn a video file into a sequence of JPEG frames and feed them directly into a long context vision LLM such as GPT-4.1, even when that LLM doesn't directly support video input. It depends on a plugin feature I added to <a href="https://llm.datasette.io/en/stable/changelog.html#v0-25">LLM 0.25</a>, which I released last night.</p>
<p>Here's how to try it out:</p>
<div class="highlight highlight-source-shell"><pre>brew install ffmpeg <span class="pl-c"><span class="pl-c">#</span> or apt-get or your package manager of choice</span>
uv tool install llm <span class="pl-c"><span class="pl-c">#</span> or pipx install llm or pip install llm</span>
llm install llm-video-frames
llm keys <span class="pl-c1">set</span> openai
<span class="pl-c"><span class="pl-c">#</span> Paste your OpenAI API key here</span>

llm -f video-frames:video.mp4 \
  <span class="pl-s"><span class="pl-pds">'</span>describe the key scenes in this video<span class="pl-pds">'</span></span> \
  -m gpt-4.1-mini</pre></div>
<p>The <code>video-frames:filepath.mp4</code> syntax is provided by the new plugin. It takes that video, converts it to a JPEG for every second of the video and then turns those into <a href="https://llm.datasette.io/en/stable/usage.html#attachments">attachments</a> that can be passed to the LLM.</p>
<p>Here's a demo, against <a href="https://static.simonwillison.net/static/2025/cleo.mp4">this video</a> of Cleo:</p>

<div style="max-width: 100%; margin-bottom: 0.4em">
    <video controls="controls" preload="none" aria-label="Cleo " poster="https://static.simonwillison.net/static/2025/cleo-still.jpg" loop="loop" style="width: 100%; height: auto;" muted="muted">
        <source src="https://static.simonwillison.net/static/2025/cleo.mp4" type="video/mp4" />
    </video>
</div>

<div class="highlight highlight-source-shell"><pre>llm -f video-frames:cleo.mp4 <span class="pl-s"><span class="pl-pds">'</span>describe key moments<span class="pl-pds">'</span></span> -m gpt-4.1-mini</pre></div>
<p>And the output from the model (<a href="https://gist.github.com/simonw/a4e26166a524f9c07b4cf32b2f8da6c9">transcript here</a>):</p>
<blockquote>
<p>The sequence of images captures the key moments of a dog being offered and then enjoying a small treat:</p>
<ol>
<li>In the first image, a hand is holding a small cupcake with purple frosting close to a black dog's face. The dog looks eager and is focused intently on the treat.</li>
<li>The second image shows the dog beginning to take a bite of the cupcake from the person's fingers. The dog's mouth is open, gently nibbling on the treat.</li>
<li>In the third image, the dog has finished or is almost done with the treat and looks content, with a slight smile and a relaxed posture. The treat is no longer in the person's hand, indicating that the dog has consumed it.</li>
</ol>
<p>This progression highlights the dog's anticipation, enjoyment, and satisfaction with the treat.</p>
</blockquote>
<p>Total cost: 7,072 input tokens, 156 output tokens - for GPT-4.1 mini that's 0.3078 cents (less than a third of a cent).</p>
<p>In this case the plugin converted the video into three images: <a href="https://static.simonwillison.net/static/2025/frame_00001.jpg">frame_00001.jpg</a>, <a href="https://static.simonwillison.net/static/2025/frame_00002.jpg">frame_00002.jpg</a> and <a href="https://static.simonwillison.net/static/2025/frame_00003.jpg">frame_00003.jpg</a>.</p>
<p>The plugin accepts additional arguments. You can increase the frames-per-second using <code>?fps=2</code> - for example:</p>
<div class="highlight highlight-source-shell"><pre>llm -f <span class="pl-s"><span class="pl-pds">'</span>video-frames:video.mp4?fps=2<span class="pl-pds">'</span></span> <span class="pl-s"><span class="pl-pds">'</span>summarize this video<span class="pl-pds">'</span></span></pre></div>
<p>Or you can add <code>?timestamps=1</code> to cause <code>ffmpeg</code> to overlay a timestamp in the bottom right corner of each frame. This gives the model a chance to return timestamps in its output.</p>
<p>Let's try that with the Cleo video:</p>
<div class="highlight highlight-source-shell"><pre>llm -f <span class="pl-s"><span class="pl-pds">'</span>video-frames:cleo.mp4?timestamps=1&amp;fps=5<span class="pl-pds">'</span></span> \
  <span class="pl-s"><span class="pl-pds">'</span>key moments, include timestamps<span class="pl-pds">'</span></span> -m gpt-4.1-mini</pre></div>
<p>Here's the output (<a href="https://gist.github.com/simonw/371719849a7d2260f1eb0f422ea63187">transcript here</a>):</p>
<blockquote>
<p>Here are the key moments from the video "cleo.mp4" with timestamps:</p>
<ul>
<li>00:00:00.000 - A dog on leash looks at a small cupcake with purple frosting being held by a person.</li>
<li>00:00:00.800 - The dog closely sniffs the cupcake.</li>
<li>00:00:01.400 - The person puts a small amount of the cupcake frosting on their finger.</li>
<li>00:00:01.600 - The dog starts licking the frosting from the person's finger.</li>
<li>00:00:02.600 - The dog continues licking enthusiastically.</li>
</ul>
<p>Let me know if you need more details or a description of any specific part.</p>
</blockquote>
<p>That one sent 14 images to the API, at a total cost of 32,968 input, 141 output = 1.3413 cents.</p>
<p>It sent 5.9MB of image data to OpenAI's API, encoded as base64 in the JSON API call.</p>
<p>The GPT-4.1 model family accepts up to 1,047,576 tokens. Aside from a 20MB size limit per image I haven't seen any documentation of limits on the number of images. You can fit a whole lot of JPEG frames in a million tokens!</p>
<p>Here's what one of those frames looks like with the timestamp overlaid in the corner:</p>
<p><img src="https://static.simonwillison.net/static/2025/cleo-finger.jpg" alt="Cleo taking a treat from my fingers, in the bottom right corner is an overlay t hat says cleo.mp4 00:00:01.600" style="max-width: 100%;" /></p>
<h4 id="how-i-built-the-plugin-with-o4-mini">How I built the plugin with o4-mini</h4>
<p>This is a great example of how rapid prototyping with an LLM can help demonstrate the value of a feature.</p>
<p>I was considering whether it would make sense for fragment plugins to return images in <a href="https://github.com/simonw/llm/issues/972#issuecomment-2849342103">issue 972</a> when I had the idea to use <code>ffmpeg</code> to split a video into frames.</p>
<p>I know <a href="https://simonwillison.net/2025/Apr/23/llm-fragment-symbex/">from past experience</a> that a good model can write an entire plugin for LLM if you feed it the right example, so I started with this (reformatted here for readability):</p>
<div class="highlight highlight-source-shell"><pre>llm -m o4-mini -f github:simonw/llm-hacker-news -s <span class="pl-s"><span class="pl-pds">'</span>write a new plugin called llm_video_frames.py which takes video:path-to-video.mp4 and creates a temporary directory which it then populates with one frame per second of that video using ffmpeg - then it returns a list of [llm.Attachment(path="path-to-frame1.jpg"), ...] - it should also support passing video:video.mp4?fps=2 to increase to two frames per second, and if you pass ?timestamps=1 or &amp;timestamps=1 then it should add a text timestamp to the bottom right conner of each image with the mm:ss timestamp of that frame (or hh:mm:ss if more than one hour in) and the filename of the video without the path as well.<span class="pl-pds">'</span></span> -o reasoning_effort high</pre></div>
<p>Here's <a href="https://gist.github.com/simonw/4f545ecb347884d1d923dbc49550b8b0#response">the transcript</a>.</p>
<p>The new attachment mechanism went from vague idea to "I should build that" as a direct result of having an LLM-built proof-of-concept that demonstrated the feasibility of the new feature.</p>
<p>The code it produced was about 90% of the code I shipped in the finished plugin. Total cost 5,018 input, 2,208 output = 1.5235 cents.</p>
<h4 id="annotated-release-notes-for-everything-else-in-llm-0-25">Annotated release notes for everything else in LLM 0.25</h4>
<p>Here are the annotated release notes for everything else:</p>
<blockquote>
<ul>
<li>New plugin feature: <a href="https://llm.datasette.io/en/stable/plugins/plugin-hooks.html#plugin-hooks-register-fragment-loaders">register_fragment_loaders(register)</a> plugins can now return a mixture of fragments and attachments. The <a href="https://github.com/simonw/llm-video-frames">llm-video-frames</a> plugin is the first to take advantage of this mechanism. <a href="https://github.com/simonw/llm/issues/972">#972</a>
</li>
</ul>
</blockquote>
<p>As decsribed above. The inspiration for this feature came from the <a href="https://github.com/agustif/llm-arxiv">llm-arxiv</a> plugin by <a href="https://github.com/agustif">agustif</a>.</p>
<blockquote>
<ul>
<li>New OpenAI models: <code>gpt-4.1</code>, <code>gpt-4.1-mini</code>, <code>gpt-41-nano</code>, <code>o3</code>, <code>o4-mini</code>. <a href="https://github.com/simonw/llm/issues/945">#945</a>, <a href="https://github.com/simonw/llm/issues/965">#965</a>, <a href="https://github.com/simonw/llm/issues/976">#976</a>.</li>
</ul>
</blockquote>
<p>My original plan was to leave these models exclusively to the new <a href="https://github.com/simonw/llm-openai-plugin">llm-openai</a> plugin, since that allows me to add support for new models without a full LLM release. I'm going to punt on that until I'm ready to entirely remove the OpenAI models from LLM core.</p>
<blockquote>
<ul>
<li>New environment variables: <code>LLM_MODEL</code> and <code>LLM_EMBEDDING_MODEL</code> for setting the model to use without needing to specify <code>-m model_id</code> every time. <a href="https://github.com/simonw/llm/issues/932">#932</a>
</li>
</ul>
</blockquote>
<p>A convenience feature for if you want to set the default model for a terminal session with LLM without using the global <a href="https://llm.datasette.io/en/stable/setup.html#setting-a-custom-default-model">default model" mechanism</a>.</p>
<blockquote>
<ul>
<li>New command: <code>llm fragments loaders</code>, to list all currently available fragment loader prefixes provided by plugins. <a href="https://github.com/simonw/llm/issues/941">#941</a>
</li>
</ul>
</blockquote>
<p>Mainly for consistence with the existing <a href="https://llm.datasette.io/en/stable/help.html#llm-templates-loaders-help">llm templates loaders</a> command. Here's the output when I run <code>llm fragments loaders</code> on my machine:</p>
<pre><code>docs:
  Fetch the latest documentation for the specified package from
  https://github.com/simonw/docs-for-llms

  Use '-f docs:' for the documentation of your current version of LLM.

docs-preview:
  Similar to docs: but fetches the latest docs including alpha/beta releases.

symbex:
  Walk the given directory, parse every .py file, and for every
  top-level function or class-method produce its signature and
  docstring plus an import line.

github:
  Load files from a GitHub repository as fragments

  Argument is a GitHub repository URL or username/repository

issue:
  Fetch GitHub issue/pull and comments as Markdown

  Argument is either "owner/repo/NUMBER" or URL to an issue

pr:
  Fetch GitHub pull request with comments and diff as Markdown

  Argument is either "owner/repo/NUMBER" or URL to a pull request

hn:
  Given a Hacker News article ID returns the full nested conversation.

  For example: -f hn:43875136

video-frames:
  Fragment loader "video-frames:&lt;path&gt;?fps=N&amp;timestamps=1"
  - extracts frames at `fps` per second (default 1)
  - if `timestamps=1`, overlays "filename hh:mm:ss" at bottom-right
</code></pre>
<p>That's from <a href="https://github.com/simonw/llm-docs">llm-docs</a>, <a href="https://github.com/simonw/llm-fragments-github">llm-fragments-symbex</a>, <a href="https://github.com/simonw/llm-fragments-github">llm-fragments-github</a>, <a href="https://github.com/simonw/llm-hacker-news">llm-hacker-news</a> and <a href="https://github.com/simonw/llm-video-frames">llm-video-frames</a>.</p>
<blockquote>
<ul>
<li>
<code>llm fragments</code> command now shows fragments ordered by the date they were first used. <a href="https://github.com/simonw/llm/issues/973">#973</a>
</li>
</ul>
</blockquote>
<p>This makes it easier to quickly debug a new fragment plugin - you can run <code>llm fragments</code> and glance at the bottom few entries.</p>
<p>I've also been using the new <a href="https://github.com/simonw/llm-echo">llm-echo</a> debugging plugin for this - it adds a new fake model called "echo" which simply outputs whatever the prompt, system prompt, fragments and attachments are that were passed to the model:</p>
<div class="highlight highlight-source-shell"><pre>llm -f docs:sqlite-utils -m <span class="pl-c1">echo</span> <span class="pl-s"><span class="pl-pds">'</span>Show me the context<span class="pl-pds">'</span></span></pre></div>
<p><a href="https://gist.github.com/simonw/cb3249856887379759515022c76d0d9e">Output here</a>.</p>
<blockquote>
<ul>
<li>
<code>llm chat</code> now includes a <code>!edit</code> command for editing a prompt using your default terminal text editor. Thanks, <a href="https://github.com/Hopiu">Benedikt Willi</a>. <a href="https://github.com/simonw/llm/pull/969">#969</a>
</li>
</ul>
</blockquote>
<p>This is a really nice enhancement to <code>llm chat</code>, making it much more convenient to edit longe prompts.</p>
<p>And the rest:</p>
<blockquote>
<ul>
<li>Allow <code>-t</code> and <code>--system</code> to be used at the same time. <a href="https://github.com/simonw/llm/issues/916">#916</a>
</li>
<li>Fixed a bug where accessing a model via its alias would fail to respect any default options set for that model. <a href="https://github.com/simonw/llm/issues/968">#968</a>
</li>
<li>Improved documentation for <a href="https://llm.datasette.io/en/stable/other-models.html#openai-compatible-models">extra-openai-models.yaml</a>. Thanks, <a href="https://github.com/rahimnathwani">Rahim Nathwani</a> and <a href="https://github.com/dguido">Dan Guido</a>. <a href="https://github.com/simonw/llm/pull/950">#950</a>, <a href="https://github.com/simonw/llm/pull/957">#957</a>
</li>
<li>
<code>llm -c/--continue</code> now works correctly with the <code>-d/--database</code> option. <code>llm chat</code> now accepts that <code>-d/--database</code> option. Thanks, <a href="https://github.com/sukhbinder">Sukhbinder Singh</a>. <a href="https://github.com/simonw/llm/issues/933">#933</a>
</li>
</ul>
</blockquote>
    
        <p>Tags: <a href="https://simonwillison.net/tags/vision-llms">vision-llms</a>, <a href="https://simonwillison.net/tags/llm">llm</a>, <a href="https://simonwillison.net/tags/plugins">plugins</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/projects">projects</a>, <a href="https://simonwillison.net/tags/ffmpeg">ffmpeg</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a></p> 

<br> 

<https://simonwillison.net/2025/May/5/llm-video-frames/#atom-everything>

---

## Why DO large language models hallucinate?

date: 2025-05-05, from: Gary Marcus blog

The Henrietta Chronicles continue, guest starring Harry Shearer 

<br> 

<https://garymarcus.substack.com/p/why-do-large-language-models-hallucinate>

---

## OneChipBook-12-A is a $215 mini laptop with an FPGA for retro computing

date: 2025-05-05, from: Liliputing

<p>TheÂ OneChipBook-12-A is a modern mini laptop design for retro computing. It&#8217;s the latest in a line of systems from 8086YES! that are designed to let you run classic code from decades past on hardware that&#8217;s more portable than anything that would have been available at the time. In fact, the newest laptop looks nearly identical [&#8230;]</p>
<p>The post <a href="https://liliputing.com/onechipbook-12-a-is-a-215-mini-laptop-with-an-fpga-for-retro-computing/">OneChipBook-12-A is a $215 mini laptop with an FPGA for retro computing</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/onechipbook-12-a-is-a-215-mini-laptop-with-an-fpga-for-retro-computing/>

---

## christopher.org for the next 100 years

date: 2025-05-05, from: Chris Coyier blog

I&#8217;m trying to do right by my old buddy Christopher Schmitt and his digital footprint. You might remember we made a thank-you site for him where people shared memories. That&#8217;s hosted on a provided Netlify account, and the code is on a public GitHub repo. Notably the site doesn&#8217;t use a custom domain name, which [&#8230;] 

<br> 

<https://chriscoyier.net/2025/05/05/christopher-org-for-the-next-100-years/>

---

**@Feed for Alt USDS** (date: 2025-05-05, from: Feed for Alt USDS)

We the Builders' Kate and Milo joined Andy and Helen from @cybershow.uk to talk about what's happening to us here, share ideas across the Atlantic, and talk about what it means to stop the destruction and begin to rebuild.

https://cybershow.uk/episodes.php?id=46 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3logt5xvhoc2d>

---

## Mom: The Ultimate Hero

date: 2025-05-05, from: Guy Kawasaki blog

Scott T. Allison, Professor of Psychology, University of Richmond. 

<br> 

<https://guykawasaki.substack.com/p/mom-the-ultimate-hero>

---

## Quoting Arvind Narayanan

date: 2025-05-05, updated: 2025-05-05, from: Simon Willisonâ€™s Weblog

<blockquote cite="https://twitter.com/random_walker/status/1919359709062033850"><p>[On using generative AI for work despite the risk of errors:]</p>
<ul>
<li>AI is helpful despite being error-prone if it is faster to verify the output than it is to do the work yourself. For example, if you're using it to find a product that matches a given set of specifications, verification may be a lot faster than search.</li>
<li>There are many uses where errors don't matter, like using it to enhance creativity by suggesting or critiquing ideas.</li>
<li>At a meta level, if you use AI without a plan and simply turn to AI tools when you feel like it, then you're unlikely to be able to think through risks and mitigations. It is better to identify concrete ways to integrate AI into your workflows, with known benefits and risks, that you can employ repeatedly.</li>
</ul></blockquote>
<p class="cite">&mdash; <a href="https://twitter.com/random_walker/status/1919359709062033850">Arvind Narayanan</a></p>

    <p>Tags: <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/arvind-narayanan">arvind-narayanan</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a></p> 

<br> 

<https://simonwillison.net/2025/May/5/arvind-narayanan/#atom-everything>

---

## Enterre Seus Mortos (43FCIU): la remasterizaciÃ³n del pasajero oscuro

date: 2025-05-05, from: IvÃ¡n Paredes ResÃ©ndiz blog, Mexico's cinema

<p>DirecciÃ³n: Marco Dutra. Guion: Macro Dutra, basado en la novela homÃ³nima de Ana Paula Maia. Elenco: Selton Mello, Marjorie Estiano, Danilo Grangheia, Betty Faria, Maria Manoella. PaÃ­s: Brasil. MÃ¡s informaciÃ³n de la pelÃ­cula: https://www.imdb.com//title/tt15738252/ Â¿QuÃ© hay despuÃ©s de la muerte? Es una pregunta que, aunque de apariencia retÃ³rica, abre un mar de dudas entre los [&#8230;]</p>
<p>La entrada <a href="https://www.palomitademaiz.net/resenas-enterre-seus-mortos-43fciu/">Enterre Seus Mortos (43FCIU): la remasterizaciÃ³n del pasajero oscuro</a> se publicÃ³ primero en <a href="https://www.palomitademaiz.net">Palomita de maÃ­z</a>.</p>
 

<br> 

<https://www.palomitademaiz.net/resenas-enterre-seus-mortos-43fciu/?utm_source=rss&utm_medium=rss&utm_campaign=resenas-enterre-seus-mortos-43fciu>

---

## HARVARD: BARBARIANS AT THE GATES, IGNORAMUSES ON THE LAWN

date: 2025-05-05, from: Howard Jacobson blog

Streetwalking with Howard Jacobson is a reader-supported publication. 

<br> 

<https://jacobsonh.substack.com/p/harvard-barbarians-at-the-gates-ignoramuses>

---

## Trust AI Less

date: 2025-05-05, updated: 2025-05-05, from: One Foot Tsunami

 

<br> 

<https://onefoottsunami.com/2025/05/05/trust-ai-less/>

---

## 100,000 People Are Using a Telegram Bot That Makes AI Cumshot Videos of Anyone

date: 2025-05-05, from: 404 Media Group

An open AI video generation model that was released last month is now being used by thousands of people to generate nonconsensual sexual videos of real people.  

<br> 

<https://www.404media.co/telegram-ai-cumshot-bot/>

---

## Are you being a fuel fool?

date: 2025-05-05, from: Status-Q blog

I&#8217;ve been driving an electric car for about a decade now, but because we also have a fossil-burning campervan, I do still occasionally need to visit one of those dirty, smelly, legacy refuelling stations, so&#8230; If you use a site like PetrolPrices.com, you can find out roughly how much fuel costs at the various petrol <a class="more-link excerpt-link" href="https://statusq.org/archives/2025/05/05/13133/">Continue Reading<span class="glyphicon glyphicon-chevron-right"></span></a> 

<br> 

<https://statusq.org/archives/2025/05/05/13133/>

---

**@Dave Winer's linkblog** (date: 2025-05-05, from: Dave Winer's linkblog)

Kristaps Porzingis sheds light on how he feels about Knicksâ€™ return. 

<br> 

<https://www.celticsblog.com/2025/5/5/24423130/kristaps-porzingis-celtics-knicks-nba-playoffs>

---

## A Note From the Netherlands

date: 2025-05-05, from: Paul Krugman

The Dutch have nice things. Why can&#8217;t we? 

<br> 

<https://paulkrugman.substack.com/p/a-note-from-the-netherlands>

---

## <default:div xmlns="http://www.w3.org/1999/xhtml" class="if-your-feed-reader-displays-this-then-it-is-violating-the-Atom-spec-RFC-4287-section-4.2.14"/>

date: 2025-05-05, updated: 2025-05-05, from: Tantek Ã‡elik's blog

 

<br> 

<https://tantek.com/2025/124/t1/may-the-fourth-be-with-you>

---

## Mr. Deepfakes, the Biggest Deepfake Porn Site on the Internet, Says Itâ€™s Shutting Down for Good

date: 2025-05-05, from: 404 Media Group

The biggest site for nonconsensual deepfake porn on the internet says itâ€™s shutting down and not coming back.
 

<br> 

<https://www.404media.co/mr-deepfakes-the-biggest-deepfake-porn-site-on-the-internet-says-its-shutting-down-for-good/>

---

**@Dave Winer's linkblog** (date: 2025-05-05, from: Dave Winer's linkblog)

Trump says he will reopen Alcatraz prison. 

<br> 

<https://apnews.com/article/trump-alcatraz-prison-fabe3385415ae03829d44e50efb3c1fb>

---

**@Dave Winer's linkblog** (date: 2025-05-04, from: Dave Winer's linkblog)

Think Twice Before Creating That ChatGPT Action Figure. 

<br> 

<https://www.wired.com/story/chatgpt-image-generator-action-figure-privacy/>

---

## 562. Peter the Great: The Rise of Russia (Part 1)

date: 2025-05-04, from: This is history podcast

<p>Why was the early life of Peter the Great &#8211; Tsar and autocrat of all the Russias, who endures to this day as an iconic symbol of Russian might &#8211; drenched in blood and violence? What amalgamation of court politics and family feuding saw him catapulted to the role of Tsar against all the odds? [&#8230;]</p>
<p>The post <a href="https://therestishistory.com/562-peter-the-great-the-rise-of-russia-part-1/">562. Peter the Great: The Rise of Russia (Part 1)</a> appeared first on <a href="https://therestishistory.com">The Rest is History</a>.</p>
 

<br> 

<https://therestishistory.com/562-peter-the-great-the-rise-of-russia-part-1/>

---

## Four Dead in Ohio

date: 2025-05-04, from: Michael Moore's blog

55 years ago... 

<br> 

<https://www.michaelmoore.com/p/four-dead-in-ohio>

---

## The Signal Clone the Trump Admin Uses Was Hacked

date: 2025-05-04, from: 404 Media Group

TeleMessage, a company that makes a modified version of Signal that archives messages for government agencies, was hacked. 

<br> 

<https://www.404media.co/the-signal-clone-the-trump-admin-uses-was-hacked/>

---

## Dummy's Guide to Modern LLM Sampling

date: 2025-05-04, updated: 2025-05-04, from: Simon Willisonâ€™s Weblog

<p><strong><a href="https://rentry.co/samplers">Dummy&#x27;s Guide to Modern LLM Sampling</a></strong></p>
This is an extremely useful, detailed set of explanations by <a href="https://x.com/AlpinDale">@AlpinDale</a> covering the various different sampling strategies used by modern LLMs. LLMs return a set of next-token probabilities for every token in their corpus - a layer above the LLM can then use sampling strategies to decide which one to use.</p>
<p>I finally feel like I understand the difference between <a href="https://rentry.co/samplers#top-k">Top-K</a> and <a href="https://rentry.co/samplers#top-p">Top-P</a>! Top-K is when you narrow down to e.g. the 20 most likely candidates for next token and then pick one of those. Top-P instead "the smallest set of words whose combined probability exceeds threshold P" - so if you set it to 0.5 you'll filter out tokens in the lower half of the probability distribution.</p>
<p>There are a bunch more sampling strategies in here that I'd never heard of before - Top-A, Top-N-Sigma, Epsilon-Cutoff and more.</p>
<p>Reading the descriptions here of <a href="https://rentry.co/samplers#repetition-penalty">Repetition Penalty</a> and <a href="https://rentry.co/samplers#dry-dont-repeat-yourself">Don't Repeat Yourself</a> made me realize that I need to be a little careful with those for some of my own uses of LLMs.</p>
<p>I frequently feed larger volumes of text (or code) into an LLM and ask it to output subsets of that text as direct quotes, to answer questions like "which bit of this code handles authentication tokens" or "show me direct quotes that illustrate the main themes in this conversation".</p>
<p>Careless use of frequency penalty strategies might go against what I'm trying to achieve with those prompts.

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=43887637">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/prompt-engineering">prompt-engineering</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/tokenization">tokenization</a></p> 

<br> 

<https://simonwillison.net/2025/May/4/llm-sampling/#atom-everything>

---

## Lilbits: Cheaper Microsoft Surface Laptop and Surface Pro coming soon

date: 2025-05-04, from: Liliputing

<p>The latest Microsoft Surface Laptop and Surface Pro tablet are both powered by Qualcomm Snapdragon X series processors and both sell for about $800 and up. But it looks like Microsoft could have some cheaper models on the way. The Microsoft Surface Team has scheduled an event for May 6th when the company is promising [&#8230;]</p>
<p>The post <a href="https://liliputing.com/lilbits-cheaper-microsoft-surface-laptop-and-surface-pro-coming-soon/">Lilbits: Cheaper Microsoft Surface Laptop and Surface Pro coming soon</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/lilbits-cheaper-microsoft-surface-laptop-and-surface-pro-coming-soon/>

---

## Breakwater Barbecue in the El Granada station for the Ocean Shore Railroad

date: 2025-05-04, updated: 2025-05-04, from: Simon Willisonâ€™s Weblog

<p>Our local BBQ spot here in El Granada - <a href="https://www.breakwaterbbq.com/">Breakwater Barbecue</a> - had a soft opening this weekend in their <a href="https://maps.app.goo.gl/f9JSpUWaFH8Hevj3A">new location</a>.</p>
<p>Here's the new building. They're still working on replacing the sign from the previous restaurant occupant:</p>
<p><img alt="Exterior photo of a restaurant with a faded sign reading &quot;MONSTER CHEF Fine Japanese Restaurant&quot; the building is cream-colored with red tile roofs and large windows. It has a little bit of a railway station vibe to it if you squint at it just the right way." src="https://static.simonwillison.net/static/2025/breakwater-today.jpg" /></p>
<p>It's actually our old railway station! From 1905 to 1920 the <a href="https://en.wikipedia.org/wiki/Ocean_Shore_Railroad">Ocean Shore Railroad</a> ran steam trains from San Francisco down through Half Moon Bay most of the way to Santa Cruz, though they never quite connected the two cities.</p>
<p>The restaurant has some photos on the wall of the old railroad. Here's what that same building looked like &gt;100 years ago.</p>
<p><img alt="Historical black and white photograph showing a train station with a steam train on the left and a Spanish-style station building with arched entrances on the right. It's clearly the same building, though the modern one has had a bunch of extra extensions added to it and doesn't look nearly as much like a train station." src="https://static.simonwillison.net/static/2025/breakwater-train.jpg" /></p>

    <p>Tags: <a href="https://simonwillison.net/tags/half-moon-bay">half-moon-bay</a>, <a href="https://simonwillison.net/tags/photos">photos</a>, <a href="https://simonwillison.net/tags/history">history</a></p> 

<br> 

<https://simonwillison.net/2025/May/4/breakwater/#atom-everything>

---

## Creativity and Courage to Save Democracy

date: 2025-05-04, from: Our Future.org

Those in power have made clear there is no democratic norm they are unwilling to break. We live in a time of chaos, and this is not by accident. Over the last 100 days, the Trump administration has sought to divide and confuse us in every way, so no one knows whatâ€™s coming next. They [&#8230;]
<p><a href="https://ourfuture.org/20250504/creativity-and-courage-to-save-democracy" rel="nofollow">Source</a></p> 

<br> 

<https://ourfuture.org/20250504/creativity-and-courage-to-save-democracy>

---

## Valentia y creatividad para salvar la democracia

date: 2025-05-04, from: Our Future.org

Los poderosos dejan en claro que no existe ninguna norma democrÃ¡tica que no estÃ©n dispuestos a romper. Vivimos en tiempos de caos, y esto no es por accidente. Durante los Ãºltimos 100 dÃ­as, la administraciÃ³n Trump ha buscado dividirnos y confundirnos por todos lados, para que nadie sepa quÃ© hacer con lo que venga. EstÃ¡n [&#8230;]
<p><a href="https://ourfuture.org/20250504/valentia-y-creatividad" rel="nofollow">Source</a></p> 

<br> 

<https://ourfuture.org/20250504/valentia-y-creatividad>

---

**@Feed for Alt USDS** (date: 2025-05-04, from: Feed for Alt USDS)

#Resistance

[contains quote post or other embedded content] 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3loe3begrok2d>

---

**@Feed for Alt USDS** (date: 2025-05-04, from: Feed for Alt USDS)

We the Builders will be telling our story at For the Public in St Paul on May 14th! We're excited to share how we got started, why community matters so much, and looking forward to rebuilding government (and its technology) very soon.

 https://www.publicgood.tech/for-the-public 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3lodu7nw6mp2j>

---

## Understanding Trumpâ€™s Budget Proposal

date: 2025-05-04, from: Paul Krugman

What&#8217;s being cut and why? 

<br> 

<https://paulkrugman.substack.com/p/understanding-trumps-budget-proposal>

---

**@Robert's feed at BlueSky** (date: 2025-05-04, from: Robert's feed at BlueSky)

ðŸ‘‡

[contains quote post or other embedded content] 

<br> 

<https://bsky.app/profile/rsdoiel.bsky.social/post/3lodatj7iuc27>

---

**@Feed for Alt USDS** (date: 2025-05-04, from: Feed for Alt USDS)

Yes, this is exactly why we're doing this.

[contains quote post or other embedded content] 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3locx4lmabs2s>

---

**@Feed for Alt USDS** (date: 2025-05-04, from: Feed for Alt USDS)

Learn about a small software engineering team at the National Park Service that reaches more people every year than Disney or the major sports in the US.

@altwasonps.bsky.social we see you over there with your tiny but mighty eng team!

 https://bit.ly/4d1rU8P 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3locvrnsk5b23>

---

**@Feed for Alt USDS** (date: 2025-05-04, from: Feed for Alt USDS)

This article is indeed inspiring. How will you take up bravery in this precarious time?

[contains quote post or other embedded content] 

<br> 

<https://bsky.app/profile/altusds.altgov.info/post/3loctz7qxdk2o>

---

**@Dave Winer's linkblog** (date: 2025-05-04, from: Dave Winer's linkblog)

A song for testing. 

<br> 

<https://daveverse.wordpress.com/2025/05/03/a-song-for-testing/>

---

**@Dave Winer's linkblog** (date: 2025-05-04, from: Dave Winer's linkblog)

Tesla discounts new Model Y in the US, pointing to demand issues. 

<br> 

<https://electrek.co/2025/05/03/tesla-tsla-discounts-new-model-y-us-demand-issues/>

---

**@Dave Winer's linkblog** (date: 2025-05-04, from: Dave Winer's linkblog)

Hyundai &amp; Kia Have The EV Bit Between Their Teeth And They Are Not Slowing Down. 

<br> 

<https://cleantechnica.com/2025/05/03/hyundai-kia-have-the-ev-bit-between-their-teeth-and-they-are-not-slowing-down/>

---

## DuckDB is Probably the Most Important Geospatial Software of the Last Decade

date: 2025-05-04, updated: 2025-05-04, from: Simon Willisonâ€™s Weblog

<p><strong><a href="https://www.dbreunig.com/2025/05/03/duckdb-is-the-most-impactful-geospatial-software-in-a-decade.html">DuckDB is Probably the Most Important Geospatial Software of the Last Decade</a></strong></p>
Drew Breunig argues that the ease of installation of DuckDB is opening up geospatial analysis to a whole new set of developers.</p>
<p>This inspired <a href="https://news.ycombinator.com/item?id=43881468#43882914">a comment on Hacker News</a> from DuckDB Labs geospatial engineer Max Gabrielsson which helps explain why the drop in friction introduced by DuckDB is so significant:</p>
<blockquote>
<p>I think a big part is that duckdbs spatial extension provides a SQL interface to a whole suite of standard foss gis packages by statically bundling everything (including inlining the default PROJ database of coordinate projection systems into the binary) and providing it for multiple platforms (including WASM). I.E there are no transitive dependencies except libc.</p>
<p>[...] the fact that you can e.g. convert too and from a myriad of different geospatial formats by utilizing GDAL, transforming through SQL, or pulling down the latest overture dump without having the whole workflow break just cause you updated QGIS has probably been the main killer feature for a lot of the early adopters.</p>
</blockquote>
<p>I've lost count of the time I've spent fiddling with dependencies like GDAL trying to get various geospatial tools to work in the past. Bundling difficult dependencies statically is an under-appreciated trick!</p>
<p>If the bold claim in the headline inspires you to provide a counter-example, bear in mind that a decade ago is 2015, and most of the key technologies
In the modern geospatial stack - QGIS, PostGIS, geopandas, SpatiaLite - predate that by quite a bit.


    <p>Tags: <a href="https://simonwillison.net/tags/drew-breunig">drew-breunig</a>, <a href="https://simonwillison.net/tags/geospatial">geospatial</a>, <a href="https://simonwillison.net/tags/gis">gis</a>, <a href="https://simonwillison.net/tags/duckdb">duckdb</a>, <a href="https://simonwillison.net/tags/sql">sql</a></p> 

<br> 

<https://simonwillison.net/2025/May/4/duckdb-is-probably-the-most-important-geospatial-software-of-the/#atom-everything>

---

**@Dave Winer's linkblog** (date: 2025-05-04, from: Dave Winer's linkblog)

Clippers vs Nuggets: Steve Ballmer flies 125 L.A. fans to Game 7 at Ball Arena. 

<br> 

<https://www.denverpost.com/2025/05/03/the-wall-clippers-nuggets-game-7-clippers-steve-ballmer/>

