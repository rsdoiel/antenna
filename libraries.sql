PRAGMA foreign_keys=OFF;
BEGIN TRANSACTION;
CREATE TABLE channels (
	link PRIMARY KEY,
	title TEXT,
	description TEXT,
	feed_link TEXT,
	links JSON,
	updated DATETIME,
	published DATETIME,
	authors JSON,
	language TEXT,
	copyright TEXT,
	generator TEXT,
	categories JSON,
	feed_type TEXT,
	feed_version TEXT
);
INSERT INTO channels VALUES('https://theparachute.blogspot.com/feeds/posts/default?alt=rss','Parachute blog','It only works when it is open —  ⓐ I claim no rights other than attribution','','["https://theparachute.blogspot.com/"]','Sun, 20 Aug 2023 07:53:36 +0000','','[{"name":"Unknown","email":"noreply@blogger.com"}]','','','Blogger','["knowledge discovery","repositories"]','rss','2.0');
INSERT INTO channels VALUES('https://rc-blog.ethz.ch/en/feed/','ETH Zurich Research Archives','Research Collection / Institutional Repository der ETH Zürich','https://rc-blog.ethz.ch/en/feed/','["https://rc-blog.ethz.ch","https://rc-blog.ethz.ch/en/feed/"]','Tue, 16 Jan 2024 08:01:54 +0000','','','en-GB','','https://wordpress.org/?v=6.4.2','','rss','2.0');
INSERT INTO channels VALUES('https://www.arl.org/feed/','Association of Research Libraries News','','https://www.arl.org/feed/','["https://www.arl.org/","https://www.arl.org/feed/"]','Thu, 11 Jan 2024 21:04:58 +0000','','','en-US','','https://wordpress.org/?v=6.4.2','','rss','2.0');
INSERT INTO channels VALUES('http://feeds.feedburner.com/c4lj','Cod4Lib Journal','','https://journal.code4lib.org/feed','["https://journal.code4lib.org","https://journal.code4lib.org/feed"]','Tue, 05 Dec 2023 20:40:03 +0000','','','en-US','','https://wordpress.org/?v=6.4.2','','rss','2.0');
INSERT INTO channels VALUES('https://scholarlykitchen.sspnet.org/feed/','Scholarly Kitchen','What’s Hot and Cooking In Scholarly Publishing','https://scholarlykitchen.sspnet.org/feed/','["https://scholarlykitchen.sspnet.org/","https://scholarlykitchen.sspnet.org/feed/"]','Sun, 14 Jan 2024 14:57:06 +0000','','','en-US','','https://wordpress.org/?v=6.3.2','','rss','2.0');
INSERT INTO channels VALUES('https://blog.scielo.org/en/feed/','SciELO in Perspective','','https://blog.scielo.org/en/feed/','["https://blog.scielo.org/en","https://blog.scielo.org/en/feed/"]','Fri, 12 Jan 2024 18:48:07 +0000','','','en-US','','https://wordpress.org/?v=6.4.1','','rss','2.0');
INSERT INTO channels VALUES('https://www.research-collection.ethz.ch/feed/rss_2.0/site','ETH Zurich, recently added','The Research Collection is ETH Zurich''s repository for publications and research data.','','["https://www.research-collection.ethz.ch:443"]','2024-01-16T15:47:55Z','Tue, 16 Jan 2024 15:47:55 GMT','','','','','','rss','2.0');
INSERT INTO channels VALUES('https://jon-e.net/blog/feed.xml','Jonny Saunders blog','Things i gone and done','https://jon-e.net/blog/feed.xml','["/bloghttps://jon-e.net","https://jon-e.net/blog/feed.xml"]','Mon, 24 Apr 2023 17:36:57 -0700','Mon, 24 Apr 2023 17:36:57 -0700','','','','Jekyll v3.9.1','','rss','2.0');
INSERT INTO channels VALUES('https://standardebooks.org/feeds/rss/new-releases','Standard Ebooks, new releaases','The 15 latest Standard Ebooks, most-recently-released first.','https://standardebooks.org/feeds/rss/new-releases','["https://standardebooks.org","https://standardebooks.org/feeds/rss/new-releases"]','Mon, 15 Jan 2024 19:10:27 +0000','','','en-US','https://creativecommons.org/publicdomain/zero/1.0/','','','rss','2.0');
CREATE TABLE items (
	link PRIMARY KEY,
	title TEXT,
	description TEXT,
	authors JSON,
	updated DATETIME,
	published DATETIME,
	label TEXT,
	tags JSON DEFAULT '',
	channel TEXT,
	retrieved DATETIME DEFAULT CURRENT_TIMESTAMP,
	status TEXT DEFAULT ''
);
INSERT INTO items VALUES('https://www.arl.org/our-priorities/advocacy-public-policy/partner-letters/appropriations/coalition-for-national-science-funding-cnsf-letter-on-supplemental-funding-for-major-science-agencies/','Coalition for National Science Funding (CNSF) Letter on Supplemental Funding for Major Science Agencies',replace('<p>On December 14, 2023, ARL joined a letter by the Coalition for National Science Funding (CNSF) call on Congressional appropriators to include $13 billion in a supplemental spending package. Read...</p>\n<p>The post <a href="https://www.arl.org/our-priorities/advocacy-public-policy/partner-letters/appropriations/coalition-for-national-science-funding-cnsf-letter-on-supplemental-funding-for-major-science-agencies/">Coalition for National Science Funding (CNSF) Letter on Supplemental Funding for Major Science Agencies</a> appeared first on <a href="https://www.arl.org">Association of Research Libraries</a>.</p>\n','\n',char(10)),NULL,'','2023-12-14 17:48:39','Association of Research Libraries News','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://www.arl.org/our-priorities/advocacy-public-policy/partner-letters/open-internet/educause-and-arl-letter-to-fcc-on-net-neutrality/','EDUCAUSE and ARL Letter to FCC on Net Neutrality',replace('<p>On December 14, ARL and EDUCAUSE responded to the Federal Communications Commission (FCC) Notice of Proposed Rulemaking on net neutrality. Our letter described how strong net neutrality rules will allow libraries...</p>\n<p>The post <a href="https://www.arl.org/our-priorities/advocacy-public-policy/partner-letters/open-internet/educause-and-arl-letter-to-fcc-on-net-neutrality/">EDUCAUSE and ARL Letter to FCC on Net Neutrality</a> appeared first on <a href="https://www.arl.org">Association of Research Libraries</a>.</p>\n','\n',char(10)),NULL,'','2023-12-14 17:41:31','Association of Research Libraries News','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://www.arl.org/day-in-review/day-in-review-december-13-14/','Day in Review (December 13–14)',replace('<p>Last Updated on December 14, 2023, 4:24 pm ET Sign up to receive the Day in Review by email. Jump to: Thursday, December 14 Wednesday, December 13 Top o’ the...</p>\n<p>The post <a href="https://www.arl.org/day-in-review/day-in-review-december-13-14/">Day in Review (December 13–14)</a> appeared first on <a href="https://www.arl.org">Association of Research Libraries</a>.</p>\n','\n',char(10)),NULL,'','2023-12-14 07:55:57','Association of Research Libraries News','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://www.arl.org/blog/how-libraries-can-lead-the-way-in-campus-decarbonization/','How Libraries Can Lead the Way in Campus Decarbonization',replace('<p>Last Updated on December 16, 2023, 6:31 am ET Libraries have long since led the way in enabling student success; advancing research; and embracing diversity, equity, and inclusion. With this...</p>\n<p>The post <a href="https://www.arl.org/blog/how-libraries-can-lead-the-way-in-campus-decarbonization/">How Libraries Can Lead the Way in Campus Decarbonization</a> appeared first on <a href="https://www.arl.org">Association of Research Libraries</a>.</p>\n','\n',char(10)),NULL,'','2023-12-13 20:05:11','Association of Research Libraries News','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://www.arl.org/our-priorities/advocacy-public-policy/partner-letters/international-daca/american-council-on-education-ace-letter-on-visa-flexibility-for-international-students/','American Council on Education (ACE) Letter on Visa Flexibility for International Students',replace('<p>Last Updated on December 13, 2023, 12:38 pm ET On December 8, 2023, ARL signed on to a letter to the US State Department asking that the current flexibilities and...</p>\n<p>The post <a href="https://www.arl.org/our-priorities/advocacy-public-policy/partner-letters/international-daca/american-council-on-education-ace-letter-on-visa-flexibility-for-international-students/">American Council on Education (ACE) Letter on Visa Flexibility for International Students</a> appeared first on <a href="https://www.arl.org">Association of Research Libraries</a>.</p>\n','\n',char(10)),NULL,'','2023-12-08 17:33:57','Association of Research Libraries News','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://www.arl.org/day-in-review/38632/','Day in Review (December 4–7)',replace('<p>Last Updated on December 7, 2023, 4:14 pm ET Sign up to receive the Day in Review by email. Jump to: Tuesday, December 5 &#124; Wednesday, December 6 &#124; Thursday,...</p>\n<p>The post <a href="https://www.arl.org/day-in-review/38632/">Day in Review (December 4–7)</a> appeared first on <a href="https://www.arl.org">Association of Research Libraries</a>.</p>\n','\n',char(10)),NULL,'','2023-12-05 14:57:59','Association of Research Libraries News','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://www.arl.org/our-priorities/advocacy-public-policy/partner-letters/research-ecosystem/american-council-on-education-ace-letter-opposing-the-deterrent-act/','American Council on Education (ACE) Letter Opposing the DETERRENT Act',replace('<p>Last Updated on December 8, 2023, 10:49 am ET On December 4, 2023, ARL joined a letter expressing the higher education community’s opposition to the “Defending Education Transparency and Ending...</p>\n<p>The post <a href="https://www.arl.org/our-priorities/advocacy-public-policy/partner-letters/research-ecosystem/american-council-on-education-ace-letter-opposing-the-deterrent-act/">American Council on Education (ACE) Letter Opposing the DETERRENT Act</a> appeared first on <a href="https://www.arl.org">Association of Research Libraries</a>.</p>\n','\n',char(10)),NULL,'','2023-12-04 15:42:59','Association of Research Libraries News','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://www.arl.org/day-in-review/day-in-review-november-27-30/','Day in Review (November 27–30)',replace('<p>Last Updated on November 30, 2023, 4:07 pm ET Sign up to receive the Day in Review by email. Jump to: Tuesday, November 28 &#124; Wednesday, November 29 &#124; Thursday,...</p>\n<p>The post <a href="https://www.arl.org/day-in-review/day-in-review-november-27-30/">Day in Review (November 27–30)</a> appeared first on <a href="https://www.arl.org">Association of Research Libraries</a>.</p>\n','\n',char(10)),NULL,'','2023-11-28 13:21:23','Association of Research Libraries News','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://www.arl.org/uncategorized/native-american-heritage-month-roundup/','Native American Heritage Month Roundup',replace('<p>Last Updated on November 16, 2023, 12:57 am ET The month of November is Native American Heritage Month, and ARL’s community of research libraries is increasing awareness of the contributions...</p>\n<p>The post <a href="https://www.arl.org/uncategorized/native-american-heritage-month-roundup/">Native American Heritage Month Roundup</a> appeared first on <a href="https://www.arl.org">Association of Research Libraries</a>.</p>\n','\n',char(10)),NULL,'','2023-11-14 19:48:31','Association of Research Libraries News','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://www.arl.org/day-in-review/day-in-review-november-13-16/','Day in Review (November 13–16)',replace('<p>Last Updated on November 16, 2023, 2:29 pm ET Sign up to receive the Day in Review by email. Jump to: Tuesday, November 14 &#124; Wednesday, November 15 &#124; Thursday,...</p>\n<p>The post <a href="https://www.arl.org/day-in-review/day-in-review-november-13-16/">Day in Review (November 13–16)</a> appeared first on <a href="https://www.arl.org">Association of Research Libraries</a>.</p>\n','\n',char(10)),NULL,'','2023-11-13 20:20:28','Association of Research Libraries News','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/18007','Editorial','Issue 58 of the Code4Lib Journal is bursting at the seams with examples of how libraries are creating new technologies, leveraging existing technologies, and exploring the use of AI to benefit library work. We had an unprecedented number of submissions this quarter and the resulting issue features 16 articles detailing some of the more unique and innovative technology projects libraries are working on today.',NULL,'','2023-12-04 17:28:59','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17839','Enhancing Serials Holdings Data: A Pymarc-Powered Clean-Up Project',replace(replace('Following the recent transition from Inmagic to Ex Libris Alma, the Technical Services department at the University of Southern California (USC) in Los Angeles undertook a post-migration cleanup initiative. This article introduces methodologies aimed at improving irregular summary holdings data within serials records using Pymarc, regular expressions, and the Alma API in MarcEdit. The challenge identified was the confinement of serials'' holdings information exclusively to the 866 MARC tag for textual holdings. \r\n\r\nTo address this challenge, Pymarc and regular expressions were leveraged to parse and identify various patterns within the holdings data, offering a nuanced understanding of the intricacies embedded in the 866 field. Subsequently, the script generated a new 853 field for captions and patterns, along with multiple instances of the 863 field for coded enumeration and chronology data, derived from the existing data in the 866 field.\r\n\r\nThe final step involved utilizing the Alma API via MarcEdit, streamlining the restructuring of holdings data and updating nearly 5,000 records for serials. This article illustrates the application of Pymarc for both data analysis and creation, emphasizing its utility in generating data in the MARC format. Furthermore, it posits the potential application of Pymarc to enhance data within library and archive contexts.\r\n','\r',char(13)),'\n',char(10)),NULL,'','2023-12-04 17:28:58','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17701','The Use of Python to Support Technical Services Work in Academic Libraries','Technical services professionals in academic libraries are firmly committed to digital transformation and have embraced technologies and data practices that reshape their work to be more efficient, reliable, and scalable. Evolving systems, constantly changing workflows, and management of large-scale data are constants in the technical services landscape. Maintaining one’s ability to effectively work in this kind of environment involves embracing continuous learning cycles and incorporating new skills - which in effect means training people in a different way and re-conceptualizing how libraries provide support for technical services work. This article presents a micro lens into this space by examining the use of Python within a technical services environment. The authors conducted two surveys and eleven follow up interviews to investigate how Python is used in academic libraries to support technical services work and to learn more about training and organizational support across the academic library community. The surveys and interviews conducted for this research indicate that understanding the larger context of culture and organizational support are of high importance for illustrating the complications of this learning space for technical services. Consequently, this article will address themes that affect skills building in technical services at both a micro and macro level.',NULL,'','2023-12-04 17:28:57','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17932','Pipeline or Pipe Dream: Building a Scaled Automated Metadata Creation and Ingest Workflow Using Web Scraping Tools',replace(replace('Since 2004, the FRASER Digital Library has provided free access to publications and archival collections related to the history of economics, finance, banking, and the Federal Reserve System. The agile web development team that supports FRASER’s digital asset management system embarked on an initiative to automate collecting documents and metadata from US governmental sources across the web. These sources present their content on web pages but do not serve the metadata and document links via an API or other semantic web technologies, making automation a unique challenge. Using a combination of third-party software, lightweight cloud services, and custom Python code, the FRASER Recurring Downloads project transformed what was previously a labor-intensive daily process into a metadata creation and ingest pipeline that requires minimal human intervention or quality control.  \r\n\r\nThis article will provide an overview of the software and services used for the Recurring Downloads pipeline, as well as some of the struggles that the team encountered during the design and build process, and current use of the final product. The project required a more detailed plan than was designed and documented. The fully manual process was not intended to be automated when established, which introduced inherent complexity in creating the pipeline. A more comprehensive plan could have made the iterative development process easier by having a defined data model, and documentation of—and strategy for—edge cases. Further initial analysis of the cloud services used would have defined the limitations of those services, and workarounds could have been accounted for in the project plan. While the labor-intensive manual workflow has been reduced significantly, the required skill sets to efficiently maintain the automated workflow present a sustainability challenge of task distribution between librarians and developers. This article will detail the challenges and limitations of transitioning and standardizing recurring web scraping across more than 50 sources to a semi-automated workflow and potential future improvements to the pipeline. ','\r',char(13)),'\n',char(10)),NULL,'','2023-12-04 17:28:56','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17663','A practical method for searching scholarly papers in the General Index without a high-performance computer','The General Index is a free database that offers unprecedented access to keywords and ngrams derived from the full text of over 107 million scholarly articles. Its simplest use is looking up articles that contain a term of interest, but the data set is large enough for text mining and corpus linguistics. Despite being positioned as a public utility, there is no user interface; one must download, query, and extract results from raw data tables. Not only is computing skill a barrier to use, but the file sizes are too large for most desktop computers to handle. This article will show a practical way to use the GI for researchers with moderate skills and resources. It will walk though building a bibliography of articles and a visualizing yearly prevalence of a topic in the General Index, using simple R programming commands and a modestly equipped desktop computer (code is available at <a href="https://osf.io/s39n7/">https://osf.io/s39n7/</a>). It will briefly discuss what else can be done (and how) with more powerful computational resources. ',NULL,'','2023-12-04 17:28:55','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17697','Using Scalable Vector Graphics (SVG) and Google Sheets to Build a Visual Tool Location Web App','At the University Libraries at Virginia Tech, we recently built a visual kiosk web app for helping patrons in our makerspace locate the tools they need and assist our staff in returning and inventorying our large selection of tools, machines, and consumables. The app is built in Svelte, and uses the Google Sheets "publish to web as csv" feature to pull data from a staff-maintained list of equipment in the space. All of this is tied to a Scalable Vector Graphics (SVG) file that is controlled by JavaScript and CSS to provide an interactive map of our shelving and storage locations, highlighting bins as patrons select specific equipment from a searchable list on the kiosk, complete with photos of each piece of equipment. In this article, you will learn why the app was made, the problems it has solved, why certain technologies were used and others weren''t, the challenges that arose during development, and where the project stands to go from here. ',NULL,'','2023-12-04 17:28:54','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17693','Bringing it All Together: Data from Everywhere to Build Dashboards','This article will talk about how Binghamton University approached building a data dashboard bringing together various datasets, from MySQL, vendor emails, Alma Analytics and other sources. Using Power BI, Power Automate and a Microsoft gateway, we can see the power of easy access to data without knowing all of the disparate systems. We will discuss why we did it, some of the how we did it, and privacy concerns.',NULL,'','2023-12-04 17:28:53','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17695','Real-Time Reporting Using the Alma API and Google Apps Script','When the University of Michigan Library migrated from the Aleph Integrated Library System (ILS) to the Alma Library Services Platform (LSP), many challenges arose in migrating our workflows from a multi-tier client/server structured ILS with an in-house, locally hosted server which was accessed by staff through a dedicated client to a cloud-based LSP accessed by staff through a browser. Among those challenges were deficiencies in timely reporting functionality in the new LSP, and incompatibility with the locally popular macro software that was currently in use. While the Alma LSP includes a comprehensive business intelligence tool, Alma Analytics, which includes a wide variety of out-of-the-box reports and on-demand reporting, it suffers from one big limitation: the data on which the reports are based are a copy of the data from Alma extracted overnight. If you need a report of data from Alma that is timely, Analytics isn’t suitable. These issues necessitated the development of an application that brought together the utility of the Alma APIs and the convenience of the Google Apps Script platform. This article will discuss the resulting tool which provides a real-time report on invoice data stored in Alma using the Google Apps Script platform.',NULL,'','2023-12-04 17:28:52','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17914','Using Airtable to download and parse Digital Humanities Data',replace(replace('Airtable is an increasingly popular cloud-based format for entering and storing research data, especially in the digital humanities. It combines the simplicity of spreadsheets like CSV or Excel with a relational database’s ability to model relationships and link records. The Center for Digital Research in the Humanities (CDRH) at Nebraska uses Airtable data for two projects, African Poetics (africanpoetics.unl.edu) and Petitioning for Freedom (petitioningforfreedom.unl.edu).  In the first project, the data focuses on African poets and news coverage of them, and in the second, the data focuses on habeas corpus petitions and individuals involved in the cases. CDRH’s existing software stack (designed to facilitate display and discovery) can take in data in many formats, including CSV, and parse it with Ruby scripts and ingest it into an API based on the Elasticsearch search index. The first step in using Airtable data is to download and convert it into a usable data format. This article covers the command line tools that can download tables from Airtable, the formats that can be downloaded (JSON being the most convenient for automation) and access management for tables and authentication. Python scripts can process this JSON data into a CSV format suitable for ingesting into other systems The article goes on to discuss how this data processing might work. It also discusses the process of exporting information from the join tables, Airtable’s relational database-like functionality. Join data is not human-readable when exported, but it can be pre-processed in Airtable into parsable formats. After processing the data into CSV format, this article touches on how CDRH API fields are populated from plain values and more complicated structures including Markdown-style links. Finally, this article discusses the advantages and disadvantages of Airtable for managing data, from a developer’s perspective.\r\n','\r',char(13)),'\n',char(10)),NULL,'','2023-12-04 17:28:51','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17818','Leveraging Aviary for Past and Future Audiovisual Collections',replace(replace('Now that audio and video recording hardware is easy to use, highly portable, affordable, and capable of producing high quality content, many universities are seeing a rise in demand for oral history projects and programs on their campuses. The burden of preserving and providing access to this complex format typically falls on the library, oftentimes with no prior involvement or consultation with library staff. This can be challenging when many library staff have no formal training in oral history and only a passing familiarity with the format. To address this issue, librarians at the College of Charleston have implemented AVPreserve’s audiovisual content platform, Aviary, to build out a successful oral history program. \r\n\r\nThe authors will share their experience building new oral history programs that coexist alongside migrated audiovisual materials from legacy systems. They will detail how they approached migrating legacy oral histories in batch form, and how they leveraged Aviary’s API and embed functionalities to present Aviary audiovisual materials seamlessly alongside other cultural heritage materials in a single, searchable catalog. This article will also discuss techniques for managing an influx of oral histories from campus stakeholders and details on how to make efficient use of time-coded transcripts and indices for the best user experience possible.','\r',char(13)),'\n',char(10)),NULL,'','2023-12-04 17:28:50','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17766','Standing Up Vendor-Provided Web Hosting Services at Florida State University Libraries: A Case Study','CreateFSU is Florida State University Libraries’ branded Reclaim Hosting, Domain of One’s Own web-hosting service. CreateFSU provides current FSU faculty, staff, and some students web domains and over 150 popular open-source content management systems including Wordpress, Drupal, Scalar, and Omeka. Since the launch of the service in September 2021, the Libraries have negotiated the demands of providing such a service with various administrative stakeholders across campus, expanded the target audience, provided support and refined our workflows and documentation to make the service fit campus needs. Using this service, members of the FSU community showcase the fruits of their research to a broad audience in ways that are highly accessible and engaging.  More work needs to be done to promote CreateFSU to the FSU community and identify opportunities to integrate the service into existing research and learning workflows. To expand the service to meet new use cases and ensure its scalability, the Libraries hope to convince campus partners to consider its utility to their missions and contribute funding. This article lays out our experiences in launching and hosting this service over its first two years and proposes steps for future development and growth.',NULL,'','2023-12-04 17:28:49','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17929','Islandora for archival access and discovery','This article is a case study describing the implementation of Islandora 2 to create a public online portal for the discovery, access, and use of archives and special collections materials at the University of Nevada, Las Vegas. The authors will explain how the goal of providing users with a unified point of access across diverse data (including finding aids, digital objects, and agents) led to the selection of Islandora 2 and they will discuss the benefits and challenges of using this open source software. They will describe the various steps of implementation, including custom development, migration from CONTENTdm, integration with ArchivesSpace, and developing new skills and workflows to use Islandora most effectively. As hindsight always provides additional perspective, the case study will also offer reflection on lessons learned since the launch, insights on open-source repository sustainability, and priorities for future development.',NULL,'','2023-12-04 17:28:48','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17857','Developing a Multi-Portal Digital Library System: A Case Study of the new University of Florida Digital Collections','The University of Florida (UF) launched the UF Digital Collections in 2006. Since this time, the system has grown to over 18 million pages of content. The locally developed digital library system consisted of an integrated public frontend interface and a production backend. As with other monoliths, being able to adapt and make changes to the system became increasingly difficult as time went on and the size of the collections grew. As production processes changed, the system was modified to make improvements on the backend, but the public interface became dated and increasingly not mobile responsive. A decision was made to develop a new system, starting with decoupling the public interface from the production system. This article will examine our experience in rearchitecting our digital library system and deploying our new multi-portal, public-facing system. After an environmental scan of digital library technologies, it was decided to not use a current open-source digital library system. A relatively new programming team, who were new to the library ecosystem, allowed us to rethink many of our existing assumptions and provided new insights and development opportunities. Using technologies that include Python, APIs, ElasticSearch, ReactJS, PostgreSQL, and more, has allowed us to build a flexible and adaptable system that allows us to hire developers in the future who may not have experience building digital library systems.',NULL,'','2023-12-04 17:28:47','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17751','Jupyter Notebooks and Institutional Repositories:  A Landscape Analysis of Realities, Opportunities  and Paths Forward',replace(replace('Jupyter Notebooks are important outputs of modern scholarship, though the longevity of these resources within the broader scholarly record is still unclear. Communities and their creators have yet to holistically understand creation, access, sharing and preservation of computational notebooks, and such notebooks have yet to be designated a proper place among institutional repositories or other preservation environments as first class scholarly digital assets. Before this can happen, repository managers and curators need to have the appropriate tools, schemas and best practices to maximize the benefit of notebooks within their repository landscape and environments.\r\n\r\nThis paper explores the landscape of Jupyter notebooks today, and focuses on the opportunities and challenges related to bringing Jupyter Notebooks into institutional repositories. We explore the extent to which Jupyter Notebooks are currently accessioned into institutional repositories, and how metadata schemas like CodeMeta might facilitate their adoption. We also discuss characteristics of Jupyter Notebooks created by researchers at the National Center for Atmospheric Research, to provide additional insight into how to assess and accession Jupyter Notebooks and related resources into an institutional repository.','\r',char(13)),'\n',char(10)),NULL,'','2023-12-04 17:28:46','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17867','Beyond the Hype Cycle: Experiments with ChatGPT’s Advanced Data Analysis at the Palo Alto City Library',replace(replace('In June and July of 2023 the Palo Alto City Library’s Digital Services team embarked on an exploratory journey applying Large Language Models (LLMs) to library projects. This article, complete with chat transcripts and code samples, highlights the challenges, successes, and unexpected outcomes encountered while integrating ChatGPT Pro into our day-to-day work.\r\n\r\nOur experiments utilized ChatGPTs Advanced Data Analysis feature (formerly Code Interpreter). The first goal tested the Search Engine Optimization (SEO) potential of ChatGPT plugins. The second goal of this experiment aimed to enhance our web user experience by revising our BiblioCommons taxonomy to better match customer interests and make the upcoming Personalized Promotions feature more relevant. ChatGPT helped us perform what would otherwise be a time-consuming analysis of customer catalog usage to determine a list of taxonomy terms better aligned with that usage. \r\n\r\nIn the end, both experiments proved the utility of LLMs in the workplace and the potential for enhancing our librarian’s skills and efficiency. The thrill of this experiment was in ChatGPT''s unprecedented efficiency, adaptability, and capacity. We found it can solve a wide range of library problems and speed up project deliverables. The shortcomings of LLMs, however, were equally palpable. Each day of the experiment we grappled with the nuances of prompt engineering, contextual understanding, and occasional miscommunications with our new AI assistant. In short, a new class of skills for information professionals came into focus.\r\n','\r',char(13)),'\n',char(10)),NULL,'','2023-12-04 17:28:45','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17820','Comparative analysis of automated speech recognition technologies for enhanced audiovisual accessibility','The accessibility of digital audiovisual (AV) collections is a difficult legal and ethical area that nearly all academic libraries will need to navigate at some point. The inclusion of AV accessibility features like captions and transcripts enormously benefit users with disabilities in addition to providing extra value to the repository more universally. However, implementing these features has proven challenging for many reasons. Recent technological advancements in automatic speech recognition (ASR) and its underlying artificial intelligence (AI) technology offer an avenue for librarians in stewarding more accessible collections. This article will discuss these opportunities and present research from Florida State University Libraries evaluating the performance of different ASR tools. The authors will also present an overview of basic AV accessibility-related concepts, ethical issues in using AI technology, and a brief technical discussion of captioning formats.',NULL,'','2023-12-04 17:28:44','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17823','Using Event Notifications, Solid and Orchestration for Decentralizing and Decoupling Scholarly Communication','The paper presents the case for a decentralized and decoupled architecture for scholarly communication. An introduction to the Event Notifications protocol will be provided as being applied in projects such as the international COAR Notify Initiative and the NDE-Usable program by memory institutions in The Netherlands. This paper provides an implementation of Event Notifications using a Solid server. The processing of notifications can be automated using an orchestration service called Koreografeye. Koreografeye will be applied to a citation extraction and relay experiment to show all these tools fit together.',NULL,'','2023-12-04 17:28:43','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17624','Editorial: Big code, little code, open code, old code','Paraphrasing the title of Christine L. Borgman’s inaugural lecture in Göttingen some years ago “Big data, little data, open data” I could say that the current issue of Code4Lib is about big code, little code, open code, old code. The good side of coding is that effective contribution could be done with different levels and types of background knowledge. The issue proves to us that even small modifications or sharing knowledge about command line usage of a tool might be very useful for the user community. Let’s see what we have!',NULL,'','2023-08-29 09:58:59','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17596','Evaluating HTJ2K as a Drop-In Replacement for JPEG2000 with IIIF',replace(replace('JPEG2000 is a widely adopted open standard for images in cultural heritage, both for delivering access and for creating preservation files that are losslessly compressed. Recently, a new extension to JPEG2000 has been developed by the JPEG Committee: “High Throughput JPEG2000,” better known as HTJ2K.  HTJ2K promises faster encoding and decoding speeds compared to traditional JPEG2000 Part-1, while requiring little or no changes to existing code and infrastructure. The IIIF community has completed a project to evaluate HTJ2K as a drop-in replacement for encoding JPEG2000 and to validate the expected improvements regarding speed and efficiency.\r\n\r\nThe group looked at a number of tools including Kakadu, OpenJPEG, and Grok that support HTJ2K and ran encoding tests comparing the encoding speeds and required disk space for these images. The group also set up decoding speed tests comparing HTJ2K with tiled pyramid TIFF and traditional JPEG2000 using one of the major open source IIIF Image servers, IIPImage. \r\n\r\nWe found that HTJ2K is significantly faster than traditional JPEG2000, though the results are more nuanced when compared with TIFF.\r\n','\r',char(13)),'\n',char(10)),NULL,'','2023-08-29 09:19:13','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17450','Standardization of Journal Title Information from Interlibrary Loan Data: A Customized Python Code Approach','Interlibrary loan (ILL) data plays a crucial role in making informed journal subscription decisions. However, inconsistent or incomplete data associated with journal titles and International Standard Serial Numbers (ISSNs) as data points often entered inaccurately by requestors, presents challenges when attempting to make use of the ILL data. This article introduces a solution utilizing customized Python code to standardize journal titles obtained from user-entered data. The solution incorporates a preprocessing workflow that filters out irrelevant information and employs Application Programming Interfaces (APIs) to replace inaccurate titles with precise ones based on retrieved ISSNs, ensuring data accuracy. The solution then presents the processed data in a dashboard format, highlighting the most requested journals and enabling librarians to interactively explore the data. By adopting this approach, librarians can make well-informed decisions and conduct thorough analysis, resulting in more efficient and effective management of library resources.',NULL,'','2023-08-29 09:18:30','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17502','ChronoNLP: Exploration and Analysis of Chronological Textual Corpora','This article introduces ChronoNLP, a free and open-source web application designed to enable the application of Natural Language Processing (NLP) techniques to textual datasets with a time-based component. This interactive Python platform allows users to filter, search, explore, and visualize this data, allowing the temporal aspect to play a central role in data analysis. ChronoNLP makes use of several powerful NLP libraries to facilitate various text analysis techniques including topic modeling, term/TF-IDF frequency evaluation, automated keyword extraction, named entity recognition and other tasks through a graphical interface without the need for coding or technical knowledge. By highlighting the temporal aspect of specific types of corpora, ChronoNLP provides access to methods of parsing and visualizing the data in a user-friendly format to help uncover patterns and trends in text-based materials.',NULL,'','2023-08-29 09:17:06','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17433','A Very Small Pond: Discovery Systems That Can Be Used with FOLIO in Academic Libraries','FOLIO, an open source library services platform, does not have a front end patron interface for searching and using library materials. Any library installing FOLIO will need at least one other software to perform those functions. This article evaluates which systems, in a limited marketplace, are available for academic libraries to use with FOLIO.',NULL,'','2023-08-29 09:16:47','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17452','Supporting Library Consortia Website Needs: Two Case Studies','LOUIS: The Louisiana Library Network provides library technology infrastructure, electronic resources, affordable learning, and digital literacy support for its 47 academic library members. With this support comes a need to develop web solutions for members, a challenging task as the members have their own websites on a multitude of platforms, and a multitude of library faculty and staff with differing needs. This article details two case studies in developing consortia-specific web design projects. The first summarizes the LOUIS Tabbed Search Box Order Form, an opportunity for members to "order" a custom-made search box for the various services LOUIS supports that can then be embedded on their library''s website. The second involves the LOUIS Community Jobs Board, a member-driven job listing tool that exists on the LOUIS site, but that members can publish jobs to using a Google Form. Both the Search Box Order Form and the Jobs Board have resulted in increased engagement with and satisfaction from member libraries. This article will include best practices, practical solutions, and sample code for both projects.',NULL,'','2023-08-29 09:15:04','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17398','From DSpace to Islandora: Why and How','The article summarizes the experience of switching from DSpace to Islandora. It briefly gives the historical background and reasons for switching to Islandora. It then compares the basic features of the two systems: installation, updates, operations, and customization options. Finally, it concludes practical lessons learned from the migration and provides examples of implemented digital libraries at Masaryk University. ',NULL,'','2023-08-29 09:14:52','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17389','Creating a Full Multitenant Back End User Experience in Omeka S with the Teams Module',replace(replace('When Omeka S appeared as a beta release in 2016, it offered the opportunity for researchers or larger organizations to publish multiple Omeka sites from the same installation. Multisite functionality was and continues to be a major advance for what had become the premiere platform for scholarly digital exhibits produced by libraries, museums, researchers, and students. However, while geared to larger institutional contexts, Omeka S poses some user experience challenges on the back end for larger organizations with numerous users creating different sites. These challenges include a “cluttered” effect for many users seeing resources they do not need to access and data integrity challenges due to the possibility of users editing resources that other users need in their current state. The University of Illinois Library, drawing on two local use cases as well as two additional external use cases, developed the Teams module to address these challenges. This article describes the needs leading to the decision to create the module, the project requirement gathering process, and the implementation and ongoing development of Teams. The module and findings are likely to be of interest to other institutions adopting Omeka S but also, more generally, to libraries seeking to contribute successfully to larger open-source initiatives.\r\n','\r',char(13)),'\n',char(10)),NULL,'','2023-08-29 09:13:43','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17406','The Forgotten Disc: Synthesis and Recommendations for Viable VCD Preservation',replace(replace('As optical media held by cultural heritage institutions has fully transitioned from use as a digital preservation ‘solution’ to a digital preservation risk, an increasing amount of effort has been focused on exploring tools and workflows to migrate the data off of these materials before it is permanently lost to physical degradation. One optical format, however, has been broadly ignored by the existing body of work: the humble Video CD.\r\n\r\nWhile never a dominant format in the Anglosphere, the Video CD, or VCD, held wide popularity from the 1990s through the 2000s in Asia and other regions. As such, a dedicated exploration of preservation solutions for VCD has utility both as a resource for institutions that collect heavily in Pacific Rim materials, as well as a means to, in a minor way, aid in the ongoing efforts to expand the Digital Preservation corpus beyond its traditional focus of issues prevalent in North America and Europe.\r\n\r\nThis paper introduces an overview of VCD as a format and summarizes its unique characteristics that impact preservation decisions and presents the results of a survey of existing tools and methods for the migration of VCD contents. This paper conveys practical methods for migrating VCD material from the original carrier and into both digital preservation and access workflows.\r\n','\r',char(13)),'\n',char(10)),NULL,'','2023-08-29 09:12:51','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17509','Breathing Life into Archon: A Case Study in Working with an Unsupported System','Archival repositories at the University of Illinois Urbana-Champaign Library have relied on Archon to represent archival description and finding aids to researchers worldwide since its launch in 2006. Archon has been officially unsupported software, however, for more than half of this time span. This article will discuss strategies and approaches used to enhance and extend Archon’s functionality during this period of little to no support for maintaining the software. Whether in enhancing accessibility and visual aesthetics through custom theming, considering how to present data points in new ways to support additional functions, or making modifications so that the database would support UTF-8 encoding, a wide variety of opportunities proved possible for enhancing user experience despite the inherent limitations of working with an unsupported system. Working primarily from the skill set of an archivist with programming experience, rather than that of a software developer, the author also discusses some of the strengths emerging from this “on the ground” approach to developing enhancements to an archival access and collection management system.',NULL,'','2023-08-29 09:11:55','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17514','An introduction to using metrics to assess the health and sustainability of library open source software projects','In LYRASIS 2021 Open Source Software Report: Understanding the Landscape of Open Source Software Support in American Libraries (Rosen &#38; Grogg, 2021), responding libraries indicated the sustainability of OSS projects to be an important concern when making decisions about adoption. However, methods libraries might use to gather information about sustainability is not discussed. Metrics defined by the Linux Foundation’s CHAOSS project (<a href="https://www.google.com/url?q=https://chaoss.community/)&#38;sa=D&#38;source=editors&#38;ust=1692370140401368&#38;usg=AOvVaw05dr1HF9_CE1rFbJYQ8Sak">https://chaoss.community/)</a> are designed to measure the health and sustainability of open source software (OSS) communities and may be useful for libraries who are making decisions about adopting particular OSS applications. I demonstrate the use of <a href="https://www.google.com/url?q=http://cauldron.io&#38;sa=D&#38;source=editors&#38;ust=1692370140401992&#38;usg=AOvVaw3dC1Im9mou6UEAJv96FzcV">cauldron.io</a> as one method to gather and visualize the data for these metrics, and discuss the benefits and limitations of using them for decision-making.',NULL,'','2023-08-29 09:10:13','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17443','Searching for Meaning Rather Than Keywords and Returning Answers Rather Than Links',replace(replace('Large language models (LLMs) have transformed the largest web search engines: for over ten years, public expectations of being able to search on meaning rather than just keywords have become increasingly realised. Expectations are now moving further: from a search query generating a list of "ten blue links" to producing an answer to a question, complete with citations.\r\n \r\nThis article describes a proof-of-concept that applies the latest search technology to library collections by implementing a semantic search across a collection of 45,000 newspaper articles from the National Library of Australia''s Trove repository, and using OpenAI''s ChatGPT4 API to generate answers to questions on that collection that include source article citations. It also describes some techniques used to scale semantic search to a collection of 220 million articles.','\r',char(13)),'\n',char(10)),NULL,'','2023-08-29 09:09:42','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://journal.code4lib.org/articles/17352','Editorial: Forget the AI, We Have Live Editors','Welcoming new editors to the Code4Lib Journal',NULL,'','2023-04-21 16:13:59','Cod4Lib Journal','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/12/15/guest-post-introducing-ssps-ai-in-scholarly-publishing-community-of-interest-coin/','Guest Post: Introducing SSP’s AI in Scholarly Publishing Community of Interest (CoIN)',replace('<p>Introducing the AI in Scholarly Publishing Community of Interest (CoIN), the SSP’s latest offering to all its members to explore and engage in all matters AI as they relate to scholarly publishing.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/12/15/guest-post-introducing-ssps-ai-in-scholarly-publishing-community-of-interest-coin/">Guest Post: Introducing SSP&#8217;s AI in Scholarly Publishing Community of Interest (CoIN)</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-12-15 10:30:11','Scholarly Kitchen','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/12/14/humanities-and-jobs-data-whats-the-real-story/','Humanities and Jobs Data:  What’s the Real Story?',replace('<p>Escalating attacks on the humanities often cite the problem of employment for humanities majors; a new report shows otherwise.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/12/14/humanities-and-jobs-data-whats-the-real-story/">Humanities and Jobs Data:  What&#8217;s the Real Story?</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-12-14 10:30:19','Scholarly Kitchen','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/12/13/guest-post-an-interview-with-prof-dr-liying-yang-of-the-chinese-academy-of-sciences/','Guest Post: An Interview with Prof. Dr. Liying Yang of the Chinese Academy of Sciences',replace('<p>Mary Miskin offers an interview with Prof. Dr. Liying Yang, Director of the Scientometrics and Research Assessment Unit at the National Science Library, Chinese Academy of Sciences, who manages the Early Warning List and the CAS Journal Ranking.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/12/13/guest-post-an-interview-with-prof-dr-liying-yang-of-the-chinese-academy-of-sciences/">Guest Post: An Interview with Prof. Dr. Liying Yang of the Chinese Academy of Sciences</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-12-13 10:30:30','Scholarly Kitchen','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/12/12/can-academia-afford-a-holiday-hiatus-from-publish-or-perish/','Can Academia Afford a Holiday Hiatus from Publish or Perish?',replace('<p>As we contemplate a pause during the holiday season, we must ask ourselves: Isn''t the researcher''s overall well-being as crucial as the research itself?</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/12/12/can-academia-afford-a-holiday-hiatus-from-publish-or-perish/">Can Academia Afford a Holiday Hiatus from Publish or Perish?</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-12-12 10:30:36','Scholarly Kitchen','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/12/11/guest-post-food-for-thought-what-are-we-feeding-llms-and-how-will-this-impact-humanity/','Guest Post — Food for Thought: What Are We Feeding LLMs, and How Will this Impact Humanity?',replace('<p>Academia has developed an amazing tree of knowledge which is arguably the most important data for Large Language Models to be trained on. Where does the scholarly communication community fit in?</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/12/11/guest-post-food-for-thought-what-are-we-feeding-llms-and-how-will-this-impact-humanity/">Guest Post &#8212; Food for Thought: What Are We Feeding LLMs, and How Will this Impact Humanity?</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-12-11 10:30:01','Scholarly Kitchen','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/12/08/bird-speed-scale-bar/','Bird Speed Scale Bar',replace('<p>A data visualization showing the relative speeds of various birds.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/12/08/bird-speed-scale-bar/">Bird Speed Scale Bar</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-12-08 10:30:10','Scholarly Kitchen','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/12/07/where-did-the-open-access-movement-go-wrong-an-interview-with-richard-poynder/','Where Did the Open Access Movement Go Wrong?: An Interview with Richard Poynder',replace('<p>Noted journalist and scholarly communication observer Richard Poynder explains why he has given up on the open access movement.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/12/07/where-did-the-open-access-movement-go-wrong-an-interview-with-richard-poynder/">Where Did the Open Access Movement Go Wrong?: An Interview with Richard Poynder</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-12-07 10:30:54','Scholarly Kitchen','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/12/06/the-impact-of-stereotypes-on-mental-wellbeing/','The Impact of Stereotypes on Mental Wellbeing',replace('<p>When we discuss systemic racism and the impact it has had to date, we must consider the stereotypes that have been put upon Black women for centuries and how that affects mental wellbeing.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/12/06/the-impact-of-stereotypes-on-mental-wellbeing/">The Impact of Stereotypes on Mental Wellbeing</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-12-06 10:30:39','Scholarly Kitchen','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/12/05/problem-heart-public-access/','The Problem at the Heart of Public Access',replace('<p>The intended beneficiary of public access is “the American public,” and we need so much more than access to the biomedical literature.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/12/05/problem-heart-public-access/">The Problem at the Heart of Public Access</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-12-05 10:30:33','Scholarly Kitchen','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/12/04/ask-the-chefs-the-us-executive-order-on-artificial-intelligence/','Ask The Chefs: The US Executive Order on Artificial Intelligence',replace('<p>We asked the Chefs for their thoughts on the Biden Administration''s Executive Order on “Safe, Secure, and Trustworthy Artificial Intelligence.”</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/12/04/ask-the-chefs-the-us-executive-order-on-artificial-intelligence/">Ask The Chefs: The US Executive Order on Artificial Intelligence</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-12-04 10:30:04','Scholarly Kitchen','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/12/01/chefs-selections-best-books-read-and-favorite-cultural-creations-during-2023-part-3/','Chefs’ Selections: Best Books Read and Favorite Cultural Creations During 2023, Part 3',replace('<p>The beginning of the holiday season means it’s time for our annual list of our favorite books read (and other cultural creations experienced) during the year.  Part 3 today.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/12/01/chefs-selections-best-books-read-and-favorite-cultural-creations-during-2023-part-3/">Chefs&#8217; Selections: Best Books Read and Favorite Cultural Creations During 2023, Part 3</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-12-01 10:30:01','Scholarly Kitchen','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/11/30/chefs-selections-best-books-read-and-favorite-cultural-creations-during-2023-part-2/','Chefs’ Selections: Best Books Read and Favorite Cultural Creations During 2023, Part 2',replace('<p>The beginning of the holiday season means it’s time for our annual list of our favorite books read (and other cultural creations experienced) during the year.  Part 2 today.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/11/30/chefs-selections-best-books-read-and-favorite-cultural-creations-during-2023-part-2/">Chefs&#8217; Selections: Best Books Read and Favorite Cultural Creations During 2023, Part 2</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-11-30 10:30:26','Scholarly Kitchen','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/11/29/chefs-selections-best-books-read-and-favorite-cultural-creations-during-2023-part-1/','Chefs’ Selections: Best Books Read and Favorite Cultural Creations During 2023, Part 1',replace('<p>The beginning of the holiday season means it’s time for our annual list of our favorite books read (and other cultural creations experienced) during the year.  Part 1 today.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/11/29/chefs-selections-best-books-read-and-favorite-cultural-creations-during-2023-part-1/">Chefs&#8217; Selections: Best Books Read and Favorite Cultural Creations During 2023, Part 1</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-11-29 10:30:51','Scholarly Kitchen','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/11/28/the-united-states-copyright-office-notice-of-inquiring-on-ai-a-quick-take/','The United States Copyright Office Notice of Inquiry on AI:  A Quick Take',replace('<p>A selection of questions and answers from Copyright Clearance Center''s response to the United States Copyright Office “Artificial Intelligence and Copyright" request for comment.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/11/28/the-united-states-copyright-office-notice-of-inquiring-on-ai-a-quick-take/">The United States Copyright Office Notice of Inquiry on AI:  A Quick Take</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-11-28 10:30:09','Scholarly Kitchen','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/11/27/mental-health-awareness-mondays-ask-the-presidents-why-is-it-important-for-ssp-to-support-the-mental-health-of-our-members/','Mental Health Awareness Mondays — Ask the Presidents: Why is it Important for SSP to Support the Mental Health of Our Members?',replace('<p>For today''s post we asked SSP''s Past Presidents to tell us why is it important for SSP to support the mental health of our members, especially around work-related issues. Read on to hear what they have to say</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/11/27/mental-health-awareness-mondays-ask-the-presidents-why-is-it-important-for-ssp-to-support-the-mental-health-of-our-members/">Mental Health Awareness Mondays &#8212; Ask the Presidents: Why is it Important for SSP to Support the Mental Health of Our Members?</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-11-27 10:30:54','Scholarly Kitchen','',NULL,'2023-12-15 15:47:35','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2016/02/are-predatory-journals-completely_11.html','Are ‘predatory’ journals completely negative, or also a sign of something positive? *',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\n<div class="p1">\n<span class="s1"><span style="font-size: x-small;">* This post was first published on the&nbsp;<a href="http://blog.scielo.org/en/2016/02/02/are-predatory-journals-completely-negative-or-also-a-sign-of-something-positive/" target="_blank">SciELO in Perspective</a>&nbsp;blog, on February 2nd, 2016 (and translations in <a href="http://blog.scielo.org/blog/2016/02/02/seriam-os-periodicos-predatorios-totalmente-negativos-ou-tambem-um-sinal-de-algo-positivo/" target="_blank">Portuguese</a> and <a href="http://blog.scielo.org/es/2016/02/02/son-las-revistas-depredadoras-algo-completamente-negativo-o-tambien-una-senal-de-algo-positivo/" target="_blank">Spanish</a> are available on SciELO in Perspective as well).</span></span></div>\n<div class="p1">\n<span class="s1"><br /></span></div>\n<div class="p1">\n<span class="s1">It’s not nice for parents to find that their toddler child is telling lies – or at least trying to tell lies. But is it so bad? It seems that the ability to tell lies is a sign of a well-developing theory of mind. And a well-developed&nbsp;<a href="http://en.wikipedia.org/wiki/Theory_of_mind" target="_blank">theory of mind</a>&nbsp;is very helpful in social interaction and things like having empathy would be very difficult without it. So if your child is beginning to tell lies, it might be cause for celebration rather than regret! [1] Of course, it doesn’t mean that lying should be unconditionally encouraged, but a well-developed theory of mind may actually help in developing proper morals as well when the child grows up.</span></div>\n<div class="p1">\n<span class="s1"><br /></span></div>\n<div class="p1">\n<span class="s1">The emergence of so-called ‘predatory journals’ (see&nbsp;<a href="http://scholarlyoa.com/publishers/" target="_blank">Beall’s list of predatory publishers</a></span><span class="s1">) could be seen in a similar light. Predatory journals are not desirable, it goes without saying, but the fact that they come about is a sign of a developing market, and a true market in scientific publishing services is a good thing, in my view. A true market offers choice to the party who pays. In the classical subscription model of scholarly journal literature, the party who pays is typically the institutional library, and they have little or no choice as to which journal to subscribe to and which not, if the journals are considered to be relevant to the research being carried out at their institution. And if they are forced to make a choice, for instance because of lack of funds, it is an agonising decision which choice to make.</span></div>\n<div class="p1">\n<span class="s1"><br /></span></div>\n<div class="p1">\n<span class="s1">In some countries – in Latin America, but also The Netherlands, for instance – the government is playing a direct role in negotiations with publishers to provide access to scientific literature. In principle, this results in a single buyer, countering the effect of a publisher monopoly by being able to bring much more negotiating clout to the table, and as a result quite possibly wider access (as is indeed being reported from Latin America [2</span><span class="s2">]</span><span class="s1">). But it doesn’t amount to a functioning market. The absence of a real choice is not remedied. Even a government cannot just choose to provide access to one publisher’s content at the exclusion of others, simply because no single publisher provides all the content the research community needs. And a monopoly (single provider)/monopsony (single buyer) system has drawbacks as well. It has a tendency to lock in a certain balance of powers (or an imbalance; Stockholm Syndrome has been mentioned to me in that regard), and in doing so, presents an impediment to progress in the quest for increasing efficiency at decreasing cost. It removes, or at least diminishes, the incentives of individual or small players to decide to buy or sell at a range of prices and service levels. For authors, for instance, it removes any economic motivation to decide to publish in low-APC journals or to communicate their research results via preprint servers. And it makes it very difficult for new publishing initiatives to gain a foothold.</span></div>\n<div class="p1">\n<span class="s1"><br /></span></div>\n<div class="p1">\n<span class="s1">A true functioning market is not just ‘peaches and cream’, though, since any true market also attracts rogues. And predatory journals certainly are. (By the way, I remain to be convinced that all publishers and journals on Beall’s list are indeed genuinely predatory; it is my impression that some of his&nbsp;<a href="https://scholarlyoa.files.wordpress.com/2015/01/criteria-2015.pdf" target="_blank">criteria</a>&nbsp;are rather shaky.) The existence of rogues is an inevitability of human nature, I’m afraid, but to authors, the attraction, insofar as there is one, of potentially predatory journals comes in part from their usually low charges and quick publication.</span></div>\n<div class="p1">\n<span class="s1"><br /></span></div>\n<div class="p1">\n<span class="s1">Yet, even with the drawback of being polluted by predatory journals, a functioning market is preferable to a quasi-market, completely dominated by monopolies or monopoly-like players. A system of subscriptions, in which the party who pays – the institutional library – has practically no meaningful choice of what to buy, differs from one of article processing charges (APCs, which make open access possible), in that the party who pays ­– the author – is the party who does have a meaningful choice of where to submit and publish. So ‘flipping’ the system from subscriptions to APCs does deliver something much more akin to a functioning market, and ‘caveat emptor’, ‘buyer beware’, applies to all markets.</span></div>\n<div class="p1">\n<span class="s1"><br /></span></div>\n<div class="p1">\n<span class="s1">It is not strictly true, of course, that in an APC system the author pays. It is most often the funder who does, by including the means to pay in the authors’ grants. This leads me to think that the subscription system could also be made to work as a quasi-market, if authors (the ones having the real choice) were made aware of the cost of the choices they make. This would be the case if authors had to find or request money in their grants for articles published in subscription journals as well, and not just for articles published in APC-supported open access ones. Imagine what will happen if authors were presented with a bill – of, say, $5000, a reasonable estimate of the collective cost per article of subscription journals; more for so-called ‘prestige’ journals – by their institution for every article they publish in a subscription journal. The likelihood is that they will more often choose APC-supported open venues, especially when it is slowly dawning upon the scientific community that openness in itself is an essential part of the quality of a published article [3].</span></div>\n<div class="p1">\n<span class="s1"><br /></span></div>\n<div class="p1">\n<span class="s1">Making researchers responsible for the financial aspects of their publishing decisions also fits into the general logic of public policies, which put the responsibility of how grants are used on the researchers, after all. Besides, responsibilities that focus on the per-article publishing costs incurred are naturally more scalable with the growth of research output.</span></div>\n<div class="p1">\n<span class="s1"><br /></span></div>\n<div class="p1">\n<span class="s1">This may even help solving the underlying problem with the current journal publishing system: the conflation of scientific communication and career-advancing reputation management [4]. This goes beyond what publishers do: in many cases, the same institutions in charge of purchase decisions of journals are also in charge of research promotion and evaluation, which is mostly – if unjustifiably – based on journal prestige, which may well constitute a conflict of interest. The consequence of separating the two may be that more articles are posted as so-called ‘preprints’ (for communication) and that not all of those are subsequently published in journals (for career purposes), given the cost of the latter. Global preprint repositories such as arΧiv, bioRχiv, and others, would acquire critical importance in that scenario. I am not dismissing the need for reputation building and career progression, but should that really stand in the way of communication for the sake of scientific progress? Is it right that the results of research – particularly of research carried out supported by public funds – should be used primarily for the purpose of authors’ reputation stratification (establishing a ‘pecking order’) via journals, many of which are not openly accessible?</span></div>\n<div class="p1">\n<span class="s1"><br /></span></div>\n<div class="p1">\n<span class="s1">The publishers of journals will say that establishing a pecking order is not their only task, or even their most important one. Most of them maintain that their gate-keeping function, via the peer review they commission, is their true&nbsp;<i>raison d’être</i>. This is a strange argument, as they are only in control of the gate to their tiny little patch of the vast forest. Virtually every article can find a journal in which to be published and so be added to the scholarly literature. What is presented as gate-keeping is in effect just sorting and ranking articles according to vague criteria such as ‘quality’ or ‘relevance’ and therefore not distinguishable from establishing a pecking order. It may help some scientists, but it doesn’t help science. On the contrary: scientific communication is being held hostage by pecking order concerns. And what’s more, these efforts are costing the scientific community a great deal. In time, money, and impediments to sharing knowledge.</span></div>\n<div class="p1">\n<span class="s1"><br /></span></div>\n<div class="p1">\n<span class="s1">It bears repeating: scientific communication and reputation management should not be combined in the same system.</span></div>\n<div class="p1">\n<span class="s1"><br /></span></div>\n<div class="p1">\n<span class="s1">Apart from the obvious costs mentioned, this kind of ‘gate-keeping’ is abusing peer review. Not only does it cause ‘cascading’, many articles being rejected, resubmitted elsewhere, being rejected again, et cetera, until they are eventually accepted. At each stage needing peer review again, and so being a tremendous burden on peer reviewers. Peer review should be aimed at helping authors to improve their articles, by questioning assertions, methods, and the like, and only as a last resort rejecting for publication (in the way of some open access journals such as PLOS-One). In this light, the emergence of ‘easy’ journals, even ‘predatory’ ones, is not miraculous. It takes some getting used to, I presume, but I see great potential in an approach like this: author-arranged open peer review [5].</span></div>\n<div class="p1">\n<span class="s1"><br /></span></div>\n<div class="p1">\n<span class="s1">Jan Velterop</span></div>\n<div class="p1">\n<span class="s1"><br /></span></div>\n<div class="p2">\n<span class="s1">References</span></div>\n<div class="p1">\n1. PAN DING, X;&nbsp;<i>et al</i>. Theory-of-Mind Training Causes Honest Young Children to Lie.&nbsp;<i>Psychological Science.</i>&nbsp;2015, vol. 26 nº 11, pp. 1812-1821. DOI:&nbsp;<span class="s3"><a href="http://dx.doi.org/10.1177/0956797615604628">10.1177/0956797615604628</a></span></div>\n<div class="p1">\n<span class="s3">2.&nbsp;</span>Personal communication.</div>\n<div class="p2">\n3. VELTEROP, J.&nbsp;<i>Openness and quality of a published article</i>. SciELO in Perspective. [viewed 27 January 2016]. Available from:&nbsp;<a href="http://blog.scielo.org/en/2015/12/16/openness-and-quality-of-a-published-article/"><span class="s3">http://blog.scielo.org/en/2015/12/16/openness-and-quality-of-a-published-article/</span></a></div>\n<div class="p1">\n<span class="s1">4.<i>&nbsp;</i></span>VELTEROP, J.&nbsp;<i>Science (which needs communication) first, careers (which need selectivity) later</i>. SciELO in Perspective. [viewed 27 January 2016]. Available from:&nbsp;<span class="s3"><a href="http://blog.scielo.org/en/2015/10/29/science-which-needs-communication-first-careers-which-need-selectivity-later/">http://blog.scielo.org/en/2015/10/29/science-which-needs-communication-first-careers-which-need-selectivity-later/</a></span></div>\n<div class="p1">\n5.<i>&nbsp;Peer Review by Endorsement (PRE).</i>&nbsp;ScienceOpen. Available from:&nbsp;<span class="s3"><a href="http://about.scienceopen.com/peer-review-by-endorsement-pre/">http://about.scienceopen.com/peer-review-by-endorsement-pre/</a></span></div>\n<div>\n<br /></div>\n</div>','\n',char(10)),NULL,'','2016-02-11 12:21:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2015/08/peer-review-by-endorsement.html','Peer Review By Endorsement',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\n<div class="tr_bq">\nBelow is the original proposal that eventually led <a href="https://www.scienceopen.com/" target="_blank">ScienceOpen</a> to give it a go and make <a href="http://blog.scienceopen.com/2015/04/welcome-jan-velterop-peer-review-by-endorsement/" target="_blank">''Peer Review by Endorsement''</a> a legitimate, efficient, and affordable alternative to the generally (very) expensive publisher-mediated peer review mechanism we all know.</div>\n<br />\nIt was originally called JONAS, for Journal Of Nature And Science, as a way to indicate the wide potential for this approach in terms of disciplines covered, and yes, a gentle play on the titles of prestige journals, also known sometimes as ''glam'' journals :-).<br />\n<br />\n(The idea of JONAS has something in common, of course, with the idea of overlay journals that have at various times over the last decade and a half been suggested for manuscripts deposited in arXiv, whereby peer review reports were added to them and so giving the article some ''official'' publication status.)<br />\n<br />\nThis is the original proposal:<br />\n<blockquote>\n<span class="s1"><b>JONAS</b> (Journals Of Nature And Science – working title) is a new approach to open access publication of peer-reviewed scientific literature.</span><br /><span class="s1">Establishing a publishing system that addresses:<br /><ul style="text-align: left;">\n<li>Open access,&nbsp;</li>\n<li>Fair and efficient peer review, &nbsp;</li>\n<li>Cost of publishing</li>\n<li>Speed of publishing</li>\n<li>Publication of negative/null results</li>\n</ul>\n</span><span class="s1"><b>Open Access.</b> The JONAS publishing system focuses on the superb technical publication, in various formats/versions, of peer-reviewed articles for optimal machine and human readability and re-use.</span></blockquote>\n<blockquote>\n<span class="s1"><b>Fair and efficient peer review.</b> Anonymous peer review has problems around issues of transparency, fairness, thoroughness, speed, publisher-bias, specious requests for further experiments or data, and possibly more. JONAS is a system using signed, pre-publication peer review, arranged by the author(s) (many publishers ask authors who to invite to review their papers anyway), and just verified by the publisher (peer review by endorsement). Reviews will be open, published with the article that’s endorsed, non-anonymous, and the rules are that peer-endorsers must be active researchers, and not be, or for at least five years have been, at the same institution as, or a co-author of, any of the authors. Such a peer-review-by-endorsement system is likely to be at least as good as, and quite probably better than, the currently widespread ‘black box’ of anonymous peer review. As reviews/endorsements would be signed and non-anonymous, there is very little danger of sub-standard articles being published, as endorsers/reviewers would not want to put their reputations at risk. The review process between authors and endorsers is likely to be iterative, resulting in improvements on the original manuscripts. “Author-arranged” may include peer review being done by services specifically set up for that purpose, as long as the reviewers are not anonymous and conform to the JONAS rules.&nbsp;</span>&nbsp;</blockquote>\n<blockquote>\n<span class="s1"></span><span class="s1"><b>Cost of publishing.</b> A system like this can be very cost-effective for authors. The technical costs of publishing are but a fraction of the cost usually quoted for organising and arranging peer review. First indication is that an amount in the order of a few hundred pounds sterling (£) per article can be sustainable, given sufficient uptake. Tiered charges could be considered depending on the state of the manuscript when submitted. If the manuscript needs very little work to bring it up to proper publishing standards, or if the author doesn’t want or need those services, the cost can be very low indeed.</span>&nbsp;</blockquote>\n<blockquote>\n<span class="s1"><b>Speed of publishing.</b> Since the peer-review-by-endorsement process has already taken place before the article arrives at the publisher, publication can ensue within days, even hours, depending on the state of the manuscript.</span><br /><span class="s1">Requirements for manuscripts: ORCIDs for authors and reviewers/endorsers; inclusion of (permanent links to) datasets used, underlying data for graphs, a section “details for replicability and reproducibility” with clear and unambiguous identification of materials used, including reagents, software and other non-standard tools and equipment.</span><span class="s1">&nbsp;&nbsp;</span><span class="s1"><b>Input</b>: Properly endorsed articles to be accepted in the form of Word, Pages, (LA)TEX, XML, HTML, Markdown, and Excel or CSV for data, and high-resolution image files (where possible scalable vector graphics) via an upload site or attached to emails.</span>&nbsp;</blockquote>\n<blockquote>\n<span class="s1"><b>Output</b>: Articles would be published as XML, HTML, PDF, ODF and ePub formats, as much as possible semantically enriched and aesthetically formatted, plus Excel/CSV for data (tables extractable and rendered in Excel from PDFs with software freely supplied).</span>&nbsp;</blockquote>\n<blockquote>\n<span class="s1"><b>Commenting and post-publication review</b>: to be enabled and encouraged for all articles, links to comments to be provided with each article. Comments may be made on different sites, and will be linked to, if that is the case. Anonymous comments will be ignored.</span>&nbsp;</blockquote>\n<blockquote>\n<span class="s1"><b>Access Licences</b>: CC-BY or CC0 — DOIs for the articles would be assigned/arranged by JONAS.</span>&nbsp;</blockquote>\n<blockquote>\n<span class="s1"><b>The core of the JONAS system</b> is effectively to have OA journals with a low-cost structure, with superb and highly optimised technical quality of the published articles (machine-readability and re-useability!). The principal difference with other OA journals would be the pre-arranged open peer review ("peer-review-by-endorsement"), organised by the authors themselves, according to a set of rules that ensures a reasonable level of assurance against reviewer bias (because of its openness and non-anonymity, actually more assurance than is provided in the usual anonymous peer review as widely practiced). Since arranging peer review is one of the major costs of any publisher (mostly staff costs), leaving that part of the publishing process in the hands of researchers and the academic community can make a great difference to the cost of publication. So far, efforts to reduce the cost of publishing have been concentrated on technical issues. Changing the mechanism (emphatically not the principle) of peer review offers much greater scope for cost reduction.</span>&nbsp;</blockquote>\n<blockquote>\n<span class="s1">What JONAS'' job would be is to take such peer-endorsed articles and make them into professionally published and complete (including data and metadata) documents, adhering to all the technical, presentational and unique identifier standards, in a number of formats, linked and linkable to databases and other relevant information, human- and machine-readable and suitable for widespread usage, for text- and data-mining, for structured analysis (incl. semantic analysis) and further knowledge discovery, and, crucially, for long-term preservation in repositories and archives of any kind.</span>&nbsp;</blockquote>\n<blockquote>\n<span class="s1">Any manuscript submitted in advance of peer-endorsement having been procured, would be placed, ‘as is’, on JonasPrePubs, a ‘preprint’ server, at no cost.</span>&nbsp;</blockquote>\n<blockquote>\n<span class="s1">The JONAS publishing system is also <b>superbly suited to scientific societies</b> and other groupings that wish to have their own journal. Such a journal can be fully integrated in the JONAS system, provided the manuscripts are submitted fully peer-endorsed or peer-reviewed (whether or not arranged by the author(s) or the scientific society in question).</span>&nbsp;<span class="s1">The charges per manuscript for individual authors and for societies wishing to publish their journals in the JONAS system would be the same.</span>&nbsp;</blockquote>\n<blockquote>\n<span class="s1">The JONAS methodology could be implemented on various publishing platforms.</span></blockquote>\n<div class="p2">\n<span class="s1"></span></div>\n<div class="p2">\n<span class="s1"></span></div>\n<div class="p2">\n<span class="s1"></span></div>\n<div class="p2">\n<span class="s1"></span></div>\n<div class="p2">\n<span class="s1"></span></div>\n<div class="p2">\n<span class="s1"></span></div>\n<div class="p2">\n<span class="s1"></span></div>\n<div class="p2">\n<span class="s1"></span></div>\n<div class="p2">\n<span class="s1"></span></div>\n<div class="p2">\n<span class="s1"></span></div>\n<div class="p2">\n<span class="s1"></span></div>\n<br />\nJan Velterop<br />\n<br /></div>','\n',char(10)),NULL,'','2015-08-16 09:29:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2015/07/levelling-open-access-paywall-playing.html','Levelling the Open Access – Paywall Playing Field for Authors',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\n<div class="p1">\nEarly career researchers are often reported to express the view that they face a dilemma. Submit to – and hopefully publish in – an open access journal, with possibly a relatively low impact factor, or in a traditional, pay-walled journal with a relatively high impact factor.</div>\n<div class="p2">\n<br /></div>\n<div class="p1">\nGiven the large number of traditional pay-walled journals with low, or no, impact factors, I find this not the most credible argument. And even for ‘glam’ journals there are now good open access alternatives.</div>\n<div class="p2">\n<br /></div>\n<div class="p1">\nAnd yet, there are moments when I understand researchers when they are having to decide where to submit their papers. Do they choose an older subscription-supported journal, or a younger APC-supported open access journal? In the latter case, they’ll have to find the funds to pay the Article Processing Charge; in the former, they don’t, since subscriptions are paid out of the library budget. &nbsp;It does make a difference to a researcher''s perception. Even though in many cases it is the funder who provides the money for the APCs, the researchers are aware of the cost and part of the decisions they take are financial/economic ones, even if sometimes subconsciously. They are not confronted with financial/economic decisions if they submit to a paywalled journal. Convenience may set in, perhaps in the form of a certain laziness, and a decision to stick with the old hassle-free subscription journals is easily taken.</div>\n<div class="p2">\n<br /></div>\n<div class="p1">\nIt may happen here and there, but what I have not seen is attempts by the library community to confront researchers with the cost of paywalled journals. I''m not talking about the subscription price, but about the cost to the system of a single paper published in such a journal. It is a significant cost. For subscription journals published by the major publishers, this is on average in excess of $5000 (there are differences depending on the publisher), and for the ‘glam’ journals presumably more, much more (<span class="s1">Phil Campbell, editor-in-chief of <i>Nature</i>, <a href="http://www.nature.com/news/open-access-the-true-cost-of-science-publishing-1.12676" target="_blank">estimated costs of $30,000–40,000 per paper in 2013</a></span><span class="s2">.</span> That’s costs to the publisher; costs to the system will be higher, as they include profits.)</div>\n<div class="p2">\n<br /></div>\n<div class="p1">\nNow imagine that universities, perhaps via their libraries, take care of any payment to publishers, be they subscription charges or APCs, and then reclaim a per-article fee from their grants whenever researchers publish their articles. The amounts for APCs identical to the amount charged by the open access journal in question, of course; the amounts for articles in subscription journals on the basis of the average per-article revenue of the publisher of those journals. (These amounts may be reasonable estimates, I imagine, as they will seldom be known in detail.) The amounts thus reclaimed for articles in subscription journals could then be used for the journal acquisitions budget.&nbsp;</div>\n<div class="p2">\n<br /></div>\n<div class="p1">\nI have no illusion that this would solve all the problems of the cost of scientific publication, but it will increase general awareness of the true cost of publishing in subscription journals, and may help to level the playing field, to use an old cliché, between open access and pay-walled literature in the mind of scientists at the point when they decide where to publish their papers.&nbsp;</div>\n<div class="p2">\n<br /></div>\n<div class="p2">\nJan Velterop</div>\n</div>','\n',char(10)),NULL,'','2015-07-20 14:31:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2015/07/dealing-with-information-overload.html','Dealing with information overload*',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\n<span style="background-color: white; color: #2f2f2f; font-family: Helvetica; font-size: 14px; line-height: 21px;">Are we overwhelmed by the amount of scientific information that is being published? PubMed adds an average of more than two abstracts a minute to its database, and that is just in the life and medical sciences. If that doesn’t amount to information overload, what does?</span><br />\n<span style="background-color: white; color: #2f2f2f; font-family: Helvetica; font-size: 14px; line-height: 21px;"><br /></span>\n<span style="background-color: white; color: #2f2f2f; font-family: Helvetica; font-size: 14px; line-height: 21px;">[<a href="http://blog.scielo.org/en/2015/05/18/dealing-with-information-overload/" target="_blank">More...</a>]</span><br />\n<span style="background-color: white; color: #2f2f2f; font-family: Helvetica; font-size: 14px; line-height: 21px;"><br /></span>\n<span style="background-color: white; color: #2f2f2f; font-family: Helvetica; font-size: 14px; line-height: 21px;">*</span><span style="background-color: white; color: #2f2f2f; font-family: Helvetica; line-height: 21px;"><span style="font-size: xx-small;">This post was first published May 18th 2015 on the SciELO blog. The ''<a href="http://blog.scielo.org/en/2015/05/18/dealing-with-information-overload/" target="_blank">more</a>'' link redirects to that blog.</span></span></div>','\n',char(10)),NULL,'','2015-07-07 09:24:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2015/05/keeping-minutes-of-science-looking-back.html','Keeping the Minutes of Science – Looking back 20 years',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\n<div class="page" title="Page 1">\n   <div class="layoutArea">\n    <div class="column">\n     <span style="font-family: Helvetica Neue, Arial, Helvetica, sans-serif;">I attended the Royal Society discussions on the Future of Scholarly Scientific Communication, held in <a href="https://royalsociety.org/events/2015/04/future-of-scholarly-scientific-communication-part-1/" target="_blank">two</a> <a href="https://royalsociety.org/events/2015/05/future-of-scholarly-scientific-communication-part-2/" target="_blank">sessions</a> of two days, the last one ending yesterday. Most interesting meetings. (Tweets from the meetings under the hash tag #FSSC).</span><br />\n<span style="font-family: Helvetica Neue, Arial, Helvetica, sans-serif;"><br /></span>\n<span style="font-family: Helvetica Neue, Arial, Helvetica, sans-serif;">The discussions brought back memories of an article I wrote 20 years ago, on "Keeping the Minutes of Science". I re-read it this morning, and it is interesting (to me at any rate) how my thoughts have evolved, from just before the introduction of what later became known as the ''Big Deal'', when this article was written, via becoming an <a href="http://www.budapestopenaccessinitiative.org/read" target="_blank">Open Access advocate</a> a few years later (before it was even called open access yet) to proposing to <a href="http://blog.scienceopen.com/2015/04/welcome-jan-velterop-peer-review-by-endorsement/" target="_blank">change the way peer review is done</a>.</span><br />\n<span style="font-family: Helvetica Neue, Arial, Helvetica, sans-serif;"><br /></span>\n<span style="font-family: Helvetica Neue, Arial, Helvetica, sans-serif;">I was at Academic Press at the time (well before it was taken over by Elsevier), which may explain some of the thoughts I then had. I am posting the full article below. (The bibliographic reference to the original is&nbsp;</span><span style="font-family: ''Helvetica Neue'', Arial, Helvetica, sans-serif;">J.J.M. Velterop, “Keeping the Minutes of Science.” In: Electronic library and visual information research (Elvira 2). Edited by Mel Collier and Kathryn Arnold. Proceedings of the second ELVIRA conference, held in May 1995 at De Montfort University, Milton Keynes. Aslib. 1995, pp 11-17.)</span><br />\n<span style="font-family: ''Helvetica Neue'', Arial, Helvetica, sans-serif; font-size: 12px;"><br /></span>\n<span style="font-family: Helvetica Neue, Arial, Helvetica, sans-serif;">The article:</span><br />\n<blockquote class="tr_bq">\n<span style="font-family: Times, Times New Roman, serif;">KEEPING THE MINUTES OF SCIENCE</span></blockquote>\n<blockquote class="tr_bq">\n<span style="font-family: Times, Times New Roman, serif;">INTRODUCTION<br />\n<span style="font-size: 12pt;">Scientific journal publishing differs markedly from most other kinds of publishing.\nBorn out of the exchange of letters on scientific topics and results, it has evolved into\nas much a service to scientists who need to publish the results of their work, as a\nservice to those who need to be kept abreast of scientific developments elsewhere.\nUnlike most other publishing, scientific journal publishing has as much to do with the\nproper recording of scientific activity as with the conveyance of information. As far as\nthe latter is concerned, scientists do not rely on scientific journals alone any more, in\norder to keep informed. Journals are only one of the variety of ways in which\nscientists gather scientific information. However, scientific information that comes to\na scientist via a scientific journal still carries the highest degree of authority for\ninformation, as it has been peer reviewed and gone through a certification and\nvalidation process before reaching the reader.<br />\n</span><span style="font-size: 12pt;">For the author a scientific journal is essential. There are currently no other ways for a\nscientist to get his work certified and validated than publishing in a journal of good\nreputation. This certification and validation process is of immense value to science. It\nis to a large degree the result of a long self-organising process that has grown into a\nhighly sophisticated structure (including a “pecking order” of journals) in which\nscientific results are placed in a hierarchical context, are ‘taxonomised’, standardised,\nformalised, made accessible through a uniform and globally accepted reference\nsystem. It forms the backbone of a scientific archive.<br />\n</span><span style="font-size: 12pt;">Scientists, libraries and publishers share a responsibility to protect and safeguard this\nelegant system of “keeping the minutes of science”. Collapse of this system is\nsomething science can ill afford, even though in the future it is quite possible that new\nsystems will arise and eventually be standardised and become globally accepted. A\nhiatus of a number of years, however, will do great damage to the continuity of\nscientific research and if there is to be a transition into a new situation, it has to be\ncarefully managed.<br />\n</span><span style="font-size: 12pt;">This paper does not deal with the issue of print journals versus electronic journals.\nJournal publishing is discussed as a concept, independent of the medium. It is\nobviously recognised that the introduction of digital technology can change the way\njournals are being used and this technology can help achieve efficiencies that were\nhitherto impossible. But the concept of a journal remains essentially unchanged.<br />\n</span><br />PROPOSITIONS<br />\n<span style="font-size: 11pt; font-weight: 700;">1. If not properly published, scientific results are fairly useless — because usually\nindistinguishable from speculation.</span><span style="font-size: 12pt;">In most democracies, anybody is free to publish anything that is not obscene or\nlibellous, and there are quite a few countries where one can get away with that as\nwell. Whether it is true, whether the argument is not flawed, whether it is ambiguous,\nwhether it is informative, whether it is new, whether it is original, </span><span style="font-size: 12pt; font-style: italic;">etcetera</span><span style="font-size: 12pt;">, is quite\nanother matter. The level of reliability of unaccredited publications is not known. It\nmay be high or dismally low. Although the unaccredited material may be intrinsically\nreliable, the fact that it is not reasonably certain that it is, makes it unreliable. In order\nto substantially increase the chance that all or most of the above can be relied upon as\nrepresenting the current state of knowledge, peer reviewed scientific journals evolved.<br />\n</span><span style="font-size: 12pt;">In the beginning, at the time the first scientific journals were established (1655, </span>LE\nJOURNAL DES SÇAVANS<span style="font-size: 12pt;">, France, quickly followed later in the same year by\n</span>PHYLOSOPHICAL TRANSACTIONS<span style="font-size: 12pt;"> of the Royal Society of London), peer review\ndid not yet exist. But it became clear fairly soon that not everything submitted was fit\nfor publication and criteria for admission were developed, although journal articles\nwere initially not regarded as definitive publications, as the mature research results\nwould still finally be written up in monographs</span><span style="font-size: 8pt; vertical-align: 6pt;">1</span><span style="font-size: 12pt;">.<br />\n</span><span style="font-size: 12pt;">It would be a mistake to believe that peer review ensures quality and integrity of the\nmaterial at all times. The American of Research Integrity (</span>ORI<span style="font-size: 12pt;">) can testify to that.\nHowever, the chance of finding total nonsense in established peer reviewed journals is\nslight. Peer review does not only ensure a good measure of </span>QIVAS<span style="font-size: 12pt;"> (Quality,\nIntegrity, Veracity, Accuracy, and Security)</span><span style="font-size: 8pt; vertical-align: 6pt;">2</span><span style="font-size: 12pt;">, but also a hierarchy, not just of\nimportance, but of relevance to the central issues of the discipline concerned as well.\nOn top of this, publication in a journal provides priority and authority (in the original\nsense of established authorship). Results cannot easily be ‘hijacked’ any more once\nthey are received by, and published in, a reputable journal and (undetected and\nuncontested) plagiarism becomes pretty difficult, too. Published results have, by\nvirtue of having been published in a peer reviewed journal, become part of the\naccepted and acknowledged body of scientific knowledge or theory.<br />\n</span><span style="font-size: 11pt; font-weight: 700;"><br /></span><span style="font-size: 11pt; font-weight: 700;">2. The growth in numbers of scientific papers is outside the influence or control of\npublishers.</span><span style="font-size: 12pt;">The laws of supply and demand do not apply in a straightforward way to scientific\ninformation. As Bernard Naylor has described it: “If there is an excess of supply over\ndemand in the journals industry, and there seems no prospect of an increase in\ndemand, the obvious alternative is that supply ought to fall. However, whichever way\nyou look at it, supply is tending to increase. The normal self-readjusting tension\nbetween supply and demand fails to operate”</span><span style="font-size: 8pt; vertical-align: 6pt;">3</span><span style="font-size: 12pt;">.<br />\n</span><span style="font-size: 12pt; font-style: italic;">But we should not forget that it is the scientists’ very job to uncover and add to the\nbody of knowledge!<br />\n</span><span style="font-size: 12pt;">Currently, the number of scientific articles published per year seems to be increasing\nfairly constantly within the order of 4 to 6 percent. This poses great problems to the\nglobal scientific community. ‘Twigging’ of disciplines and further specialisation is\nstill the most common response. As long as the need and desire for insight into natural&nbsp;</span><span style="font-size: 12pt;">phenomena grows, scientific activity grows, and with scientific activity, scientific\npublications. Scientific papers are, however, not just used to record and convey\nresults. They are also used to advance careers and boost egos. Indeed, in many\nsituations they are the single most important measure of a scientist’s performance.\nAnd not just scientists are being measured by the number of their papers, but entire\ndepartments and whole research institutions as well.</span><span style="font-size: 12pt;">Growth of scientific material seems inevitable. It is becoming more and more\ndifficult, of course, to be sure that one’s paper will actually be seen by the majority of\nthe intended audience. So apart from ‘slicing’ their results into many papers which\none would do for reasons of career advancement, some researchers resort to this\ntechnique in order to increase their chance to be ‘found’. Further growth of the\namount of published material will only make this a more attractive (some would say\nnecessary) option, in order to increase the ‘signal to noise ratio’, so to speak.<br />\n</span><span style="font-size: 12pt;">Publishers do not increase the amount of scientific articles; scientists do, driven by\n‘publish-or-perish’ and performance criteria, but essentially just doing what they are\nexpected to do and what they are paid for. Publishers only respond to the phenomenon\nand as often as not, also experience it as a problem. The irony is that the very same\ngovernments that insist on proving maximum performances with published papers are\nthe first to cut the budgets that, by way of paying for subscriptions to the journals,\nsupport the mechanisms that make publication of those papers possible.<br />\n</span><span style="font-size: 11pt; font-weight: 700;"><br /></span><span style="font-size: 11pt; font-weight: 700;">3. Scientific articles should be published only for their scientific merit, not for their\ncommercial merit.</span><span style="font-size: 12pt;">One of the attractions of the current model in which articles are published in the\ncontext of journals is that no commercial judgement is passed. The only reason why\nan article is accepted or rejected is its quality or relevance to the particular forum that\nthe journal constitutes. This is done exclusively by the active scientists who act as\neditors-in-chief, members of editorial boards, and reviewers of the journals, with no\ninterference from the publisher. Particularly not if the publisher is independent of a\nparticular scientific constituency and is unencumbered by any possible scientific (or\neven political) controversy or secret agenda.<br />\n</span><span style="font-size: 12pt;">Independent journal publishing differs markedly from book publishing, where the\nmarket potential also has a large influence on the decisions, made by the publishers,\non whether or not to publish. Scientifically worthy books are, as a rule, not published\nif insufficient prospective buyers can be found.<br />\n</span><span style="font-size: 12pt;">The fact that journal articles are published on their scientific merits only is worth\npreserving. Market forces may (and will) introduce an improper bias. Just as it is\nimproper to sell academic degrees, it would be improper to give undue preference to\nscientific results coming from wealthier institutes or companies. This would be likely\nto happen, though, if commercial criteria were introduced for the publication of\nprimary research results. Wider distribution than the normal journal circulation is\nalready being sponsored for certain articles. This is a welcome source of income to\npublishers and likely to influence decisions if the current system of publishing purely\non scientific merit is compromised.<br />\n</span><span style="font-size: 12pt;">This is a realistic risk, though, as publishing on exclusively scientific criteria is being\nthreatened by the advent of P3, or Pay-Per-Paper, a.k.a. Pay-per-View (in electronic&nbsp;</span><span style="font-size: 12pt;">environments), document delivery (DocDel) or individual article supply (</span>IAS<span style="font-size: 12pt;">). After\nall, except in extraordinary circumstances, no publisher, independent or associated\nwith a scientific society, will want to commit resources to the publishing of an article\nwhich offers no, or very limited, potential for recouping the investment through sales\nof the article. Such an </span>IAS<span style="font-size: 12pt;"> system is likely to favour publication of articles with clear\ncommercial potential. In practice, this is likely to mean articles written by well-known\nscientists from English speaking countries, especially the United States (for that is\nwhere a major market will be found), and from universities or research centres with\nresounding names, or companies with deep pockets which are willing to sponsor the\npublication. It is not difficult to imagine claims of cultural and commercial\nimperialism in such a scenario.</span></span>&nbsp;</blockquote>\n<blockquote class="tr_bq">\n<span style="font-family: Times, Times New Roman, serif;"><span style="font-size: 11pt; font-weight: 700;">4. Information is not a commodity.<br />\n</span><span style="font-size: 12pt;">The Oxford dictionary defines ‘commodity’ as “...a thing of use or value, </span><span style="font-size: 12pt; font-style: italic;">spec. </span><span style="font-size: 12pt;">a thing\nthat is an object of trade, </span><span style="font-size: 12pt; font-style: italic;">esp. </span><span style="font-size: 12pt;">a raw material or agricultural crop”. The only faithfully\nrecorded instant when commodities behaved like information occurred almost 2000\nyears ago. It concerned loaves and fish, and the emphasis should be on ‘faithfully’,\nnot on ‘recorded’. Since then, it has not happened again that one could give away a\ncommodity like a loaf of bread and still have it. It can be done with information,\nthough!<br />\n</span><span style="font-size: 12pt;">It follows that information cannot truly be expected to have the same economic\nproperties as commodities. Sharing information does not mean the same as sharing a\nbushel of wheat, unless it takes the form of keeping the first five pages of an article to\noneself and giving the other five to someone else. Hence the virtually worldwide\nestablishment of legal constructions like copyright, which are awkward and imperfect,\nbut the only means currently available to make sure that the necessary resources\nremain to be committed to the recording and dissemination of information. It would\nbe attractive for purchasers of information to treat it as a commodity, especially given\nits ‘loaf-and-fish’ properties. What really is copying of information and document\ndelivery is known as ‘resource sharing’, or sometimes goes under the euphemism of\n‘interlibrary loan’. The potential is enormous: take out one subscription per country\nand share it with all the other libraries. The law permits it! It doesn’t take a rocket\nscientist to see the consequences, though.<br />\n</span><span style="font-size: 11pt; font-weight: 700;"><br /></span><span style="font-size: 11pt; font-weight: 700;">5. The real product of scientific journal publishers is not paper, not distribution, not\ncontent, but the service of providing a structured forum for scientific discourse.\n</span><span style="font-size: 12pt;">But alas, information is not a commodity and it is not even the publishers’ product.\nStevan Harnad, editor of the electronic journal </span>PSYCOLOQUY<span style="font-size: 12pt;">, describes in his\npaper “Implementing Peer Review on the Net: Scientific Quality Control in Scholarly\nElectronic Journals”</span><span style="font-size: 8pt; vertical-align: 6pt;">4 </span><span style="font-size: 12pt;">how his eyes were opened in a conversation with a television\nnetwork executive, who told him that </span>TV<span style="font-size: 12pt;">‘s product is not the programmes that are\nbroadcast, but the viewers’ eyeballs which are sold to the advertisers (although in\nmany countries outside the </span>USA<span style="font-size: 12pt;"> this would be either not or only partially true).\nIn a similar vein, scientific journal publishers’ product is not the content (that is the\nauthors’), not the printed paper (that is the printers’), not the distribution (that is the\nmail’s), but the provision of a forum for the conduct of scientific discourse, which\nfacilitates the proper keeping of the minutes of science. A journal is a concept, not\nnecessarily a physical entity. The publisher provides a structured (‘pecking order’)\nand controlled (‘quality label’) forum, complete with gatekeepers (editor and\nreviewers), organisers (indexers for secondary literature and databases), and&nbsp;</span><span style="font-size: 12pt;">‘translators’ (although the accepted </span><span style="font-size: 12pt; font-style: italic;">lingua franca </span><span style="font-size: 12pt;">of science seems to have become\nEnglish, the ‘real’ language of science is more than this: it is a closely knit framework\nof standardisations, rules and conventions, in the interest of precision and the\navoidance of ambiguities, which amounts to a ‘grammar’ and ‘idiom’ that few\nscientists fully adhere to; hence the need for ‘translators’, better known as subeditors\nor technical editors, who often also provide conventional translation services for those\nauthors whose native tongue is not English). Almost as an afterthought, publishers\nalso arrange for composition (typesetting for print; </span>SGML<span style="font-size: 12pt;">-coding for electronic\ndissemination), printing or mounting on servers, and subsequent dissemination.</span><span style="font-size: 12pt;">The service of providing a structured and controlled forum is as important for authors\nas it is for readers of journals. It is not for nothing that many scientific societies are\ncharging the authors for publication of their articles. It is inherently fair that both\nauthors and readers contribute to the maintenance of the forum. Societies are finding\nit difficult to keep up the system of page charges, as most independent publishers are\nnot levying them. The American Physical Society is currently examining its page\ncharge levies, after an experimental period of suspending page charges for\nmanuscripts submitted electronically to </span>PHYSICAL REVIEW C<span style="font-size: 12pt;">. One of the\narguments used for continuing the system of page-charges is “...that it is reasonable to\nexpect research grants to bear some of the publication costs, since publication could\nbe considered an important aspect of research”</span><span style="font-size: 8pt; vertical-align: 6pt;">5</span><span style="font-size: 12pt;">. Most independent publishers have\nconcentrated on subscriptions as the sole source of financial support for the journals.\nShould this lead to journals accepting only papers from researchers at institutions or‘\ncompanies underwriting and supporting the journal via a subscription? It would be\nfair, but hardly feasible and introduce a similar potential bias as discussed under\nProposition 3.<br />\n</span><span style="font-size: 11pt; font-weight: 700;"><br /></span><span style="font-size: 11pt; font-weight: 700;">6. Economic models for journal publishing exclusively based on subscriptions are\nbecoming less viable; the ones based on individual article sales (document delivery)\nhave never been, nor will ever be viable.</span><span style="font-size: 12pt;">The flaw in the previous proposition is, of course, that publishers in reality derive\ntheir income basically from treating content, printing and dissemination as their\nproduct. Content is first converted into a pseudo-commodity, with the aid of\ncopyright, and then sold on a just-in-case basis by the subscription, and, reluctantly,\non a just-in-time basis (or just-too-late, as Bernard Naylor aptly describes it!) by the\nindividual article. The transactional document delivery model is particularly badly\nsuited to the forum concept of a journal. It reduces the intricate fabric of written\nscientific discourse to the one-way street of information provision, devoid of much\ncontextual and meta information that makes the package of a journal so valuable\n(even aside from concessions document delivery makes to browseability and\nserendipity). Also, each individual article would have to be purchased hundreds of\ntimes at the prices that currently seem usual, or carry a price tag that is substantially\nhigher, in order to make it possible that investments in the publication of the articles\ncould be recouped. But a more serious danger lies in the fact that document delivery\nleads to a model in which articles are no longer published on their scientific merit, but\non their commercial merit, as already discussed under Proposition 3.\nSubscriptions are not satisfactory any longer either. Library budgets have decreased in\nreal terms over the last decade, pretty much worldwide. Resource sharing and inter-\nlibrary loan are a result, and subscriptions, in combination with fair-use and library\nprivileges provided by law, are ideally suited to that. Or so it seems. The natural&nbsp;</span><span style="font-size: 12pt;">course of events is now that numbers of subscriptions will go down, interlibrary\nlending up, subscription prices also up as a consequence, with the result that users’\naccess to material becomes more difficult or cumbersome; libraries spend their\nbudgets on administrative chores connected with inter-library loan instead of building\ncollections in order to optimally serve their constituencies; authors see the potential of\nchance encounters of their articles with readers dwindle; scientific societies cease to\nexist or are forced to minimise the service to their members; and publishers go out of\nbusiness. In short, everyone loses, except, of course, the suppliers of photocopiers and\nthe paper they churn out.</span></span></blockquote>\n<blockquote class="tr_bq">\n<span style="font-family: Times, Times New Roman, serif;"><span style="font-size: 11pt; font-weight: 700;">7. Academic Press is convinced that there are viable alternatives that do much more\njustice to the needs of authors, libraries, users, and publishers, without, on the whole\nand in total, costing more.</span><span style="font-size: 12pt;">Fortunately, there may be other scenarios. Academic Press clearly sees the plight of\nthe libraries, which is, by extension, the plight of the entire scientific community.\nSupply is not decreasing but increasing, demand is not increasing but decreasing\n(economic demand, by the entities that pay; not the end-user demand or the demand\nfrom authors for a vehicle to publish their papers in), so the only alternative left is to\nreduce costs. Academic Press is working on paradigms in which subscriptions are\nessentially replaced with licences, giving subsequent free electronic access to every\nuser affiliated with the library taking the licence, thereby essentially reacting to\nincreasing end-user demand, while at the same time accommodating the dire financial\nsituation the libraries find themselves in. Options to grant major incentives to\nconsortia of libraries for taking licences that span a whole range of journals are\ncurrently being explored. We are even including the possibility of offering such\nlicences to loose consortia of all libraries in a given province, state, or even country,\nwhich are then free to share all the material amongst all members of the consortium in\nwhatever form (electronically or on paper) and however frequently as is desired. This\nscheme is called </span>APPEAL<span style="font-size: 12pt;">, for Academic Press Print and Electronic Access Licence.<br />\n</span><span style="font-size: 12pt;">In the view of Academic Press, the paradigm of an </span>APPEAL<span style="font-size: 12pt;"> licence would\npotentially offer promising benefits to all parties concerned:<br />\n</span><span style="font-size: 12pt;">the authors would have the assurance that their papers are directly available to\na much larger potential audience than is the case now;<br />\n</span><span style="font-size: 12pt;">the libraries would be able to offer the research, teaching and student\ncommunity much wider instant access to much more material;<br />\n</span><span style="font-size: 12pt;">the barrier to turning to and browsing through many more sources would be\nremoved for researchers, students and other library users;<br />\n</span><span style="font-size: 12pt;">the publishers would be able to make the necessary investments in improving\nthe sophistication of the ‘forum’ and the cost per unit-of-information ratio.<br />\n</span><span style="font-size: 12pt;">All this for substantially the same amount of money that is being spent on scientific\nliterature by libraries now. On top of that, the libraries would be able to make\nappreciable savings on costly inter-library loan and cut down, or even eliminate,\nexpenses for commercial or semicommercial (</span>BLDSC<span style="font-size: 12pt;">) document delivery, at least\nregarding current journal material.</span></span></blockquote>\n<blockquote class="tr_bq">\n<span style="font-family: Times, Times New Roman, serif;">CONCLUSION<br />\n<span style="font-size: 12pt;">A form of formal publishing, whether in print or electronic, remains essential for the\nstructuring and preservation of the body of scientific knowledge, however many\nproblems the unrestricted growth of scientific knowledge poses to the global scientific\ncommunity. It is imperative that sufficient resources continue to he made available for\nthis. However, the resources currently used for ‘keeping the minutes of science’ can\nbe used far more efficiently, doing much more justice to the scientific efforts carried\nout and catering much better to the identified needs of the scientific community.<br />\n</span><span style="font-size: 14pt;"><br /></span>REFERENCES<br />\n<span style="font-size: 6pt; vertical-align: 5pt;">1 </span><span style="font-size: 10pt;">Manten, A.A. (1980), Development of European Scientific Journal Publishing before 1850, in:\nMeadows, A.J. (Ed) Development in Science Publishing in Europe, Amsterdam, Elsevier.<br />\n</span><span style="font-size: 6pt; vertical-align: 5pt;">2 </span><span style="font-size: 10pt;">Lindsay, John (1995), Academics Can Do It For Themselves. Presented at the UK Serials Group\nMeeting, UMIST, Manchester, 1994. STM Newsletter; no. 96.<br />\n</span><span style="font-size: 6pt; vertical-align: 5pt;">3 </span><span style="font-size: 10pt;">Naylor, Bernard (1994), The Future of the Scholarly Journal. Presented at the General Meeting of\nLIBER, July 1994.<br />\n</span><span style="font-size: 6pt; vertical-align: 5pt;">4 </span><span style="font-size: 10pt;">Harnad, Stevan (1995), Implementing Peer Review on the Net: Scientific Quality Control in\nScholarly Electronic Journals. In: Peek, R. &amp; Newby, G. (Eds) Electronic Publishing Confronts\nAcademia: The Agenda for the Year 2000, Cambridge MA, MIT Press.<br />\n</span><span style="font-size: 6pt; vertical-align: 5pt;">5 </span><span style="font-size: 10pt;">APS News (American Physical Society), Member Input Sought on Page Charges, 9 March 1995\n(11158).&nbsp;</span></span></blockquote>\n</div>\n</div>\n</div>\n<br />\n<div class="page" title="Page 7">\n   <div class="layoutArea">\n    <div class="column">\n     \n     \n     \n     <span style="font-size: 10pt;"><span style="font-family: Helvetica Neue, Arial, Helvetica, sans-serif;"><br /></span></span>\n<span style="font-family: Helvetica Neue, Arial, Helvetica, sans-serif;">Jan Velterop</span><br />\n<div>\n<span style="font-size: 9pt;"><br /></span></div>\n</div>\n</div>\n</div>\n</div>','\n',char(10)),NULL,'','2015-05-07 08:13:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2015/04/how-to-take-peer-review-out-of-clutches.html','How to take peer review out of the clutches of publishers',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\nYou may remember that some time ago I wrote about JONAS – <a href="http://theparachute.blogspot.co.uk/2014/10/journals-of-nature-and-science.html" target="_blank">Journals Of Nature And Science</a> – the essence of which was to take peer review out of the clutches of publishers and make it a purely academic responsibility again, what it should be in reality anyway. The result will not only be a cheaper system (by an order of magnitude compared to the current one), but also likely a better, fairer, more expert and possibly faster one. And because publishers'' main focus will necessarily be on the technical issues of producing correctly XML-coded, archivable, preservable, findable, machine-readable as well as human readable, text- and data-mineable articles in a variety of formats for different purposes (e.g. XML, HTML, PDF, ePub), the currently often sloppy production may be greatly improved (you''d be surprised at the number of errors in the material published by even the publishers priding themselves most on quality – mixing up β with ß or <u>+</u> with ±, for instance!).<br />\n<br />\n<a href="https://www.scienceopen.com/home" target="_blank">ScienceOpen</a> has decided to follow up on the JONAS idea and recently <a href="http://blog.scienceopen.com/2015/04/welcome-jan-velterop-peer-review-by-endorsement/" target="_blank">announced</a> that they will give authors the option of publisher-free peer review. Needless to say that I''m very pleased with that. Several scientists have remarked that "this is an important experiment" and expressed their hope that it will take off.<br />\n<br />\nScienceOpen will probably face some substantial hurdles, as is generally the case with new ideas in the area of scholarly publishing. I''m reminded of the early days of open access, in that regard. However, tenacity and persistence will do a lot to overcome those hurdles, as does help from those in the academic community who would like to progress peer review reform and open access.<br />\n<br />\nSuch help doesn''t have to be onerous. Simply talking to colleagues and peers about it, retweeting relevant tweets, mentioning it in blog posts, et cetera, will be of tremendous value. The fact is that ScienceOpen, as a small new outfit, doesn''t have a big marketing budget, and therefore relies on word-of-mouth. Moreover, even if they had a larger budget, they would rather refrain from email spamming and the like. In my view, they should be rewarded for that attitude with whatever help those who are sympathetic to new approaches in scholarly publishing can offer.<br />\n<br />\nAnd, of course, if you could consider trying out this approach by publishing a paper with the Peer Review by Endorsement method, that would be super.<br />\n<br />\nPropagating this blog post would be highly appreciated, too, obviously. Many thanks in advance.<br />\n<br />\nJan Velterop</div>','\n',char(10)),NULL,'','2015-04-29 09:18:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2014/10/journals-of-nature-and-science.html','Journals of Nature and Science',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\n\n\n\n\n\n\n<!--[if gte mso 9]><xml>\n <o:OfficeDocumentSettings>\n  <o:AllowPNG/>\n </o:OfficeDocumentSettings>\n</xml><![endif]-->\n\n<!--[if gte mso 9]><xml>\n <w:WordDocument>\n  <w:View>Normal</w:View>\n  <w:Zoom>0</w:Zoom>\n  <w:TrackMoves/>\n  <w:TrackFormatting/>\n  <w:PunctuationKerning/>\n  <w:ValidateAgainstSchemas/>\n  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>\n  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>\n  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>\n  <w:DoNotPromoteQF/>\n  <w:LidThemeOther>EN-GB</w:LidThemeOther>\n  <w:LidThemeAsian>JA</w:LidThemeAsian>\n  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>\n  <w:Compatibility>\n   <w:BreakWrappedTables/>\n   <w:SnapToGridInCell/>\n   <w:WrapTextWithPunct/>\n   <w:UseAsianBreakRules/>\n   <w:DontGrowAutofit/>\n   <w:SplitPgBreakAndParaMark/>\n   <w:EnableOpenTypeKerning/>\n   <w:DontFlipMirrorIndents/>\n   <w:OverrideTableStyleHps/>\n   <w:UseFELayout/>\n  </w:Compatibility>\n  <m:mathPr>\n   <m:mathFont m:val="Cambria Math"/>\n   <m:brkBin m:val="before"/>\n   <m:brkBinSub m:val="&#45;-"/>\n   <m:smallFrac m:val="off"/>\n   <m:dispDef/>\n   <m:lMargin m:val="0"/>\n   <m:rMargin m:val="0"/>\n   <m:defJc m:val="centerGroup"/>\n   <m:wrapIndent m:val="1440"/>\n   <m:intLim m:val="subSup"/>\n   <m:naryLim m:val="undOvr"/>\n  </m:mathPr></w:WordDocument>\n</xml><![endif]--><!--[if gte mso 9]><xml>\n <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="true"\n  DefSemiHidden="true" DefQFormat="false" DefPriority="99"\n  LatentStyleCount="276">\n  <w:LsdException Locked="false" Priority="0" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Normal"/>\n  <w:LsdException Locked="false" Priority="0" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="heading 1"/>\n  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="heading 2"/>\n  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="heading 3"/>\n  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="heading 4"/>\n  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="heading 5"/>\n  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="heading 6"/>\n  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="heading 7"/>\n  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="heading 8"/>\n  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="heading 9"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 1"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 2"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 3"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 4"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 5"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 6"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 7"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 8"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 9"/>\n  <w:LsdException Locked="false" Priority="35" QFormat="true" Name="caption"/>\n  <w:LsdException Locked="false" Priority="10" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Title"/>\n  <w:LsdException Locked="false" Priority="1" Name="Default Paragraph Font"/>\n  <w:LsdException Locked="false" Priority="11" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Subtitle"/>\n  <w:LsdException Locked="false" Priority="22" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Strong"/>\n  <w:LsdException Locked="false" Priority="20" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Emphasis"/>\n  <w:LsdException Locked="false" Priority="59" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Table Grid"/>\n  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Placeholder Text"/>\n  <w:LsdException Locked="false" Priority="1" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="No Spacing"/>\n  <w:LsdException Locked="false" Priority="60" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Shading"/>\n  <w:LsdException Locked="false" Priority="61" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light List"/>\n  <w:LsdException Locked="false" Priority="62" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Grid"/>\n  <w:LsdException Locked="false" Priority="63" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 1"/>\n  <w:LsdException Locked="false" Priority="64" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 2"/>\n  <w:LsdException Locked="false" Priority="65" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 1"/>\n  <w:LsdException Locked="false" Priority="66" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 2"/>\n  <w:LsdException Locked="false" Priority="67" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 1"/>\n  <w:LsdException Locked="false" Priority="68" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 2"/>\n  <w:LsdException Locked="false" Priority="69" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 3"/>\n  <w:LsdException Locked="false" Priority="70" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Dark List"/>\n  <w:LsdException Locked="false" Priority="71" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Shading"/>\n  <w:LsdException Locked="false" Priority="72" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful List"/>\n  <w:LsdException Locked="false" Priority="73" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Grid"/>\n  <w:LsdException Locked="false" Priority="60" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Shading Accent 1"/>\n  <w:LsdException Locked="false" Priority="61" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light List Accent 1"/>\n  <w:LsdException Locked="false" Priority="62" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Grid Accent 1"/>\n  <w:LsdException Locked="false" Priority="63" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 1"/>\n  <w:LsdException Locked="false" Priority="64" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 1"/>\n  <w:LsdException Locked="false" Priority="65" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 1 Accent 1"/>\n  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Revision"/>\n  <w:LsdException Locked="false" Priority="34" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="List Paragraph"/>\n  <w:LsdException Locked="false" Priority="29" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Quote"/>\n  <w:LsdException Locked="false" Priority="30" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Intense Quote"/>\n  <w:LsdException Locked="false" Priority="66" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 2 Accent 1"/>\n  <w:LsdException Locked="false" Priority="67" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 1"/>\n  <w:LsdException Locked="false" Priority="68" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 1"/>\n  <w:LsdException Locked="false" Priority="69" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 1"/>\n  <w:LsdException Locked="false" Priority="70" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Dark List Accent 1"/>\n  <w:LsdException Locked="false" Priority="71" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Shading Accent 1"/>\n  <w:LsdException Locked="false" Priority="72" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful List Accent 1"/>\n  <w:LsdException Locked="false" Priority="73" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Grid Accent 1"/>\n  <w:LsdException Locked="false" Priority="60" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Shading Accent 2"/>\n  <w:LsdException Locked="false" Priority="61" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light List Accent 2"/>\n  <w:LsdException Locked="false" Priority="62" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Grid Accent 2"/>\n  <w:LsdException Locked="false" Priority="63" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 2"/>\n  <w:LsdException Locked="false" Priority="64" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 2"/>\n  <w:LsdException Locked="false" Priority="65" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 1 Accent 2"/>\n  <w:LsdException Locked="false" Priority="66" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 2 Accent 2"/>\n  <w:LsdException Locked="false" Priority="67" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 2"/>\n  <w:LsdException Locked="false" Priority="68" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 2"/>\n  <w:LsdException Locked="false" Priority="69" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 2"/>\n  <w:LsdException Locked="false" Priority="70" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Dark List Accent 2"/>\n  <w:LsdException Locked="false" Priority="71" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Shading Accent 2"/>\n  <w:LsdException Locked="false" Priority="72" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful List Accent 2"/>\n  <w:LsdException Locked="false" Priority="73" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Grid Accent 2"/>\n  <w:LsdException Locked="false" Priority="60" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Shading Accent 3"/>\n  <w:LsdException Locked="false" Priority="61" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light List Accent 3"/>\n  <w:LsdException Locked="false" Priority="62" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Grid Accent 3"/>\n  <w:LsdException Locked="false" Priority="63" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 3"/>\n  <w:LsdException Locked="false" Priority="64" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 3"/>\n  <w:LsdException Locked="false" Priority="65" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 1 Accent 3"/>\n  <w:LsdException Locked="false" Priority="66" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 2 Accent 3"/>\n  <w:LsdException Locked="false" Priority="67" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 3"/>\n  <w:LsdException Locked="false" Priority="68" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 3"/>\n  <w:LsdException Locked="false" Priority="69" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 3"/>\n  <w:LsdException Locked="false" Priority="70" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Dark List Accent 3"/>\n  <w:LsdException Locked="false" Priority="71" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Shading Accent 3"/>\n  <w:LsdException Locked="false" Priority="72" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful List Accent 3"/>\n  <w:LsdException Locked="false" Priority="73" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Grid Accent 3"/>\n  <w:LsdException Locked="false" Priority="60" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Shading Accent 4"/>\n  <w:LsdException Locked="false" Priority="61" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light List Accent 4"/>\n  <w:LsdException Locked="false" Priority="62" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Grid Accent 4"/>\n  <w:LsdException Locked="false" Priority="63" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 4"/>\n  <w:LsdException Locked="false" Priority="64" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 4"/>\n  <w:LsdException Locked="false" Priority="65" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 1 Accent 4"/>\n  <w:LsdException Locked="false" Priority="66" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 2 Accent 4"/>\n  <w:LsdException Locked="false" Priority="67" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 4"/>\n  <w:LsdException Locked="false" Priority="68" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 4"/>\n  <w:LsdException Locked="false" Priority="69" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 4"/>\n  <w:LsdException Locked="false" Priority="70" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Dark List Accent 4"/>\n  <w:LsdException Locked="false" Priority="71" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Shading Accent 4"/>\n  <w:LsdException Locked="false" Priority="72" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful List Accent 4"/>\n  <w:LsdException Locked="false" Priority="73" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Grid Accent 4"/>\n  <w:LsdException Locked="false" Priority="60" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Shading Accent 5"/>\n  <w:LsdException Locked="false" Priority="61" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light List Accent 5"/>\n  <w:LsdException Locked="false" Priority="62" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Grid Accent 5"/>\n  <w:LsdException Locked="false" Priority="63" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 5"/>\n  <w:LsdException Locked="false" Priority="64" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 5"/>\n  <w:LsdException Locked="false" Priority="65" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 1 Accent 5"/>\n  <w:LsdException Locked="false" Priority="66" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 2 Accent 5"/>\n  <w:LsdException Locked="false" Priority="67" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 5"/>\n  <w:LsdException Locked="false" Priority="68" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 5"/>\n  <w:LsdException Locked="false" Priority="69" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 5"/>\n  <w:LsdException Locked="false" Priority="70" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Dark List Accent 5"/>\n  <w:LsdException Locked="false" Priority="71" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Shading Accent 5"/>\n  <w:LsdException Locked="false" Priority="72" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful List Accent 5"/>\n  <w:LsdException Locked="false" Priority="73" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Grid Accent 5"/>\n  <w:LsdException Locked="false" Priority="60" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Shading Accent 6"/>\n  <w:LsdException Locked="false" Priority="61" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light List Accent 6"/>\n  <w:LsdException Locked="false" Priority="62" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Grid Accent 6"/>\n  <w:LsdException Locked="false" Priority="63" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 6"/>\n  <w:LsdException Locked="false" Priority="64" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 6"/>\n  <w:LsdException Locked="false" Priority="65" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 1 Accent 6"/>\n  <w:LsdException Locked="false" Priority="66" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 2 Accent 6"/>\n  <w:LsdException Locked="false" Priority="67" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 6"/>\n  <w:LsdException Locked="false" Priority="68" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 6"/>\n  <w:LsdException Locked="false" Priority="69" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 6"/>\n  <w:LsdException Locked="false" Priority="70" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Dark List Accent 6"/>\n  <w:LsdException Locked="false" Priority="71" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Shading Accent 6"/>\n  <w:LsdException Locked="false" Priority="72" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful List Accent 6"/>\n  <w:LsdException Locked="false" Priority="73" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Grid Accent 6"/>\n  <w:LsdException Locked="false" Priority="19" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Subtle Emphasis"/>\n  <w:LsdException Locked="false" Priority="21" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Intense Emphasis"/>\n  <w:LsdException Locked="false" Priority="31" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Subtle Reference"/>\n  <w:LsdException Locked="false" Priority="32" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Intense Reference"/>\n  <w:LsdException Locked="false" Priority="33" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Book Title"/>\n  <w:LsdException Locked="false" Priority="37" Name="Bibliography"/>\n  <w:LsdException Locked="false" Priority="39" QFormat="true" Name="TOC Heading"/>\n </w:LatentStyles>\n</xml><![endif]-->\n\n<!--[if gte mso 10]>\n<style>\n /* Style Definitions */\ntable.MsoNormalTable\n {mso-style-name:"Table Normal";\n mso-tstyle-rowband-size:0;\n mso-tstyle-colband-size:0;\n mso-style-noshow:yes;\n mso-style-priority:99;\n mso-style-parent:"";\n mso-padding-alt:0cm 5.4pt 0cm 5.4pt;\n mso-para-margin:0cm;\n mso-para-margin-bottom:.0001pt;\n mso-pagination:widow-orphan;\n font-size:10.0pt;\n font-family:"Times New Roman";\n mso-fareast-language:JA;}\n</style>\n<![endif]-->\n\n\n\n<!--StartFragment-->\n\n<div class="MsoNormal">\n<a href="" name="OLE_LINK14"></a><span lang="EN-US" style="font-size: 11pt;">Joe Esposito''s recent&nbsp;<a href="http://scholarlykitchen.sspnet.org/2014/10/08/stick-to-your-ribs-what-does-a-scientist-want/" target="_blank">post on the Scholarly Kitchen</a> prompted me to post the following proposal, which I have discussed with various people, but which has no takers yet. But who knows what the future holds...</span></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="font-size: 11pt;"><br /></span></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="font-size: 11pt;">I called the proposed system&nbsp;<b>JONAS</b></span><span lang="EN-US" style="font-size: 11.0pt;"> (for ''Journals Of Nature And Science'' – working\ntitle, obviously). It is, I think, a new approach to open access publication of peer-reviewed scientific\nliterature. If it isn''t I''ve missed something (entirely possible).</span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="font-size: 11.0pt;">JONAS is about establishing\na publishing system that addresses:</span></div>\n<div class="MsoNormal">\n</div>\n<ul style="text-align: left;">\n<li><span style="font-size: 11pt; text-indent: -18pt;">Open access,</span></li>\n<li><span style="font-size: 11pt; text-indent: -18pt;">Fair and efficient peer review,&nbsp;</span></li>\n<li><span style="font-size: 11pt; text-indent: -18pt;">Cost of publishing</span></li>\n<li><span style="font-size: 11pt; text-indent: -18pt;">Speed of publishing</span></li>\n<li><span style="font-size: 11pt; text-indent: -18pt;">Publication of negative/null results</span></li>\n</ul>\n<br />\n\n\n\n\n\n\n\n\n\n\n<div class="MsoNormal">\n<b style="text-indent: -18pt;"><span lang="EN-US" style="font-size: 11.0pt;">Open Access —&nbsp;</span></b><span lang="EN-US" style="font-size: 11pt; text-indent: -18pt;">The JONAS publishing system focuses on the\nsuperb technical publication, in various formats/versions, of peer-reviewed\narticles for optimal machine and human readability and re-use.</span></div>\n<div class="MsoNormal">\n<b style="text-indent: -18pt;"><span lang="EN-US" style="font-size: 11.0pt;"><br /></span></b></div>\n<div class="MsoNormal">\n<b style="text-indent: -18pt;"><span lang="EN-US" style="font-size: 11.0pt;">Fair and efficient peer review —</span></b><span lang="EN-US" style="font-size: 11pt; text-indent: -18pt;">&nbsp;Anonymous peer review has problems around\nissues of transparency, fairness, thoroughness, speed, publisher-bias, specious\nrequests for further experiments or data, and possibly more. JONAS is a system\nusing signed, pre-publication peer review, arranged by the author(s) (many\npublishers ask authors who to invite to review their papers anyway), and merely verified by the publisher (peer review by endorsement). Reviews would be open,\npublished with the article that’s endorsed, non-anonymous, under the rules that peer-endorsers must be active researchers, and not be, or for at least\nfive years have been, at the same institution as, or a co-author of, any of the\nauthors. Such a peer-review-by-endorsement system is likely to be at least as\ngood as, and quite probably better than, the currently widespread ‘black box’\nof anonymous peer review. As reviews/endorsements would be signed and\nnon-anonymous, there is very little danger of sub-standard articles being\npublished (not worse than is currently the case anyway), as endorsers/reviewers would not want to put their reputations at\nrisk. The review process between authors and endorsers is likely to be\niterative, resulting in improvements on the original manuscripts.\n“Author-arranged” may perhaps include peer review being arranged on behalf of the authors by services specifically\nset up for that purpose, as long as the reviewers are not anonymous and conform\nto the JONAS rules. The <a href="http://www.liberatingresearch.org/" target="_blank">LIBRE service</a> is one example (</span><span lang="EN-US" style="font-size: 11pt; text-indent: -18pt;">currently in prototype</span><span lang="EN-US" style="font-size: 11pt; text-indent: -18pt;">).</span></div>\n<div class="MsoNormal">\n<b style="text-indent: -18pt;"><span lang="EN-US" style="font-size: 11.0pt;"><br /></span></b></div>\n<div class="MsoNormal">\n<b style="text-indent: -18pt;"><span lang="EN-US" style="font-size: 11.0pt;">Cost of publishing —</span></b><span lang="EN-US" style="font-size: 11pt; text-indent: -18pt;">&nbsp;A system like this can be very\ncost-effective for authors. The technical costs of proper publishing are but a\nfraction of the cost usually quoted for organizing and arranging peer review. First\nindication is that an amount in the order of £100-150 per article can be sustainable,\ngiven sufficient uptake. Tiered charges should be considered depending on the\nstate of the manuscript when submitted. If the manuscript needs very little\nwork to bring it up to proper publishing standards, or if the author doesn’t\nwant or need those services, the cost could be very low indeed.</span></div>\n<div class="MsoNormal">\n<b style="text-indent: -18pt;"><span lang="EN-US" style="font-size: 11.0pt;"><br /></span></b></div>\n<div class="MsoNormal">\n<b style="text-indent: -18pt;"><span lang="EN-US" style="font-size: 11.0pt;">Speed of publishing —</span></b><span lang="EN-US" style="font-size: 11pt; text-indent: -18pt;">&nbsp;Since the peer-review-by-endorsement\nprocess has already taken place before the article arrives at the publisher,\npublication can ensue within days, even hours, depending on the state of the\nmanuscript.</span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="font-size: 11.0pt;">Requirements\nfor manuscripts: ORCIDs for authors and reviewers/endorsers; inclusion of (permanent\nlinks to) datasets used, underlying data for graphs, a section “details for\nreplicability and reproducibility” with clear and unambiguous identification of\nmaterials used, including reagents, software and other non-standard tools and\nequipment.<o:p></o:p></span></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="font-size: 11.0pt;">&nbsp; <o:p></o:p></span></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="font-size: 11.0pt;">Input:\nProperly endorsed articles to be accepted in the form of Word, Pages, (LA)TEX,\nXML, HTML, Markdown, and Excel or CSV for data, and high-resolution image files\n(where possible scalable vector graphics) attached to\nemails or via a simple upload site.<o:p></o:p></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="font-size: 11.0pt;">Output:\n</span><span lang="EN-US" style="font-size: 11.0pt;">Articles\nwould be published as XML, HTML, PDF, ODF and ePub formats</span><span lang="EN-US" style="font-size: 11.0pt;">, as much as possible semantically enriched\nand aesthetically formatted, plus Excel/CSV for data (tables extractable and\nrendered in Excel from PDFs with the software to do that, <a href="http://utopiadocs.com/" target="_blank">Utopia Documents</a>, freely supplied).<o:p></o:p></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="font-size: 11.0pt;">Commenting\nand post-publication review (signed comments and reviews only) would be encouraged for all articles, links to comments to\nbe provided with each article. Comments may be made on different sites, and\nwould be linked to, if that is the case. Anonymous comments would be ignored.<o:p></o:p></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="font-size: 11.0pt;">Access\nLicences: CC-BY or CC0 — DOIs for the articles, and where appropriate for individual elements within articles, would be assigned/arranged by\nJONAS.<o:p></o:p></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<b><span lang="EN-US" style="font-size: 11.0pt; mso-fareast-language: JA;">The core of the\nJONAS system</span></b><span lang="EN-US" style="font-size: 11.0pt; mso-fareast-language: JA;"> would effectively be to have OA journals with a low-cost\nstructure, with superb and highly optimized technical quality of the published\narticles. The principal difference with other OA journals would be the\npre-arranged open peer review ("peer-review-by-endorsement"),\norganised by the authors themselves, according to a set of rules that ensures a\nreasonable level of assurance against reviewer bias (because of its openness\nand non-anonymity, actually more assurance than is provided in the usual\nanonymous peer review as widely practiced). Since arranging peer review is one\nof the major costs of any publisher (mostly staff costs), leaving that part of\nthe publishing process in the hands of researchers and the academic community\ncan make a great difference to the cost of publication. So far, efforts to\nreduce the cost of publishing have been concentrated on technical issues.\nChanging the mechanism (emphatically not the principle) of peer review offers\nmuch greater scope for cost reduction.<o:p></o:p></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="font-size: 11.0pt; mso-fareast-language: JA;">What JONAS'' job would be is to take such peer-endorsed\narticles and make them into professionally published and complete (including\ndata and metadata) documents, adhering to all the technical, presentational and\nunique identifier standards, in a number of formats, linked and linkable to\ndatabases and other relevant information, human- and machine-readable and\nsuitable for widespread usage, for text- and data-mining, for structured\nanalysis (incl. semantic analysis) and further knowledge discovery, and,\ncrucially, for long-term preservation in repositories and archives of any kind.<o:p></o:p></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="font-size: 11.0pt; mso-fareast-language: JA;">An added service could be that manuscripts submitted in advance of peer-endorsement\nhaving been procured, would be placed, ‘as is’, on JonasPrePubs, a ‘preprint’\nserver, at no cost. This could help to secure priority (as a kind of ''prophylactic'' against high-jacking of ideas – which would never happen in science, of course, but better to be safe than sorry, right?).<o:p></o:p></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="font-size: 11.0pt; mso-fareast-language: JA;">The JONAS publishing system would also be&nbsp;<b>superbly suited to scientific societies</b>\nand other groupings that wish to have their own journal. Such a journal could be\nfully integrated in the JONAS system, provided the manuscripts are submitted\nfully peer-endorsed or peer-reviewed (whether or not arranged by the author(s)\nor the scientific society in question). The charges per manuscript for\nindividual authors and for societies wishing to publish their journals in the\nJONAS system would be the same, I imagine.<o:p></o:p></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="font-size: 11.0pt; mso-fareast-language: JA;">The JONAS methodology could, of course, be implemented on various\npublishing platforms.</span><span lang="EN-US" style="font-size: 11.0pt;"><o:p></o:p></span></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="font-size: 11.0pt; mso-fareast-language: JA;"><br /></span></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="font-size: 11.0pt; mso-fareast-language: JA;">Jan Velterop</span></div>\n<!--EndFragment--></div>','\n',char(10)),NULL,'','2014-10-08 12:27:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2014/09/does-open-access-include-reuse.html','Does ''Open Access'' include reuse?',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\n<div class="MsoNormal" style="text-align: left;">\n<span style="font-family: Arial, Helvetica, sans-serif;"><a href="" name="OLE_LINK2"></a><span style="mso-bookmark: OLE_LINK2;"><span lang="EN-US">At\nthe end of 2001, a number of people (me included) came together in Budapest and\nset out to give the emerging notion that research results, particularly those\nobtained with public funds, should be available and usable by anybody,\nanywhere. There wasn’t an agreed term for that notion – ‘free online\nscholarship’ (FOS) and ‘free access’ were some of the terms relatively\nfrequently used – and in Budapest we settled on the term ‘open access’. The\nmeeting in Budapest resulted in the Budapest Open Access Initiative (BOAI) and\nin the declaration issued a few months later, we explained what we meant by\n‘open access’ of the scholarly peer reviewed research literature:</span></span></span></div>\n<div style="text-align: left;">\n</div>\n<blockquote class="tr_bq">\n<span style="mso-bookmark: OLE_LINK1;"><span style="mso-bookmark: OLE_LINK2;"><i style="mso-bidi-font-style: normal;"><span lang="EN-US"><span style="font-family: Arial, Helvetica, sans-serif;">By "open access" to this literature, we mean its free\navailability on the public internet, permitting any users to read, download,\ncopy, distribute, print, search, or link to the full texts of these articles,\ncrawl them for indexing, pass them as data to software, or <b style="mso-bidi-font-weight: normal;">use them for any other lawful purpose</b>, without financial, legal, or\ntechnical barriers other than those inseparable from gaining access to the\ninternet itself. The only constraint on reproduction and distribution, and the\nonly role for copyright in this domain, should be to give authors control over\nthe integrity of their work and the right to be properly acknowledged and\ncited.</span></span></i></span></span></blockquote>\n<br />\n<div class="MsoNormal" style="text-align: left;">\n<span style="mso-bookmark: OLE_LINK1;"><span style="mso-bookmark: OLE_LINK2;"><span lang="EN-US"><span style="font-family: Arial, Helvetica, sans-serif;">While this definition has a flaw – there is no mention\nof immediacy in it – it clearly does include the right to reuse.<o:p></o:p></span></span></span></span></div>\n<div class="MsoNormal" style="text-align: left;">\n<br /></div>\n<div class="MsoNormal" style="text-align: left;">\n<span style="font-family: Arial, Helvetica, sans-serif;"><span style="mso-bookmark: OLE_LINK1;"><span style="mso-bookmark: OLE_LINK2;"><span lang="EN-US">So why has there be a recantation of one of the\noriginal signatories of the BOAI definition (perhaps more than one, but that I\ndon’t know, and I doubt it)? And why has the BOAI definition been watered down,\neven adulterated, by some other people. ‘Free access’, ‘gratis access’, ‘public\naccess’, etc. all disregard reuse, a crucial element of the notion of ‘open\naccess’ and of its BOAI definition (as well as of the Bethesda and Berlin\nStatements on OA – <i style="mso-bidi-font-style: normal;">“</i></span></span></span><span style="mso-bookmark: OLE_LINK1;"><span style="mso-bookmark: OLE_LINK2;"><i style="mso-bidi-font-style: normal;"><span lang="EN-US">The author(s) and\ncopyright holder(s) grant(s) to all users a free, irrevocable, worldwide,\nperpetual right of access to, and a license to copy, <b style="mso-bidi-font-weight: normal;">use</b>, distribute, transmit and display the work publicly and to make\nand distribute <b style="mso-bidi-font-weight: normal;">derivative works</b>, in\nany digital medium for any responsible purpose, subject to proper attribution\nof authorship.”</span></i></span></span><span style="mso-bookmark: OLE_LINK1;"><span style="mso-bookmark: OLE_LINK2;"><span lang="EN-US">). The Creative Commons Attribution licence (CC-BY) best captures the intention of these definitions.<o:p></o:p></span></span></span></span></div>\n<div class="MsoNormal" style="text-align: left;">\n<br /></div>\n<div class="MsoNormal" style="text-align: left;">\n<span style="mso-bookmark: OLE_LINK1;"><span style="mso-bookmark: OLE_LINK2;"><span lang="EN-US"><span style="font-family: Arial, Helvetica, sans-serif;">What are the motives of those who don’t like CC-BY and the reuse element of the BOAI/Bethesda/Berlin definitions and do what they can to water it all down to access without reuse?<o:p></o:p></span></span></span></span></div>\n<div class="MsoNormal" style="text-align: left;">\n<br /></div>\n<div class="MsoNormal" style="text-align: left;">\n<span style="mso-bookmark: OLE_LINK1;"><span style="mso-bookmark: OLE_LINK2;"><span lang="EN-US"><span style="font-family: Arial, Helvetica, sans-serif;">Are these some?<o:p></o:p></span></span></span></span></div>\n<ul>\n<li><span lang="EN-US" style="text-indent: -18pt;"><span style="font-family: Arial, Helvetica, sans-serif;">Expediency – giving up difficult to reach ideals for potentially easier to reach, though sub-optimal, goals;</span></span></li>\n</ul>\n<ul>\n<li><span lang="EN-US" style="text-indent: -18pt;"><span style="font-family: Arial, Helvetica, sans-serif;">Appeasement – giving in to established powers and processes;</span></span></li>\n</ul>\n<ul>\n<li><span lang="EN-US" style="text-indent: -18pt;"><span style="font-family: Arial, Helvetica, sans-serif;">Putting career advancement above the advancement of science;</span></span></li>\n</ul>\n<ul>\n<li><span lang="EN-US" style="text-indent: -18pt;"><span style="font-family: Arial, Helvetica, sans-serif;">General contrarianism.</span></span></li>\n</ul>\n<div class="MsoListParagraphCxSpFirst" style="text-align: left; text-indent: -18pt;">\n</div>\n<div class="MsoNormal" style="text-align: left;">\n<span style="font-family: Arial, Helvetica, sans-serif;"><span style="mso-bookmark: OLE_LINK1;"><span style="mso-bookmark: OLE_LINK2;"><span lang="EN-US">Quite possibly a combination of these, and more. Let’s have an open dialogue,\nincluding as John Wilbanks suggested, “about </span></span></span><span style="mso-bookmark: OLE_LINK1;"><span style="mso-bookmark: OLE_LINK2;"><span lang="EN-US">the ways publishers are exploiting green\nto undermine OA.</span></span></span><span style="mso-bookmark: OLE_LINK1;"><span style="mso-bookmark: OLE_LINK2;"><span lang="EN-US">”<o:p></o:p></span></span></span></span></div>\n<div class="MsoNormal" style="text-align: left;">\n<br /></div>\n<div class="MsoNormal" style="text-align: left;">\n<span style="mso-bookmark: OLE_LINK1;"><span style="mso-bookmark: OLE_LINK2;"><span lang="EN-US"><span style="font-family: Arial, Helvetica, sans-serif;">Comments welcome.<o:p></o:p></span></span></span></span></div>\n<div class="MsoNormal" style="text-align: left;">\n<br /></div>\n<div class="MsoNormal" style="text-align: left;">\n<span style="mso-bookmark: OLE_LINK1;"><span lang="EN-US"><span style="font-family: Arial, Helvetica, sans-serif;">Jan Veltero</span>p</span></span></div>\n</div>','\n',char(10)),NULL,'','2014-09-08 15:27:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2014/09/achieving-true-open-access-aint-easy.html','Achieving True Open Access Ain’t Easy',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\n<div class="MsoNormal">\n<span lang="EN-US"><span style="font-family: inherit;">In December of\n2001, a <a href="http://www.budapestopenaccessinitiative.org/read" title="See bottom of linked web page">number of people</a> who wanted to\nincrease the efficacy and usefulness of scholarly communication, particularly research\nresults published in the peer-reviewed journal literature, came together in\nBudapest. Quickly, a consensus emerged as to what that would <a href="http://www.budapestopenaccessinitiative.org/read" title="See 3rd paragraph in linked web page">mean</a>: <o:p></o:p></span></span></div>\n<div class="MsoNormal">\n<span lang="EN-US"><span style="font-family: inherit;">Peer-reviewed journal articles should be\nfreely available on the public internet, permitting any users to read,\ndownload, copy, distribute, print, search, or link to the full texts of these\narticles, crawl them for indexing, pass them as data to software, or use them\nfor any other lawful purpose, without financial, legal, or technical barriers\nother than those inseparable from gaining access to the internet itself. The\nonly constraint on reproduction and distribution, and the only role for\ncopyright in this domain, should be to give authors control over the integrity\nof their work and the right to be properly acknowledged and cited.<o:p></o:p></span></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US"><span style="font-family: inherit;">We called it “Open Access”, and in February of\n2002 the Budapest Open Access Initiative (BOAI) statement was published. It is\nfair to say that we (I was one of them) probably underestimated the difficulty\nof reaching the goal we set ourselves. It was – and still is – very difficult. <o:p></o:p></span></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US"><span style="font-family: inherit;">Shortly after, in December of 2002, the <a href="http://web.archive.org/web/20030124192733/http://creativecommons.org/" title="Creative Commons web page of 24 January 2003">CC-BY</a> (Creative\nCommons Attribution) licence was <a href="http://web.archive.org/web/20020913043654/http://www.creativecommons.org/">publicly\nreleased</a>, which captured the letter and spirit of the BOAI notion of Open\nAccess very well. For a while, Open Access and CC-BY were, to all intents and\npurposes, synonymous.<o:p></o:p></span></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US"><span style="font-family: inherit;">Apart from stating a goal, we also came up\nwith two strategies to achieve it (later called ‘green’ and ‘gold’,\nrespectively):</span></span></div>\n<div class="MsoNormal">\n</div>\n<ul style="text-align: left;">\n<li><span style="font-family: inherit; text-indent: -18pt;">Self-archiving, by the author(s), in open electronic archives or\nrepositories, manuscript versions of articles (to be) published in traditional\nsubscription journals – later called the ‘green’ road;</span></li>\n<li><span style="font-family: inherit; text-indent: -18pt;">Publishing ‘born-open-access’ articles in journals set up to provide open\naccess to the formally published version at the point of publication – later\ncalled the ‘gold’ road.</span></li>\n</ul>\n<br />\n<div class="MsoNormal">\n<span lang="EN-US"><span style="font-family: inherit;">The strategies\nwere straightforward, it seemed. That proved to be an illusion. Strategy one,\nself-archiving (‘green’), was based on the idea that authors’ manuscripts, even\nafter they had been peer-reviewed and accepted by subscription journals, were\ncovered by the authors’ copyright and therefore they could do with them what\nthey wanted, including posting the manuscripts in open repositories. Of course,\nthat was correct, up until the moment that authors were transferring the\ncopyright to any of their articles to the publishers. Yet, many publishers\n(reluctantly) allowed this practice, as they had allowed it for a long time\nalready in areas such as physics, where a long-standing habit of preprint\npublication existed (arXiv.org) that didn’t appear to harm their subscriptions,\nand the conviction that the open repository landscape would be chaotic, deposit\nas well as access cumbersome, and repositories would contain all manner of\ncontent with all manner of access restrictions mixed in with open access\nmaterial, providing an incentive for institutional and corporate users of the\njournals to stick with their subscriptions. That situation has changed very\nlittle. Although it has gradually become easier to find a freely accessible\nversion of many an article, subscription levels have, on the whole, held up.\nAnd freely accessible ‘green’ articles are often not covered by a CC-BY licence\nand thus not freely reusable <a href="" name="OLE_LINK2"></a><a href="" name="OLE_LINK1"><span style="mso-bookmark: OLE_LINK2;">in the way the BOAI intended.</span></a> When\ncopyright has been transferred to the publisher, the author cannot subsequently\nattach a CC-BY licence to the version deposited in an open repository. Were\nthat possible, and habitually done, ‘green’ might be true Open Access. As it\nis, ‘green’ articles are free to read (gratis access), but rarely free to\nreuse.<o:p></o:p></span></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US"><span style="font-family: inherit;">But also strategy\ntwo didn’t turn out to be straightforward. The thought was that the only\ndifficulty to overcome was the necessary cost. Some journals are being kept\nafloat by subsidies, and many funding agencies allow ‘article processing\ncharges’ (APCs) to be paid out of grants, within reason. So seemingly the cost\nhurdle could largely be taken, except for unfunded, impecunious authors, to\nwhom many journals offer APC waivers. Open Access, i.e. articles published with\na CC-BY licence, would result. That straightforwardness proved an illusion,\ntoo. The term Open Access is not an officially standardized one, and various\npublishers have started to call articles Open Access even though restrictions\napply that go beyond CC-BY, such as non-commercial clauses (NC). Yet they nonetheless\nrequire author-side payment of APCs. Some even require ‘basic’ APCs for\nrestricted access, and APC top-ups for true Open Access CC-BY licences. NC\nclauses potentially give the publisher the opportunity to exclusively exploit\nthe article further (e.g. reprints) and realize more income than just the APC.\nI say ‘potentially’, because the sale of reprints is a commercial activity, forbidden\nby NC, unless copyright has been transferred to the publisher (in which case\ncommercial exploitation is the publisher’s right) or there is an exclusive\nlicence in place whereby the author-copyright-holder gives the publisher the\nright to do so. An NC clause means, in countries like Germany for instance,\nthat the article in question cannot be used for educational purposes unless\nexplicit permission is obtained, which makes the hurdle, in those\ncircumstances, practically identical to the “all rights reserved” of plain\ncopyright. The upshot is that ‘gold’ is also not always Open Access in the way\nthe BOAI intended.<o:p></o:p></span></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US"><span style="font-family: inherit;">Since Open Access\nhas become an ambiguous term, you cannot trust the label to mean what you think\nit does, and certainly not that it allows you to reuse the article. Only CC-BY\ndoes that (and CC-zero, which does away with attribution as well – suitable and\nappropriate for data).<o:p></o:p></span></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US"><span style="font-family: inherit;"><b>Where do we go\nfrom here?</b><o:p></o:p></span></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US"><span style="font-family: inherit;">FFAR, I would\nhope. For data, the concept of FAIR is being proposed (Findable, Accessible,\nInteroperable, and Reusable). For journal literature, ‘interoperable’ may not\nbe a useful notion, so I’d like to modify the idea to Findable, Freely\nAccessible and Reusable. <o:p></o:p></span></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormalCxSpLast">\n<span lang="EN-US"><span style="font-family: inherit;">How?\nWell, ‘gold’ publication with CC-BY is a good way to achieve it, but there remains\nthe hurdle of APCs. The International Council for Science, ICSU, has recently\nissued a <a href="http://www.icsu.org/general-assembly/news/ICSU%20Report%20on%20Open%20Access.pdf" title="This links to a PDF">report</a>, in which they advocate the following\ngoals for Open Access:</span></span></div>\n<div class="MsoNormalCxSpLast">\n</div>\n<ul style="text-align: left;">\n<li><span style="text-indent: -18pt;"><span style="font-family: inherit;">free of financial barriers for any researcher to contribute to;</span></span></li>\n<li><span style="text-indent: -18pt;"><span style="font-family: inherit;">free of financial barriers for any user to access immediately on\npublication;&nbsp;</span></span></li>\n<li><span style="text-indent: -18pt;"><span style="font-family: inherit;">made available without restriction on reuse for any purpose, subject to\nproper attribution;</span></span></li>\n<li><span style="text-indent: -18pt;"><span style="font-family: inherit;">quality-assured and published in a timely manner; and</span></span></li>\n<li><span style="text-indent: -18pt;"><span style="font-family: inherit;">archived and made available in perpetuity.</span></span></li>\n</ul>\n<br />\n<div class="MsoNormalCxSpLast">\n<span style="font-family: inherit;">1 and 2 mean that the cost of 4 and 5 need to\nbe carried by other parties than the user or author. For authors funded by\nagencies who support Open Access and are willing to bear the APC costs, there\nis no barrier, but of course, not every author is.</span></div>\n<div class="MsoNormalCxSpLast">\n<span style="font-family: inherit;"><br /></span></div>\n<div class="MsoNormalCxSpLast">\n<span style="font-family: inherit;">There is no easy way out of this. But it’s not\nimpossible, in principle. However, ingrained deep conservatism of the scholarly\ncommunity, and particularly scholarly officialdom, is in the way. (You’d think\nthat ‘pushing the envelope’ is endemic to science, but in reality it is applied\nto knowledge, not to communicating that knowledge). Imagine the following\nscenario:</span></div>\n<div class="MsoNormalCxSpLast">\n</div>\n<ul style="text-align: left;">\n<li><span style="text-indent: -18pt;"><span style="font-family: inherit;">The authors arrange for peers they trust to review their articles, and\nopenly endorse their article as worthy of publication;</span></span></li>\n<li><span style="text-indent: -18pt;"><span style="font-family: inherit;">Authors publish their article, properly formatted (I’m sure services would\nspring up for those who’d rather not do that themselves) and accompanied by the\nopen endorsements on one of the many free (blog) platforms available, under a\nCC-BY licence.</span></span></li>\n</ul>\n<br />\n<div class="MsoNormalCxSpLast">\n<span style="font-family: inherit;"><span lang="EN-US">Of course, permanency and archiving in\nperpetuity is not guaranteed, but that used to be the responsibility of\nlibraries in the print era, and they might wish to take that responsibility\nagain for electronic literature. Central repositories like arXiv, bioR</span><span lang="EN-US">χ</span><span lang="EN-US">iv, PubMedCentral, etc. could do that, too.</span></span></div>\n<div class="MsoNormalCxSpLast">\n<span style="font-family: inherit;"><br /></span></div>\n<div class="MsoNormalCxSpLast">\n<span style="font-family: inherit;">I’m sure someone could come up with\nmodifications to this scenario that would make it more practicable, technically\nrobust, and such. But the main hurdle to take is academic officialdom, in\nparticular the Impact Factor counters, who would have to accept this kind of\npublication for career and funding purposes.</span></div>\n<div class="MsoNormalCxSpLast">\n<span style="font-family: inherit;"><br /></span></div>\n<div class="MsoNormalCxSpLast">\n<span style="font-family: inherit;">Achieving true Open Access ain’t easy. So much\nis clear.</span></div>\n<div class="MsoNormalCxSpLast">\n<span style="font-family: inherit;"><br /></span></div>\n<div class="MsoNormalCxSpLast">\n<span style="font-family: inherit;">Jan Velterop</span></div>\n</div>','\n',char(10)),NULL,'','2014-09-04 13:22:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2014/03/proposed-open-access-symbol.html','Proposed open access symbol',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\nI have proposed a new Unicode symbol to denote true open access, for instance applied to scholarly literature, in a similar way in which © and ® denote copyright and registered trademarks respectively. The proposed symbol is an encircled lower case letter a, in particular in a font where the a has a ''tail'', as in a font like Arial and Times, for instance, (a), and not as in a font like Century Gothic (<span style="font-family: inherit;">without the ''tail'' as it were)</span>.<br />\n<br />\nMy proposal should be on the Unicode discussion list (http://www.unicode.org/consortium/distlist-unicode.html), and I am soliciting support, and input from technically-minded as well as legally-minded open access supporters.<br />\n<br />\nThis is the symbol I have in mind:<br />\n<br />\n<div class="separator" style="clear: both; text-align: center;">\n<a href="http://4.bp.blogspot.com/-EEX9CsdMDJk/UywcvuiKjXI/AAAAAAAAAD4/-uFpaouKRmg/s1600/Screen+Shot+2014-03-21+at+09.07.23.png" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img border="0" src="http://4.bp.blogspot.com/-EEX9CsdMDJk/UywcvuiKjXI/AAAAAAAAAD4/-uFpaouKRmg/s1600/Screen+Shot+2014-03-21+at+09.07.23.png" height="188" width="200" /></a></div>\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\nJan Velterop</div>','\n',char(10)),NULL,'','2014-03-21 11:06:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2013/12/lo-fun-and-hi-fun.html','Lo-fun and hi-fun',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\nI have recently been talking to some major (and minor) publishers about what they could do in regard of open access, given the increasing demand, even if converting to ‘gold’ open access models is not realistic for them, in their view. I suggested that they should make human-readable copies of articles freely accessible immediately upon publication. Access to human-readable articles would of course not satisfy everybody, but it would satisfy the ‘green’ OA crowd, if I assume Stevan Harnad is their prime spokesperson. He dismisses machine-readability and reuse as distractions from his strategy of ‘green’ open access, and he even supports embargoes, as long as articles are self-archived in institutional repositories, which is his primary goal. Human-readable final published versions directly upon publication would be an improvement on that. It would also likely satisfy the occasional reader from the general public, who wishes to be able to access a few scientific articles. <br /><br />How could those publishers possibly agree to this? Well, I told them, they could reconsider their view that there is a fundamental difference between the published version of an article and the final, peer reviewed and accepted author manuscript (their justification for allowing the author-manuscript to be self-archived). There may well be, of course, and there often is, but it is not likely to be a material difference in the eyes of most readers. Instead of making much (more than there usually is) of any differences in content, they could distinguish between low-functionality versions and high-functionality ones of the final published article, the ‘lo-fun’ version just suitable for human reading (the print-on-paper analogue), and the ‘hi-fun’ version suitable for machine-reading, text- and data-mining, endowed with all the enrichment, semantic and otherwise, that the technology of today makes possible. The ‘lo-fun’ version could then be made freely available immediately upon publication, on the assumption that it would not likely undermine subscriptions, and the ‘hi-fun’ version could be had on subscription. Librarians would of course not be satisfied with such a ‘solution’.<br /><br />Although initially greeted with interest, the idea soon hit a stone wall. Although no one has explicitly said that they would never do this, the subsequent radio silence made me conclude that among the publishers I talked with the fear might have emerged that a system with immediate open access to a ‘lo-fun’ version accompanied by a ‘hi-fun’ version paid for by subscriptions would expose the relatively low publisher added value in terms of people’s perceptions and in terms of what they would be prepared to pay for it. That fear is probably justified, I have to give it to them.<br /><br />There is no doubt that formal publication adds value to scientific articles. The success of the ‘gold’ open access publishers, where authors or their funders are paying good money for the service of formal publication, is testament to that. There must be a difference – of perception at the very least – between formally published material and articles ‘published’ by simply depositing them in an open repository. That added value largely consists of two elements: 1) publisher-mediated pre-publication peer review and 2) technical ‘production’, i.e. standardised to a sufficient degree, correctly coded (e.g. no ß where a β is intended), ‘internet- and archive-proof’,&nbsp; rendered into several user formats, such as PDF, HTML and Mobile, aesthetically pleasing where possible, interoperable, search-engine optimised, and so forth. The first element is mostly performed by the scientific community, without payment, and although the publisher organises it, that doesn’t amount to a substantial publisher-added value, in the common perception. The second element on the other hand, is true value added by the publisher, is seen as such by reasonable people, and it is entirely justifiable for a publisher to expect to be paid for that. There are some authors who could do this ‘production’ themselves, but the vast majority make a dog’s dinner out of it when they try.<br /><br />There is of course a third element in the equation: marketing. Marketing is responsible for brand and quality perception. Quality mainly comes from good authors choosing to submit to a journal. Getting those good authors to do that is in large part a function of marketing. The resulting brand identity, sometimes amounting to prestige, is also an added value that a self-published article, even if peer-reviewed, lacks. But alas, it is not commonly seen to be an important value-add that needs to be paid for.<br /><br />Having ''lo-fun'' and ''hi-fun'' versions of articles makes the publishers’ real contribution explicit. That’s the rub, of course.<br /><br />Back to ‘gold’, I’m afraid. Or rather, not so afraid, as ‘gold’ OA doesn’t have any of the drawbacks of ‘lo-fun’. Fortunately ‘gold’ is more and more showing to be a healthily viable and sustainable business model for open access, at least as long as the scientific community sets so much store by publisher-mediated pre-publication peer review (see <a href="http://theparachute.blogspot.co.uk/2013/11/essence-of-academic-publishing.html" target="_blank">previous post</a> for my thoughts on that). <br />\n<br />\nJan Velterop</div>','\n',char(10)),NULL,'','2013-12-11 21:40:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2013/11/essence-of-academic-publishing.html','Essence of academic publishing',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\n\n\n\n\n\n\n\n\n\n\n\n\n\n<style>@font-face {\n  font-family: "ＭＳ 明朝";\n}@font-face {\n  font-family: "Cambria Math";\n}p.MsoNormal, li.MsoNormal, div.MsoNormal { margin: 0cm 0cm 0.0001pt; font-size: 12pt; font-family: "Times New Roman"; }p.MsoFootnoteText, li.MsoFootnoteText, div.MsoFootnoteText { margin: 0cm 0cm 0.0001pt; font-size: 12pt; font-family: "Times New Roman"; }p.MsoCommentText, li.MsoCommentText, div.MsoCommentText { margin: 0cm 0cm 0.0001pt; font-size: 12pt; font-family: "Times New Roman"; }span.MsoFootnoteReference { vertical-align: super; }span.CommentTextChar {  }span.FootnoteTextChar {  }.MsoChpDefault { font-size: 10pt; }div.WordSection1 { page: WordSection1; }</style>\n\n\n\n\n\n\n<div class="MsoNormal">\n<span lang="EN-US">Let me start with a bit of context, all of\nwhich will be known, understood and widely discussed. The blame of\nunaffordability of the ever-increasing amount of scholarly literature, be it\nbecause of high subscription prices or article processing fees for ‘gold’ open\naccess, is often laid at the door of the publishers. </span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US">The blame, however, should be on the\nacademic preoccupation with the imperative of publisher-mediated prepublication\npeer review (PPR).</span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US">Of course, publishers, subscription-based\nones as well as open access outfits, have a business which depends to a very\nlarge degree on being the organisers of PPR and few of them would like to see\nthe imperative disappear. The ‘need’ – real or perceived – for\npublisher-mediated PPR in the academic ecosystem is the main <i style="mso-bidi-font-style: normal;">raison d’être</i> of most publishers. And it\nis responsible for most of their costs (personnel costs), even though it is\nactually carried out by academics and not publishers. The technical costs of\npublishing are but a fraction of that, at least the cost of electronic\npublishing (print and its distribution are quite expensive, but to be seen as\nan optional service and not as part of the essence of academic publishing).</span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US">Despite it being the imperative in\nAcademia, publisher-mediated PPR has flaws, to say the least. Among causes for\ndeep concern are its anonymity and general lack of transparency, highly variable\nquality, and the unrealistic expectations of what peer review can possibly deliver\nin the first place. The increasing amount of journal articles being submitted\nis making the process of finding appropriate reviewers not easier, either. </span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US">Originally, PPR was a perfectly rational\napproach to ensuring that scarce resources were not spent on the expensive\nbusiness of printing and distributing paper copies of articles that were indeed\nnot deemed to be worth that expense. Unfortunately, the rather subjective\njudgment needed for that approach led to unwelcome side effects, such as\nnegative results not being published. In the era of electronic communication,\nwith its very low marginal costs of dissemination, prepublication filtering\nseems anachronistic. Of course, initial technical costs of publishing each\narticle remain, but the amounts involved are but a fraction of the costs per\narticle of the traditional print-based system, and an even smaller fraction of\nthe average revenues per article many publishers make.</span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US">Now, with the publishers’ argument of\navoiding excessive costs of publishing largely gone, PPR is often presented as\nsome sort of quality filter, protecting readers against unintentionally\nspending their valuable time and effort on unworthy literature. Researchers\nmust be a naïve lot, given the protection they seem to need. The upshot of PPR\nseems to be that anything that is peer reviewed before publication, and does\nget through the gates, is to be regarded as proper, worthwhile, and relevant\nmaterial. But is it? Can it be taken as read that everything in peer-reviewed\npublications is beyond doubt? Should a researcher be reassured by the fact that\nit has passed a number of filters that purport to keep scientific ‘rubbish’\nout? </span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US">Of course they should. These filtering\nmechanisms are there for a reason. They diminish the need for critical\nthinking. Researchers should just believe what they read in ‘approved’\nliterature. They shouldn’t just question everything. </span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US">Or are these the wrong answers?</span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US">Isn’t it time that academics who are\nrelying on PPR ‘quality’ filters – and let us hope it’s a minority of them –\nshould stop believing at face value what is being presented in the ‘properly\npeer-reviewed and approved’ literature, and go back to the critical stance that\nis the hallmark of a true scientist: “why should I believe these results or\nthese assertions?” The fact that an article is peer-reviewed in no way absolves\nresearchers of applying professional skepticism to whatever they are reading.\nFurther review, post-publication, remains necessary. It’s part of the\nfundamentals of the scientific method. </span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US">So, what about this: a system in which\nauthors discuss, in-depth and critically, their manuscripts with a few people\nwho they can identify and accept as their peers. And then ask those people to\nput their name to the manuscript as ‘endorsers’. As long as some reasonable\nsafeguards are in place that endorsers are genuine, serious and without\nundeclared conflicts of interest (e.g. they shouldn’t be recent colleagues at\nthe same institution as the author, or be involved in the same collaborative\nproject, or have been a co-author in, say, the last five years), the value of\nthis kind of peer-review – author-mediated PPR, if you wish – is unlikely to be\nany less than publisher-mediated PPR. In fact, it’s likely to offer more value,\nif only due to transparency and to the expected reduction in the cost of\npublishing. It doesn’t mean, of course, that the peer-endorsers should agree\nwith all of the <i style="mso-bidi-font-style: normal;">content</i> of the\narticles they endorse. They merely endorse its <i style="mso-bidi-font-style: normal;">publication</i>. Steve Pettifer of the University of Manchester once\npresented a perfect example of this. He showed a quote from Alan Singleton\nabout a peer reviewer’s report<a href="http://www.blogger.com/blogger.g?blogID=12960760#_ftn1" name="_ftnref1" style="mso-footnote-id: ftn1;" title=""><span class="MsoFootnoteReference"><span style="mso-special-character: footnote;"><span class="MsoFootnoteReference"><span lang="EN-US" style="font-family: &quot;Times New Roman&quot;; font-size: 12.0pt; mso-ansi-language: EN-US; mso-bidi-language: AR-SA; mso-fareast-font-family: &quot;ＭＳ 明朝&quot;; mso-fareast-language: EN-US; mso-fareast-theme-font: minor-fareast;">[1]</span></span></span></span></a>:</span></div>\n<div class="MsoNormal">\n<span lang="EN-US"><br /></span></div>\n<div class="MsoNormal">\n<span lang="EN-US"><span style="mso-spacerun: yes;">\n\n\n\n\n\n\n\n\n\n\n\n\n<style>\n<!--\n /* Font Definitions */\n@font-face\n {font-family:"ＭＳ 明朝";\n mso-font-charset:78;\n mso-generic-font-family:auto;\n mso-font-pitch:variable;\n mso-font-signature:1 134676480 16 0 131072 0;}\n@font-face\n {font-family:"Cambria Math";\n panose-1:2 4 5 3 5 4 6 3 2 4;\n mso-font-charset:0;\n mso-generic-font-family:auto;\n mso-font-pitch:variable;\n mso-font-signature:-536870145 1107305727 0 0 415 0;}\n /* Style Definitions */\np.MsoNormal, li.MsoNormal, div.MsoNormal\n {mso-style-unhide:no;\n mso-style-qformat:yes;\n mso-style-parent:"";\n margin:0cm;\n margin-bottom:.0001pt;\n mso-pagination:widow-orphan;\n font-size:12.0pt;\n font-family:"Times New Roman";\n mso-fareast-font-family:"ＭＳ 明朝";\n mso-fareast-theme-font:minor-fareast;\n mso-ansi-language:EN-US;}\n.MsoChpDefault\n {mso-style-type:export-only;\n mso-default-props:yes;\n font-size:10.0pt;\n mso-ansi-font-size:10.0pt;\n mso-bidi-font-size:10.0pt;\n mso-fareast-font-family:"ＭＳ 明朝";\n mso-fareast-theme-font:minor-fareast;\n mso-fareast-language:JA;}\n@page WordSection1\n {size:612.0pt 792.0pt;\n margin:72.0pt 90.0pt 72.0pt 90.0pt;\n mso-header-margin:36.0pt;\n mso-footer-margin:36.0pt;\n mso-paper-source:0;}\ndiv.WordSection1\n {page:WordSection1;}\n-->\n</style>\n\n\n\n\n\n\n</span></span></div>\n<div class="MsoNormal" style="margin-left: 36.0pt; text-align: justify; text-justify: inter-ideograph;">\n<i style="mso-bidi-font-style: normal;"><span lang="EN-US" style="mso-fareast-language: JA;">"This is a remarkable result – in fact, I\ndon’t believe it. However, I have examined the paper and can find no fault in\nthe author’s methods and results. Thus I believe it should be published so that\nothers may assess it and the conclusions and/or repeat the experiment to see\nwhether the same results are achieved."</span><span lang="EN-US"></span></i></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="mso-fareast-language: JA;">An\nauthor-mediated PPR-ed manuscript could subsequently be properly published,\ni.e. put in a few robust, preservation-proof formats, properly encoded with\nUnicode characters, uniquely identified and identifiable, time-stamped, citable\nin any reference format, suitable for human- and machine-reading, data\nextraction, reuse, deposit in open repositories, printing, and everything else\nthat one might expect of a professionally produced publication, including a facility for post-publication commenting and review. That will cost,\nof course, but it will be a fraction of the current costs of publication, be\nthey paid for via subscriptions, article processing charges, or subsidies. Good\nfor the affordability of open access publishing for minimally funded authors,\ne.g. in the social sciences and humanities, and for the publication of negative\nresults that, though very useful, hardly get a chance in the current system.</span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="mso-fareast-language: JA;">Comments welcome.</span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US" style="mso-fareast-language: JA;">Jan Velterop </span></div>\n<div style="mso-element: footnote-list;">\n<br clear="all" />\n\n<hr align="left" size="1" width="33%" />\n\n\n\n<div id="ftn1" style="mso-element: footnote;">\n\n<div class="MsoCommentText">\n<a href="http://www.blogger.com/blogger.g?blogID=12960760#_ftnref1" name="_ftn1" style="mso-footnote-id: ftn1;" title=""><span class="MsoFootnoteReference"><span lang="EN-US"><span style="mso-special-character: footnote;"><span class="MsoFootnoteReference"><span lang="EN-US" style="font-family: &quot;Times New Roman&quot;; font-size: 12.0pt; mso-ansi-language: EN-US; mso-bidi-language: AR-SA; mso-fareast-font-family: &quot;ＭＳ 明朝&quot;; mso-fareast-language: EN-US; mso-fareast-theme-font: minor-fareast;">[1]</span></span></span></span></span></a><span lang="EN-US"> Singleton, A. The Pain Of Rejection, <i>Learned Publishing</i>,\n24:162–163 </span></div>\n<div class="MsoFootnoteText">\n<span lang="EN-US">doi:10.1087/20110301</span></div>\n</div>\n</div>\n</div>','\n',char(10)),NULL,'','2013-11-05 18:41:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2013/02/transitions-transitions.html','Transitions, transitions',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\n\n\n\n\n\n\n\n\n\n\n\n\n<style>\n<!--\n /* Font Definitions */\n@font-face\n {font-family:"ＭＳ 明朝";\n mso-font-charset:78;\n mso-generic-font-family:auto;\n mso-font-pitch:variable;\n mso-font-signature:-536870145 1791491579 18 0 131231 0;}\n@font-face\n {font-family:"ＭＳ 明朝";\n mso-font-charset:78;\n mso-generic-font-family:auto;\n mso-font-pitch:variable;\n mso-font-signature:-536870145 1791491579 18 0 131231 0;}\n /* Style Definitions */\np.MsoNormal, li.MsoNormal, div.MsoNormal\n {mso-style-unhide:no;\n mso-style-qformat:yes;\n mso-style-parent:"";\n margin:0cm;\n margin-bottom:.0001pt;\n mso-pagination:widow-orphan;\n font-size:12.0pt;\n font-family:"Times New Roman";\n mso-fareast-font-family:"ＭＳ 明朝";\n mso-fareast-theme-font:minor-fareast;\n mso-ansi-language:EN-US;}\na:link, span.MsoHyperlink\n {mso-style-priority:99;\n color:blue;\n mso-themecolor:hyperlink;\n text-decoration:underline;\n text-underline:single;}\na:visited, span.MsoHyperlinkFollowed\n {mso-style-noshow:yes;\n mso-style-priority:99;\n color:purple;\n mso-themecolor:followedhyperlink;\n text-decoration:underline;\n text-underline:single;}\n.MsoChpDefault\n {mso-style-type:export-only;\n mso-default-props:yes;\n font-size:10.0pt;\n mso-ansi-font-size:10.0pt;\n mso-bidi-font-size:10.0pt;\n mso-fareast-font-family:"ＭＳ 明朝";\n mso-fareast-theme-font:minor-fareast;\n mso-fareast-language:JA;}\n@page WordSection1\n {size:595.0pt 842.0pt;\n margin:72.0pt 89.85pt 72.0pt 89.85pt;\n mso-header-margin:35.45pt;\n mso-footer-margin:35.45pt;\n mso-paper-source:0;}\ndiv.WordSection1\n {page:WordSection1;}\n-->\n</style>\n\n\n\n\n\n\n<br />\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<b style="mso-bidi-font-weight: normal;"><span lang="EN-US" style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;"></span></b><span lang="EN-US" style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;"></span><span lang="EN-US" style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;">Although I am generally very skeptical of\nany form of exceptionalism, political, cultural, academic, or otherwise, I do\nthink that scholarly publishing is quite different from professional and\ngeneral non-fiction publishing. The difference is the relationship between\nauthors and readers. That relationship is far more of a two-way affair for\nscholarly literature than for any other form of publishing.</span>\n\n</div>\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<br /></div>\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<span lang="EN-US" style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;">Broad and open dissemination of research\nresults, knowledge, and insights has always been the hallmark of science. When\nthe Elseviers/Elzevirs (no relation to the current company of the same name,\nwhich was started by Mr. Robbers [his last name; I can’t help it] a century and\na half after the Elsevier family stopped their business), among the first true\n‘publishers’, started to publish scholarship, for example the writings of\nErasmus, they used the technology of the day to spread knowledge as widely as\nwas then possible. </span></div>\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<br /></div>\n<div class="MsoNormal" style="text-align: left;">\n<span lang="EN-US" style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;">In those days, publishing meant ‘to make\npublic’. And ‘openness’ was primarily to do with escaping censorship. (Some\nmembers of the Elsevier family went as far as to establish a pseudonymous\nimprint, <a href="http://en.wikipedia.org/wiki/Pierre_Marteau" target="_blank">Pierre Marteau</a>, </span><span lang="EN-US"><a href="http://en.wikipedia.org/wiki/Pierre_Marteau"><span style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;"></span></a></span><span lang="EN-US" style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;"> in order to secure\nfreedom from censorship). <span style="mso-bookmark: OLE_LINK2;">But openness in a wider sense — freedom from\ncensorship as well as broad availability — has, together with peer-review, been\na constituent part of what is understood by the notions of scholarship and\nscience since the Enlightenment. Indeed, science can be seen as a process of\ncontinuous and open review, criticism, and revision, by people who understand\nthe subject matter: ‘peers’.</span></span></div>\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<br /></div>\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<span style="mso-bookmark: OLE_LINK1;"><span style="mso-bookmark: OLE_LINK2;"><span lang="EN-US" style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;">The practicalities of\ndissemination in print dictated that funds must be generated to defray the cost\nof publishing. And pre-publication peer review emerged as a way to limit waste\nof precious paper and its distribution cost by weeding out what wasn’t up to\nstandards of scientific rigour and therefore not worth the expense needed to\npublish. The physical nature of books and journals, and of their transportation\nby stagecoach, train, ship, lorry, and the like, made it completely\nunderstandable and acceptable that scientific publications had to be paid for.\nUsually by means of subscriptions. However, scientific information never really\nwas a physical good. It only looked like that, because of the necessary\nphysicality of the information carriers. The essence of science publishing was\nthe service of making public. You paid for the service, though it felt like\npaying for something tangible.</span></span></span></div>\n<span style="mso-bookmark: OLE_LINK2;"></span><span style="mso-bookmark: OLE_LINK1;"></span>\n\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<br /></div>\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<span lang="EN-US" style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;">The new technology of the internet,\nspecifically the development of web browsers (remember <a href="ftp://ftp.ncsa.uiuc.edu/Web/Mosaic/Windows/Archive/MosaicHistory.html" target="_blank">Mosaic</a>?),\nchanged the publishing environment fundamentally. The need for carriers that\nhad to be physically transported all but disappeared from the equation. The\nirresistible possibility of unrestrained openness emerged. But something else\nhappened as well. With the disappearance of physical carriers of information,\nsoftware, etc. the perception of value changed. The psychology of paying for\nphysical carriers, such as books, journals, CDs, DVDs is very different from\nthe psychology of paying for intangibles, such as binary strings downloaded\nfrom the web, with no other carrier than wire, or optical cable, or even radio\nwaves. In order to perceive value, the human expectation — need, even — for\nphysical, tangible goods in exchange for payment is very strong, though not\nnecessarily rational, especially where we have been used to receiving physical\ngoods in exchange for money for a very long time. That is not to say that we\nwouldn’t be prepared to value and to pay for intangibles, like services. We do\nthat all the time. But it has to be clear to us what exactly the value of a\nservice is — something we often find more difficult, reportedly, than for\nphysical goods.</span></div>\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<br /></div>\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<span lang="EN-US" style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;">This is a conundrum for science publishers.\nCarrying on with what they are used to, but then presented as a service and not\n‘supported’ by physical goods any longer, can look very ‘thin’. Yet it is clear\nthat the assistance publishers provide to the process of science communication\nis a service <i style="mso-bidi-font-style: normal;">par excellence</i>. Mainly\nto authors (''publish-or-perish'') and less so to readers (‘read-or-rot’ isn’t a\nstrong adage). Hence the author-side payment pioneered by open access\npublishers (Article Processing Charges, or APCs).</span></div>\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<br /></div>\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<span lang="EN-US" style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;">Although it would be desirable to make the\ntransit to open access electronic publishing swiftly, the reality of inertia in\nthe ‘system’ dictates that there be a transition period and method. This\ntransition is sought in many different ways: new, born-OA journals that\ngradually attract more authors; hybrid journals that accept OA articles against\nauthor-side payment; ‘green’ mandates, that require authors to self-archive a\ncopy of their published articles; unmediated, ‘informal’ publishing such as in\narXiv; even publishing on blogs. </span></div>\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<br /></div>\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<span lang="EN-US" style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;">What may be an underestimated transition —\nand no-doubt a controversial one — is a model (a kind of ‘freemium’ model?)\nthat’s gradually changing from restrictive to more and more open, extending the\n‘free’, ‘open’ element and reducing the features that have to be paid for by\nthe user. I even don’t think it is recognized as a potential transition model\nat the moment at all, but that may be missing opportunities. Let’s take a look\nat an </span><span lang="EN-US"><a href="http://www.sciencedirect.com/science/article/pii/S0022283608015040"><span style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;">example</span></a></span><span lang="EN-US" style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;">. If you don’t have a\nsubscription you can’t see the full-text. However, where only a short time ago\nyou saw only the title and the abstract, you now see those, plus keywords and the\nabbreviations used in the article, its outline in some detail, and all the\nfigures with their captions (hint to authors: put as much of the essence of\nyour paper in the captions). All useful information. It is not a great stretch\nto imagine that the references are added to what non-subscribers can see\n(indeed, </span><span lang="EN-US"><a href="http://opencitations.wordpress.com/2012/06/16/science-joins-nature-in-opening-reference-citations/"><span style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;">some publishers</span></a></span><span lang="EN-US" style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;"> already do that), and\neven the important single scientific assertions in an article, possibly in the\nform of ‘<a href="http://nanopub.org/wordpress/">nanopublications</a>’, on the\nway to eventual complete openness. </span></div>\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<br /></div>\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<span lang="EN-US" style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;">Of course, it is not the same as full, <a href="http://www.opensocietyfoundations.org/openaccess/read" target="_blank">BOAI-compliant open access</a>, but in\nareas where ‘ocular’ access is perhaps less important than the ability to use\nand recombine factual data found in the literature, it may provide important\nsteps during what may otherwise be quite a protracted transition from\ntoll-access to open access, from a model based on physical product analogies to\none based on the provision of services that science needs.</span></div>\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<br /></div>\n<div class="MsoNormal" style="mso-layout-grid-align: none; mso-pagination: none; text-autospace: none;">\n<span lang="EN-US" style="font-family: Helvetica; mso-bidi-font-family: Helvetica; mso-fareast-language: JA;">Jan Velterop </span></div>\n</div>','\n',char(10)),NULL,'','2013-02-05 14:36:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2013/01/on-knowledge-sharing-upgoerfive.html','On knowledge sharing — #upgoerfive',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\nThis post was written with the&nbsp; <a href="http://splasho.com/upgoer5/" target="_blank">#upgoerfive text editor</a>, using only the most common 1000 words in English.<br />\n<br />\nAt one time there was a man who some people thought was god. Other \npeople thought he was sent to the world by god. This man had two water \nanimals you could eat and five pieces of other food and he wanted the \nmany people who were with him to have enough to eat. But two water \nanimals and five other pieces of food were not enough for the people if \nthey all had to eat. So the man who some people thought was god and \nothers that he was sent by god, made the food last until all the people \nhad had enough to eat. This was a wonder. The people saw this and did \nnot know if they could believe what they saw. But when it seemed true \nthat he had a power that no other men or women had, they believed the man \nwas really god or sent by god, because he could do what other men could \nnever do at all. This story became very well known. And many people \nbelieve it is about food.<br /><br />But I think it is not about food. I \nthink it is about food for thought. About what we know, not about what \nwe eat. Because if we give food that we have to others, we do not have \nit anymore for us to eat. But if we tell others what we know, they know \nit, too, and we still know it as well. So we can not share our food and \nstill have it all, but we can share what we know and still have it all. \nWe should share what we know if it is good for us all. Especially people\n who work on knowing more and more every day, as their job. They are \npaid by us all to work in their jobs on knowing more and more, and they \nreally should share what they come to know with us, and in such a way \nthat we can understand it, too.<br />\n<br />\nJan Velterop </div>','\n',char(10)),NULL,'','2013-01-19 09:15:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2013/01/imagine-if-funding-bodies-did-this.html','Imagine if funding bodies did this',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\n<div>\n<style>\n<!--\n /* Font Definitions */\n@font-face\n {font-family:"Courier New";\n panose-1:2 7 3 9 2 2 5 2 4 4;\n mso-font-charset:0;\n mso-generic-font-family:auto;\n mso-font-pitch:variable;\n mso-font-signature:-536859905 -1073711037 9 0 511 0;}\n@font-face\n {font-family:Wingdings;\n panose-1:2 0 5 0 0 0 0 0 0 0;\n mso-font-charset:2;\n mso-generic-font-family:auto;\n mso-font-pitch:variable;\n mso-font-signature:0 268435456 0 0 -2147483648 0;}\n@font-face\n {font-family:"ＭＳ 明朝";\n mso-font-charset:78;\n mso-generic-font-family:auto;\n mso-font-pitch:variable;\n mso-font-signature:-536870145 1791491579 18 0 131231 0;}\n@font-face\n {font-family:Verdana;\n panose-1:2 11 6 4 3 5 4 4 2 4;\n mso-font-charset:0;\n mso-generic-font-family:auto;\n mso-font-pitch:variable;\n mso-font-signature:-1593833729 1073750107 16 0 415 0;}\n@font-face\n {font-family:"Cambria Math";\n panose-1:2 4 5 3 5 4 6 3 2 4;\n mso-font-charset:0;\n mso-generic-font-family:auto;\n mso-font-pitch:variable;\n mso-font-signature:-536870145 1107305727 0 0 415 0;}\n /* Style Definitions */\np.MsoNormal, li.MsoNormal, div.MsoNormal\n {mso-style-unhide:no;\n mso-style-qformat:yes;\n mso-style-parent:"";\n margin:0cm;\n margin-bottom:.0001pt;\n mso-pagination:widow-orphan;\n font-size:12.0pt;\n font-family:"Times New Roman";\n mso-fareast-font-family:"ＭＳ 明朝";\n mso-fareast-theme-font:minor-fareast;\n mso-ansi-language:EN-US;}\np.MsoListParagraph, li.MsoListParagraph, div.MsoListParagraph\n {mso-style-priority:34;\n mso-style-unhide:no;\n mso-style-qformat:yes;\n margin-top:0cm;\n margin-right:0cm;\n margin-bottom:0cm;\n margin-left:36.0pt;\n margin-bottom:.0001pt;\n mso-add-space:auto;\n mso-pagination:widow-orphan;\n font-size:12.0pt;\n font-family:"Times New Roman";\n mso-fareast-font-family:"ＭＳ 明朝";\n mso-fareast-theme-font:minor-fareast;\n mso-ansi-language:EN-US;}\np.MsoListParagraphCxSpFirst, li.MsoListParagraphCxSpFirst, div.MsoListParagraphCxSpFirst\n {mso-style-priority:34;\n mso-style-unhide:no;\n mso-style-qformat:yes;\n mso-style-type:export-only;\n margin-top:0cm;\n margin-right:0cm;\n margin-bottom:0cm;\n margin-left:36.0pt;\n margin-bottom:.0001pt;\n mso-add-space:auto;\n mso-pagination:widow-orphan;\n font-size:12.0pt;\n font-family:"Times New Roman";\n mso-fareast-font-family:"ＭＳ 明朝";\n mso-fareast-theme-font:minor-fareast;\n mso-ansi-language:EN-US;}\np.MsoListParagraphCxSpMiddle, li.MsoListParagraphCxSpMiddle, div.MsoListParagraphCxSpMiddle\n {mso-style-priority:34;\n mso-style-unhide:no;\n mso-style-qformat:yes;\n mso-style-type:export-only;\n margin-top:0cm;\n margin-right:0cm;\n margin-bottom:0cm;\n margin-left:36.0pt;\n margin-bottom:.0001pt;\n mso-add-space:auto;\n mso-pagination:widow-orphan;\n font-size:12.0pt;\n font-family:"Times New Roman";\n mso-fareast-font-family:"ＭＳ 明朝";\n mso-fareast-theme-font:minor-fareast;\n mso-ansi-language:EN-US;}\np.MsoListParagraphCxSpLast, li.MsoListParagraphCxSpLast, div.MsoListParagraphCxSpLast\n {mso-style-priority:34;\n mso-style-unhide:no;\n mso-style-qformat:yes;\n mso-style-type:export-only;\n margin-top:0cm;\n margin-right:0cm;\n margin-bottom:0cm;\n margin-left:36.0pt;\n margin-bottom:.0001pt;\n mso-add-space:auto;\n mso-pagination:widow-orphan;\n font-size:12.0pt;\n font-family:"Times New Roman";\n mso-fareast-font-family:"ＭＳ 明朝";\n mso-fareast-theme-font:minor-fareast;\n mso-ansi-language:EN-US;}\n.MsoChpDefault\n {mso-style-type:export-only;\n mso-default-props:yes;\n font-size:10.0pt;\n mso-ansi-font-size:10.0pt;\n mso-bidi-font-size:10.0pt;\n mso-fareast-font-family:"ＭＳ 明朝";\n mso-fareast-theme-font:minor-fareast;\n mso-fareast-language:JA;}\n@page WordSection1\n {size:612.0pt 792.0pt;\n margin:72.0pt 90.0pt 72.0pt 90.0pt;\n mso-header-margin:36.0pt;\n mso-footer-margin:36.0pt;\n mso-paper-source:0;}\ndiv.WordSection1\n {page:WordSection1;}\n /* List Definitions */\n@list l0\n {mso-list-id:739521957;\n mso-list-template-ids:67698719;\n mso-list-style-id:1897082247;}\n@list l0:level1\n {mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:18.0pt;\n text-indent:-18.0pt;}\n@list l0:level2\n {mso-level-text:"%1\.%2\.";\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:39.6pt;\n text-indent:-21.6pt;}\n@list l0:level3\n {mso-level-text:"%1\.%2\.%3\.";\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:61.2pt;\n text-indent:-25.2pt;}\n@list l0:level4\n {mso-level-text:"%1\.%2\.%3\.%4\.";\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:86.4pt;\n text-indent:-32.4pt;}\n@list l0:level5\n {mso-level-text:"%1\.%2\.%3\.%4\.%5\.";\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:111.6pt;\n text-indent:-39.6pt;}\n@list l0:level6\n {mso-level-text:"%1\.%2\.%3\.%4\.%5\.%6\.";\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:136.8pt;\n text-indent:-46.8pt;}\n@list l0:level7\n {mso-level-text:"%1\.%2\.%3\.%4\.%5\.%6\.%7\.";\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:162.0pt;\n text-indent:-54.0pt;}\n@list l0:level8\n {mso-level-text:"%1\.%2\.%3\.%4\.%5\.%6\.%7\.%8\.";\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:187.2pt;\n text-indent:-61.2pt;}\n@list l0:level9\n {mso-level-text:"%1\.%2\.%3\.%4\.%5\.%6\.%7\.%8\.%9\.";\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:216.0pt;\n text-indent:-72.0pt;}\n@list l1\n {mso-list-id:1897082247;\n mso-list-template-ids:67698719;\n mso-list-style-priority:99;\n mso-list-style-name:"1 \/ 1\.1 \/ 1\.1\.1";}\n@list l1:level1\n {mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:18.0pt;\n text-indent:-18.0pt;}\n@list l1:level2\n {mso-level-text:"%1\.%2\.";\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:39.6pt;\n text-indent:-21.6pt;}\n@list l1:level3\n {mso-level-text:"%1\.%2\.%3\.";\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:61.2pt;\n text-indent:-25.2pt;}\n@list l1:level4\n {mso-level-text:"%1\.%2\.%3\.%4\.";\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:86.4pt;\n text-indent:-32.4pt;}\n@list l1:level5\n {mso-level-text:"%1\.%2\.%3\.%4\.%5\.";\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:111.6pt;\n text-indent:-39.6pt;}\n@list l1:level6\n {mso-level-text:"%1\.%2\.%3\.%4\.%5\.%6\.";\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:136.8pt;\n text-indent:-46.8pt;}\n@list l1:level7\n {mso-level-text:"%1\.%2\.%3\.%4\.%5\.%6\.%7\.";\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:162.0pt;\n text-indent:-54.0pt;}\n@list l1:level8\n {mso-level-text:"%1\.%2\.%3\.%4\.%5\.%6\.%7\.%8\.";\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:187.2pt;\n text-indent:-61.2pt;}\n@list l1:level9\n {mso-level-text:"%1\.%2\.%3\.%4\.%5\.%6\.%7\.%8\.%9\.";\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n margin-left:216.0pt;\n text-indent:-72.0pt;}\n@list l2\n {mso-list-id:2004042459;\n mso-list-type:hybrid;\n mso-list-template-ids:451457354 67698691 67698691 67698693 67698689 67698691 67698693 67698689 67698691 67698693;}\n@list l2:level1\n {mso-level-number-format:bullet;\n mso-level-text:o;\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n text-indent:-18.0pt;\n font-family:"Courier New";\n mso-bidi-font-family:"Times New Roman";}\n@list l2:level2\n {mso-level-number-format:bullet;\n mso-level-text:o;\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n text-indent:-18.0pt;\n font-family:"Courier New";\n mso-bidi-font-family:"Times New Roman";}\n@list l2:level3\n {mso-level-number-format:bullet;\n mso-level-text:;\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n text-indent:-18.0pt;\n font-family:Wingdings;}\n@list l2:level4\n {mso-level-number-format:bullet;\n mso-level-text:;\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n text-indent:-18.0pt;\n font-family:Symbol;}\n@list l2:level5\n {mso-level-number-format:bullet;\n mso-level-text:o;\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n text-indent:-18.0pt;\n font-family:"Courier New";\n mso-bidi-font-family:"Times New Roman";}\n@list l2:level6\n {mso-level-number-format:bullet;\n mso-level-text:;\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n text-indent:-18.0pt;\n font-family:Wingdings;}\n@list l2:level7\n {mso-level-number-format:bullet;\n mso-level-text:;\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n text-indent:-18.0pt;\n font-family:Symbol;}\n@list l2:level8\n {mso-level-number-format:bullet;\n mso-level-text:o;\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n text-indent:-18.0pt;\n font-family:"Courier New";\n mso-bidi-font-family:"Times New Roman";}\n@list l2:level9\n {mso-level-number-format:bullet;\n mso-level-text:;\n mso-level-tab-stop:none;\n mso-level-number-position:left;\n text-indent:-18.0pt;\n font-family:Wingdings;}\nol\n {margin-bottom:0cm;}\nul\n {margin-bottom:0cm;}\n</style> <br />\n<span style="mso-bookmark: OLE_LINK5;"><span lang="EN-US" style="font-family: Verdana; font-size: 10.0pt; mso-bidi-font-family: Verdana; mso-fareast-language: JA;">There is apparently a widespread fear that if a ‘gold’\n(author-side paid) open access model for publishing scientific research is supported by funding bodies, the\nso-called article processing fees, paid for by funders on behalf of authors, might see unbridled increases. This fear is\nnot unwarranted if not addressed properly. If funders agree to pay whatever\npublishers charge, they undermine the potential for competition among\npublishers and provide them with an incentive to maximize their income, while\nat the same time removing any price sensitivity on the part of the publishing\nresearcher. However, it is not very difficult to address this problem.</span></span><br />\n<br />\n<span style="mso-bookmark: OLE_LINK4;"><span style="mso-bookmark: OLE_LINK5;"><span lang="EN-US" style="font-family: Verdana; font-size: 10.0pt; mso-bidi-font-family: Verdana; mso-fareast-language: JA;">In order to avoid untrammeled article processing\nfee increases, funding bodies should foster competition amongst publishers, and create price\nsensitivity to article processing charges in researchers publishing their\nresults.</span></span></span><br />\n<br />\n<span style="mso-bookmark: OLE_LINK4;"><span style="mso-bookmark: OLE_LINK5;"><span lang="EN-US" style="font-family: Verdana; font-size: 10.0pt; mso-bidi-font-family: Verdana; mso-fareast-language: JA;">Imagine if they did the following:</span></span></span><br />\n<ul style="text-align: left;">\n<li><span style="mso-bookmark: OLE_LINK4;"><span style="mso-bookmark: OLE_LINK5;"><span lang="EN-US" style="font-family: Verdana; font-size: 10.0pt; mso-bidi-font-family: Verdana; mso-fareast-language: JA;">Require open access publishing of research results; </span></span></span></li>\n<li><span style="mso-bookmark: OLE_LINK4;"><span style="mso-bookmark: OLE_LINK5;"><span lang="EN-US" style="font-family: Verdana; font-size: 10.0pt; mso-bidi-font-family: Verdana; mso-fareast-language: JA;">Include in any grants a fixed amount for\npublishing results in open access journals;</span></span></span></li>\n<li><span style="mso-bookmark: OLE_LINK4;"><span style="mso-bookmark: OLE_LINK5;"><span lang="EN-US" style="font-family: Verdana; font-size: 10.0pt; mso-bidi-font-family: Verdana; mso-fareast-language: JA;">Allow researchers to spend either more or less\nthan that amount on article processing charges, any surplus to be used for the\nresearch itself, or any shortfall to be paid from the research budget; </span></span></span></li>\n<li><span style="mso-bookmark: OLE_LINK4;"><span style="mso-bookmark: OLE_LINK5;"><span lang="EN-US" style="font-family: Verdana; font-size: 10.0pt; mso-bidi-font-family: Verdana; mso-fareast-language: JA;">Require any excess paid over and above the\nfixed amount to be justified by the researcher to the funder;</span></span></span></li>\n<li><span style="mso-bookmark: OLE_LINK4;"><span style="mso-bookmark: OLE_LINK5;"><span lang="EN-US" style="font-family: Verdana; font-size: 10.0pt; mso-bidi-font-family: Verdana; mso-fareast-language: JA;">Provide a fixed amount for more than one\npublication if the research project warrants that, but so that researchers have\nan incentive to limit the number of published articles instead of\nsalami-slicing the results into as many articles as possible, again by giving\nthem discretion over how the fixed amounts are spent.&nbsp; </span></span></span></li>\n</ul>\n</div>\n<span style="mso-bookmark: OLE_LINK4;"><span style="mso-bookmark: OLE_LINK5;"><span lang="EN-US" style="font-family: Verdana; font-size: 10.0pt; mso-bidi-font-family: Verdana; mso-fareast-language: JA;">Jan Velterop</span></span></span><div>\n<ul style="text-align: left;">\n</ul>\n<div style="text-align: left;">\n</div>\n</div>\n</div>','\n',char(10)),NULL,'','2013-01-15 09:26:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2012/09/pixels-of-information.html','''Pixels of information''',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\n<i>My friend Barend Mons wrote to me and I think it is worth sharing his letter on this blog. I checked with him, and he agrees that it can be shared on this blog.</i><br />\n<blockquote class="tr_bq">\n<span style="font-size: small;"><span style="font-family: inherit;">Dear Jan,<br /><br />I''m writing to you inspired by your remark that "OA is not a goal in itself but one means to an end: more effective knowledge discovery". <br /><br />What we need for eScience is Open Information to support the Knowledge Discovery process. As eScience can be pictured as ''science that can not be done without a computer'', computer reasonable information is the most important element to be ''open''.&nbsp; </span></span></blockquote>\n<span style="font-size: small;"><i>You''re right, Barend. That''s why I think CC-BY is a necessary element of open access.&nbsp;</i></span><br />\n<blockquote class="tr_bq">\n<span style="font-size: small;"><span style="font-family: inherit;">As we discussed many times before, computer reasoning and ''<i>in silico</i>'' knowledge discovery leads essentially to ''hypotheses'' not to final discoveries. There are two very important next steps. First, what I would call ''<i>in cerebro</i>'' validation, mainly browsing the suggestions provided by computer algorithms mining the literature and ''validating'' individual assertions (call them triples if you wish) in their original context. ''Who asserted it, where, based on what experimental evidence, assay...?'' etc. In other words, why should I believe (in the context of my knowledge discovery process) this individual element of my ''hypothesis-graph'' to be ''true'' or ''valid''? Obviously in the end, the entire hypothesis put forward by a computer algorithm and ''pre''-validated by human reasoning based on ''what we collectively already know'' needs to be experimentally proven (call it ''<i>in origine</i>'' validation). <br /><br />What I would like to discuss in a bit more depth is the ''<i>in cerebro</i>'' part. For practical purposes I here define ''everything we collectively know'', or at least what we have ''shared'' as the ''explicitome'' (I hope Jon Eisen doesn''t include that in his ''bad -omes''), essentially a huge dynamic graph of ''<a href="http://nanopub.org/wordpress/" target="_blank">nanopublications</a>'' or actually rather ''cardinal assertions'' where identical, repetitive nanopublications have already been aggregated and assigned an ''evidence factor''.&nbsp; Whenever a given assertion (connecting triple) is not a ''completely established fact'' (the sort of assertion you repeat in a new narrative without the need to add a reference/citation) we will go to narrative text ''forever'' to ''check the validity'' in my opinion.<br /><br />Major computer power is now exploited for various intelligent ways to infer the ''implicitome'' of what we implicitly know (sorry, Jon, should you ever see this!), but triples captured in RDF are certainly no replacement for narrative in terms of reading a good reasoning, why conclusions are warranted, extensive description of materials and methods etc. So the ''validation'' of triples outside their context will be a very important process in eScience for many decades to come. In fact your earlier metaphor of the ''<a href="http://opendepot.org/1291/" target="_blank">minutes of science</a>'' fits perfectly in this model. ''Why would I believe this particular assertion''? ... Well, look in the minutes by whom, where and based on what evidence it was made''. <br /><br />Now here is a very relevant part of the OA discussion: The time when some people thought that OA was a sort of charity model for scientific publishing is definitely over, with profitable OA publishers around us. The only real difference is: do we (the authors) pay up front, or do we refuse that (for whatever good reason, see below) and now the reader has to pay ''after the fact''. So let''s first agree that there is no ''moral superiority'', whatever that is, in OA over the traditional subscription model. &nbsp;</span></span></blockquote>\n<span style="font-size: small;"><i>Not sure if I agree, Barend. OK, let''s leave morals out of it, but first of all, articles in subscription journals can also be made open access via the so-called ''green'' route of depositing the accepted manuscript in an open repository; and secondly, OA at source, the so-called ''gold'' route, is definitely practically and transparently the superior way to share scientific information with anyone who needs or wants it.</i></span><br />\n<blockquote class="tr_bq">\n<span style="font-size: small;"><span style="font-family: inherit;">We have also seen the downsides of OA, for instance for researchers in developing countries who may still have great difficulty to find the substantial fees to publish in the leading Open Access journals. <br /><br />I believe however, that we have a great paradigm shift right in front of us. Computer reasoning and ultralight ''RDF graphs'' distributing the results to (<i>inter alia</i>) mobile devices will allow global open distribution of such ''pixels of information'' at affordable costs, even in developing countries. Obviously, a practice that will be associated is to ''go and check'' the validity of individual assertions in these graphs. That is exactly where the ''classical'' narrative article will continue to have its great value. It is clear that the costs of reviewing, formatting, cross-linking and sustainably providing the ''minutes of science'' is costly and that the community will have to pay for these costs via various routes. I feel that it is perfectly defensible that those articles for which the publishing costs have not been paid for by the authors, and that are still being provided by classical publishing houses, should continue to ''have a price''. As long as all nanopublications (let''s say the assertions representing the ''dry facts'' contained in the narrative legacy as well as data in databases) are exposed in Open (RDF) Spaces for people and computers to reason with, the knowledge discovery process will be enormously accelerated. Some people may still resent that they may have to pay (at least for some time to come) for narrative that was published following the ''don''t pay now — subscribe later'' adage. We obviously believe that the major players from the ''subscription age'' have a responsibility, but also a very strong incentive to develop new methods and business models that allow a smooth transition to eScience-supportive publication without becoming extinct before they can adapt. <br /><br />Best,</span></span></blockquote>\n<blockquote class="tr_bq">\n<span style="font-size: small;"><span style="font-family: inherit;">Barend</span></span></blockquote>\n<i>Your views are certainly worth a serious and in-depth discussion, Barend. I invite readers of this blog to join in and engage in that discussion.</i><br />\n<br />\n<i>Jan Velterop</i><br />\n</div>','\n',char(10)),NULL,'','2012-09-09 14:11:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2012/08/open-access-gold-versus-green.html','Open access – gold versus green',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\nRecently, Andrew Adams contributed to the ''gold'' vs. ''green'' open access discussion and he wrote this on the LIBLICENSE list (edited for typos):<br />\n<blockquote class="tr_bq">\n<i>There are on the order of 10,000 research instutitions and more than ten times as many journals. Persudaing 10,000 institutions to adopt OA deposit mandates seems to me a quicker and more certain route to obtain OA than persuading 100,000 journals to go Gold (and finding more money to bribe them into it, it would appear – money which is going to continue to be demanded by them in perpetuity, not accepted as a transitional fee – there''s nothing so permanent as a temporary measure).</i> (Full message <a href="http://listserv.crl.edu/wa.exe?A2=ind1208&amp;L=LIBLICENSE-L&amp;F=&amp;S=&amp;P=8655" target="_blank">here</a>.)</blockquote>\nThe LIBLICENSE list moderator would not post my response, so I''m giving it here:<br />\n<br />\n10,000 research institutes means, in terms of Harnadian ''green'' mandates, a need for 10,000 repositories; 100,000 journals (if there were so many; I''ve only ever heard numbers in the order of 20-25,000 [recently confirmed as in the order of 28K]) does not mean 100,000 publishers. Besides, there is no existential reason for institutions to have a repository and ''green'' mandate. The fact that others have repositories and it doesn''t have one itself does not harm a research institution in the same way that not being ''gold'' (or at least having a ''gold'' option) does existentially harm journals in an environment of more and more ''gold'' journals. <br /><br />As for costs, there are two things that seem to escape the attention of ''green'' advocates (by which I mean those who see no place for ''gold'' open access at this stage on the basis that ''green'' would be a faster route to OA and would be cheaper):<br />\n<ol style="text-align: left;">\n<li>''Green'' fully depends on the prolongation of the subscription model. Without subscription revenues no journals, hence no peer-reviewed articles, hence nothing to self-archive but manuscripts, arXiv-style. (That would be fine by me, actually, with post-publication peer review mechanisms overlaying arXiv-oids). The cost of maintaining subscriptions is completely ignored by exclusively ''green'' advocates, who always talk about ''green'' costing next to nothing. They are talking about the *marginal* cost of ''green'', and compare it to the *integral* cost of ''gold''.</li>\n<li>Exclusively ''green'' advocates do not seem to understand that for ''gold'' journals, publishers are not in any position to "demand money". They can only offer their services in exchange for a fee if those who would pay the fee are willing to pay it. That''s known as ''competition'', or as a ''functioning market''. By its very nature, it drives down prices. This in contrast to the monopoloid subscription market, a dysfunctional market, where the price drivers face upwards. Sure, some APC''s increased since the early beginnings of ''gold'' OA publishing, when ''gold'' publishers found out they couldn''t do it for amounts below their costs. But generally, the average APCs per ''gold'' article are lower — much lower — than the average publisher revenues per subscription article. And this average per-article subscription price will still have to be coughed up in order to keep ''green'' afloat.</li>\n</ol>\n<div style="text-align: left;">\nPrice-reducing mechanisms would even work faster if and when the denizens of the ivory tower were to reduce their culturalism and anglo-linguism that currently prevails, in which case we could rapidly see science publishing emerge in places like China, India, and other countries keen on establishing their place in a global market, competing on price. APCs could tumble. Some call this ''predatory gold OA publishing''. Few seem to realise that the ''prey'' is the subscription model.</div>\n<br />\nThe recently published <a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=4&amp;ved=0CFAQFjAD&amp;url=http%3A%2F%2Fwww.researchinfonet.org%2Fwp-content%2Fuploads%2F2012%2F06%2FFinch-Group-report-FINAL-VERSION.pdf&amp;ei=j-ggUPIV7pHRBeiwgbAL&amp;usg=AFQjCNFx2J11qh6Kq8-4xfOFe2guQ1UTNg&amp;sig2=oTAe3_Ool95Sp8MLWQpAWg" target="_blank">Finch Report</a> expresses a preference for immediate, ''libre'', open access, and sees ''gold'' as more likely to be able to deliver that than ''green''. Meanwhile, ''green'' is a way to deliver OA (albeit delayed and not libre) in cases where ''gold'' is not feasible yet. That is an entirely sensible viewpoint, completely compatible with the letter – and I think also the spirit – of the <a href="http://www.soros.org/openaccess/read" target="_blank">Budapest Open Access Initiative</a> (BOAI). Incidentally, referring to the BOAI is characterised as "fetishism" (sic) by Andrew Adams.<br /><br />Comparing ''green'' and ''gold'' is almost, to borrow a phrase from Stevan Harnad, "comparing apples and orang-utans". The Finch report is not mistaken to see ''green'' as (<a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=19&amp;ved=0CFgQFjAIOAo&amp;url=http%3A%2F%2Fwww.researchinfonet.org%2Fwp-content%2Fuploads%2F2012%2F07%2FRF-article-25-July.pdf&amp;ei=C-IgUJCgC6aK0AXg6YGQDg&amp;usg=AFQjCNG9xzzPCaJEst7D_tSlKfe5yhZfKg&amp;sig2=7SD8mkly8f8wZq5IxgQ6cQ" target="_blank">in the words of Michael Jubb</a>) an "impoverished type of open access, with embargo periods, access only to an authors’ manuscript, without links and semantic enrichment; and severe limitations on the rights of use." After all, in the ''green'' <a href="http://openaccess.eprints.org/index.php?/archives/71-guid.html" target="_blank">ID/OA</a> scheme (ID = Immediate Deposit and OA meaning ''Optional Access" here) favoured by Harnad c.s., deposited articles may be made open if and when the publisher permits.<br />\n<br />Besides, ''gold'' implies also ''green'' (''gold'' articles can be deposited, without embargo or limits on use, anywhere, and by anyone), where ''green'' does not imply ''gold''. A Venn diagram might look like this (below).<br />\n<div class="separator" style="clear: both; text-align: center;">\n<a href="http://4.bp.blogspot.com/-ql8cshc1Fbo/UCDwAVLmVMI/AAAAAAAAAC8/OeF3Y6uB9_A/s1600/Screen+Shot+2012-08-07+at+12.37.10.png" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img border="0" height="194" src="http://4.bp.blogspot.com/-ql8cshc1Fbo/UCDwAVLmVMI/AAAAAAAAAC8/OeF3Y6uB9_A/s200/Screen+Shot+2012-08-07+at+12.37.10.png" width="200" /></a></div>\n<br />\nThe Finch group has come to its conclusions because they have clearly learnt the lessons of the last decade. There is nothing — repeat:\n *nothing* — that prevents academics to eschew the services of \n"rent-seeking" (as Adams put it) publishers. They could easily self-organise (though I \nrealise that both the words ''could'' and ''easily'' are probably \nmisplaced). To expect publishers (for-profit and not-for-profit ones \nalike) to refuse providing services that academics are seeking from them\n is silly.<br />\n<br />\nFor the avoidance of doubt, I am not against ''green'' OA (in spite of what some ''green''-only advocates assert), especially not where there is no other option. The choice is not so much for or against ''green'' or ''gold'', but emphatically <b>for</b> full, unimpeded open access, however it is delivered, as long as it is "permitting any users to read, download, copy, distribute, print, search, or link to the full texts of these articles, crawl them for indexing, pass them as data to software, or use them for any other lawful purpose, without financial, legal, or technical barriers other than those inseparable from gaining access to the internet itself." You recognise this last phrase? Indeed, the precise wording of the BOAI.<br />\n<br />\nJan Velterop</div>','\n',char(10)),NULL,'','2012-08-07 10:43:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2012/08/the-triumph-of-cloud-cuckoo-land-over.html','The triumph of cloud cuckoo land over reality?',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\nIt should be abundantly clear that Open Access policies by Finch, RCUK, Wellcome Trust and many others are very important for the development of universal OA, in that they not only indicate practical ways of achieving it, but also signal to the scholarly community and the wider society interested in scientific knowledge and its advance that OA should be the norm.<br /><br />\nThe ''sin'' that RCUK, Finch and the Wellcome Trust committed is that they didn''t formulate their policies according to strict Harnadian orthodoxy. It''s not that they forbid Harnadian OA (a.k.a. ''green''), oh no. It is that they see the ''gold'' route to OA as worthy of support as well. Harnad, as ultimate arbiter of Harnadian OA (though he has acolytes), would like to see funder and institutional OA policies focus entirely and only on Harnadian OA, and would want them, to all intents and purposed, forbid the ''gold'' route. In Harnad''s view, the ''gold'' route comes into play (as ''downsized gold'', whatever that means) only once all scholarly journal literature is OA according to Harnadian rules. These rules are quite specific:<br />\n<ul style="text-align: left;">\n<li>articles must be published in peer-reviewed subscription journals;&nbsp;</li>\n<li>institutions must mandate their subsequent deposit in an institutional repository (not, for instance in a global subject repository);&nbsp;</li>\n<li>there must be no insistence on OA immediately upon publication (his big idea is ID/OA — Institutional Deposit / Optional [sic] Access);&nbsp;</li>\n<li>here must be no insistence on CC-BY or equivalent (which would make re-use and text-mining possible — OA in his view should just be ocular access, not machine-access).</li>\n</ul>\n<div style="text-align: left;">\nIt must be difficult to comply with these rules, and seeing his recent applause, subsequently followed by withdrawal of support, for the RCUK policy, even Harnad himself finds it difficult to assess whether his rules are ''properly'' adhered to. It also seems as if his main focus is not OA but mandated deposit in institutional repositories. Probably hoping that that will eventually lead to OA. He would like to see ''gold'' OA — OA at source — considered only if and when it is "downsized Gold OA, once Green OA has prevailed globally, making subscriptions unsustainable and forcing journals to downsize." It is the equivalent of opening the parachute only a split second before hitting the ground. It would be the triumph of a dogmatically serial process over a pragmatically parallel one. The triumph of cloud cuckoo land over reality.<br /><br />Open Access is more than worth having. Different, complementary, ways help achieve it. There are many roads leading to Rome.<br /><br />Jan Velterop<br />OA advocate</div>\n</div>','\n',char(10)),NULL,'','2012-08-01 06:43:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2012/06/small-publications-large-implications.html','Small publications, large implications',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\n\n\n\n\n\n\n\n\n\n\n\n\n\n<style>\n<!--\n /* Font Definitions */\n@font-face\n {font-family:"ＭＳ 明朝";\n mso-font-charset:78;\n mso-generic-font-family:auto;\n mso-font-pitch:variable;\n mso-font-signature:-536870145 1791491579 18 0 131231 0;}\n@font-face\n {font-family:"Cambria Math";\n panose-1:2 4 5 3 5 4 6 3 2 4;\n mso-font-charset:0;\n mso-generic-font-family:auto;\n mso-font-pitch:variable;\n mso-font-signature:-536870145 1107305727 0 0 415 0;}\n /* Style Definitions */\np.MsoNormal, li.MsoNormal, div.MsoNormal\n {mso-style-unhide:no;\n mso-style-qformat:yes;\n mso-style-parent:"";\n margin:0cm;\n margin-bottom:.0001pt;\n mso-pagination:widow-orphan;\n font-size:12.0pt;\n font-family:"Times New Roman";\n mso-fareast-font-family:"ＭＳ 明朝";\n mso-fareast-theme-font:minor-fareast;\n mso-ansi-language:EN-US;}\na:link, span.MsoHyperlink\n {mso-style-priority:99;\n color:blue;\n mso-themecolor:hyperlink;\n text-decoration:underline;\n text-underline:single;}\na:visited, span.MsoHyperlinkFollowed\n {mso-style-noshow:yes;\n mso-style-priority:99;\n color:purple;\n mso-themecolor:followedhyperlink;\n text-decoration:underline;\n text-underline:single;}\n.MsoChpDefault\n {mso-style-type:export-only;\n mso-default-props:yes;\n font-size:10.0pt;\n mso-ansi-font-size:10.0pt;\n mso-bidi-font-size:10.0pt;\n mso-fareast-font-family:"ＭＳ 明朝";\n mso-fareast-theme-font:minor-fareast;\n mso-fareast-language:JA;}\n@page WordSection1\n {size:595.0pt 842.0pt;\n margin:72.0pt 89.85pt 72.0pt 89.85pt;\n mso-header-margin:35.45pt;\n mso-footer-margin:35.45pt;\n mso-paper-source:0;}\ndiv.WordSection1\n {page:WordSection1;}\n-->\n</style>\n\n\n\n\n\n\n<br />\n<div class="MsoNormal">\n<a href="" name="OLE_LINK6"></a><span style="mso-bookmark: OLE_LINK6;"><span lang="EN-US">When I recently enjoyed lunch\nwith Steve Pettifer of Manchester University (the ‘father’ of </span></span><a href="http://utopiadocs.com/"><span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"><span lang="EN-US">Utopia Documents</span></span></span></a><span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"><span lang="EN-US">), the conversation turned to nanopublications. Ah, you want to know\nwhat nanopublications are. </span></span></span><a href="http://nanopub.org/"><span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"><span lang="EN-US">Nanopublications</span></span></span></a><span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"><span lang="EN-US"> are\nmachine-readable, single, attributable, scientific assertions.</span></span></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"><span lang="EN-US">Steve posed the question “why would any scientist\nbelieve a nanopublication, particularly if out of context?” Indeed, why would\nthey? Why should they, well versed as scientists are in the art of critical\nthinking. They won’t, at least not without seeing the appropriate context.</span></span></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"><span lang="EN-US">Herein lies a great opportunity. </span></span></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"><span lang="EN-US">Let me explain. Nanopublications, or rather, their\ncore in the form of machine-readable object-predicate-subject triples, can be\nincorporated in (vast) collections of such triples and used for reasoning, to discover\nnew knowledge, or to make explicit hitherto tacit or hidden knowledge. Triples\ncan therefore be very valuable to science. (The </span></span></span><a href="http://www.openphacts.org/"><span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"><span lang="EN-US">Open PHACTS</span></span></span><span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"></span></span></a><span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"><span lang="EN-US"> project is in the process of establishing the value of this\napproach for drug discovery.) Many, perhaps most, scientific articles contain\nsuch single assertions, which could be presented as nanopublications. </span></span></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"><span lang="EN-US">In a recent Nature Genetics commentary called ‘<a href="" name="OLE_LINK4"></a><a href="" name="OLE_LINK3"><span style="mso-bookmark: OLE_LINK4;"></span></a></span></span></span><a href="http://www.nature.com/ng/journal/v43/n4/full/ng0411-281.html"><span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"><span style="mso-bookmark: OLE_LINK3;"><span style="mso-bookmark: OLE_LINK4;"><span lang="EN-US">The Value of Data</span></span></span></span></span><span style="mso-bookmark: OLE_LINK4;"></span><span style="mso-bookmark: OLE_LINK3;"></span><span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"></span></span></a><span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"><span lang="EN-US">’, Barend Mons <i style="mso-bidi-font-style: normal;">et al.</i>\naddressed this issue with the metaphor of the chicken and the egg. Now that\neggs (individual assertions) are being distributed (‘traded’), their value\n(they all look roughly the same) can only be truly assessed by knowing the\nparents. Scientists will always want to personally judge whether a crucial\nconnecting assertion in a given hypothesis is one they can accept as valid. The\nability to locate where the assertion came from, in which article, in which\njournal, by which author, and when it was published – in short the ‘provenance’\nof individual scientific assertions functioning in computer reasoning – is\ncrucial for that. As is the ability to access the article in question.</span></span></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"><span lang="EN-US">Scientific publishers should, in their quest to add\nvalue to research publications, expose and clearly present the nanopublications\ncontained in the articles they publish, particularly those that are believed\n(e.g. by the author, or the reviewers) to be unique and new. What’s more, they\nshould make them openly and freely available, like they do with abstracts, even\npublishers that are not yet convinced that they should change their business\nmodels and make all their content open access. And they should not just make\nnanopublications open and accessible to human readers, but also to machines,\nbecause only machines are able to effectively process large numbers of\nnanopublications, treating each one as a ‘pixel’ of the larger picture that a\nresearcher is building up. </span></span></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"><span lang="EN-US">So what’s the opportunity?</span></span></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"><span lang="EN-US">Well, openly accessible nanopublications are very\nuseful for scientific discovery, they are attributable (to author, article, and\njournal) and scientist don’t just believe them when they see them, particularly\nif the assertion is new to them or when they find it in a process of computer-assisted\n(<i style="mso-bidi-font-style: normal;">in silico</i>) reasoning. Researchers\nwill be eager to investigate their source, i.e. check out the article from\nwhich the nanopublication comes. They may cite the nanopublication, and in\ndoing so, cite the article. An obvious win-win situation for scientists (in\ntheir roles of users and authors) and publishers alike.</span></span></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span style="mso-bookmark: OLE_LINK5;"><span style="mso-bookmark: OLE_LINK6;"><span lang="EN-US">What are we waiting for?</span></span></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span><span><span lang="EN-US">Jan Velterop </span></span></span></div>\n</div>','\n',char(10)),NULL,'','2012-06-11 10:09:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2012/04/oa-not-just-for-institutionalised.html','OA not just for institutionalised scientists',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\nOn the Global Open Access List, an email list, a thread has developed on <a href="http://mailman.ecs.soton.ac.uk/pipermail/goal/2012-April/thread.html" target="_blank">''Open Access Priorities: Peer Access and Public Access''</a>. Of course, true open access means access both for peers (meaning fellow-scientists, in this case, not just members of the UK House of Lords) and for the general public at large, so the discussion is really about what is more important and what is the more persuasive argument to get research scientists to make their publications available with open access. And should that argument mainly be quasi-legal, in the form of institutional mandates.<br />\n<br />\nMy view is this:<br />\n<br />\nIs it not so that when there is no wide cultural or societal support for whatever law or mandate, more effort is generally being spent on evasion than on compliance and enforcement turns out to be like mopping up with the tap still running? If one should be taking examples from US politics, the ''war on drugs'' is the one to look at.<br /><br />Forcing scientists into open access via mandates and the like is only ever likely to be truly successful if it is rooted in an already changing culture. An academic culture with an expectation that research results are openly available to all. By the shame that researchers will be made to feel in the lab, at dinner parties, or in the pub, if their results are not published with open access. Of course that will still be mainly peer-pressure, but changing hearts and minds of peers is greatly helped if there were a societal substrate in which the open culture can grow. Mandates or not, OA will never happen if scientists aren''t convinced from within. An appeal to them as human beings and members of society is more likely to achieve that than mandates, in my view. The latter should back up a general change of heart, not be a substitute for it.<br /><br />What is ''the general public'' should not be misunderstood and be construed to be only those interested in medical literature. It includes all those interested in the other 999 areas as well. Ex scientists, retired scientists, start-ups and SMEs, scientists interested in another discipline or cross-discipline topics, students, lawyers, reporters, teachers, even hobbyists. Einstein wasn''t an institutionalised scientist when he worked on his most important work; he was a patent clerk. <br /><br />Of course, those OA evangelists who wish to pursue mandates should be pursuing mandates. I encourage them to keep doing just that. But to narrow the efforts of OA evangelism to what is stubbornly being called "the quickest route", in spite of it being no more than a hypothesis which<br />certainly over the last decade and a half hasn''t proved itself to be as effective as first thought, is a mistake. <br /><br />By all means where there are opportunities to promote mandates let us do that, but not at the expense of making the moral and societal responsibility case for OA. <br />\n<br />\nJan Velterop<br />\n<a href="" name="334"><br /></a></div>','\n',char(10)),NULL,'','2012-04-29 17:10:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2012/04/enriching-open-access-articles.html','''Enriching'' Open Access articles',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\nI''ve been asked what the relevance is of my previous post to Open Access. The relevance of Utopia Documents to Open Access may not be immediately clear, but it is certainly there. Though Utopia Documents doesn''t make articles open that aren''t, it provides ''article-of-the-future-like'' functionality for any PDFs, OA or not. It opens them up in terms of Web connectivity, as it were, and it is completely publisher-independent. So PDFs in open repositories – even informal, author-manuscript ones – and from small OA publishers can have the same type of functionality that hitherto only larger publishers could afford to provide, and then only for HTML versions of articles. <br /><br />PDFs are often getting a bad press, as you probably know, yet according to statistics from many publishers, PDFs still represent by far the largest share of scientific article downloads. PDFs have great advantages, but until now, also disadvantages relative to HTML versions, particularly with regard to the latter''s Web connectedness (this – open – article is worth reading: <a href="http://dx.doi.org/10.1087/20110309">http://dx.doi.org/10.1087/20110309</a>). This digital divide, however, has now been bridged! The Utopia Documents PDF-viewer is built around the concept of connecting hitherto static PDFs to the Web, and it bridges the ''linkability gap'' between HTML and PDF, making the latter just as easily connected to whatever the Internet has on offer as the former (as long as you are online, of course). <br /><br />The new – wholly renewed – version (2.0) of the Utopia Documents scientific PDF-viewer has now been released. It is free and <a href="http://utopiadocs.com/" target="_blank">downloads</a> are currently available for Mac and Windows (and a Linux version is expected soon). Version 2.0 automatically shows Altmetrics (see how the article is doing), Mendeley (see related articles available there), Sherpa/RoMEO (check its open archiving status), etcetera, and connects directly to many more scientific and laboratory information resources on the Web, straight from the PDF.<br /><br />Utopia Documents allows you, if you so wish, to experience dynamically enriched scientific articles. Articles from whichever publisher or OA repository, since Utopia Documents is completely publisher-independent, providing enrichment for any modern PDF*, even ''informal'' ones made by authors of their manuscript (e.g. via ''Save as PDF'') and deposited in institutional repositories.<br /><br />''Enrichment'' means, among other things, easy Web connectivity, directly from highlighted text in the PDF, to an ever-expanding variety of data sources and scientific information and search tools. It also means the possibility to extract any tables into a spreadsheet format, and a ''toggle'' that converts numerical tables into easy-to-read scatter plots. It means up-to-date Altmetrics, whenever available, that let you see how articles are doing. It means a comments function that lets you carry out relevant discussions that stay right with the paper, rather than necessarily having to go off onto a blog somewhere. It means being able to quickly flick through the images and illustrations in an article. It means that existing PDFs from whatever source are ''converted'', as it were, on-the-fly, to what some publishers call ''articles of the future''. (The original PDF is in no way altered; the ''conversion'' is virtual).<br /><br />With Utopia Documents, publishers, repositories, libraries, even individuals with PDFs on their personal sites, can offer enriched scientific articles just by encouraging their users to read PDFs with the free Utopia Documents PDF-viewer, and so get more out of the scientific literature at hand than would otherwise be possible. Utopia Documents is indeed truly free, and not even registration is needed (except for adding comments).<br /><br />Utopia Documents is usable in all scientific disciplines, but its default specialist web resources are currently optimised for the biomedical/biochemical spectrum. <a href="http://utopiadocs.com/" target="_blank">http://utopiadocs.com</a></div>','\n',char(10)),NULL,'','2012-04-11 07:00:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2012/04/pee-dee-effing-brilliant.html','Pee Dee Effing Brilliant',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\nAre you a scientist or student? Life sciences? Do you ever read research literature in PDF format?<br />\n<br />\nDid it ever occur to you that it might be useful, or at least convenient, if scientific articles in PDF format were a bit more ''connected'' to the rest of the web? And would enable you, for instance, directly from the text, to:<br />\n<ul style="text-align: left;">\n<li>look up more information about a term or phrase you''re encountering (e..g a gene, a protein, etc.)</li>\n<li>look up the latest related articles (e.g. in PubMed, Mendeley)</li>\n<li>see, in real time, how the article is doing (Altmetrics)</li>\n<li>search (NCBI databases, protein databases, Google, Wikipedia, Quertle, etc.)</li>\n<li>share comments with fellow researchers</li>\n</ul>\nWell, all of that – and much more – is now possible. All you have to do is view your PDFs in the new <a href="http://utopiadocs.com/" target="_blank">Utopia Documents</a>.<br />\n<br />\nUtopia Documents has been developed by researchers from the University of Manchester, is completely free, and available for Mac, Windows and Linux. It works with all PDFs* irrespective of their origin**.<br />\n<br />\nI invite you – urge you – to try it out, tell your colleagues and friends, and ask them to tell theirs. And tweet and blog about it. Registration is not necessary, except if you want to make use of the public ''comment'' function. Feedback is highly appreciated. Either as a comment on this blog, or directly to the <a href="mailto:info@utopiadocs.com" target="_blank">Utopia crew</a>. And testimonials, too, obviously.<br />\n<br />\nDisclosure: I work with these guys. A lot. They are brilliant and yet pragmatic. Driven by a desire to make life easier for scientists and students alike.<br />\n<br />\n<span style="font-size: x-small;">*With the exception of bitmap-only PDFs (scans)</span><br />\n<span style="font-size: x-small;">**From any publisher, and even including ''informal'' PDFs as can be found in repositories, or those that you have created yourself from a manuscript written in Word, for instance </span><br />\n<br /></div>','\n',char(10)),NULL,'','2012-04-06 06:41:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2012/02/theyre-changing-clause-and-even-some.html','They’re changing a clause, and even some laws, yet everything stays the way it was.',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\n\n\n\n\n\n\n\n\n\n\n\n\n\n<style>\n<!--\n /* Font Definitions */\n@font-face\n {font-family:Times;\n panose-1:2 0 5 0 0 0 0 0 0 0;\n mso-font-charset:0;\n mso-generic-font-family:auto;\n mso-font-pitch:variable;\n mso-font-signature:3 0 0 0 1 0;}\n@font-face\n {font-family:"ＭＳ 明朝";\n mso-font-charset:78;\n mso-generic-font-family:auto;\n mso-font-pitch:variable;\n mso-font-signature:-536870145 1791491579 18 0 131231 0;}\n@font-face\n {font-family:"Cambria Math";\n panose-1:2 4 5 3 5 4 6 3 2 4;\n mso-font-charset:0;\n mso-generic-font-family:auto;\n mso-font-pitch:variable;\n mso-font-signature:-536870145 1107305727 0 0 415 0;}\n /* Style Definitions */\np.MsoNormal, li.MsoNormal, div.MsoNormal\n {mso-style-unhide:no;\n mso-style-qformat:yes;\n mso-style-parent:"";\n margin:0cm;\n margin-bottom:.0001pt;\n mso-pagination:widow-orphan;\n font-size:12.0pt;\n font-family:"Times New Roman";\n mso-fareast-font-family:"ＭＳ 明朝";\n mso-fareast-theme-font:minor-fareast;\n mso-ansi-language:EN-US;}\nh1\n {mso-style-priority:9;\n mso-style-unhide:no;\n mso-style-qformat:yes;\n mso-style-link:"Heading 1 Char";\n mso-margin-top-alt:auto;\n margin-right:0cm;\n mso-margin-bottom-alt:auto;\n margin-left:0cm;\n mso-pagination:widow-orphan;\n mso-outline-level:1;\n font-size:24.0pt;\n font-family:Times;}\nspan.Heading1Char\n {mso-style-name:"Heading 1 Char";\n mso-style-priority:9;\n mso-style-unhide:no;\n mso-style-locked:yes;\n mso-style-link:"Heading 1";\n mso-ansi-font-size:24.0pt;\n mso-bidi-font-size:24.0pt;\n font-family:Times;\n mso-ascii-font-family:Times;\n mso-hansi-font-family:Times;\n mso-font-kerning:18.0pt;\n mso-fareast-language:EN-US;\n font-weight:bold;}\n.MsoChpDefault\n {mso-style-type:export-only;\n mso-default-props:yes;\n font-size:10.0pt;\n mso-ansi-font-size:10.0pt;\n mso-bidi-font-size:10.0pt;\n mso-fareast-font-family:"ＭＳ 明朝";\n mso-fareast-theme-font:minor-fareast;\n mso-fareast-language:JA;}\n@page WordSection1\n {size:612.0pt 792.0pt;\n margin:72.0pt 90.0pt 72.0pt 90.0pt;\n mso-header-margin:36.0pt;\n mso-footer-margin:36.0pt;\n mso-paper-source:0;}\ndiv.WordSection1\n {page:WordSection1;}\n-->\n</style>\n\n\n\n\n\n\n<br />\nThe title captures the feeling of frustration with the often glacial pace of changes we regard as necessary and inevitable. So we try to influence the speed of change, and one time-honoured tool we take out of the box is the boycott. Boycotts are a way to get things off your chest; even to get some guilt relief, but although there are notable exceptions, they rarely change things fundamentally. Take the Elsevier Science boycott. I understand the feeling behind it, but if their prices were reduced to half of what they are now, or even if they went out of business, would that really be a solution to the problems with which scientific communication wrestles? As many a boycott does, this one, too, is likely to result in ‘changing a clause, changing some laws, yet everything staying the way it was’.<br /><br />A boycott doesn’t alter the fact that we view publishers as publishers. That''s how they view themselves, too. However, that is the underlying problem. Perhaps publishers were publishers, in the past, but they are no longer. Any dissemination of knowledge that results from their activities is not much more than a side effect. No, publishers’ role is not to ‘publish’; it is to feed the need of the scientific ego-system for public approbation, and of its officialdom for proxies for validation and scientific prowess assessment in order to make their decisions about tenure, promotion and grants easier and swifter.<br /><br />Crazy line of thought, no? Well, maybe, but look at what happens in physics. The actual publishing – dissemination of information and knowledge – takes place by posting in <a href="http://arxiv.org/" target="_blank">arXiv</a>. Yet a good portion of articles in arXiv – quite possibly the majority, does anyone have the numbers? – are subsequently submitted to journals and formally ‘published’. Why? Well, "peer review" is the stock answer. And acquiring impact factors (even though especially in physics one would expect scientists to pay heed to Einstein’s dictum that “not everything that can be counted counts and not everything that counts can be counted”).<br /><br />Clearly, officialdom in physics is prepared to pay, to the tune of thousands of dollars per article, for the organization of the peer review ritual and the acquisition of impact factor ‘tags’ that come with formal publication of a ‘version of record’. So be it. If officialdom perceives these things as necessary and is willing to pay, ‘publishers’ are of course happy to provide them. <br /><br />But one of the biggest problems in science communication, the free flow of information, seems to have been solved in physics, as arXiv is completely open. If arXiv-like platforms were to exist in other disciplines as well, and if a cultural expectation were to emerge that papers be posted on those platforms before submission to journals, and their posting be accepted as a priority claim, we would have achieved free flow of information in those other areas as well.<br /><br />I suspect that the essence of the Federal Research Public Access Act (<a href="http://en.wikipedia.org/wiki/Federal_Research_Public_Access_Act" target="_blank">FRPAA</a>) is about achieving a situation like the one that exists in physics with arXiv. Given that arXiv has done no discernable damage to publishers (at least as far as I’m aware, and, reportedly, also <a href="http://en.wikipedia.org/wiki/Open_access" target="_blank">according to the publishing arms of the AmericanPhysical Society and the UK Institute of Physics</a>), pushing for the Research Works Act (<a href="http://en.wikipedia.org/wiki/Research_Works_Act" target="_blank">RWA</a>) instead of making the case for extending an arXiv-like ‘preprint’ system to disciplines beyond physics seems an extraordinary lapse of good judgement.<br /><br />On the other hand, the concern that publishers have about the academic community not being willing for long to pay the sort of money they now do for what is little more than feeding the officialdom monster, is a realistic concern. Unfortunately for them, stopping the evolution of science communication in its tracks is simply not an option. Perhaps the current boycott is one of the rare successful ones, and perhaps it will spur publishers on to reconsider their role and position. There are definitely ways for a publisher to play a beneficial role. Just a small example: I was told of a recent case where the peer reviewer expressed his frustration with the words “Imagine if before it was sent to me for review a professional editor actually read all 40 pages and discovered the heinous number of basic grammatical issues, spelling errors, and typos, and sent it back to the authors or to an English correction service before I had to spend more time on that, rather than on the actual scientific content.”<br /><br />Personally, I think open arXiv-like set-ups in disciplines other than physics are the way forward. Publishers should – and truly forward-looking ones may – establish those themselves, if they don’t want to be reduced to an afterthought in the scientific communication game.<br /><br />We live in hope, though not holding our breath.<br /><br />Jan Velterop<br /><div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<br /></div>\n<span style="font-family: &quot;Times New Roman&quot;; font-size: 12pt; font-weight: normal;"> </span><span style="font-family: &quot;Times New Roman&quot;; font-size: 12.0pt; font-weight: normal; mso-bidi-font-weight: bold; mso-fareast-font-family: &quot;Times New Roman&quot;;"></span>\n\n\n\n\n\n</div>','\n',char(10)),NULL,'','2012-02-23 09:00:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2012/02/collaborate-dont-frustrate.html','Collaborate, don''t frustrate',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\n<br />\n<div class="MsoNormal">\nWe have seen a fair amount of\nactivity on the web in the last few weeks with regard to protests, even\nboycotts, aimed at prominent publishers. Most of it seems to be about money. When money\nis tight, it leads to a fight. <o:p></o:p></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\nWe are in the huge pickle of a dysfunctional\nsystem. And that’s certainly not just the publishers’ fault. They just make the\nmost of the system that is there and that is being kept alive by the scientific\ncommunity at large. See my <a href="http://theparachute.blogspot.com/2012/02/publishers-are-not-evil.html" target="_blank">previous post</a>. All publishers are commercial and all want to optimize\ntheir profits, although some, the not-for-profit outfits, optimize their\n‘results’ or their ‘surplus’. Same thing, really. It’s just the way the\ncapitalist system works. The system is dysfunctional because there is no\ncompetition. The scientific community allows it to exist without competition.\nRelying on subscriptions for their income makes journals, and their publishers,\nmonopoloid in an environment where content is non-rivalrous. If the only\noptions to get from A to B – and you have to get from A to B – are a train or\nwalking, because there are no roads, then the train company has a hold on you.\nAnd on your money. The situation in science publishing is scarcely different. <o:p></o:p></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\nSo the solution is introducing competition.\n‘Gold’ Open Access publishing does just that, albeit perhaps in a fairly primitive way,\nso far. It’s typically a game of new entrants. But in order to be truly\nsuccessful, the scientific community at large has to buy in to it. Literally\n‘buy’ into it. Publishers can lead the horse to the Open Access water, but they can’t make\nit drink.<o:p></o:p></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\nI won’t hold my breath. And there is so much\nelse in science publishing, besides money matters, that needs to be improved. <o:p></o:p></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\nJust one example: fragmentation. Fragmentation\nis a big, frustrating problem. Particularly for the efficient and effective ingestion of\ninformation. But it need not be so bad. Although science publishers are bound\nby antitrust rules, there are areas of a pre-competitive nature where they are\nallowed to collaborate. Think standards, think CrossRef. Those forms of\ncollaboration, for the benefit of science, could be expanded. Other standards\ncould be introduced, to do with data linking, for instance, with data\nrepresentation, computer-readability, interoperability. Things like <a href="http://www.nlm.nih.gov/pubs/techbull/ja10/ja10_structured_abstracts.html" target="_blank">structured abstracts</a>.\nPerhaps even ontologies and agreed vocabularies for scientific concepts,\nanalogous to biological and chemical nomenclature. User licences could be\nstandardized, pre-competitively. <i>Et cetera</i>. There are some sophisticated\nfeatures around, but their wide adoption all too often suffers from the\nnot-invented-here syndrome. Publishers, too, live in an ego-system of their\nown.<o:p></o:p></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\nAnd it is not just in pre-competitive areas\nwhere fragmentation could be remedied. There are areas that you could call\n‘post-competitive’, where collaborations between publishers and\nstandardisations of practices and technologies could be of tremendous value to\nthe scientific community, without costing the publishers much, or even\nanything. Take fragmentation again. Even if the subscription system were to be\nkept alive, publishers could, PubMedCentral-like, deposit all the journal articles\nthey publish in discipline-central global databases, after, say, a year. The\nvast majority of the realizable economic value of annual subscriptions is\nrealized within a year (that’s why the subscriptions are annual), and although\nopen access after a year is not ideal, it would be a massive improvement over\nthe current situation with very little cost to the publishers. And unlike\nPubMedCentral, the publishers should, collectively and proactively, set up and\norganize these open repositories. Asking funding agencies to help support the future maintenance of such repositories should not be too difficult. It''s a conservation issue the responsibility for which cannot and should not be put on the shoulders of potentially fickle private enterprise.&nbsp;<o:p></o:p></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\nAnother area of post-competitive collaboration,\nor at least cooperation, would be the so-called ‘enrichment’ of journal\narticles. In html as well as in their pdf manifestations. Every publisher seems to have its own ideas, and that’s all very\nwell, but it doesn’t make life easier for researchers. Why not pool these ideas\nand apply them as widely as possible? There is hardly, if any, competitive cost\nto that, and a great deal of potential benefit to the scientific community, the\nprofessed aim of virtually all scientific publishers. <o:p></o:p></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\nIt clearly is not beyond the publishers to work\ntogether and create something very useful. Just look at <a href="http://crossref.org/01company/02history.html" target="_blank">CrossRef</a>. It is an\nexample worthy of being the paradigm for publisher attitudes and behaviour with regard to pre-competitive and post-competitive collaborations.&nbsp;<o:p></o:p></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\nJan Velterop</div>\n</div>','\n',char(10)),NULL,'','2012-02-05 16:14:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://theparachute.blogspot.com/2012/02/publishers-are-not-evil.html','Publishers are not evil',replace('<div dir="ltr" style="text-align: left;" trbidi="on">\n\n\n\n\n\n\n\n<!--[if gte mso 9]><xml>\n <o:OfficeDocumentSettings>\n  <o:AllowPNG/>\n </o:OfficeDocumentSettings>\n</xml><![endif]-->\n\n<!--[if gte mso 9]><xml>\n <w:WordDocument>\n  <w:View>Normal</w:View>\n  <w:Zoom>0</w:Zoom>\n  <w:TrackMoves/>\n  <w:TrackFormatting/>\n  <w:PunctuationKerning/>\n  <w:ValidateAgainstSchemas/>\n  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>\n  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>\n  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>\n  <w:DoNotPromoteQF/>\n  <w:LidThemeOther>EN-GB</w:LidThemeOther>\n  <w:LidThemeAsian>JA</w:LidThemeAsian>\n  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>\n  <w:Compatibility>\n   <w:BreakWrappedTables/>\n   <w:SnapToGridInCell/>\n   <w:WrapTextWithPunct/>\n   <w:UseAsianBreakRules/>\n   <w:DontGrowAutofit/>\n   <w:SplitPgBreakAndParaMark/>\n   <w:EnableOpenTypeKerning/>\n   <w:DontFlipMirrorIndents/>\n   <w:OverrideTableStyleHps/>\n   <w:UseFELayout/>\n  </w:Compatibility>\n  <m:mathPr>\n   <m:mathFont m:val="Cambria Math"/>\n   <m:brkBin m:val="before"/>\n   <m:brkBinSub m:val="&#45;-"/>\n   <m:smallFrac m:val="off"/>\n   <m:dispDef/>\n   <m:lMargin m:val="0"/>\n   <m:rMargin m:val="0"/>\n   <m:defJc m:val="centerGroup"/>\n   <m:wrapIndent m:val="1440"/>\n   <m:intLim m:val="subSup"/>\n   <m:naryLim m:val="undOvr"/>\n  </m:mathPr></w:WordDocument>\n</xml><![endif]--><!--[if gte mso 9]><xml>\n <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="true"\n  DefSemiHidden="true" DefQFormat="false" DefPriority="99"\n  LatentStyleCount="276">\n  <w:LsdException Locked="false" Priority="0" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Normal"/>\n  <w:LsdException Locked="false" Priority="9" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="heading 1"/>\n  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 2"/>\n  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 3"/>\n  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 4"/>\n  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 5"/>\n  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 6"/>\n  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 7"/>\n  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 8"/>\n  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 9"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 1"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 2"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 3"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 4"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 5"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 6"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 7"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 8"/>\n  <w:LsdException Locked="false" Priority="39" Name="toc 9"/>\n  <w:LsdException Locked="false" Priority="35" QFormat="true" Name="caption"/>\n  <w:LsdException Locked="false" Priority="10" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Title"/>\n  <w:LsdException Locked="false" Priority="1" Name="Default Paragraph Font"/>\n  <w:LsdException Locked="false" Priority="11" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Subtitle"/>\n  <w:LsdException Locked="false" Priority="22" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Strong"/>\n  <w:LsdException Locked="false" Priority="20" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Emphasis"/>\n  <w:LsdException Locked="false" Priority="59" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Table Grid"/>\n  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Placeholder Text"/>\n  <w:LsdException Locked="false" Priority="1" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="No Spacing"/>\n  <w:LsdException Locked="false" Priority="60" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Shading"/>\n  <w:LsdException Locked="false" Priority="61" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light List"/>\n  <w:LsdException Locked="false" Priority="62" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Grid"/>\n  <w:LsdException Locked="false" Priority="63" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 1"/>\n  <w:LsdException Locked="false" Priority="64" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 2"/>\n  <w:LsdException Locked="false" Priority="65" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 1"/>\n  <w:LsdException Locked="false" Priority="66" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 2"/>\n  <w:LsdException Locked="false" Priority="67" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 1"/>\n  <w:LsdException Locked="false" Priority="68" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 2"/>\n  <w:LsdException Locked="false" Priority="69" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 3"/>\n  <w:LsdException Locked="false" Priority="70" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Dark List"/>\n  <w:LsdException Locked="false" Priority="71" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Shading"/>\n  <w:LsdException Locked="false" Priority="72" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful List"/>\n  <w:LsdException Locked="false" Priority="73" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Grid"/>\n  <w:LsdException Locked="false" Priority="60" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Shading Accent 1"/>\n  <w:LsdException Locked="false" Priority="61" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light List Accent 1"/>\n  <w:LsdException Locked="false" Priority="62" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Grid Accent 1"/>\n  <w:LsdException Locked="false" Priority="63" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 1"/>\n  <w:LsdException Locked="false" Priority="64" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 1"/>\n  <w:LsdException Locked="false" Priority="65" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 1 Accent 1"/>\n  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Revision"/>\n  <w:LsdException Locked="false" Priority="34" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="List Paragraph"/>\n  <w:LsdException Locked="false" Priority="29" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Quote"/>\n  <w:LsdException Locked="false" Priority="30" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Intense Quote"/>\n  <w:LsdException Locked="false" Priority="66" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 2 Accent 1"/>\n  <w:LsdException Locked="false" Priority="67" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 1"/>\n  <w:LsdException Locked="false" Priority="68" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 1"/>\n  <w:LsdException Locked="false" Priority="69" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 1"/>\n  <w:LsdException Locked="false" Priority="70" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Dark List Accent 1"/>\n  <w:LsdException Locked="false" Priority="71" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Shading Accent 1"/>\n  <w:LsdException Locked="false" Priority="72" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful List Accent 1"/>\n  <w:LsdException Locked="false" Priority="73" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Grid Accent 1"/>\n  <w:LsdException Locked="false" Priority="60" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Shading Accent 2"/>\n  <w:LsdException Locked="false" Priority="61" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light List Accent 2"/>\n  <w:LsdException Locked="false" Priority="62" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Grid Accent 2"/>\n  <w:LsdException Locked="false" Priority="63" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 2"/>\n  <w:LsdException Locked="false" Priority="64" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 2"/>\n  <w:LsdException Locked="false" Priority="65" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 1 Accent 2"/>\n  <w:LsdException Locked="false" Priority="66" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 2 Accent 2"/>\n  <w:LsdException Locked="false" Priority="67" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 2"/>\n  <w:LsdException Locked="false" Priority="68" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 2"/>\n  <w:LsdException Locked="false" Priority="69" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 2"/>\n  <w:LsdException Locked="false" Priority="70" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Dark List Accent 2"/>\n  <w:LsdException Locked="false" Priority="71" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Shading Accent 2"/>\n  <w:LsdException Locked="false" Priority="72" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful List Accent 2"/>\n  <w:LsdException Locked="false" Priority="73" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Grid Accent 2"/>\n  <w:LsdException Locked="false" Priority="60" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Shading Accent 3"/>\n  <w:LsdException Locked="false" Priority="61" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light List Accent 3"/>\n  <w:LsdException Locked="false" Priority="62" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Grid Accent 3"/>\n  <w:LsdException Locked="false" Priority="63" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 3"/>\n  <w:LsdException Locked="false" Priority="64" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 3"/>\n  <w:LsdException Locked="false" Priority="65" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 1 Accent 3"/>\n  <w:LsdException Locked="false" Priority="66" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 2 Accent 3"/>\n  <w:LsdException Locked="false" Priority="67" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 3"/>\n  <w:LsdException Locked="false" Priority="68" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 3"/>\n  <w:LsdException Locked="false" Priority="69" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 3"/>\n  <w:LsdException Locked="false" Priority="70" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Dark List Accent 3"/>\n  <w:LsdException Locked="false" Priority="71" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Shading Accent 3"/>\n  <w:LsdException Locked="false" Priority="72" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful List Accent 3"/>\n  <w:LsdException Locked="false" Priority="73" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Grid Accent 3"/>\n  <w:LsdException Locked="false" Priority="60" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Shading Accent 4"/>\n  <w:LsdException Locked="false" Priority="61" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light List Accent 4"/>\n  <w:LsdException Locked="false" Priority="62" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Grid Accent 4"/>\n  <w:LsdException Locked="false" Priority="63" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 4"/>\n  <w:LsdException Locked="false" Priority="64" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 4"/>\n  <w:LsdException Locked="false" Priority="65" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 1 Accent 4"/>\n  <w:LsdException Locked="false" Priority="66" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 2 Accent 4"/>\n  <w:LsdException Locked="false" Priority="67" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 4"/>\n  <w:LsdException Locked="false" Priority="68" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 4"/>\n  <w:LsdException Locked="false" Priority="69" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 4"/>\n  <w:LsdException Locked="false" Priority="70" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Dark List Accent 4"/>\n  <w:LsdException Locked="false" Priority="71" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Shading Accent 4"/>\n  <w:LsdException Locked="false" Priority="72" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful List Accent 4"/>\n  <w:LsdException Locked="false" Priority="73" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Grid Accent 4"/>\n  <w:LsdException Locked="false" Priority="60" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Shading Accent 5"/>\n  <w:LsdException Locked="false" Priority="61" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light List Accent 5"/>\n  <w:LsdException Locked="false" Priority="62" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Grid Accent 5"/>\n  <w:LsdException Locked="false" Priority="63" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 5"/>\n  <w:LsdException Locked="false" Priority="64" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 5"/>\n  <w:LsdException Locked="false" Priority="65" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 1 Accent 5"/>\n  <w:LsdException Locked="false" Priority="66" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 2 Accent 5"/>\n  <w:LsdException Locked="false" Priority="67" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 5"/>\n  <w:LsdException Locked="false" Priority="68" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 5"/>\n  <w:LsdException Locked="false" Priority="69" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 5"/>\n  <w:LsdException Locked="false" Priority="70" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Dark List Accent 5"/>\n  <w:LsdException Locked="false" Priority="71" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Shading Accent 5"/>\n  <w:LsdException Locked="false" Priority="72" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful List Accent 5"/>\n  <w:LsdException Locked="false" Priority="73" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Grid Accent 5"/>\n  <w:LsdException Locked="false" Priority="60" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Shading Accent 6"/>\n  <w:LsdException Locked="false" Priority="61" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light List Accent 6"/>\n  <w:LsdException Locked="false" Priority="62" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Light Grid Accent 6"/>\n  <w:LsdException Locked="false" Priority="63" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 6"/>\n  <w:LsdException Locked="false" Priority="64" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 6"/>\n  <w:LsdException Locked="false" Priority="65" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 1 Accent 6"/>\n  <w:LsdException Locked="false" Priority="66" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium List 2 Accent 6"/>\n  <w:LsdException Locked="false" Priority="67" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 6"/>\n  <w:LsdException Locked="false" Priority="68" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 6"/>\n  <w:LsdException Locked="false" Priority="69" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 6"/>\n  <w:LsdException Locked="false" Priority="70" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Dark List Accent 6"/>\n  <w:LsdException Locked="false" Priority="71" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Shading Accent 6"/>\n  <w:LsdException Locked="false" Priority="72" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful List Accent 6"/>\n  <w:LsdException Locked="false" Priority="73" SemiHidden="false"\n   UnhideWhenUsed="false" Name="Colorful Grid Accent 6"/>\n  <w:LsdException Locked="false" Priority="19" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Subtle Emphasis"/>\n  <w:LsdException Locked="false" Priority="21" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Intense Emphasis"/>\n  <w:LsdException Locked="false" Priority="31" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Subtle Reference"/>\n  <w:LsdException Locked="false" Priority="32" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Intense Reference"/>\n  <w:LsdException Locked="false" Priority="33" SemiHidden="false"\n   UnhideWhenUsed="false" QFormat="true" Name="Book Title"/>\n  <w:LsdException Locked="false" Priority="37" Name="Bibliography"/>\n  <w:LsdException Locked="false" Priority="39" QFormat="true" Name="TOC Heading"/>\n </w:LatentStyles>\n</xml><![endif]-->\n\n<!--[if gte mso 10]>\n<style>\n /* Style Definitions */\ntable.MsoNormalTable\n {mso-style-name:"Table Normal";\n mso-tstyle-rowband-size:0;\n mso-tstyle-colband-size:0;\n mso-style-noshow:yes;\n mso-style-priority:99;\n mso-style-parent:"";\n mso-padding-alt:0cm 5.4pt 0cm 5.4pt;\n mso-para-margin:0cm;\n mso-para-margin-bottom:.0001pt;\n mso-pagination:widow-orphan;\n font-size:10.0pt;\n font-family:"Times New Roman";\n mso-fareast-language:JA;}\n</style>\n<![endif]-->\n\n\n\n<!--StartFragment-->\n\n<br />\n<div class="MsoNormal">\n<span lang="EN-US">Commercial publishers, as a class, are not\nevil. To think so is wrong. They have just been doing what the scientific\ncommunity can''t or won''t do by itself. And like most businesses, they charge\nwhat they can get away with. It’s known as ‘the market’. They can’t be\ncriticised for existing and functioning in a perfectly legal capitalist market\nand regulatory environment. That doesn’t mean they can’t be criticised. Individual publishers can be criticised for their actions and inactions. As an industry, among\nthe things they can be criticised for are not evolving fast\nenough, given the environmental change that the web has brought about. But so\ncan the academic community. The reliance on old and now effectively dysfunctional\nsystems and habits from a bygone era is mutual.<o:p></o:p></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US">Centuries ago, in Europe, non-Christians\nwere forbidden to belong to the guilds, which made it impossible for them to be\nany kind of craftsman, essentially leaving them with few other options than\nbeing an unskilled labourer, trader, or money lender. So some became very\nwealthy and thus became the target of envy. And accused of usury and the like. Just\nfor doing the only thing they were allowed to do and society needed someone to\ndo. It’s more complicated than that, but it captures the essence.<o:p></o:p></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US">The relevance of this to science\npublishing? Well, at a certain point, when science had grown into a sizeable,\nprofessional and global pursuit, academics didn’t, or couldn’t, organise publishing\nproperly anymore on that global scale. University presses were, by definition,\nrather local, and so were scientific societies. Commercial publishers stepped\ninto the breach, some became very wealthy, and are now the target of envy. Or\nat least of criticism of their wealth. And accused of greed and the like. Just\nfor doing some of the things the academic community needs or thinks it needs,\nin the environment of a ‘market’ (starting in the 1950’s with e.g. internationalisation\nof science communication; abolishing the sort of author charges the scientific\nsocieties were levying for their journals, standardisation of article\nstructures, language, et cetera).<o:p></o:p></span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US">Lesson: if you leave it to outsiders to\nprovide your essential services, because you can’t, or won’t, truly assimilate\nand embed those outsiders, and provide the services from within your own circles,\nyou risk losing control and you cannot blame the outsiders for taking the\nopportunities you give them.<o:p></o:p></span></div>\n<div class="MsoNormal">\n<span lang="EN-US"><br /></span></div>\n<div class="MsoNormal">\n<span lang="EN-US">Jan Velterop</span></div>\n<div class="MsoNormal">\n<br /></div>\n<div class="MsoNormal">\n<span lang="EN-US">PS. The first Open Access publisher was a\ncommercial publisher. The largest publisher of&nbsp;</span>Open Access articles&nbsp;today is a\ncommercial publisher. Why are there not more scientist-led initiatives like\nPLoS?</div>\n<div class="MsoNormal">\n<br /></div>\n<!--EndFragment--></div>','\n',char(10)),NULL,'','2012-02-05 14:56:00','Parachute blog','',NULL,'2023-12-15 15:47:36','read');
INSERT INTO items VALUES('https://blog.scielo.org/blog/2023/12/13/como-reformular-a-publicacao-cientifica-para-enfrentar-a-crise-da-avaliacao-por-pares/#new_tab','How to reformulate scholarly publishing to face the peer review crisis',replace('<p>The time between submission and publication of articles in the field of microbiology has been increasing in recent years. In addition, editors are having to invite more and more reviewers to identify those willing to evaluate manuscripts. What are the implications of this for peer review? Available in Portuguese only. <span class="ellipsis">&#8230;</span> <span class="more-link-wrap"><a href="https://blog.scielo.org/blog/2023/12/13/como-reformular-a-publicacao-cientifica-para-enfrentar-a-crise-da-avaliacao-por-pares/#new_tab" class="more-link"><span>Read More &#8594;</span></a></span></p>\n<p>The post <a href="https://blog.scielo.org/blog/2023/12/13/como-reformular-a-publicacao-cientifica-para-enfrentar-a-crise-da-avaliacao-por-pares/#new_tab">How to reformulate scholarly publishing to face the peer review crisis</a> first appeared on <a href="https://blog.scielo.org/en">SciELO in Perspective</a>.</p>','\n',char(10)),NULL,'','2023-12-13 13:30:15','SciELO in Perspective','',NULL,'2023-12-15 18:12:57','read');
INSERT INTO items VALUES('https://blog.scielo.org/es/2023/12/06/puede-la-ia-hacer-arbitrajes-confiables-de-articulos-cientificos/#new_tab','Can AI do reliable review scientific articles?',replace('<p>The cost of reviewing scientific publications, both in terms of money and time spent, is growing to unmanageable proportions with current methods. It is necessary to use AI as a trust system and thus free up human resources for research tasks. It would be important for SciELO to progressively incorporate AI modules for evaluation in its preprints server as a new advance and development of the technologies it manages. Available in Spanish only. <span class="ellipsis">&#8230;</span> <span class="more-link-wrap"><a href="https://blog.scielo.org/es/2023/12/06/puede-la-ia-hacer-arbitrajes-confiables-de-articulos-cientificos/#new_tab" class="more-link"><span>Read More &#8594;</span></a></span></p>\n<p>The post <a href="https://blog.scielo.org/es/2023/12/06/puede-la-ia-hacer-arbitrajes-confiables-de-articulos-cientificos/#new_tab">Can AI do reliable review scientific articles?</a> first appeared on <a href="https://blog.scielo.org/en">SciELO in Perspective</a>.</p>','\n',char(10)),NULL,'','2023-12-06 13:30:42','SciELO in Perspective','',NULL,'2023-12-15 18:12:57','read');
INSERT INTO items VALUES('https://blog.scielo.org/blog/2023/11/29/a-comunidade-cientifica-esta-publicando-muito-mais-e-isso-e-um-problema/#new_tab','The scientific community is publishing (much) more and that’s a problem',replace('<p>A study posted on arXiv reports an exponential increase in the number of refereed scientific articles published in recent years, disproportionately outstripping the increase in the number of researchers. Scientific output per researcher as author, reviewer, and editor has increased dramatically, a phenomenon referred to as "pressure on scientific publication", classified as a problem to be identified and resolved. Available in Portuguese only. <span class="ellipsis">&#8230;</span> <span class="more-link-wrap"><a href="https://blog.scielo.org/blog/2023/11/29/a-comunidade-cientifica-esta-publicando-muito-mais-e-isso-e-um-problema/#new_tab" class="more-link"><span>Read More &#8594;</span></a></span></p>\n<p>The post <a href="https://blog.scielo.org/blog/2023/11/29/a-comunidade-cientifica-esta-publicando-muito-mais-e-isso-e-um-problema/#new_tab">The scientific community is publishing (much) more and that’s a problem</a> first appeared on <a href="https://blog.scielo.org/en">SciELO in Perspective</a>.</p>','\n',char(10)),NULL,'','2023-11-29 14:15:09','SciELO in Perspective','',NULL,'2023-12-15 18:12:57','read');
INSERT INTO items VALUES('https://blog.scielo.org/en/2023/11/24/research-and-scholarly-communication-ai-and-the-upcoming-legislation/','Research and scholarly communication, AI, and the upcoming legislation',replace('<p>Can AI be used to generate terrorist "papers", spread deadly viruses, or learn how to make nuclear bombs at home? Is there legislation that can protect us? It looks like international regulation is on the way. <span class="ellipsis">&#8230;</span> <span class="more-link-wrap"><a href="https://blog.scielo.org/en/2023/11/24/research-and-scholarly-communication-ai-and-the-upcoming-legislation/" class="more-link"><span>Read More &#8594;</span></a></span></p>\n<p>The post <a href="https://blog.scielo.org/en/2023/11/24/research-and-scholarly-communication-ai-and-the-upcoming-legislation/">Research and scholarly communication, AI, and the upcoming legislation</a> first appeared on <a href="https://blog.scielo.org/en">SciELO in Perspective</a>.</p>','\n',char(10)),NULL,'','2023-11-24 16:30:33','SciELO in Perspective','',NULL,'2023-12-15 18:12:57','read');
INSERT INTO items VALUES('https://blog.scielo.org/en/2023/11/17/ai-how-to-detect-chatbox-texts-and-their-plagiarism/','AI: How to detect chatbox texts and their plagiarism',replace('<p>The ChatGPT-3 application is consulted on four topics under discussion for the production of academic texts acceptable to scientific journal editors. Each question is followed by the answer given by the OpenAI application itself and then by our evaluation, consulting recent sources published on the Internet. Finally, some (human) reflections are presented which, like all things, are subject to discussion or changes brought about by advances in technology. <span class="ellipsis">&#8230;</span> <span class="more-link-wrap"><a href="https://blog.scielo.org/en/2023/11/17/ai-how-to-detect-chatbox-texts-and-their-plagiarism/" class="more-link"><span>Read More &#8594;</span></a></span></p>\n<p>The post <a href="https://blog.scielo.org/en/2023/11/17/ai-how-to-detect-chatbox-texts-and-their-plagiarism/">AI: How to detect chatbox texts and their plagiarism</a> first appeared on <a href="https://blog.scielo.org/en">SciELO in Perspective</a>.</p>','\n',char(10)),NULL,'','2023-11-17 17:30:35','SciELO in Perspective','',NULL,'2023-12-15 18:12:57','read');
INSERT INTO items VALUES('https://blog.scielo.org/en/2023/11/14/chatgpt-and-other-ais-will-transform-all-scientific-research-initial-reflections-on-uses-and-consequences-part-2/','ChatGPT and other AIs will transform all scientific research: initial reflections on uses and consequences – part 2',replace('<p>In this second part of the essay, we seek to present some risks that arise particularly in the use of generative AI in the scientific field and in academic work. Although all the problems have not been fully mapped out, we have tried to offer initial reflections to support and encourage debate.  <span class="ellipsis">&#8230;</span> <span class="more-link-wrap"><a href="https://blog.scielo.org/en/2023/11/14/chatgpt-and-other-ais-will-transform-all-scientific-research-initial-reflections-on-uses-and-consequences-part-2/" class="more-link"><span>Read More &#8594;</span></a></span></p>\n<p>The post <a href="https://blog.scielo.org/en/2023/11/14/chatgpt-and-other-ais-will-transform-all-scientific-research-initial-reflections-on-uses-and-consequences-part-2/">ChatGPT and other AIs will transform all scientific research: initial reflections on uses and consequences – part 2</a> first appeared on <a href="https://blog.scielo.org/en">SciELO in Perspective</a>.</p>','\n',char(10)),NULL,'','2023-11-14 17:35:13','SciELO in Perspective','',NULL,'2023-12-15 18:12:57','read');
INSERT INTO items VALUES('https://blog.scielo.org/en/2023/11/10/chatgpt-and-other-ais-will-transform-all-scientific-research-initial-thoughts-on-uses-and-consequences-part-1/','ChatGPT and other AIs will transform all scientific research: initial thoughts on uses and consequences – part 1',replace('<p>We discuss some possible consequences, risks, and paradoxes of the use of AIs in research, such as potential deterioration of research integrity, possible changes in the dynamics of knowledge production and center-periphery relations in the academic environment. We concluded by calling for an in-depth dialog on regulation and the creation of technologies adapted to our needs. <span class="ellipsis">&#8230;</span> <span class="more-link-wrap"><a href="https://blog.scielo.org/en/2023/11/10/chatgpt-and-other-ais-will-transform-all-scientific-research-initial-thoughts-on-uses-and-consequences-part-1/" class="more-link"><span>Read More &#8594;</span></a></span></p>\n<p>The post <a href="https://blog.scielo.org/en/2023/11/10/chatgpt-and-other-ais-will-transform-all-scientific-research-initial-thoughts-on-uses-and-consequences-part-1/">ChatGPT and other AIs will transform all scientific research: initial thoughts on uses and consequences – part 1</a> first appeared on <a href="https://blog.scielo.org/en">SciELO in Perspective</a>.</p>','\n',char(10)),NULL,'','2023-11-10 16:30:19','SciELO in Perspective','',NULL,'2023-12-15 18:12:57','read');
INSERT INTO items VALUES('https://doi.org/10.1590/0001-37652023952#new_tab','One of the great dilemmas for editors of scientific journals: to charge or not to charge, that is the question!',replace('<p>The issue of charging publication fees has been haunting editors and authors. Contrary to what it may seem, there doesn''t seem to be any appreciation or recognition on the part of researchers in favor of journals that have made a great effort not to charge any fees and to make articles available free of charge. <span class="ellipsis">&#8230;</span> <span class="more-link-wrap"><a href="https://doi.org/10.1590/0001-37652023952#new_tab" class="more-link"><span>Read More &#8594;</span></a></span></p>\n<p>The post <a href="https://doi.org/10.1590/0001-37652023952#new_tab">One of the great dilemmas for editors of scientific journals: to charge or not to charge, that is the question!</a> first appeared on <a href="https://blog.scielo.org/en">SciELO in Perspective</a>.</p>','\n',char(10)),NULL,'','2023-10-31 18:30:32','SciELO in Perspective','',NULL,'2023-12-15 18:12:57','read');
INSERT INTO items VALUES('https://blog.scielo.org/en/2023/10/27/scielo-as-a-space-for-thinking-through-scholarly-communication/','SciELO as a space for thinking through scholarly communication',replace('<p>Understanding SciELO as a place to think through scholarly communication allows us to address new challenges for publishers, such as artificial intelligence. SciELO has an ethical component, a technological component and, at its core, a concern for the people who make up the scholarly communication community. <span class="ellipsis">&#8230;</span> <span class="more-link-wrap"><a href="https://blog.scielo.org/en/2023/10/27/scielo-as-a-space-for-thinking-through-scholarly-communication/" class="more-link"><span>Read More &#8594;</span></a></span></p>\n<p>The post <a href="https://blog.scielo.org/en/2023/10/27/scielo-as-a-space-for-thinking-through-scholarly-communication/">SciELO as a space for thinking through scholarly communication</a> first appeared on <a href="https://blog.scielo.org/en">SciELO in Perspective</a>.</p>','\n',char(10)),NULL,'','2023-10-27 12:00:27','SciELO in Perspective','',NULL,'2023-12-15 18:12:57','read');
INSERT INTO items VALUES('https://blog.scielo.org/en/2023/10/20/revista-dados-creates-special-editorial-office-on-replicability/','Revista DADOS creates special editorial office on replicability',replace('<p>As of this year, <em>Revista DADOS</em> will have an editorial department specifically set up to deal with issues of the replicability of its articles. This commitment included a break with essayism in favor of a more systematic research view, which led to the publication of manuscripts strongly supported by empirical evidence. <span class="ellipsis">&#8230;</span> <span class="more-link-wrap"><a href="https://blog.scielo.org/en/2023/10/20/revista-dados-creates-special-editorial-office-on-replicability/" class="more-link"><span>Read More &#8594;</span></a></span></p>\n<p>The post <a href="https://blog.scielo.org/en/2023/10/20/revista-dados-creates-special-editorial-office-on-replicability/"><em>Revista DADOS</em> creates special editorial office on replicability</a> first appeared on <a href="https://blog.scielo.org/en">SciELO in Perspective</a>.</p>','\n',char(10)),NULL,'','2023-10-20 16:45:29','SciELO in Perspective','',NULL,'2023-12-15 18:12:57','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/648442','Inferring Implicit 3D Representations from Human Figures on Pictorial Maps','Schnürer, Raimund',NULL,'','2022-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-18 18:57:20','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/648441','Practice Repair','Tümerdem, Nazlı; Marić, Marija; Watabe, Reishin; Gee, Alfie; Miljacki, Ana; Massoud, George; Perkins, Amy; Burch, Oliver',NULL,'','2023-10-01 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-18 18:57:20','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/648440','Instance Segmentation, Body Part Parsing, and Pose Estimation of Human Figures in Pictorial Maps','Schnürer, Raimund',NULL,'','2021-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-18 18:57:20','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/620259','Dataset for A new method for detailed discharge and volume measurements of debris flows based on high-frequency 3D LiDAR point clouds; Illgraben, Switzerland','Spielmann, Raffaele; Aaron, Jordan',NULL,'','2023-12-18 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-18 18:57:20','read');
INSERT INTO items VALUES('https://rc-blog.ethz.ch/en/eth-researcher-wins-the-swiss-national-ord-prize/','ETH researcher wins the Swiss National ORD Prize','Adriano Rutz, a Postdoc at ETH Zurich, wins the first National Prize for Open Research Data (ORD) for “The LOTUS Initiative” project. Read more<img src="https://analytics.library.ethz.ch/piwik.php?idsite=1&amp;rec=1&amp;url=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Feth-researcher-wins-the-swiss-national-ord-prize%2F&amp;action_name=ETH+researcher+wins+the+Swiss+National+ORD+Prize&amp;urlref=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Ffeed%2F" style="border:0;width:0;height:0" width="0" height="0" alt="" />',NULL,'','2023-12-08 10:55:39','ETH Zurich Research Archives','',NULL,'2023-12-18 18:57:21','read');
INSERT INTO items VALUES('https://rc-blog.ethz.ch/en/free-of-charge-and-without-embargo-how-to-meet-the-snsfs-new-open-access-requirements-using-the-rights-retention-strategy/','Free of charge and without embargo: How to meet the SNSF’s new open access requirements using the Rights Retention Strategy','Coffee Lecture, 22 November 2023, 3.15 &#8211; 3.30 pm. Read more<img src="https://analytics.library.ethz.ch/piwik.php?idsite=1&amp;rec=1&amp;url=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Ffree-of-charge-and-without-embargo-how-to-meet-the-snsfs-new-open-access-requirements-using-the-rights-retention-strategy%2F&amp;action_name=Free+of+charge+and+without+embargo%3A+How+to+meet+the+SNSF%26%238217%3Bs+new+open+access+requirements+using+the+Rights+Retention+Strategy&amp;urlref=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Ffeed%2F" style="border:0;width:0;height:0" width="0" height="0" alt="" />',NULL,'','2023-11-15 15:53:29','ETH Zurich Research Archives','',NULL,'2023-12-18 18:57:21','read');
INSERT INTO items VALUES('https://rc-blog.ethz.ch/en/do-you-have-a-data-management-plan-for-your-approved-snsf-project/','Do you have a data management plan for your approved SNSF project?','You could submit your application for project funding to the Swiss National Science Foundation (SNSF) until 01 October 2023. Remember that you need a data management plan (DMP) for approved projects. Read more<img src="https://analytics.library.ethz.ch/piwik.php?idsite=1&amp;rec=1&amp;url=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Fdo-you-have-a-data-management-plan-for-your-approved-snsf-project%2F&amp;action_name=Do+you+have+a+data+management+plan+for+your+approved+SNSF+project%3F&amp;urlref=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Ffeed%2F" style="border:0;width:0;height:0" width="0" height="0" alt="" />',NULL,'','2023-11-07 07:03:58','ETH Zurich Research Archives','',NULL,'2023-12-18 18:57:21','read');
INSERT INTO items VALUES('https://rc-blog.ethz.ch/en/the-eth-zurich-research-collection-is-awarded-the-coretrustseal/','The ETH Zurich Research Collection is awarded the CoreTrustSeal','The ETH Library is the first Swiss university library to be awarded the CoreTrustSeal. As ETH Zurich’s institutional repository, the Research Collection now has a globally recognised certification. Read more<img src="https://analytics.library.ethz.ch/piwik.php?idsite=1&amp;rec=1&amp;url=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Fthe-eth-zurich-research-collection-is-awarded-the-coretrustseal%2F&amp;action_name=The+ETH+Zurich+Research+Collection+is+awarded+the+CoreTrustSeal&amp;urlref=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Ffeed%2F" style="border:0;width:0;height:0" width="0" height="0" alt="" />',NULL,'','2023-10-19 06:09:50','ETH Zurich Research Archives','',NULL,'2023-12-18 18:57:21','read');
INSERT INTO items VALUES('https://rc-blog.ethz.ch/en/how-to-proceed-for-funding-of-publication-fees-with-snsf-grants/','How to proceed for funding of publication fees with SNSF grants','When the Swiss National Science Foundation (SNSF) funds a project, it covers the fees for any resulting gold open-​access publications. Researchers from ETH Zurich use the SNSF’s ChronosHub platform to settle these fees. Read more<img src="https://analytics.library.ethz.ch/piwik.php?idsite=1&amp;rec=1&amp;url=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Fhow-to-proceed-for-funding-of-publication-fees-with-snsf-grants%2F&amp;action_name=How+to+proceed+for+funding+of+publication+fees+with+SNSF+grants&amp;urlref=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Ffeed%2F" style="border:0;width:0;height:0" width="0" height="0" alt="" />',NULL,'','2023-10-12 06:02:37','ETH Zurich Research Archives','',NULL,'2023-12-18 18:57:21','read');
INSERT INTO items VALUES('https://rc-blog.ethz.ch/en/course-academic-reporting-aaa/','Course Academic Reporting (AAA)','In this two-hour course you will learn how to create an AAA report for your professorship (user interface, workflow, entering and displaying data) and how to enter publications in the Research Collection.Finance and Controlling courses for administrative staff<img src="https://analytics.library.ethz.ch/piwik.php?idsite=1&amp;rec=1&amp;url=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Fcourse-academic-reporting-aaa%2F&amp;action_name=Course+Academic+Reporting+%28AAA%29&amp;urlref=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Ffeed%2F" style="border:0;width:0;height:0" width="0" height="0" alt="" />',NULL,'','2023-10-11 12:50:13','ETH Zurich Research Archives','',NULL,'2023-12-18 18:57:21','read');
INSERT INTO items VALUES('https://rc-blog.ethz.ch/en/these-are-the-coffee-lectures-in-november/','These are the Coffee Lectures in November','This November is going to be interesting. In the new Coffee Lectures, we will teach you new tools and relevant topics for your academic work in a quarter of an hour. Read more<img src="https://analytics.library.ethz.ch/piwik.php?idsite=1&amp;rec=1&amp;url=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Fthese-are-the-coffee-lectures-in-november%2F&amp;action_name=These+are+the+Coffee+Lectures+in+November&amp;urlref=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Ffeed%2F" style="border:0;width:0;height:0" width="0" height="0" alt="" />',NULL,'','2023-10-11 06:14:41','ETH Zurich Research Archives','',NULL,'2023-12-18 18:57:21','read');
INSERT INTO items VALUES('https://rc-blog.ethz.ch/en/new-calls-from-the-ord-programme-of-the-eth-domain/','New Calls from the ORD Programme of the ETH Domain','There are two new calls from the Open Research Data (ORD) Programme of the ETH Domain for financial support of researcher for projects related to ORD practices, which have been launched recently. Read more<img src="https://analytics.library.ethz.ch/piwik.php?idsite=1&amp;rec=1&amp;url=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Fnew-calls-from-the-ord-programme-of-the-eth-domain%2F&amp;action_name=New+Calls+from+the+ORD+Programme+of+the+ETH+Domain&amp;urlref=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Ffeed%2F" style="border:0;width:0;height:0" width="0" height="0" alt="" />',NULL,'','2023-10-10 09:30:40','ETH Zurich Research Archives','',NULL,'2023-12-18 18:57:21','read');
INSERT INTO items VALUES('https://rc-blog.ethz.ch/en/the-new-eth-library-course-programme-is-online/','The new ETH Library course programme is online','In the second semester of 2023, you can expect diverse topics such aswriting with AI-based tools, the visualisation of research data or “Rock your Master&#8217;s” – a new event especially for Master&#8217;s students. Read more<img src="https://analytics.library.ethz.ch/piwik.php?idsite=1&amp;rec=1&amp;url=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Fthe-new-eth-library-course-programme-is-online%2F&amp;action_name=The+new+ETH+Library+course+programme+is+online&amp;urlref=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Ffeed%2F" style="border:0;width:0;height:0" width="0" height="0" alt="" />',NULL,'','2023-09-04 06:13:19','ETH Zurich Research Archives','',NULL,'2023-12-18 18:57:21','read');
INSERT INTO items VALUES('https://rc-blog.ethz.ch/en/research-data-management-and-related-topics-know-how-for-your-research-project-5/','Research data management and related topics: know-how for your research project','This series of workshops organised by the ETH Library and Scientific IT Services at ETH Zurich introduces you to varied aspects of research data management. Read more<img src="https://analytics.library.ethz.ch/piwik.php?idsite=1&amp;rec=1&amp;url=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Fresearch-data-management-and-related-topics-know-how-for-your-research-project-5%2F&amp;action_name=Research+data+management+and+related+topics%3A+know-how+for+your+research+project&amp;urlref=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Ffeed%2F" style="border:0;width:0;height:0" width="0" height="0" alt="" />',NULL,'','2023-08-29 06:11:01','ETH Zurich Research Archives','',NULL,'2023-12-18 18:57:21','read');
INSERT INTO items VALUES('https://www.arl.org/our-priorities/advocacy-public-policy/partner-letters/open-internet/ace-letter-to-fcc-on-net-neutrality/','ACE Letter to FCC on Net Neutrality',replace('<p>Last Updated on December 18, 2023, 2:16 pm ET On December 14, 2023, ARL joined an American Council on Education (ACE) letter regarding the US Federal Communications Commission (FCC) Notice...</p>\n<p>The post <a href="https://www.arl.org/our-priorities/advocacy-public-policy/partner-letters/open-internet/ace-letter-to-fcc-on-net-neutrality/">ACE Letter to FCC on Net Neutrality</a> appeared first on <a href="https://www.arl.org">Association of Research Libraries</a>.</p>\n','\n',char(10)),NULL,'','2023-12-14 15:09:50','Association of Research Libraries News','',NULL,'2023-12-18 18:57:31','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/12/18/kitchen-essentials-an-interview-with-chris-shillum-of-orcid/','Kitchen Essentials: An Interview with Chris Shillum of ORCID',replace('<p>In today''s Kitchen Essentials interview, Alice Meadows asks Chris Shillum, Executive DIrector of ORCID, to share his thoughts about his career in research infrastructure</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/12/18/kitchen-essentials-an-interview-with-chris-shillum-of-orcid/">Kitchen Essentials: An Interview with Chris Shillum of ORCID</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-12-18 10:30:00','Scholarly Kitchen','',NULL,'2023-12-18 18:57:32','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/12/20/fortune-brainstorm-ai/','Fortune Brainstorm AI Conference: Themes and Ideas',replace('<p>Themes and ideas from the Fortune Brainstorm AI. “People won''t lose their jobs to AI; they’ll lose their jobs to people that are using AI.”</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/12/20/fortune-brainstorm-ai/">Fortune Brainstorm AI Conference: Themes and Ideas</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-12-20 10:30:21','Scholarly Kitchen','',NULL,'2023-12-21 01:15:29','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/12/19/library-licensing-strategies/','Library Licensing Strategies',replace('<p> Libraries are accelerating engagement with transformative and pure publish agreements, balancing contract-based publishing support with an APC fund, and investing in the scholarly communications ecosystem.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/12/19/library-licensing-strategies/">Library Licensing Strategies</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-12-19 10:30:53','Scholarly Kitchen','',NULL,'2023-12-21 01:15:29','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/648445','Inferring Implicit 3D Representations from Human Figures on Pictorial Maps','Schnürer, Raimund',NULL,'','2023-12-20 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-21 01:15:33','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/648952','Wie sehen unsere Städte im Jahr 2082 aus? Wird es dann noch Autos in der Stadt geben?','Wälty, Sibylle',NULL,'','2022-05-01 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-21 01:15:33','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/648951','Zielkonflikt zwischen Lärmschutz und Verdichtung','Wälty, Sibylle',NULL,'','2022-03-01 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-21 01:15:33','read');
INSERT INTO items VALUES('https://rc-blog.ethz.ch/en/closing-christmas-new-year/','Closing Christmas / New Year','The ETH Library is closed from 24 December 2023 until 2 January 2024. During this time, you can still deposit new publications. The Research Collection team will process them from 3 January. We wish you a merry Christmas and a happy New Year.<img src="https://analytics.library.ethz.ch/piwik.php?idsite=1&amp;rec=1&amp;url=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Fclosing-christmas-new-year%2F&amp;action_name=Closing+Christmas+%2F+New+Year&amp;urlref=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Ffeed%2F" style="border:0;width:0;height:0" width="0" height="0" alt="" />',NULL,'','2023-12-19 06:42:45','ETH Zurich Research Archives','',NULL,'2023-12-21 01:15:34','read');
INSERT INTO items VALUES('https://www.arl.org/blog/navigating-the-complex-landscape-of-research-data-management-and-sharing-dms-dms-activities-from-the-rads-initiative/','Navigating the Complex Landscape of Research Data Management and Sharing (DMS): DMS Activities from the RADS Initiative',replace('<p>Last Updated on December 19, 2023, 2:09 pm ET The Realities of Academic Data Sharing (RADS) Initiative has entered the second phase of the project, generously funded by the Institute...</p>\n<p>The post <a href="https://www.arl.org/blog/navigating-the-complex-landscape-of-research-data-management-and-sharing-dms-dms-activities-from-the-rads-initiative/">Navigating the Complex Landscape of Research Data Management and Sharing (DMS): DMS Activities from the RADS Initiative</a> appeared first on <a href="https://www.arl.org">Association of Research Libraries</a>.</p>\n','\n',char(10)),NULL,'','2023-12-19 19:09:45','Association of Research Libraries News','',NULL,'2023-12-21 01:15:35','read');
INSERT INTO items VALUES('https://www.arl.org/day-in-review/day-in-review-december-18-20/','Day in Review (December 18–19)',replace('<p>Last Updated on December 20, 2023, 11:24 am ET Sign up to receive the Day in Review by email. Jump to: Tuesday, December 19 &#124; Note: Day in Review will...</p>\n<p>The post <a href="https://www.arl.org/day-in-review/day-in-review-december-18-20/">Day in Review (December 18–19)</a> appeared first on <a href="https://www.arl.org">Association of Research Libraries</a>.</p>\n','\n',char(10)),NULL,'','2023-12-19 08:58:09','Association of Research Libraries News','',NULL,'2023-12-21 01:15:35','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/12/21/guest-post-scholarly-social-findings-from-the-ssp-social-media-survey/','Guest Post — Scholarly Social: Findings from the SSP Social Media Survey',replace('<p>Results from the SSP survey on the changing nature of social media use by publishers, research societies, libraries, vendors, and others in our community.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/12/21/guest-post-scholarly-social-findings-from-the-ssp-social-media-survey/">Guest Post &#8212; Scholarly Social: Findings from the SSP Social Media Survey</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-12-21 10:30:30','Scholarly Kitchen','',NULL,'2023-12-21 18:22:26','read');
INSERT INTO items VALUES('https://blog.scielo.org/es/2023/12/20/es-que-la-inteligencia-artificial-tiene-alucinaciones/#new_tab','Does Artificial Intelligence have hallucinations?',replace('<p>AI applications have demonstrated impressive capabilities, including the generation of very fluent and convincing responses. However, LLMs, chatbots, and the like, are known for their ability to generate non-objective or nonsensical statements, more commonly known as "hallucinations." Could it be that they are on drugs? Available in Spanish only. <span class="ellipsis">&#8230;</span> <span class="more-link-wrap"><a href="https://blog.scielo.org/es/2023/12/20/es-que-la-inteligencia-artificial-tiene-alucinaciones/#new_tab" class="more-link"><span>Read More &#8594;</span></a></span></p>\n<p>The post <a href="https://blog.scielo.org/es/2023/12/20/es-que-la-inteligencia-artificial-tiene-alucinaciones/#new_tab">Does Artificial Intelligence have <em>hallucinations</em>?</a> first appeared on <a href="https://blog.scielo.org/en">SciELO in Perspective</a>.</p>','\n',char(10)),NULL,'','2023-12-20 17:30:15','SciELO in Perspective','',NULL,'2023-12-21 18:22:28','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649176','Key factors to enhance efficacy of 3D digital environments for transformative landscape and urban planning','Grêt-Regamey, Adrienne; Fagerholm, Nora',NULL,'','2024-04-01 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-21 18:22:29','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649175','AgroAnything','Keller, Beat; Muller, Onno; Steier, Angelina; Zimmermann, Lars; Ribeiro, Junior',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-21 18:22:29','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/648878','Animal-associated marine Acidobacteria with a rich natural-product repertoire','Leopold-Messer, Stefan; Chepkirui, Clara; Mabesoone, Mathijs F.J.; Meyer, Joshua; Paoli, Lucas; Sunagawa, Shinichi; Uria, Agustinus R.; Wakimoto, Toshiyuki; Piel, Jörn',NULL,'','2023-12-14 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-21 18:22:29','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/648468','Genome organization regulates nuclear pore complex formation and promotes differentiation during Drosophila oogenesis','Kotb, Noor M.; Ulukaya, Gulay; Chavan, Ankita; Nguyen, Son C.; Proskauer, Lydia; Joyce, Eric; Hasson, Dan; Jagannathan, Madhav; Rangan, Prashanth',NULL,'','2023-11-16 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-21 18:22:29','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/647563','Ambiguous genes due to aligners and their impact on RNA-seq data analysis','Szabelska-Beresewicz, Alicja; Zyprych-Walczak, Joanna; Siatkowski, Idzi; Okoniewski, Michał',NULL,'','2023-12-08 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-22 19:37:01','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649491','Development of Tailored Catalysts by Atomic Layer Deposition: Relating Catalytic Performance with Coordination Environment and Surface Acidity','Chen, Zixuan',NULL,'','2023-12-06 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-22 19:37:01','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/647263','Reactivity of kaolinitic clays calcined in the 650 °C–1050 °C temperature range: Towards a robust assessment of overcalcination','Zunino, Franco; Scrivener, Karen',NULL,'','2024-02-01 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-22 19:37:01','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649384','Rapid-Scan Nonlinear Time-Resolved Spectroscopy over Arbitrary Delay Intervals','Flöry, Tobias; Stummer, Vinzenz; Pupeikis, Justinas; Willenberg, Benjamin; Nussbaum-Lapping, Alexander; Kaksis, Edgar; Camargo, Franco V. A.; Barkauskas, Martynas; Phillips, Christopher R.; Keller, Ursula; Cerullo, Giulio; Cerullo, Giulio; Baltuška, Andrius',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-22 19:37:01','read');
INSERT INTO items VALUES('https://www.arl.org/our-priorities/advocacy-public-policy/public-policy-briefing/november-december-2023/','November–December 2023',replace('<p>Last Updated on December 22, 2023, 7:30 am ET Public Policy Briefing (November–December 2023) This issue includes: Copyright and Fair Use/Fair Dealing ARL, Canadian Association of Research Libraries (CARL) Host...</p>\n<p>The post <a href="https://www.arl.org/our-priorities/advocacy-public-policy/public-policy-briefing/november-december-2023/">November–December 2023</a> appeared first on <a href="https://www.arl.org">Association of Research Libraries</a>.</p>\n','\n',char(10)),NULL,'','2023-12-22 12:29:23','Association of Research Libraries News','',NULL,'2023-12-22 19:37:03','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/12/22/scholarly-communications-meets-your-christmas-cracker/','Scholarly Communications Meets your Christmas Cracker',replace('<p>It''s been "the year of generative AI", so Charlie Rapple asked ChatGPT to  write some cracker-standard Christmas jokes with a scholarly communications theme.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/12/22/scholarly-communications-meets-your-christmas-cracker/">Scholarly Communications Meets your Christmas Cracker</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-12-22 10:30:07','Scholarly Kitchen','',NULL,'2023-12-22 19:37:04','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649492','Viscous and ballistic transport in GaAs and graphene','Ginzburg, Lev',NULL,'','2023-12-15 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-22 19:50:08','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649532','Die Innovationsleistung der Schweizer Hightech-Industrie: ein Überblick','Wörter, Martin',NULL,'','2023-05-09 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-23 19:21:57','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649531','Innovation activities in the Swiss economy – status report','Wörter, Martin; Spescha, Andrin',NULL,'','2023-03-24 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-23 19:21:57','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649530','Die Schweizer Innovationswirtschaft im Wandel:  F&E-Tätigkeit, Innovationshemmnisse und die Innovationsleistung im internationalen Vergleich','Wörter, Martin; Spescha, Andrin',NULL,'','2023-03-21 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-23 19:21:57','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649529','KOF-Innovationsumfrage: ein Vehikel zur Messung der Innovationsleistung','Wörter, Martin',NULL,'','2023-03-08 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-23 19:21:57','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649542','Performance indicators in speed climbing: insights from the literature supplemented by a video analysis and expert interviews','Askari Hosseini, Somayeh; Wolf, Peter',NULL,'','2023-12-22 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-24 19:13:25','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649541','CFD-assisted dispersing flow optimization in  a novel ultra-high-pressure device',replace('Windhab, Erich\nMurai, Yuichi','\n',char(10)),NULL,'','2023-03-08 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-24 19:13:25','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649540','In-line rheometry and Raman spectroscopy for process control in viscoelastic protein melt extrusion processing',replace('Windhab, Erich\nMurai, Yuichi','\n',char(10)),NULL,'','2023-03-07 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-24 19:13:25','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649539','Holz-Beton-Verbunddecken – Forschung und Entwicklung an der ETH',replace('Frangi, Andrea\nForum Holzbau, /','\n',char(10)),NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-24 19:13:25','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649588','I tempi del diritto: crisi climatica e mutamento delle forme giuridiche','Pecile, Veronica; Pecile, Veronica',NULL,'','2023-12-01 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-25 22:34:10','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649587','Rethinking legal time: The temporal turn in socio-legal studies','Pecile, Veronica',NULL,'','2023-12-20 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-25 22:34:10','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649586','Are screen media the new pacifiers? The role of parenting stress and parental attitudes for children''s screen time in early childhood','Brauchli V.; Sticca F.; Edelsbrunner P.; von Wyl A.; Lannen P.',NULL,'','2024-03-01 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-25 22:34:10','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649585','Role of the pea protein aggregation state on their interfacial properties','Grasberger K.F.; Lund F.W.; Simonsen A.C.; Hammershøj M.; Fischer P.; Corredig M.',NULL,'','2024-03-15 00:00:00','ETH Zurich, recently added','',NULL,'2023-12-25 22:34:10','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2024/01/03/kitchen-essentials-phoebe-mcmellon-geoscienceworld/','Kitchen Essentials: An Interview with Phoebe McMellon of GeoScienceWorld',replace('<p>In today’s Kitchen Essentials interview, Roger Schonfeld speaks with Phoebe McMellon about her career trajectory and her work at GeoScienceWorld. </p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2024/01/03/kitchen-essentials-phoebe-mcmellon-geoscienceworld/">Kitchen Essentials: An Interview with Phoebe McMellon of GeoScienceWorld</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2024-01-03 10:30:07','Scholarly Kitchen','',NULL,'2024-01-03 18:04:23','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2024/01/02/the-year-in-review-2023-in-the-scholarly-kitchen/','The Year in Review: 2023 in The Scholarly Kitchen',replace('<p>Before we launch into 2024, a look back at 2023 in The Scholarly Kitchen.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2024/01/02/the-year-in-review-2023-in-the-scholarly-kitchen/">The Year in Review: 2023 in The Scholarly Kitchen</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2024-01-02 10:30:44','Scholarly Kitchen','',NULL,'2024-01-03 18:04:23','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2023/12/26/happy-holidays-see-you-in-2024/','Happy Holidays, See You in 2024',replace('<p>We''re off for the holidays, see you in January.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2023/12/26/happy-holidays-see-you-in-2024/">Happy Holidays, See You in 2024</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2023-12-26 10:30:12','Scholarly Kitchen','',NULL,'2024-01-03 18:04:23','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/647550','Geometric effects position renal vesicles during kidney development','Mederacke, Malte Christopher; Conrad, Lisa; Doumpas, Nikolaos; Vetter, Roman; Iber, Dagmar',NULL,'','2023-12-26 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-03 18:04:27','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/650234','Broadband Antenna-coupled THz Quantum Cascade Laser Frequency Combs With Inverse-designed Waveguide Facets','Senica, Urban; Gloor, Sebastian; Micheletti, Paolo; Beck, Matthias; Faist, Jérôme; Scalari, Giacomo',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-03 18:04:27','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/647561','Single-cell Analysis Reveals Inter- and Intratumour Heterogeneity in Metastatic Breast Cancer','Hamelin, Baptiste; Obradović, Milan M.S.; Sethi, Atul; Kloc, Michal; Münst, Simone; Beisel, Christian; Eschbach, Katja; Kohler, Hubertus; Soysal, Savas; Vetter, Marcus; Weber, Walter P.; Stadler, Michael B.; Bentires-Alj, Mohamed',NULL,'','2023-12-08 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-03 18:04:27','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/645577','MIMO Grid Impedance Identification of Three-Phase Power Systems: Parametric vs. Nonparametric Approaches','Häberle, Verena; Huang, Linbin; He, Xiuqiang; Prieto-Araujo, Eduardo; Smith, Roy; Dörfler, Florian',NULL,'','2023-12-13 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-03 18:04:27','read');
INSERT INTO items VALUES('https://jon-e.net/blog/2023/04/24/Re-NIH-RFI-OSTP-Memo/','Re: NIH RFI on Plan to Enhance Public Access to the Results of NIH-Supported Research',replace('<p><strong>tl;dr:</strong> The NIH should directly oppose a for-profit APC-driven publication system and cloud research infrastructure, and instead focus efforts on building truly public information infrastructures.</p>\n\n<p>This is a response to: <a href="https://osp.od.nih.gov/nih-plan-to-enhance-public-access-to-the-results-of-nih-supported-research/">Request for Information on the NIH Plan to Enhance Public Access to the Results of NIH-Supported Research</a>, an RFI for <a href="https://grants.nih.gov/grants/guide/notice-files/NOT-OD-23-091.html">NOT-OD-23-091</a> and the <a href="https://www.whitehouse.gov/wp-content/uploads/2022/08/08-2022-OSTP-Public-Access-Memo.pdf">2022 Nelson open access memo</a>.</p>\n\n<p>The RFI was posed as four questions rather than a general response, the prompt is in the blockquote and my response is the body text.</p>\n\n<h1 id="questions">Questions</h1>\n\n<h2 id="how-to-best-ensure-equity-in-publication-opportunities-for-nih-supported-investigators">How to best ensure equity in publication opportunities for NIH-supported investigators.</h2>\n\n<blockquote>\n  <p>The NIH Public Access Plan aims to maintain the existing broad discretion for researchers and authors to choose how and where to publish their results. Consistent with current practice, the NIH Public Access Plan allows the submission of final published articles to PubMed Central (PMC) (in cases where a formal agreement is in place) to minimize the compliance burden on NIH-supported researchers and also maintains the flexibility of NIH-supported researchers to submit the final peer-reviewed manuscript. NIH seeks information on additional steps it might consider taking to ensure that proposed changes to implementation of the NIH Public Access Policy do not create new inequities in publishing opportunities or reinforce existing ones.</p>\n</blockquote>\n\n<p>The steps towards openness in the 2022 OSTP Memorandum and subsequent notices like NOT-OD-23-091 are admirable steps to use the power of the NIH as a funding body to set standards for equity in public research. The proposals as written seem to be “fighting the last war,”  however, focused on closed-access publication without considering the significant shift in market structure as traditional scientific publishers have transformed into data brokers.</p>\n\n<p>It is impossible to ignore the role of for-profit academic publishers as a primary source of inequity when considering these policies – without their prior model of subscription-based access, there would be no need for these policies at all. We cannot play coy and pretend to be market neutral when considering how scientific publishing should work: for-profit scientific publishing, now largely an oligopoly owned by a handful of information conglomerates, is an ethical catastrophe, and if we intend to grasp at the root of the problem we need to contend with the ways their business models distort the practice of science at every stage.</p>\n\n<p>The publishing oligopoly has had ample time to prepare for the shoe of universal open access to drop, and if their shareholder-facing communications are any indication, they have already fully accounted for it and adapted their business models accordingly. They have been focused heavily on shifting their default strategy from subscription-based publication to author-pays APC-driven open access, as this proposal tacitly endorses. This model is <em>intrinsically inequitable,</em> as it is explicitly designed to shift the burden of payment from libraries to individual researchers, and more closely align the cost of publication with the benefits accrued through the prestige associated with a journal brand. At the point when (1) there is <em>any</em> gradient of APCs such that high-prestige journals like Nature and Cell have a higher cost, and (2) publications in high-prestige journals are a necessity for grant funding and promotion, the system is fundamentally inequitable. Worse, by atomizing the ability to negotiate with publishers, shifting from libraries and library consortia to individual researchers, we neutralize the power of some of the few organizations capable of pushing back against the for-profit publishers by embracing a positive feedback loop where researchers have every incentive to slide the slippery slope of rising APCs in order to retain their employment.</p>\n\n<p>If this proposal leaves the for-profit publishing apparatus largely intact, it will enter the history of half-measures made in deference to the publishing oligopoly that leave the problem perpetually unsolved. One can only imagine the state of every field of research from pharmaceuticals to astrophysics if we had the courage in 1999 to implement the full version of Harold Varmus’ vision for PubMed Central, displacing for-profit publishing entirely with free to publish, free to read research as the norm. What could the world be like if we had 20 years of experimenting with open research dissemination, rather than spending the dawn of the information era hobbled by broken systems accessible to a vanishingly small and privileged few? Will we be looking back in another 20 years wishing we had the courage to end for-profit publishing now?</p>\n\n<p>The very framing of this RFI as being focused on open access publication rather than the infrastructure of our communication demonstrates that we are missing the implications of the shift in the business models of the major for-profit publishers towards “surveillance publishing.” The next era of scholarly communication battles will be about <em>infrastructure.</em> Profit models are consolidating around collecting user data and repackaging it into bibliometrics and informatics platforms like so-called “research intelligence” tools like RELX’s SciVal. With the requirement for open data, we will face another period of enclosure where there is a less clear distinction between publishing, data sharing, and computation. As written, the NIH would directly create a new triple-pay system in the very policy that is intended to address the prior one: if NIH’s STRIDES project is the intended model, NIH pays cloud providers for discounts so that researchers can pay to archive their data as well as pay to export it.</p>\n\n<p>The infrastructure of scientific communication is a fraction of the complexity of that which will be required for universal open data: it is trivial to start a new journal-like website, it is not so trivial to create a new server farm for storing bulk data. The inequity from APCs will be orders of magnitude greater as the process of science congeals into a series of pay-to-use platforms that skim public funding at every stage from grant proposal through data collection, analysis, and publication. The NIH discusses monitoring funding inequity for publication, but is it prepared to handle the broader inequities from the capture of research information infrastructure by a handful of cloud platform giants? Who, exactly, will have the funding necessary to pay for tools that produce clean data, to hire the data scientists to manage it, and to pay the costs of cloud storage and computation? Plainly, the NIH stands to slice off an increasing fraction of its budget to orbiting information rentiers rather than directly funding research, and the dream of universal information access will always be out of reach beyond some exorbitant hosting bill.</p>\n\n<p>The landscape of options that would truly make a more equitable and robust scientific process is wide open, and all of them mean taking a meaningful stand in favor of a public information commons and against for-profit private ownership of information infrastructure. Rather than a single recommendation, I urge the NIH to reorient this and future proposals towards a nonprofit, publicly-owned informational commons. Requiring that all publishers must be operated as nonprofits is one first step. A fixed and decreasing cap on APCs to sunset pay-to-publish models in favor of so-called “diamond” open access is another. Publishing venue-agnostic grant decisions are another. Addressing the next generation of infrastructure needs equitably requires that we look beyond the “Platform as a Service” model articulated in NIH’s 2018 strategic plan for data science where public research bodies outsource and rent basic infrastructure from cloud providers. A full technical evaluation is of course out of scope of this RFI, but a system of peer to peer infrastructure that can leverage resources from individual computers through institutional and federal systems without dependence on cloud providers would be capable of addressing inequity as well as realizing the ambitions of information access articulated in these proposals.</p>\n\n<p>I and others have written elsewhere and are working on these systems.</p>\n\n<h2 id="steps-for-improving-equity-in-access-and-accessibility-of-publications">Steps for improving equity in access and accessibility of publications.</h2>\n\n<blockquote>\n  <p>Removal of the currently allowable 12-month embargo period for NIH-supported publications will improve access to these research products for all. As noted in the NIH Public Access Plan, NIH also plans to continue making articles available in human and machine-readable forms to support automated text processing. NIH will also seek ways to improve the accessibility of publications via assistive devices. NIH welcomes input on other steps that could be taken to improve equity in access to publications by diverse communities of users, including researchers, clinicians and public health officials, students and educators, and other members of the public.</p>\n</blockquote>\n\n<p>The greatest hindrance to accessibility of scientific publications is not technical (though the ailing infrastructure of the traditional publications is some decades behind the rest of the web), but the socio-economic construct of traditional journals themselves. The form of the scientific journal article is entirely unlike how the vast majority of non-scientists interact with information, and is structured by an industry that maintains its profit by strategically suppressing semantic organization in favor of using journal brands as the primary organization principle to maintain the effect of their prestige. It is prestigious to publish in Nature because people will read it. People read Nature papers because there are no effective means of finding research based on its content, leaving scientists to organize dissemination in ad-hoc media like Twitter or be dependent on downstream patches like Google Scholar.</p>\n\n<p>If the NIH is serious about making scientific research more accessible to non-scientists, it must address the ways that research incentives uniformly encourage publication of impenetrable prose in domain- or prestige-limited venues in favor of promoting alternative means of organizing scientific communication, including peer review and publication. We need to not only make it easier for everyone to make sense of the scientific record, we must also reckon with how our incentive structures cause the scientific record to be so difficult to make sense of in the first place.</p>\n\n<p>Accessibility for people that need assistive technologies can <em>only be helped</em> by taking more direct control over our infrastructures of communication. Rather than being beholden to the structure imposed by journals, we should directly address the technologies and social systems that structure scientific communication as part of a holistic project of information accessibility.</p>\n\n<h2 id="methods-for-monitoring-evolving-costs-and-impacts-on-affected-communities">Methods for monitoring evolving costs and impacts on affected communities.</h2>\n\n<blockquote>\n  <p>NIH proposes to actively monitor trends in publication fees and policies to ensure that they remain reasonable and equitable. NIH seeks information on effective approaches for monitoring trends in publication fees and equity in publication opportunities.</p>\n</blockquote>\n\n<p>If the NIH agrees to step in and offset exorbitant APCs in prestige journals in the name of equity, particularly without clear language about what counts as a “reasonable” cost, it sends the message that it is willing to pay any price that the publishers demand. The framing of monitoring evolving costs indicates that the NIH is aware that this policy will increase publication costs, and those increases will inequitably affect researchers outside of the highest echelons of funding and prestige. We do not need to accept this as an inevitability — there are multiple routes towards explicitly avoiding an APC-driven publishing market, and towards creating a peer to peer data infrastructure that avoids outsized cost burdens for marginalized researchers.</p>\n\n<h2 id="early-input-on-considerations-to-increase-findability-and-transparency-of-research">Early input on considerations to increase findability and transparency of research.</h2>\n\n<blockquote>\n  <p>Section IV of the NIH Public Access Plan is a first step in developing the NIH’s updated plan for persistent identifiers (PIDs) and metadata, which will be submitted to OSTP by December 31, 2024. NIH seeks suggestions on any specific issues that should be considered in efforts to improve use of PIDs and metadata, including information about experiences institutions and researchers have had with adoption of different identifiers.</p>\n</blockquote>\n\n<p>It is critical to understand the history of PIDs and how they structure and reinforce the for-profit publishing system, advantaging larger players and disadvantaging independent alternatives. The DOI system itself was created in response to NIH’s 1999 push for PubMed Central in order to preserve the publishing industry’s dominance in assigning identifiers — and thus what can be counted as research. The decades of research on persistent identifiers show that decentralized alternatives like the ARK or IPFS’s CID work, and we should prioritize identifiers that can be created and structured by any researcher, rather than controlled by a centralized authority. Critical research on ontologies and metadata also show their intrinsically political nature, which also points towards tooling to express metadata rather than the current approach taken by NIH’s Biomedical Translator project of creating quasi-universal ontologies to be mapped onto.</p>\n\n<p>I am available for further comment on this and the rest of the responses to this RFI, and I appreciate any time taken to read this.</p>','\n',char(10)),NULL,'','2023-04-24 07:00:00','Jonny Saunders blog','',NULL,'2024-01-03 18:04:29','read');
INSERT INTO items VALUES('https://jon-e.net/blog/2022/04/16/a-halfway-decent-latex-setup/','A Halfway Decent LaTeX Writing Setup',replace('<p>I wouldn’t necessarily <em>recommend</em> writing anything in LaTeX unless you’re already in the cult, but if you are, this is how I’ve managed to write in a way that doesn’t make me curse us having taught electrified rocks about letters in the first place.</p>\012\012<p>In short, we’ll be able to</p>\012\012<ul>\012  <li>One-click add a citation to our document and download a pdf using Zotero</li>\012  <li>Edit nicely with LaTeXTools and Sublime Text</li>\012  <li>Compile our document on save with Tectonic</li>\012  <li>Sync back and forth from the pdf and the source!</li>\012</ul>\012\012<h1 id="prereqs">Prereqs</h1>\012\012<p>We’ll need some software!</p>\012\012<p>I’m using a mac, but most key combinations in windows just swap <code class="language-plaintext highlighter-rouge">cmd</code> for <code class="language-plaintext highlighter-rouge">ctrl</code>.</p>\012\012<ul>\012  <li><a href="https://www.zotero.org/">Zotero</a> - Reference and PDF management - <a href="https://www.zotero.org/download/">download</a>\012    <ul>\012      <li>We’ll also need the <a href="http://zotfile.com/">zotfile</a> and <a href="https://retorque.re/zotero-better-bibtex/">Better BibTeX</a> plugins, as well as the relevant zotero browser extension.</li>\012    </ul>\012  </li>\012  <li><a href="https://www.sublimetext.com/">Sublime Text</a> - Text editor! - <a href="https://www.sublimetext.com/download">download</a> or with homebrew: <code class="language-plaintext highlighter-rouge">brew install --cask sublime-text</code>\012    <ul>\012      <li>Within sublime text we’ll be using some plugins, so install the plugin manager <a href="https://packagecontrol.io/installation">Package Control</a>. From within sublime, open the command palette <code class="language-plaintext highlighter-rouge">cmd+shift+p</code>, type <code class="language-plaintext highlighter-rouge">Install Package Control</code> (an autocomplete menu should get you to the right place before you finish typing the full thing) then press <code class="language-plaintext highlighter-rouge">enter</code></li>\012      <li>Install <a href="LaTeXTools">https://packagecontrol.io/packages/LaTeXTools</a> - open command palette again, type <code class="language-plaintext highlighter-rouge">Package Control: Install Package</code>, type <code class="language-plaintext highlighter-rouge">LaTeXTools</code>, then <code class="language-plaintext highlighter-rouge">enter</code></li>\012      <li>Repeat the above to also install <a href="https://packagecontrol.io/packages/LaTeX-cwl"><code class="language-plaintext highlighter-rouge">LaTeX-cwl</code></a> for code completions! and <a href="https://packagecontrol.io/packages/Hooks"><code class="language-plaintext highlighter-rouge">Hooks</code></a> for building on saving</li>\012    </ul>\012  </li>\012  <li><a href="https://skim-app.sourceforge.io/">Skim</a> - PDF Viewer that supports forward and back syncing with the document (windows users try SumatraPDF).</li>\012  <li><a href="https://tectonic-typesetting.github.io/en-US/">Tectonic</a> - LaTeX Builder - <a href="https://tectonic-typesetting.github.io/book/latest/installation/index.html">installation instructions</a>, or with homebrew: <code class="language-plaintext highlighter-rouge">brew install tectonic</code></li>\012</ul>\012\012<h1 id="document-structure">Document Structure</h1>\012\012<h2 id="new-tectonic-project">New Tectonic Project</h2>\012\012<p>Let’s make a document!</p>\012\012<p>Tectonic uses its own directory structure and a <code class="language-plaintext highlighter-rouge">Tectonic.toml</code> file to configure its builds. To create it, use <code class="language-plaintext highlighter-rouge">tectonic -X new &lt;document name&gt;</code>. For the sake of this example we’ll call ours <code class="language-plaintext highlighter-rouge">my_document</code>. After doing so, you should have a folder that looks like this:</p>\012\012<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>my_document/\012├── Tectonic.toml\012└── src\012    ├── _postamble.tex\012    ├── _preamble.tex\012    └── index.tex\012</code></pre></div></div>\012\012<p>By default, the <code class="language-plaintext highlighter-rouge">Tectonic.toml</code> file will look like this:</p>\012\012<div class="language-toml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[doc]</span>\012<span class="py">name</span> <span class="p">=</span> <span class="s">''my_document''</span>\012<span class="py">bundle</span> <span class="p">=</span> <span class="s">''https://data1.fullyjustified.net/tlextras-2020.0r0.tar''</span>\012\012<span class="nn">[[output]]</span>\012<span class="py">name</span> <span class="p">=</span> <span class="s">''default''</span>\012<span class="py">type</span> <span class="p">=</span> <span class="s">''pdf''</span>\012</code></pre></div></div>\012\012<p>First we’ll change our output document name, also calling it <code class="language-plaintext highlighter-rouge">my_document</code> rather than <code class="language-plaintext highlighter-rouge">default</code>. You can also change the name of each of the document subsections, <code class="language-plaintext highlighter-rouge">_preamble.tex</code>, <code class="language-plaintext highlighter-rouge">index.tex</code>, and <code class="language-plaintext highlighter-rouge">_postamble.tex</code> by setting them explicitly here. For example:</p>\012\012<div class="language-toml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[doc]</span>\012<span class="py">name</span> <span class="p">=</span> <span class="s">''my_document''</span>\012<span class="py">bundle</span> <span class="p">=</span> <span class="s">''https://data1.fullyjustified.net/tlextras-2020.0r0.tar''</span>\012\012<span class="nn">[[output]]</span>\012<span class="py">name</span> <span class="p">=</span> <span class="s">''my_document''</span>\012<span class="py">index</span> <span class="p">=</span> <span class="s">''my_document.tex''</span>\012<span class="py">type</span> <span class="p">=</span> <span class="s">''pdf''</span>\012</code></pre></div></div>\012\012<p>Then if we build the document with <code class="language-plaintext highlighter-rouge">tectonic -X build</code> then we’ll get something like this:</p>\012\012<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>my_document/\012├── Tectonic.toml\012├── build\012│   └── my_document\012│       └── my_document.pdf\012└── src\012    ├── _postamble.tex\012    ├── _preamble.tex\012    └── my_document.tex\012\012</code></pre></div></div>\012\012<h2 id="subsections">Subsections</h2>\012\012<p>Tectonic helps us out by splitting out the preamble and postamble of LaTeX documents, but the <code class="language-plaintext highlighter-rouge">index</code> file then contains the whole ass document which can get huge and unmanageable. Instead we can split our document into subsections and use the <code class="language-plaintext highlighter-rouge">\input</code> command to combine them.</p>\012\012<p>Let’s make the basic structure for our intro, results, and conclusion. We’ll also probably want to include some figures, so we can also make a directory for that too!</p>\012\012<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>../my_document/\012├── Tectonic.toml\012├── build\012│   └── my_document\012│       ├── my_document.log\012│       └── my_document.pdf\012└── src\012    ├── _postamble.tex\012    ├── _preamble.tex\012    ├── figures\012    │   ├── figure_1.png\012    │   └── figure_2.png\012    ├── my_document.tex\012    └── sections\012        ├── conclusion.tex\012        ├── intro.tex\012        └── results.tex\012</code></pre></div></div>\012\012<p>Since <code class="language-plaintext highlighter-rouge">\input</code> effectively copies and pastes the text directly, you can include your figures with <code class="language-plaintext highlighter-rouge">\includegraphics{figures/figure_1.png}</code> without needing to jump up and out of relative directories. You can also make additional layers of nesting for very long documents, prepend numbers to the filenames to keep them in order, etc. Whatever works for you!</p>\012\012<p>While we’re editing, to speed up navigation around multiple files, we can take advantage of Sublime Text’s <a href="https://docs.sublimetext.io/guide/usage/file-management/navigation.html#goto-anything">goto</a> features – <code class="language-plaintext highlighter-rouge">cmd+p</code> and then start typing a filename, and there are more syntax commands to jump to specific places in the document (see linked docs).</p>\012\012<h1 id="references--pdfs-with-zotero">References &amp; PDFs with Zotero</h1>\012\012<p>Let’s make our lit review easier and one-click add a reference and download a PDF with zotero.</p>\012\012<p>First we can make a new collection or subcollection for references within zotero, click the yellow folder icon in the top left of the window, or else right click in the library pane and click “New subcollection” within an existing collection.</p>\012\012<h2 id="grab-pdfs-from-sci-hub">Grab PDFs from Sci-Hub</h2>\012\012<p>Then we configure zotero to use Sci-Hub to automatically grab PDFs for papers if they can’t be found using its usual methods. Open the config editor: Zotero &gt; Preferences… &gt; Advanced &gt; Config Editor. Search for the <code class="language-plaintext highlighter-rouge">extensions.zotero.findPDFs.resolvers</code> configuration option, double click copy the following JSON configuration, and click OK:</p>\012\012<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">     \012  </span><span class="nl">"name"</span><span class="p">:</span><span class="s2">"Sci-Hub"</span><span class="p">,</span><span class="w">     \012  </span><span class="nl">"method"</span><span class="p">:</span><span class="s2">"GET"</span><span class="p">,</span><span class="w">     \012  </span><span class="nl">"url"</span><span class="p">:</span><span class="s2">"https://sci-hub.se/{doi}"</span><span class="p">,</span><span class="w">     \012  </span><span class="nl">"mode"</span><span class="p">:</span><span class="s2">"html"</span><span class="p">,</span><span class="w">     \012  </span><span class="nl">"selector"</span><span class="p">:</span><span class="s2">"#pdf"</span><span class="p">,</span><span class="w">     \012  </span><span class="nl">"attribute"</span><span class="p">:</span><span class="s2">"src"</span><span class="p">,</span><span class="w">     \012  </span><span class="nl">"automatic"</span><span class="p">:</span><span class="kc">true</span><span class="w"> \012</span><span class="p">}</span><span class="w">\012</span></code></pre></div></div>\012\012<p>If we have configured Zotfile (see documentation on the <a href="http://zotfile.com/">zotfile site</a>) to automatically grab new downloads, rename them, and add them to the citation, then when you click the zotero icon in your browser you should automatically get a PDF in a nice and tidy place!</p>\012\012<h2 id="better-bibtex---autoupdate-bibliographies">Better BibTex - Autoupdate bibliographies</h2>\012\012<p>Now let’s get our reference in our document!</p>\012\012<ul>\012  <li>Right click on the collection from within Zotero,</li>\012  <li>Click “Export Collection…”</li>\012  <li>Select “Better BibLaTeX”</li>\012  <li>Check “Keep updated”</li>\012  <li>and then export it to the <code class="language-plaintext highlighter-rouge">src</code> directory of our document.</li>\012</ul>\012\012<p>Within the <code class="language-plaintext highlighter-rouge">_preamble.tex</code>  we prepare our citation style, as well as do some other nice things like enabling backlinks from our references to the sections where they’re used.</p>\012\012<div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">\documentclass</span><span class="p">{</span>article<span class="p">}</span>\012<span class="k">\usepackage</span><span class="na">[usenames, svgnames]</span><span class="p">{</span>xcolor<span class="p">}</span>\012<span class="k">\usepackage</span>[\012  colorlinks = true,\012    hyperfootnotes=true,\012    urlcolor = DarkOrchid,\012    citecolor = DarkOrchid,\012    backref = section\012]<span class="p">{</span>hyperref<span class="p">}</span>\012<span class="k">\usepackage</span><span class="p">{</span>natbib<span class="p">}</span>\012<span class="k">\bibliographystyle</span><span class="p">{</span>plainnat<span class="p">}</span>\012\012<span class="k">\title</span><span class="p">{</span>My Document<span class="p">}</span>\012<span class="nt">\begin{document}</span>\012</code></pre></div></div>\012\012<p>And then our <code class="language-plaintext highlighter-rouge">my_document.tex</code> again:</p>\012\012<div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">\input</span><span class="p">{</span>sections/intro<span class="p">}</span>\012\012<span class="k">\input</span><span class="p">{</span>sections/results<span class="p">}</span>\012\012<span class="k">\input</span><span class="p">{</span>sections/conclusion<span class="p">}</span>\012\012<span class="k">\bibliography</span><span class="p">{</span>my<span class="p">_</span>document<span class="p">}</span>\012</code></pre></div></div>\012\012<p>Since Better BibLaTeX will auto-update our .bib file, Now we can get a reference, automatically get a PDF, automatically update our bibliography file for our paper, and then immediately cite something!</p>\012\012<h1 id="editing-with-sublime-text--latextools">Editing with Sublime Text &amp; LaTeXTools</h1>\012\012<p>When you’re working with sublime text, it’s useful to open the whole folder rather than individual files. You can also use a <code class="language-plaintext highlighter-rouge">sublime-project</code> file, which allegedly lets you set project-wide settings with LaTeXTools, but I’ve never gotten that to work. To do that you either use the File &gt; Open… command and open the folder, or else use from the cli <code class="language-plaintext highlighter-rouge">subl ./my_document</code>. This way, if you open the sidebar (default <code class="language-plaintext highlighter-rouge">cmd+shift+a</code>), you can see the whole document structure and group together files from a project within individual windows.</p>\012\012<h2 id="latextools-setup">LaTeXTools Setup</h2>\012\012<p>LaTeXTools is a lovely, unwieldy, and I think no longer maintained package, so we need to use it with care. Out of the box it will give you some useful completions and shortcuts, but we need to do a few things to make it work the way we want it.</p>\012\012<p>By default it should be configured to do forward and backwards sync with skim, but you need to do some additional setup for Skim to do the reverse seeking, follow the instructions in the <a href="https://latextools.readthedocs.io/en/latest/install/#installation">LaTeXTools Installation docs</a>.</p>\012\012<h3 id="headers">Headers</h3>\012\012<p>At the start of each of our subsections, we’ll need to an indication to LaTeXTools that it should consider the top-level <code class="language-plaintext highlighter-rouge">.tex</code> file as the document root – this lets it find the bibliography file for autocompletion, among other things.</p>\012\012<div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">%!TEX root = ../my_document.tex</span>\012</code></pre></div></div>\012\012<p>We also need to tell it that the resulting PDF of our tectonic build will be in a different place than the source directory. This only needs to happen once, in the main <code class="language-plaintext highlighter-rouge">my_document.tex</code> file</p>\012\012<div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">%!TEX jobname = my_document</span>\012<span class="c">%!TEX output_directory = ../build/my_document</span>\012</code></pre></div></div>\012\012<h3 id="script-build-on-save">Script Build on Save</h3>\012\012<p>To tell latextools that we want to build with Tectonic, we have to configure it to use a <code class="language-plaintext highlighter-rouge">script builder</code> rather than its usual combination of pdflatex et al.</p>\012\012<p>To edit the LaTeXTools settings, from sublime text go to Sublime Text &gt; Preferences… &gt; Package Settings &gt; LaTeXTools &gt; Settings - User. Change these configuration options (varying depending on your operating system:</p>\012\012<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">\012  </span><span class="nl">"builder"</span><span class="p">:</span><span class="w"> </span><span class="s2">"script"</span><span class="p">,</span><span class="w">\012  </span><span class="nl">"builder_settings"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">\012\012    </span><span class="err">//</span><span class="w"> </span><span class="err">General</span><span class="w"> </span><span class="err">settings:</span><span class="w">\012    </span><span class="err">//</span><span class="w"> </span><span class="err">See</span><span class="w"> </span><span class="err">README</span><span class="w"> </span><span class="err">or</span><span class="w"> </span><span class="err">third-party</span><span class="w"> </span><span class="err">documentation</span><span class="w">\012\012    </span><span class="err">//</span><span class="w"> </span><span class="err">(built-ins):</span><span class="w"> </span><span class="kc">true</span><span class="w"> </span><span class="err">shows</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">log</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">each</span><span class="w"> </span><span class="err">command</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">output</span><span class="w"> </span><span class="err">panel</span><span class="w">\012    </span><span class="nl">"display_log"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span><span class="w">\012    </span><span class="nl">"program"</span><span class="p">:</span><span class="w"> </span><span class="s2">"xelatex"</span><span class="p">,</span><span class="w">\012\012    </span><span class="err">//</span><span class="w"> </span><span class="err">Platform-specific</span><span class="w"> </span><span class="err">settings:</span><span class="w">\012    </span><span class="nl">"osx"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">\012      </span><span class="nl">"script_commands"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"echo $file; tectonic -X build --keep-logs"</span><span class="p">]</span><span class="w">\012    </span><span class="p">},</span><span class="w">\012\012    </span><span class="nl">"windows"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">\012      </span><span class="err">//</span><span class="w"> </span><span class="err">See</span><span class="w"> </span><span class="err">README</span><span class="w"> </span><span class="err">or</span><span class="w"> </span><span class="err">third-party</span><span class="w"> </span><span class="err">documentation</span><span class="w">\012    </span><span class="p">},</span><span class="w">\012\012    </span><span class="nl">"linux"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">\012      </span><span class="err">//</span><span class="w"> </span><span class="err">See</span><span class="w"> </span><span class="err">README</span><span class="w"> </span><span class="err">or</span><span class="w"> </span><span class="err">third-party</span><span class="w"> </span><span class="err">documentation</span><span class="w">\012    </span><span class="p">},</span><span class="w">\012  </span><span class="p">},</span><span class="w">\012</span><span class="p">}</span><span class="w">\012\012</span></code></pre></div></div>\012\012<p>We have do <code class="language-plaintext highlighter-rouge">echo $file;</code> before running tectonic because annoyingly if <code class="language-plaintext highlighter-rouge">$file</code> isn’t present in the script command, LaTeXTools just sticks it on the end of the command automatically.</p>\012\012<p>Then to automatically build the document every time we save, open the LaTeX-specific preferences at Sublime Text &gt; Preferences &gt; Settings - Syntax Specific (because we only want to do this for .tex files) and add:</p>\012\012<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">\012  </span><span class="nl">"on_post_save_async_language"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">\012    </span><span class="p">{</span><span class="w">\012        </span><span class="nl">"command"</span><span class="p">:</span><span class="w"> </span><span class="s2">"build"</span><span class="p">,</span><span class="w">\012        </span><span class="nl">"scope"</span><span class="p">:</span><span class="w"> </span><span class="s2">"window"</span><span class="w">\012    </span><span class="p">}</span><span class="w">\012  </span><span class="p">]</span><span class="w">\012</span><span class="p">}</span><span class="w">\012</span></code></pre></div></div>\012\012<p>See the <a href="https://packagecontrol.io/packages/Hooks">Hooks</a> docs for more information on the syntax.</p>\012\012<h2 id="synctex">SyncTeX</h2>\012\012<p>Synctex lets you jump back and forth from your source code to your document, taking you to the position in the rendered document where your cursor is in the source, or taking you to the point in the source where you clicked.</p>\012\012<p>To enable generating SyncTeX hooks for your document, put <code class="language-plaintext highlighter-rouge">\synctex=1</code> in your preamble, so:</p>\012\012<div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">\documentclass</span><span class="p">{</span>article<span class="p">}</span>\012<span class="k">\usepackage</span><span class="na">[usenames, svgnames]</span><span class="p">{</span>xcolor<span class="p">}</span>\012<span class="k">\usepackage</span>[\012  colorlinks = true,\012    hyperfootnotes=true,\012    urlcolor = DarkOrchid,\012    citecolor = DarkOrchid,\012    backref = section\012]<span class="p">{</span>hyperref<span class="p">}</span>\012<span class="k">\usepackage</span><span class="p">{</span>natbib<span class="p">}</span>\012<span class="k">\bibliographystyle</span><span class="p">{</span>plainnat<span class="p">}</span>\012\012<span class="k">\synctex</span>=1\012\012<span class="k">\title</span><span class="p">{</span>My Document<span class="p">}</span>\012<span class="nt">\begin{document}</span>\012</code></pre></div></div>\012\012<p>You’ll then see a <code class="language-plaintext highlighter-rouge">my_document.synctex.gz</code> file on next build.</p>\012\012<p>This should work out of the box with LaTeXTools, but there’s an obnoxious <a href="https://github.com/SublimeText/LaTeXTools/issues/1539">indentation bug</a> with an <a href="https://github.com/SublimeText/LaTeXTools/pull/1540">unmerged pull request</a> that we have to patch ourselves.</p>\012\012<p>Installed packages, on mac, are located at <code class="language-plaintext highlighter-rouge">/Users/&lt;username&gt;/Library/Application Support/Sublime Text 3/Packages</code>, or you can get there by opening up the preferences for any package and then using File &gt; Open which should dump you in the location of the preferences file (where the packages are).</p>\012\012<p>Within <code class="language-plaintext highlighter-rouge">LaTeXTools</code>, edit lines 101 and 103 to have correct indentation according to <a href="https://github.com/SublimeText/LaTeXTools/pull/1540/files">the PR</a></p>\012\012<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">file_name</span> <span class="o">=</span> <span class="n">view</span><span class="p">.</span><span class="n">file_name</span><span class="p">()</span>\012    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_tex_file</span><span class="p">(</span><span class="n">file_name</span><span class="p">):</span>\012      <span class="k">if</span> <span class="n">from_keybinding</span><span class="p">:</span>\012</code></pre></div></div>\012\012<ul>\012  <li>To jump <strong>source &gt; document</strong>: <code class="language-plaintext highlighter-rouge">cmd+l,j</code> (that’s do <code class="language-plaintext highlighter-rouge">cmd+l</code> to issue a <code class="language-plaintext highlighter-rouge">l</code>atextools command, and then afterwards press <code class="language-plaintext highlighter-rouge">j</code> for jump).</li>\012  <li>To jump <strong>document &gt; source</strong> (with Skim): <code class="language-plaintext highlighter-rouge">cmd+Shift+click</code> on the text you want to jump to the source of.</li>\012</ul>\012\012<h1 id="a-few-nice-to-haves">A few “Nice To Haves”</h1>\012\012<h2 id="hashed-document-version">Hashed Document Version</h2>\012\012<p>I version control my documents so that I don’t self-destruct, and like to use git tags to label different epochs of the draft. You can use git hooks to automatically dump the version of the document into a .tex file and then include it in your document.</p>\012\012<p>For example, in the <code class="language-plaintext highlighter-rouge">.git/hooks/post-commit</code> file, put:</p>\012\012<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/sh</span>\012git describe <span class="o">&gt;</span> proposal/src/git-version.tex\012</code></pre></div></div>\012\012<p>Then from your document, using the titling package:</p>\012\012<div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">\usepackage</span><span class="p">{</span>titling<span class="p">}</span>\012\012<span class="k">\postdate</span><span class="p">{</span> - Version: <span class="k">\texttt</span><span class="p">{</span> <span class="k">\input</span><span class="p">{</span> git-version.tex<span class="p">}</span> <span class="p">}</span> <span class="p">}</span>\012</code></pre></div></div>\012\012<p>Which yields something like this:</p>\012\012<p><img src="/blog/assets/images/document_version.png" alt="A block of text with a red line and the word &quot;TODO&quot; to the left of it" /></p>\012\012<h2 id="todo-environment">TODO environment</h2>\012\012<p>When I’m drafting, I like to leave notes to myself in-place, but to differentiate them from finished text I’ve made a few different environments to make different kind of notes stand out. One of them is a <code class="language-plaintext highlighter-rouge">todo</code> environment, which adds a red bar along the left of the text like this:</p>\012\012<p><img src="/blog/assets/images/todo_environment.png" alt="A block of text with a red line and the word &quot;TODO&quot; to the left of it" /></p>\012\012<p>Add this to your <code class="language-plaintext highlighter-rouge">_preamble.tex</code> (but really put it in its own file where you keep custom environments and then load it in your preamble)</p>\012\012<div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">\usepackage</span><span class="p">{</span>framed<span class="p">}</span>\012<span class="k">\usepackage</span><span class="p">{</span>rotating<span class="p">}</span>\012\012<span class="c">% todo leftbar</span>\012<span class="k">\newenvironment</span><span class="p">{</span>todo<span class="p">}{</span> <span class="c">%</span>\012<span class="k">\def\FrameCommand</span><span class="p">{</span><span class="k">\hspace</span><span class="p">{</span>-2em<span class="p">}</span><span class="c">%</span>\012<span class="nt">\begin{sideways}</span><span class="c">%</span>\012<span class="k">\textcolor</span><span class="p">{</span>red<span class="p">}{</span><span class="k">\textsf</span><span class="p">{</span><span class="k">\small</span> TODO<span class="p">}}</span><span class="c">%</span>\012<span class="nt">\end{sideways}</span><span class="c">%</span>\012<span class="k">\hspace</span><span class="p">{</span>0.5em<span class="p">}</span><span class="k">\textcolor</span><span class="p">{</span>red<span class="p">}{</span><span class="k">\vrule</span> width 0.5pt<span class="p">}</span> <span class="k">\hspace</span><span class="p">{</span>0.5em<span class="p">}}</span><span class="k">\MakeFramed</span> <span class="p">{</span><span class="k">\advance\hsize</span>-<span class="k">\width</span> <span class="k">\FrameRestore</span><span class="p">}}</span>\012<span class="p">{</span><span class="k">\endMakeFramed</span><span class="p">}</span>\012</code></pre></div></div>\012\012<p>Then you use it like</p>\012\012<div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">\begin{todo}</span>\012Hello i have this to do\012<span class="nt">\end{todo}</span>\012\012</code></pre></div></div>\012\012<h2 id="latextools-shortcuts">LaTeXTools shortcuts</h2>\012\012<p>LaTeXTools has a few useful <a href="https://latextools.readthedocs.io/en/latest/keybindings/">keybindings</a> that really help if you get used to them. One shortcut I like is <code class="language-plaintext highlighter-rouge">cmd+l, e</code> to create an environment from the current text, eg</p>\012\012<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>enumerate\012</code></pre></div></div>\012\012<p>becomes</p>\012\012<div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">\begin{enumerate}</span>\012\012<span class="nt">\end{enumerate}</span>\012</code></pre></div></div>','\012',char(10)),NULL,'','2022-04-16 07:00:00','Jonny Saunders blog','',NULL,'2024-01-03 18:04:29','read');
INSERT INTO items VALUES('https://jon-e.net/blog/2022/01/10/wordle/','What''s the Best First Guess in Wordle?',replace('<p>I was stuck at home and bored today, and saw <a href="https://twitter.com/qntm/status/1480152847522361345">@qntm’s</a> post showing that the list of words for each day in <a href="https://www.powerlanguage.co.uk/wordle/">wordle</a> is actually hardcoded in the source of the site, so I tried a few ways of estimating a best first word to play so that I would never have to bear the shame of failing to solve an online noncompetetive word puzzle again.</p>\n\n<p>Sorry this is such hell on mobile, I’m in the process of rebuilding my website and so this is a combination of ancient overengineering as well as being sorta a half-stitched together partially-transitioning website.</p>\n\n<h2 id="tldr-slate-or-canoe">tl;dr slate or canoe</h2>\n\n<p><em>(depending on how you measure it.)</em></p>\n\n<p>A few companion files:</p>\n\n<ul>\n  <li><a href="/blog/assets/hosted/global_entropy.pck.xz"><code class="language-plaintext highlighter-rouge">global_entropy.pck.xz</code></a> - to save you some time on a lengthy calculation</li>\n  <li><a href="/blog/assets/hosted/global_entropy.pck.xz"><code class="language-plaintext highlighter-rouge">wordle_helpers.py</code></a> - all the code is in this page, but thought i’d include a few of the helper functions that had to be offloaded to a separate file to deal with jupyter notebook’s incompatibiltiy with multiprocessing.</li>\n  <li><a href="/blog/assets/hosted/wordle_words.json"><code class="language-plaintext highlighter-rouge">wordle_words.json</code></a> - the words used in wordle, both lists used for target words as well as all allowable guess words.</li>\n</ul>\n\n<div class="jupyter-notebook" style="position: relative; width: calc(100% + 50px); left: -25px; margin: 0px auto; padding-bottom: 5000px;"><div class="jupyter-notebook-iframe-container" style="padding-bottom: 4990px;"> </div>\n<iframe src="../../../../assets/notebooks/2022-01-10-wordle-notebook.html" style="position: absolute; top: 0; left: 0; border-style: none;" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + ''px''" width="100%" height="100%"></iframe></div>','\n',char(10)),NULL,'','2022-01-10 08:00:00','Jonny Saunders blog','',NULL,'2024-01-03 18:04:29','read');
INSERT INTO items VALUES('https://jon-e.net/blog/2021/10/14/Oregon-Public-Records/','Public Records in Oregon',replace('<p>Writing down a bit of what I’ve learned about getting public records for a skillshare. This’ll focus mostly on Oregon, but most states have similar public records laws modeled off FOIA :). A lot of this comes from the <a href="https://cldc.org/">CLDC’s</a> public records and FOIA workshops, plus a lil sleuthing of my own. Note that I am <strong>not a lawyer</strong> and <strong>none of this information should be considered legal advice or even definitive.</strong></p>\n\n<h1 id="public-records--foia">Public Records &amp; FOIA</h1>\n\n<p>Public records are the state version of FOIA, which allow anyone to request information about the operation of public entities. Public records laws are modeled after FOIA, although each state has subtle statutory and judicial differences.</p>\n\n<p>In Oregon, public records are governed by <a href="https://oregon.public.law/statutes/ors_chapter_192">ORS 192</a>, which defines a “Public Record” broadly as:</p>\n\n<blockquote>\n  <p><a href="https://oregon.public.law/statutes/ors_192.311">ORS 192.311(5)(a)</a>: “Public record” includes any writing that contains information relating to the conduct of the public’s business, including but not limited to court records, mortgages, and deed records, prepared, owned, used or retained by a public body regardless of physical form or characteristics.</p>\n\n  <p><a href="https://oregon.public.law/statutes/ors_192.311">ORS 192.311(5)(b)</a>: “Public record” does not include any writing that does not relate to the conduct of the public’s business and that is contained on a privately owned computer.</p>\n</blockquote>\n\n<p>“Writing” is similarly broadly defined:</p>\n\n<blockquote>\n  <p><a href="https://oregon.public.law/statutes/ors_192.311">ORS 192.311(7)</a>: “Writing” means handwriting, typewriting, printing, photographing and every means of recording, including letters, words, pictures, sounds, or symbols, or combination thereof, and all papers, maps, files, facsimiles or electronic recordings.</p>\n</blockquote>\n\n<p>So the law is constructed to start from assuming effectively <em>all</em> records should be able to be requested, and then carving out specific exemptions for those that aren’t (rather than listing specific records that <em>are</em> covered).</p>\n\n<p>You can do it too! Anyone can file a request, and so you can find your way to getting fun documents like:</p>\n\n<p><img src="/blog/assets/images/phil_schill.png" alt="The President of UOregon, Mike Schill, expresses his undying love for Phil Knight" /></p>\n\n<h2 id="history-of-foia">History of FOIA</h2>\n\n<p>FOIA is codified in <a href="https://www.law.cornell.edu/uscode/text/5/552">5 USC § 552</a>, and it requires federal agencies of the executive branch to disclose their records.</p>\n\n<p>FOIA was proposed in 1955 by John Moss, who was elected in 1953 by a thin margin after accusations that he was a <a href="https://unredacted.com/2018/04/17/john-moss-and-the-roots-of-the-freedom-of-information-act-worldwide-implications/">communist or communist sympathizer</a>. In 1947, Truman had signed <a href="https://en.wikipedia.org/wiki/Executive_Order_9835">Executive Order 9835</a> which established the “Loyalty Program” to investigate communist activity in the government:</p>\n\n<blockquote>\n  <p>Based on the results of these investigations, the targets could be fired from their government jobs, prosecuted, and made virtually unemployable. They faced public condemnation and personal humiliation in the process. People investigated under the Loyalty Program were not allowed to confront their accusers or see the charges against them, often based on hearsay evidence that was held in secret files compiled by the Federal Bureau of Investigation. (<a href="https://unredacted.com/2018/04/17/john-moss-and-the-roots-of-the-freedom-of-information-act-worldwide-implications/">unredacted</a>)</p>\n</blockquote>\n\n<p>After much pushback (and support from oddly enough Donald Rumsfeld and eventually even Joseph McCarthy others) a bill similar to Moss’s initial proposal was passed in 1965. The bill went to LBJ’s desk where it languished for awhile, just up until the July 4th deadline:</p>\n\n<p><img src="/blog/assets/images/oregonian_foia.png" alt="Letter from the Oregonian urging LBJ to pass FOIA " /></p>\n\n<p>But after a veto threat, LBJ signed it, his press secretary Bill Moyers <a href="http://www.pbs.org/now/commentary/moyers4.html">later</a> said:</p>\n\n<blockquote>\n  <p>LBJ had to be dragged kicking and screaming to the signing ceremony. [Johnson] hated . . . of journalists rummaging in government closets; hated them challenging the official view of reality. He dug in his heels and even threatened to pocket veto the bill after it reached the White House. Only the courage and political skill of a Congressman named John Moss got the bill passed at all, and that was after a twelve-year battle against his elders in Congress who blinked every time the sun shined in the dark corridors of power. They managed to cripple the bill Moss had drafted. And even then, only some lastminute calls to LBJ from a handful of newspaper editors overcame the President’s reluctance; he signed . . . [the f—ing thing] as he called it . . . and then went out to claim credit for it. So the Freedom of Information Act became law.</p>\n</blockquote>\n\n<p>In his signing statement, LBJ described the purpose of the bill (taking credit for it):</p>\n\n<p><img src="/blog/assets/images/lbj_foia_statement.png" alt="LBJ FOIA statement, important part being &quot;I have always believed that freedom of information is so vital that only the national security, not the desire of public officials or private citizens, should determine when it is restricted ... I am instructing every official in this Administration to cooperate to this end and to make information available to the full extent consistent with individual privacy and with the national interest&quot;" /></p>\n\n<p>Since then federal courts have both chipped away at and reinforced the strength of the bill, but its purpose, to ensure records that allow the public to understand the operation of their government, animates the process:</p>\n\n<blockquote>\n  <p>It has often been observed that the central purpose of the FOIA is to “open up the workings of government to public scrutiny.” One of the premises of that objective is the belief that “an informed electorate is vital to the proper operation of a democracy.” <strong>A more specific goal implicit in the foregoing principles is to give citizens access to the information on the basis of which government agencies make their decisions, thereby equipping the populace to evaluate and criticize those decisions.</strong> Each of these objectives — and particularly the last — would be best promoted by a rule that all records in an agency’s possession, whether created by the agency itself or by other bodies covered by the Act, constitute “agency records.”</p>\n\n  <p><a href="https://casetext.com/case/mcgehee-v-cia">McGehee v CIA 697 F.2d 1095 (D.C. Cir. 1983)</a></p>\n</blockquote>\n\n<h1 id="exemptions">Exemptions</h1>\n\n<p>There are 7 broad categories of Exemptions in FOIA, and Oregon extends them with a relatively large number of additional categories.</p>\n\n<h2 id="foia-exemptions">FOIA Exemptions</h2>\n\n<p>FOIA exemptions are illustrative of the kinds of records that are also typically exempt in Public Records, though again they are different!</p>\n\n<ol>\n  <li><strong>National Security</strong> - documents that are confidential, secret, or top secret. Originally made in <a href="https://www.justice.gov/oip/blog/foia-update-executive-order-12958-classified-national-security-information">Executive Order 12958</a> and later updated with <a href="https://www.archives.gov/isoo/policy-documents/cnsi-eo.html">EO 13526</a> that added additional limits on what kinds of documents could be classified.</li>\n  <li><strong>Internal Personnel Rules</strong> - HR rules and practices, etc. But can get around by arguing it’s in the public interest to know</li>\n  <li><strong>The Exemption Exemption</strong> - if stuff is specifically exempt by other laws, then it’s exempt</li>\n  <li><strong>Trade Secrets</strong> - Information that could harm a businessssss like proprietary information.</li>\n  <li><strong>Deliberative Process</strong> - internal communications within/between agencies that lead to decisions. Stuff like memos. More protective of personal opinions than official agency positions and communication.</li>\n  <li><strong>Personnel and Medical Files</strong> - you can’t request someone’s social security number and stuff</li>\n  <li><strong>Law Enforcement</strong> - Records compiled for law enforcement purposes that\n    <ol>\n      <li>would interfere with enforcement proceedings</li>\n      <li>would deprive someone of right to fair trial</li>\n      <li>disclose identities of confidential sources</li>\n      <li>disclose techniques and procedures for law enforcement investigations</li>\n      <li>endanger life or physical safety</li>\n    </ol>\n  </li>\n  <li><strong>Documents for Financial Institutions</strong> - rare</li>\n  <li><strong>Geological and GIS Data</strong> - like maps, rare.</li>\n</ol>\n\n<p>All these exemptions are weighed against the public interest, though some (like national security) are effectively blanket exemptions.</p>\n\n<h2 id="public-records-exemptions">Public Records Exemptions</h2>\n\n<p>Oregon makes a list of its exemptions available here: <a href="https://justice.oregon.gov/PublicRecordsExemptions/">https://justice.oregon.gov/PublicRecordsExemptions/</a></p>\n\n<p>There are two categories of exemptions in Oregon, “Conditional” exemptions that depend on “whether the public interest requires disclosure in the particular instance,” codified in <a href="https://oregon.public.law/statutes/ors_192.345">ORS 192.345</a>, and “unconditional” exemptions that are always exempt, codified in <a href="https://casetext.com/statute/oregon-revised-statutes/title-19-miscellaneous-matters-related-to-government-and-public-affairs/chapter-192-records-public-reports-and-meetings/records-and-reports-in-english/section-192355-public-records-exempt-from-disclosure">ORS 192.355</a></p>\n\n<p>There are way too many to list, so just go to those pages and search around!</p>\n\n<h1 id="making-a-request">Making a Request</h1>\n\n<p>So it’s time to actually do one of these, eh?</p>\n\n<h2 id="finding-the-records">Finding The Records</h2>\n\n<p>First, you have to know what you want. The most effective requests are for specific, named or numbered documents, but you can describe anything you want and there are standards for how interpretable your request can be. More information about that will come next.</p>\n\n<ol>\n  <li><strong>See if it’s already been released</strong> - check <a href="https://www.muckrock.com/">MuckRock</a> and the other information sources listed in the <a href="#oregon-records-sources">Oregon Records Sources</a></li>\n  <li><strong>Check Records Retention Schedules</strong> - Go shopping! The Oregon Secretary of State maintains <a href="https://secure.sos.state.or.us/oard/displayChapterRules.action?selectedChapter=175">a list</a> of documents and information that various agencies are required to keep and for how long. The agencies are legally required to have this information ready to go, so they can’t give you a <a href="https://en.wikipedia.org/wiki/Glomar_response">Glomar</a> or pretend like they don’t have them, and the case for a low fee is easier to make. For example\n    <ul>\n      <li><a href="https://secure.sos.state.or.us/oard/viewSingleRule.action?ruleVrsnRsn=26067">OAR 166-150-0135</a> - Law Enforcement</li>\n      <li><a href="https://secure.sos.state.or.us/oard/viewSingleRule.action?ruleVrsnRsn=26071">OAR 166-150-0145</a> - 9-1-1</li>\n      <li><a href="https://secure.sos.state.or.us/oard/displayDivisionRules.action?selectedDivision=613">OAR 166-475-0005</a> - Oregon University System</li>\n      <li><a href="https://secure.sos.state.or.us/oard/viewSingleRule.action?ruleVrsnRsn=26075">OAR 166-150-0165</a> - County Planning</li>\n    </ul>\n  </li>\n  <li>Look for writing or public communication that references some particular piece of information. Eg. if a public official mentions that “according to our internal research…” then you have grounds to request the research!</li>\n  <li>Just describe it! Don’t be shy! shoot off a quick public records request that just says “hello i would like to have the contract between x and y” or “would like to have x person’s emails from y to z date!”</li>\n</ol>\n\n<h2 id="writing-the-request">Writing the Request</h2>\n\n<p>Your request will have a few components, you want to tailor it to sail through the process (described below) so you need to be reasonably strategic (described further below).</p>\n\n<p>What do you want? You have to strike a balance between generality (so you get <em>everything</em> you want) and specificity (so they don’t ask <em>infinity dollars</em> for it). The guidelines for what constitutes a “reasonable description” of public records are pretty vague, but some guardrails have been given by the courts. Again, FOIA and public records laws are supposed to be written to favor document release, and the courts seem pretty fine with the argument “cmon, you know what they’re talking about”:</p>\n\n<blockquote>\n  <p>“agency is able to determine precisely what records are being requested”</p>\n\n  <p><a href="https://casetext.com/case/yeager-v-drug-enforcement-administration">(Yeager v. Drug Enforcement Admin 678 F2d 315, 326 (Dc Cir 1982))</a></p>\n</blockquote>\n\n<blockquote>\n  <p>A request must “be sufficient . . . to enable a professional employee of the agency who was familiar with the subject area of the request to locate the record with a reasonable amount of effort.”</p>\n\n  <p><a href="https://nsarchive2.gwu.edu/nsa/foialeghistory/H.R.%20Rep.%20No.%2093-876%20(Mar.%205,%201974).pdf">H.R. Rept. No. 93-876, 93d Cong. 2d Sess. (1974) at 6.</a></p>\n</blockquote>\n\n<p>The language here can be tricky, so you want to be as specific as you can be. For example if you are asking for all emails between two people in which they are talking about a specific event, you should use a word like “mention,” and ideally give them a list of words, rather than “refer,” “relate to,” or “concern” because there isn’t a bright line around what it means to be “related to” a particular object. Think about how the records custodian is going to search for the records, and try and mirror that. eg. “I would like to request all emails from <code class="language-plaintext highlighter-rouge">&lt;person&gt;</code> that contain any of the following words: <code class="language-plaintext highlighter-rouge">&lt;word 1&gt;</code>, <code class="language-plaintext highlighter-rouge">&lt;word 2&gt;</code>, …”</p>\n\n<p>To constrain your search, particularly for emails or other documents that are produced continuously, specify a date range. If you aren’t sure about what dates exactly would be relevant, try requesting a narrow range near the end of the period you’re concerned with and ask for all previous messages in the email chain to also be included.</p>\n\n<p>Constrain your search, but also make sure you request all parts of what you are interested in, for example contracts often have supplementary documents or appendices, so you should make sure to request “and all referenced documents” or something similar. When requesting emails, request attachments and replies. The public records officer will probably want to give you as little as they can while still being responsive to the request.</p>\n\n<p>You can request that the documents be returned in a specific format,</p>\n\n<p>Make sure you request a fee waiver (described further in <a href="#strategy-tips">strategy tips</a>), or else make your request with a journalist or something like Muckrock which will make it more likely to have your waiver approved.</p>\n\n<p>Identify the responsive agency — sometimes that might be clear, but otherwise every agency will have to list some records custodian that you usually can find with a quick google. For example, public records requests for the University of Oregon to go <code class="language-plaintext highlighter-rouge">pubrec@uoregon.edu</code>. Refer to public records retention schedules which will list what agencies will have which information if in doubt.</p>\n\n<p>Send it off! Email is good, if you need to submit by mail, consider certified, though certified mail can be rejected which is bad.</p>\n\n<p>An example can be as simple as</p>\n\n<blockquote>\n  <p>Hello,</p>\n\n  <p>I would like to request any contracts the University of Oregon or any of its subsidiary organizations have entered into that agree to provide rooms in UO residence halls during the international track and field championship. The Register Guard has <a href="https://www.registerguard.com/news/20191215/housing-owner-withdraws-2021-beds-over-oregon-rent-control-emails-show">previously reported</a> that UO agreed to provide “4,145 [beds] from new and rennovated dorm rooms” as part of its bid.</p>\n\n  <p>I would like to request a complete fee waiver, as information about the financial arrangements worth hundreds of millions of dollars between public universities and outside agencies is eminently in the public interest.</p>\n\n  <p>xoxo</p>\n</blockquote>\n\n<h2 id="request-process">Request Process</h2>\n\n<p>Once you submit your request…</p>\n\n<ol>\n  <li>The records custodian will <strong>acknowledge</strong> your request, and will give you a determination whether or not they can fill your request and how much it costs. If you’re lucky, you will just get the records right off! In Oregon, the custodian must acknowledge receipt of your request within <strong>5 business days</strong>.</li>\n  <li>After acknowledgement FOIA requests have a <strong>20 day</strong> window to <strong>respond</strong> to your request, and every response “tolls” that 20 day period. In Oregon, they have <em>no more than</em> <strong>15 business days</strong> after receiving the request to complete it. They additionally are supposed to complete requests “as soon as possible and without unreasonable delay,” so theoretically you are allowed to skip straight to an appeal if they drag out a really straightforward request, but I have never had luck with getting records faster this way.</li>\n  <li>If they respond with a fee estimate, the deadline is <em>suspended</em> until the fee has been paid or waived. Denial of a fee waiver, since you should generally get them unless the records don’t have a compelling public interest, is typically a shortcut to litigation — “sue us we dare you.”</li>\n  <li>\n    <p>If they <strong>miss the deadline or refuse your fee waiver,</strong> file an <a href="https://www.doj.state.or.us/oregon-department-of-justice/public-records/appeal-a-state-agency-public-records-denial/">administrative appeal</a> to the Attorney General. The form is <a href="https://www.doj.state.or.us/oregon-department-of-justice/public-records/petition-for-public-records-order/">here</a>. CLDC says “do them they work,” if you file an appeal you will likely have it approved.</p>\n\n    <p>Other reasons to appeal include:</p>\n\n    <ul>\n      <li>inadequate search for records</li>\n      <li>improper withholding (they aren’t supposed to withhold a document if even one line is pertinent to the search)</li>\n      <li>improper redaction</li>\n    </ul>\n  </li>\n  <li>If your document comes back <strong>heavily redacted,</strong> request that the redactions are itemized, citing the specific exemptions that justify them. That gives you a better sense of how to appeal and also might give you some information about what they are.</li>\n  <li>If you get a <strong>“Glomar Response”</strong> that refuses to confirm or deny the existence of responsive documents (as opposed to an affirmation that they do not have the documents), see if the records have been acknowledged officially elsewhere in any speeches or documents. Leaks don’t always count as official acknowledgement. If documents are known to be publicly available (eg. if a newspaper has written that it has received them) they can’t be withheld.</li>\n  <li>If your <strong>administrative appeal</strong> fails, then you have to litigate! I have never been here before, but you need to have <em>standing,</em> which means demonstrating some injury, file a lawsuit in the appropriate juristiction/venue (where the requestor lives, where the records are, or Washington DC for some federal agencies), and ask for a specific remedy — or what you want the court to do. You can ask for a <a href="https://foia.wiki/wiki/Preliminary_Injunctions">preliminary injunction</a> to expedite your request if you are likely to prevail in winning the appeal, whether you will be irreparably harmed without the injunction (eg. if you need some records before a certain date), and whether the public will benefit from the injunction. A Permanent injunction asks for the records themselves to be turned over immediately.</li>\n</ol>\n\n<h2 id="strategy-tips">Strategy Tips</h2>\n\n<ol>\n  <li>Always request a fee waiver - you should get a partial or full fee waiver if doing so “is in the public interest because making the record available primarily benefits the general public.” This is weighed against your ability to distribute the records/likelihood that you will, so working with a journalist or Muckrock is a good idea here. Otherwise you can just say “i plan to publish these records and write about them in the paper” or something like that.</li>\n  <li>If an agency fails to abide by the timelines set out by FOIA or public records laws, <em>the agency may have waived its right to collect fees from you</em> and you can specify that in the administrative appeal.</li>\n  <li>Make your request cheap - the primary determinant of cost (aside from caprice) is the labor time it would take to prepare the request. Doing requests that can be done with a computer, don’t need manual curation like reading a bunch of documents to see what is relevant, or don’t need a bunch of redactions will all be cheaper.</li>\n  <li>Do it iteratively! get summaries first and then expand later. Spiderweb through documents, rather than getting held up by a $500 request, narrow it and use the first request to target subsequent requests.</li>\n  <li>If you’re requesting something that will need heavy redaction (eg. be expensive), request some summary of the documents first that wouldn’t so you know where to target further. Eg. request a summary of the number of emails sent between a set of email addresses in a certain date range, request only the subject lines, and so on. This is especially useful for police records because those always come back maximally redacted. Getting a summary also gives you a point of reference for future requests: if they say there were 87 use of force incidents, there better be 87 when you request them.</li>\n  <li>If you need to salami-slice a request, do it iteratively or from different email addresses spaced out over time. In my experience records custodians hate getting 50 records requests for the same thing in an attempt to get them cheaper.</li>\n  <li>You don’t need to identify yourself to make a public records request! Since anyone can do it, there’s no need to verify anything, so go ahead and use an anonymous email address – though you are less likely to get a fee waiver this way since there’s no way they can estimate how likely you are to disseminate the records.</li>\n</ol>\n\n<h1 id="resources">Resources</h1>\n\n<h2 id="general">General</h2>\n\n<ul>\n  <li><a href="/blog/assets/hosted/FOIA-Workshop-Handouts.pdf">CLDC FOIA Workshop Handout</a></li>\n  <li><a href="/blog/assets/hosted/OregonPublicRecordLaw.pdf">Guide to Oregon Public Records</a></li>\n  <li><a href="https://www.doj.state.or.us/oregon-department-of-justice/public-records/attorney-generals-public-records-and-meetings-manual/">Oregon Attorney General Public Records Manual</a></li>\n  <li><a href="https://justice.oregon.gov/PublicRecordsExemptions/">Oregon Records Exemptions</a></li>\n  <li><a href="https://secure.sos.state.or.us/oard/displayChapterRules.action?selectedChapter=175">Oregon Records Retention Schedules</a></li>\n  <li><a href="https://www.muckrock.com/">Muckrock</a> - search for records, file a request, submit what ya get!</li>\n  <li><a href="http://foiaproject.org/">FOIA Project</a></li>\n  <li><a href="https://nsarchive.gwu.edu/">National Security Archive</a></li>\n  <li><a href="https://foia.wiki/wiki/Main_Page">FOIA.wiki</a></li>\n  <li>Not really public records or FOIA, but a lot of government data is on <a href="https://www.data.gov/">data.gov</a></li>\n  <li><a href="https://projects.propublica.org/nonprofits/">Nonprofit 990 Forms</a> - eg. the <a href="https://projects.propublica.org/nonprofits/organizations/936015767">UO Foundation</a></li>\n</ul>\n\n<h2 id="oregon--uo-records-sources">Oregon &amp; UO Records Sources</h2>\n\n<p>Skip the request! Lots of public information is already available! Many of these are specific to my area, but they give you an idea of what kind of records repositories are out there</p>\n\n<ul>\n  <li>Oregon Secretary of State records <a href="http://records.sos.state.or.us/ORSOSWebDrawer/Search">(ORMS)</a> - lots of meeting minutes, legislative text, etc.</li>\n  <li>Oregon <a href="https://sos.oregon.gov/business/pages/find.aspx">Business Records</a></li>\n  <li>Oregon <a href="https://justice.oregon.gov/charities">Charities/Nonprofits</a></li>\n  <li>Oregon DPSST training records <a href="https://www.bpl-orsnapshot.net/PublicInquiry_CJ/EmployeeSearch.aspx">(IRIS)</a></li>\n  <li>IRS <a href="https://www.irs.gov/charities-non-profits/tax-exempt-organization-search">Nonprofit Search</a></li>\n  <li>Lane County <a href="https://lanecounty.hosted.civiclive.com/cms/One.aspx?portalId=3585881&amp;pageId=5145461">Property information search</a></li>\n  <li>Lane County <a href="https://www.rlid.org/index.cfm">regional land information database</a></li>\n  <li>Lane County <a href="https://lcmaps.lanecounty.org/LaneCountyMaps/SIDOMapsApp/index.html">Survey maps (SIDO)</a></li>\n  <li>Lane County <a href="http://apps.lanecounty.org/LMDPro/">Lane records and building permits</a></li>\n  <li>Eugene <a href="https://pdd.eugene-or.gov/buildingpermits/permitsearch">Permits</a></li>\n  <li>Eugene <a href="https://coeapps.eugene-or.gov/ruralfirecad">Fire and EMS CAD Calls</a></li>\n  <li>EPD <a href="https://coeapps.eugene-or.gov/epddispatchlog">Dispatch Log</a></li>\n  <li><a href="https://uomatters.com">uomatters</a> - Bill Harbaugh’s huge stash of history and records of UO malfeasance.</li>\n  <li><a href="https://ir.uoregon.edu/salary">UO Salary Records</a>, .csv versions here: <a href="https://github.com/sneakers-the-rat/uoregon_salary_data">https://github.com/sneakers-the-rat/uoregon_salary_data</a></li>\n  <li><a href="https://ir.uoregon.edu/">UO Internal Research</a></li>\n  <li><a href="https://brp.uoregon.edu/content/Budget-Reports">UO Budgets</a></li>\n  <li><a href="https://lists.uoregon.edu/mailman/listinfo">UO Mailing Lists Archive</a> - (try searching <code class="language-plaintext highlighter-rouge">site:https://lists.uoregon.edu/mailman/listinfo</code> )</li>\n</ul>\n\n<p>and bonus</p>\n\n<ul>\n  <li><a href="https://jon-e.net/projects/records">a selection of records i’ve gathered</a></li>\n</ul>','\n',char(10)),NULL,'','2021-10-14 07:00:00','Jonny Saunders blog','',NULL,'2024-01-03 18:04:29','read');
INSERT INTO items VALUES('https://jon-e.net/blog/2021/03/01/Systems-Neuro-Infrastructure/','Building the Basic Infrastructure That a Layperson Would Expect Systems Neuroscientists to Have Would Revolutionize the Discipline: A Vision for ONICE',replace('<div style="background-color:#ffcccc;padding:20px;border:1px red solid;"><h1>Note:</h1> This was something I wrote hastily a long time ago, and my thinking has *dramatically changed* since this was written (read: i think most of this is wrong or at least too coy to be useful). I am keeping it around for historical reasons, to remind myself of growth. A fuller manuscript is forthcoming :) -jonny 21-10-14</div>\n\n<h1 id="we-would-run-a-factory-into-the-ground">We Would Run A Factory Into The Ground</h1>\n\n<h2 id="neuroscientists-probably-have-servers-right">“Neuroscientists Probably Have Servers, Right?”</h2>\n\n<p>Say, to a crude approximation, scientists are workers who produce “knowledge.” Backing hastily away from the scare quotes, seeing the seething oceans of quote tweets which it may spawn, we might say instead, at least for systems neuroscientists, that we are workers who produce and interpret data. Taking one step into the countryside for the purpose of metaphor, we might further say we shepherd data from its wily naked unobservedness in the Real onto scihub.</p>\n\n<p>As a layperson with a probably cartoonish image of the infrastructure I would expect a worker in a factory would have for managing their product, I imagine they would have some system of indexing it so that none of it is lost, it’s stored in a standardized warehousing system with standardized packaging, and they provide some access point for workers at other factories to query and request what they have so that they can… you know sell their product… at the risk of thinning the metaphor beyond recognition. If they need to figure out how to do something new, they likely have some manual they can turn to.</p>\n\n<p>Literally where is your data? What format is it in? How did you collect it? What would you have to do to share it with someone?</p>\n\n<p>I imagine a nonscientist (if prompted to consider such an arcane question) would expect scientists to have something similar: their data is collected by some standardized set of tools, is stored in some standardized format, on some server accessible to them and their other labmates and perhaps able to be made available to other collaborators who may want to use their data. They might suspect that there is some standard design for T-mazes or otherwise some way to look up how to build something, program something, etc.</p>\n\n<h2 id="wait-what-they-dont-and-the-dereliction-of-scientific-stewardship">“Wait What? They Don’t?” and the Dereliction of Scientific Stewardship</h2>\n\n<p>Anyone familiar with the reality of systems neuroscience knows what dissapointment they should prepare their nonscientist friend for. The problems with this reality are much greater than a sort of embarassed chuckle and “we’ll get a grad student to clean the data” would suggest. Instead they are reflective of</p>\n\n<ul>\n  <li>A prodigious duplication and dead-weight loss of labor as each lab, and sometimes each person within each lab, will reinvent basic code, tools, and practices from scratch</li>\n  <li>A profoundly leaky knowledge acquisition system where entire PhDs worth of data can be lost and rendered useless when a student leaves a lab and no one remembers how to access the data or how it’s formatted.</li>\n  <li>The need to constantly peer at the brain through the pinprickiest peephole of just the most recent data you or your lab have collected rather than being able to index across all relevant data from not only your lab, but all other labs that have measured the same phenomena</li>\n  <li>The dearth of data transparency where it is still in the year of our lord 2021 rare for systems neuro papers to publish the full, raw data along with all the analysis code because the data <em>and</em> analysis code are both completely homebrew and often omitted just due to the labor of cleaning it or the embarassment of sharing it (not kidding).</li>\n  <li>The inevitability of a replication crisis because it is often literally impossible to replicate an experiment that is done on a rig that was built one time, used entirely in-lab code, and was never documented</li>\n  <li>An insular system where the inaccessibility of all the “meso” level knowledge that is beneath the level of publication but necessary to perform experiments, like “how to build this apparatus,” “what kind of motor would work here,” etc. is a force that favors established and well-funded labs who can rely on local knowledege and hiring engineers/etc. and excludes new, lesser-funded labs at non-ivy institutions.</li>\n</ul>\n\n<p>Considered separately, these are problems, but together they are a damning indictment of our role as stewards of our corner of the human knowledge project.</p>\n\n<p>We arrive at this situation not because systems neuroscientists are lazy and stupid, but because the appropriate tools that fit the requirements of their discipline don’t exist. If your reaction to reading the above section was to start listing in your head all the reasons why overcoming these problems is hard: that’s because it is, but it doesn’t have to be.</p>\n\n<p>Imagine for a moment the utopia of having solved all of these problems: you have some new research question, and so you turn to the standard Python (or whatever) library that allows you to query data from yours and all other labs who share their data with this system. You’re immediately able to filter through to find all the recordings from a particular subtype of cell in a particular region being exposed to some particular set of stimuli across some particular manipulation. Since you have access to decades of labor by thousands of scientists, even with that complex filter you still find, say for the sake of drama, a million recordings. Because they’re all in some standardized format, over the years a common analysis pipeline has been developed, so you’re also immediately able to perform the analyses to confirm the hunch for your new question, so it’s time to implement it. You don’t need to implement the whole thing from scratch because you can check out a similar experiment from the centralized library of task code, make the minor tweaks you need for your experiment, read the communally maintained build documentation, and you’re off and running. After your experiment, the data you produce is also in this same standardized format, so you plug it back into the global knowledge pool, do a pull request for the improvements you’ve made to the experimental software, and the loop is complete: a closed knowledge system.</p>\n\n<p>Sorta like scientific permaculture I guess.</p>\n\n<p>The way forward is, yes, a technical problem, but the equally important problem is that of <em>design.</em> In order for movement to be made, it needs to be <em>easier than not to do good science.</em> So the tools that need to be made are those that conform to the needs of systems neuroscientists, and using them needs to provide some substantial benefit over the system they are using already.</p>\n\n<p>I think that the problems are less insurmountable than they appear, and with a combination of software, protocol, and infrastructure development, ONICE could make ION a test case in how the next generation of neuroscience should work. We can and should aim higher than informally sharing methods and resources, and instead should attempt to build that infrastructure and develop an experimental framework for labs that lets us all contribute to and share in the benefit of each other’s labor.</p>\n\n<h1 id="the-peculiar-habits-of-systems-neuroscientists">The Peculiar Habits of Systems Neuroscientists…</h1>\n\n<p>Every discipline has its own particular technical needs, and is subject to its own peculiar history and culture. Why has systems neuroscience failed to produce the kind of shared infrastructure present in immediately adjacent disciplines? I won’t attempt a complete explanation, but instead will offer a few patterns I have noticed in my own limited exposure to the field.</p>\n\n<p><strong>Diversity of Preps</strong> — Though there are certain well-limbered experimental backbones like the two-alternative forced choice task, even within them there seems to be a comparatively broad diversity of experimental preparations in systems neuro relative to adjacent fields. Even a visual two-alternative forced choice task is substantially different than an auditory one, but there is almost nothing shared between those and, for example, <a href="https://doi.org/10.7554/eLife.29053">measuring the representation of 3d space in a free-flying echolocating bat</a>. So unlike cognitive neuroscience and psychophysics that has tools like <a href="https://pavlovia.org/">pavlovia</a> where the basic requirements and structure of experiments are more standardized, BioRXiv is replete with technical papers documenting “high throughput systems for this one very specific experiment” and there <a href="https://docs.auto-pi-lot.com">isn’t</a> a true experimental framework that satisfies the need for flexibility.</p>\n\n<p><strong>Diversity of Measurements</strong> — Molecular biology and geneticists are perhaps the subdisciplines with the best data analytical structure, spawning and occupying the near totality of a new subdiscipline of Bioinformatics. Though the experiments are of course just as complex as those in systems neuroscience, most rely on a small number of stereotyped sequencing methods that result in the same one-dimensional, four character sequence data structure of base pairs. Systems neuroscience experiments increasingly incorporate dozens of measurements, electrophysiology, calcium imaging, multiple video streams, motion, infrared, and other sensors, and so on. Even the seemingly “common” electrophysiological or multiphoton imaging data can have multiple forms – raw voltage traces? spike times? spike templates and times? single or multiunit? The <a href="https://www.nwb.org/">Neurodata Without Borders</a> project has made a valiant effort to unify these multiple formats, but has suffered from a relatively difficult to use API and few incentives to adopt it. Contrast this with the <a href="https://bids.neuroimaging.io/">BIDS</a> data structure for fMRI data, where by converting your data to the structure you unlock a huge library of analysis pipelines for free. (Of course this is a chicken and egg problem where the analysis pipelines needs to exist for people to adopt it, but people need to adopt it to build the analyis pipelines… but I haven’t seen much movement to build pipelines on top of NWB in general).</p>\n\n<p><strong>The Hacker Spirit and Celebration of Heroism</strong> — Many people are attracted to systems neuroscience because of the… playful… attitude we take towards our rigs. If you want to do something, don’t ask questions just break out the hot glue, vaseline, and aluminum foil and hack at it until it does what you want. Wrapped like ouroboros around the hacker spirit is the veneration of heroism: it is a <em>good thing</em> to have done an experiment that only you are capable of doing because that means you’re the best hacker. Not unrelated is the strong incentive to make something new rather than build on existing tools — you don’t get publications from pull requests, and you don’t get a job without publications. I dont’ want to treat this ethic as causative of any outcome, just to make the speculative nature of these claims clear, but perhaps the reason why systems neuroscientists don’t contribute to a communal base of tools is that once they have started the boulder rolling down the hill of heroic idiosyncracy, it becomes difficult to then eg. return your experimental code to some shared library, or convert your data to some shared format (how do you convert some labview workflow to a Python package again???).</p>\n\n<h1 id="-and-the-tools-therefore">… and the Tools Therefore</h1>\n\n<p>These special habits of systems neuroscience have implications for the types of tools that we need. I’ll try to explicate some of the tools and practices that we need to adopt along with the requirements they have to be compatible with systems neuro, and give a basic sketch of the ways we could implement them. I will phrase this as it applies to ION and ONICE, but these are general principles.</p>\n\n<h2 id="shared-data">Shared Data</h2>\n\n<p>All data should be archived and publicly available</p>\n\n<p><strong>Common Format</strong></p>\n\n<ul>\n  <li>All data should be in a common format, complete with metadata that makes it possible for other researchers to reuse it without additional documentation. Failing that, labs should write a conversion script for turning their lab-specific format to this common format. Failing that, labs should write formal documentation that describes their data that allows someone else to write such a conversion function.</li>\n  <li>I propose that we adopt the NWB standard and invest in improving the tools used for interacting with NWB files. Should that prove inadequate for some reason, we should work to extend their format rather than reinventing a new one. We should participate in its communal development by raising issues and publicly describing the ways that our perhaps idiosyncratic data does not work with the format rather than adopting chimeric data storage formats.</li>\n</ul>\n\n<p><strong>Server Directory</strong></p>\n\n<ul>\n  <li>All labs should store all their data on a single server (or single cluster of servers) that can be made available to other labs through a common access protocol.</li>\n  <li>Ideally it would be possible to browse a lab’s data by metadata without explicit access, and ideally this data sharing system would not require detailed knowledge of shell commands or other programming skills, so some frontend system should be preferred.</li>\n  <li>There are several tools that are possible here, <a href="https://datajoint.io/">DataJoint</a> is a natural contender, as is a tool like the IBL’s <a href="https://github.com/cortex-lab/alyx">alyx</a>.</li>\n  <li>In addition to the tool itself we need to establish a <em>protocol</em> that all labs can follow to use it. Rather than requiring opting in and manually curating data, we should develop tools to make the conversion and storage of data in centralized servers <em>automatic</em>.</li>\n</ul>\n\n<h2 id="shared-tools">Shared Tools</h2>\n\n<p>We should always work in such a way that our labor is preserved, made available to others, and makes use of others. We should use the same tools.</p>\n\n<p><strong>Experimental Framework</strong></p>\n\n<ul>\n  <li>We should adopt and develop an experimental framework that is flexible enough to perform our experiments, but standardized enough that we can share development between experiments. Though transition costs are high, this piece is central to making an integrated system that makes the rest of these steps more powerful.</li>\n  <li>The experimental framework should provide a clear means of extending particular components, as well as a clear means of documentation</li>\n  <li>The experimental framework should provide a clear means of replicating experiments, as well as sharing code between experiments with the same logical structure</li>\n  <li>I propose we investigate developing and adopting <a href="https://docs.auto-pi-lot.com">autopilot</a> <a href="https://www.biorxiv.org/content/10.1101/807693v1">preprint</a>, noting that i’m more than a bit biased as it’s my bouncing baby, though I developed it because nothing comparable existed/exists (that I’m aware of). As a framework, it is built modularly (you can pick and choose its parts and use them however you want and flexibly (no limits on task structure, trivial to implement controllers for new hardware, easy to integrate external tools like I did with <a href="https://elifesciences.org/articles/61909">DeepLabCut-Live</a>, etc.). It is also designed for replicability, where it attempts to preserve records for everything an experimental subject ever experiences and every time a system changes, facilitating exact replication even on different hardware. It is also extensively documented, and makes additional documentation trivial as it is generated from the docstrings within the code itself. An extension of its data manipulation <a href="https://docs.auto-pi-lot.com/en/dev/autopilot.core.subject.html">Subject</a> class to use NWB would accomplish the adoption of a shared data standard, making conversion unnecessary.</li>\n</ul>\n\n<p><strong>Analysis Framework</strong></p>\n\n<ul>\n  <li>We should contribute to and develop a shared analysis framework built on top of the shared data format.</li>\n  <li>We should build such a framework using basic “building blocks” of data transformations that can be composed together</li>\n  <li>We should make the analysis pipelines capable of being deployed on computing clusters by encapsulating requirements and install procedures in virtual environments or containers like Docker.</li>\n  <li>I have less of a clear picture for how this should be accomplished, but DataJoint again provides a framework for this that we should investigate.</li>\n</ul>\n\n<h2 id="shared-knowledge">Shared Knowledge</h2>\n\n<p>We should commit to documenting and sharing the technical knowledge necessary for doing experiments but that doesn’t fit in traditional papers.</p>\n\n<p><strong>Methods Wiki</strong></p>\n\n<ul>\n  <li>We should create a wiki for documenting methodological information from hardware descriptions and experiences to design considerations for behavioral experiments. A wiki is the appropriate level of durability and fungibility — extremely low barrier to contribution, but contribution is permanent rather than in some forum, slack, etc.</li>\n  <li>We should use <a href="https://www.semantic-mediawiki.org/wiki/Semantic_MediaWiki">Semantic MediaWiki</a> to create structured, computable descriptions. Semantic wikis allow you to describe schemas for particular types of information — eg see this template for a hardware <a href="https://wiki.auto-pi-lot.com/index.php/Template:Part">Part</a> on the prototype autopilot wiki, where in addition to the rest of the human-written documentation, each part is described by a manufacturer, datasheet, etc. The Part template can then be extended for particular types of parts, eg. a “Resistor” part might add a field for the particular value of the resistor. These schemas can then be exposed to users as forms, structuring submission such that each person can easily submit new information without needing to learn any markup. Critically, structure information can be computed upon, so for example a build guide can automatically create a parts list table complete with all the details for each of the parts it mentions by pulling them from the structured description of the part.</li>\n  <li>Additionally, using Semantic MediaWiki + Autopilot will let us create a more powerful system by bidirectionally combining the high-level descriptions of the wiki with their implementation in code. For example, if browsing the wiki one was able to find a particular motion sensor to use for their experiment, one could then be linked to the Autopilot documentation page for the object that controls that motion sensor. If they started using that motion sensor, and upon using it ran the calibration routine, they could be prompted to submit their calibration to the wiki, which could then index them and provide automatically generated reliability statistics. By many people submitting calibration results, it could then be possible to provide data-driven defaults for future calibrations… and so on. Though this is one trivial example, the benefits of an integrated knowledge system and experimental framework are innumerable — another would be the ability to link detailed descriptions about different considerations about designing a particular task (how long should i have a timeout delay between incorrect answers in a 2afc task???) to the methods that implement them in code, and then those claims could use anonymously collected data to substantiate/refute them (across 1000 sessions, tasks that used x timeout had the highest y value).</li>\n</ul>\n\n<h1 id="we-need-a-map">We Need a Map</h1>\n\n<p>Though the future painted here may be bright (perhaps blindingly, gratingly so in its optimism) it won’t spring into the world fully formed. Instead we should work as a consortium to plot a course together to see what makes sense to do when. We should start the process of abandoning the heroic, private model of development by working with each other to collaborate on the structure and realization of this vision. We shouldn’t retreat to our own fears of difficulty, or lean back on the inertia of history, and instead trust each other that collectively we have the will and expertise to set goals and meet them — don’t worry if <em>you</em> can’t write a line of code, the goal is to design a system where we can all contribute what we can and reap the collected benefits. We should take lessons where we can learn them from other groups working on similar efforts, and avoid reinventing the wheel as much as we can, but also acknowledge that creation de novo can itself be an act of learning from others. We shouldn’t think of this work as something we do in isolation, but as something we do as active contributors to the scientific endeavor at large — <em>someone</em> should do something about scientific infrastructure! and that <em>someone</em> should be <em>us.</em></p>\n\n<p>The feared word on the tip of my tongue is <strong>governance</strong>. This project will be hopeless if we never reach the level of organization beyond having made a slack. If we are serious about making concrete progress on collaborative infrastructure, we need to have structured mechanisms for reaching decisions that help everyone feel valued in their contribution and prevent us from feeling like we’re just floating. I will propose we adopt a system of consensus decisionmaking that I have learned from years of organizing in co-ops, activist groups, and other communal spaces. I think that we can bring this model to the broader movement towards “big science” as a non-hierarchical alternative to traditional governance structures that inevitably concentrate decisionmaking power in one or a few highly-connected people.</p>\n\n<p>In sum, it’s about time to build the basic infrastructure of systems neuroscience, and we should start in our own backyard.</p>','\n',char(10)),NULL,'','2021-03-01 08:00:00','Jonny Saunders blog','',NULL,'2024-01-03 18:04:29','read');
INSERT INTO items VALUES('https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/','Past Art Vol 2: About a Year of It',replace('<p>There’s a folder on my computer that is named <code class="language-plaintext highlighter-rouge">stupid_bullshit_projects</code> that continually fills up with the things that i make and never end up telling anyone about. It is never in a hurry to get filled up, and so I add to it in limps and startles.</p>\012\012<p>This last year was an especially good year for <code class="language-plaintext highlighter-rouge">stupid_bullshit_projects</code> because I was doing anything I could to distract myself from some heartbreak that was unbearable almost all of the time. Don’t close the tab just yet, I’m mostly past it now, most of what’s left is just reflecting.</p>\012\012<p>I wanted to try to remember some of the things that I make, because maybe that would make them feel more real. Visual art came into my life very late, and I haven’t quite shaken the feeling that I’m not invited. I’ve been led to believe that visual artists have a medium, and I don’t really have the discipline to maintain one of those. Music has instruments and genres, but since synthesis and hip-hop have made a mess of those they never felt quite so intimidating.</p>\012\012<p>Not really expecting anyone but me to get much joy out of them, but here are some things that I’ve made because I sorta had to.</p>\012\012<h1 id="with-music">With Music</h1>\012\012<p>Music is subtly but potently visual to me, and while I haven’t quite gotten to the point that I can make video with my own music, I do love making videos to other people’s music.</p>\012\012<h2 id="murmuration-20200210">Murmuration (2020.02.10)</h2>\012\012<p>The sun was just starting to come back to Eugene and I was putting some periods on some memories. Things were bulging and shifting and nothing really felt settled. There were some nice winter sunsets though.</p>\012\012<p>This is a simple lil glitch, a pulsed p-frame duplication with an RGB channel shift. The blooming effect from 00:48 to 00:54 was what I was itching for. Most of the beauty comes from the source video, a starling murmuration.</p>\012\012<p>Music: Laura Jean Anderson - thinkin bout you</p>\012\012<p><a data-fancybox="" href="https://vimeo.com/390663030" vidid="390663030" class="vimeo-vid">\012</a></p>\012\012<h2 id="thao--the-get-down-stay-down---a-man-alive-20200127">Thao &amp; The Get Down Stay Down - A Man Alive (2020.01.27)</h2>\012\012<p>A) I love this album, and B) it was saying exactly what I was feeling at the time. These were three songs that I thought summed my bittersweet ass up relatively neatly <em>(you know I’m so easy to find, you won’t come get your girl)</em>.</p>\012\012<p>Technically very simple, rgb shift and a bunch of manual time warping &amp; splicing.</p>\012\012<h3 class="no_toc" id="endless-love">Endless Love</h3>\012\012<p><a data-fancybox="" href="https://vimeo.com/391770842" vidid="391770842" class="vimeo-vid">\012</a></p>\012\012<h3 class="no_toc" id="departure">Departure</h3>\012\012<p><a data-fancybox="" href="https://vimeo.com/391765834" vidid="391765834" class="vimeo-vid">\012</a></p>\012\012<h3 class="no_toc" id="guts">Guts</h3>\012\012<p><a data-fancybox="" href="https://vimeo.com/391768918" vidid="391768918" class="vimeo-vid">\012</a></p>\012\012<h2 class="no_toc" id="guillotine-20191202">Guillotine (2019.12.02)</h2>\012\012<p>Someone I like on Twitter posted some video using <a href="https://github.com/abedavis/visbeat">visbeat</a> and so I made a bunch of deathgrips memes. this was my favorite one.</p>\012\012<p>video: <a href="https://www.youtube.com/watch?v=CgHiSwR05VM">Arthur Ganson, The First Noble Truth</a></p>\012\012<p><a data-fancybox="" href="https://vimeo.com/390680486" vidid="390680486" class="vimeo-vid">\012</a></p>\012\012<h2 id="nick-hakim---miss-chew-20191102">Nick Hakim - Miss Chew (2019.11.02)</h2>\012\012<p>We had a party at my house and I had taken some MDMA that had some little extra kick in it that made my eyeballs spin out of my sockets. When I could focus my vision again I started synthesizing video to project over the dancefloor i mean our living room. A housemate of mine that loves horror movies had suggested we watch Nosferatu the night before so I was using that as some of the source material. Burned a bunch of music into a good place in my heart.</p>\012\012<p>The next day I had a sentimental hangover, my heart was vacant, mostly I was full of missing. Another simple p-frame duplication with a little random hex noise thrown into the encoded video stream before it gets decoded.</p>\012\012<p><a data-fancybox="" href="https://vimeo.com/390679861" vidid="390679861" class="vimeo-vid">\012</a></p>\012\012<h2 id="tirzah---affection-20191022">Tirzah - Affection (2019.10.22)</h2>\012\012<p>I was in an unexpected new depth in a hopeless argument with my heart, bargaining with my memories and promising to change, and working on a bunch of computer vision code. I started shooting video as a demo of the code for my collaborators, but got lost in its sort of numbing sparseness.</p>\012\012<p>I can’t really describe the process for this one – the source video is some computer-vision glitch that I just kept pushing my thumb into until it looked right. Then I lost a few days layering and cutting the clips until it was done.</p>\012\012<p><a data-fancybox="" href="https://vimeo.com/401774066" vidid="401774066" class="vimeo-vid">\012</a></p>\012\012<h1 id="webzones">Webzones</h1>\012\012<h2 id="perlin-particles-20200119">Perlin Particles (2020.01.19)</h2>\012\012<p>A friend and mentor who is a recently-minted PI asked me to make her a lab website. This ended up being the central design element, but along the way I made a version just to play with.</p>\012\012<p>Particles on 2D perlin noise. I think this one does better without documentation, just play with the slideys and see.</p>\012\012<p><a data-fancybox="" data-type="iframe" href="/projects/perlin/index.html" class="iframe-preview">Open demo</a></p>\012\012<h2 id="how-to-never-get-hired-for-any-job-pt-2-20191219">how to never get hired for any job pt 2. (2019.12.19)</h2>\012\012<p>My <a href="https://jon-e.net/about/">about me</a> page is sorta an anti-about me page… while I was still getting used to having to be professional all the time it seemed super weird to me to have an entire page just describing yourself. So right now the page just indeciperably refers to my feelings about having people look at an “about me” page about me. I was trying to fix that and got lost along the way. The idea was to have my information passing by on these mountains and to make the user move their mouse to make certain regions lie flat long enough to read. I decided that sucks and that I should just make a real one, but inner me is holding up the timeline.</p>\012\012<p><a data-fancybox="" data-type="iframe" href="/about/terrain.html" class="iframe-preview">Open demo</a></p>\012\012<h2 id="speeding-atlas-20191115">Speeding Atlas (2019.11.15)</h2>\012\012<p>If you combine the <a href="https://openpolicing.stanford.edu/data/">Stanford Open Policing Project</a> data with transportation department road use data and assume that speeding is roughly equally likely on all roads, you can make a map of the roads that you are more or less likely to get a speeding ticket on. This is a map for just Washington state because other states have less data available and beacause I realized what a huge waste of time this was.</p>\012\012<p>Map made with <a href="https://rstudio.github.io/leaflet/">leaflet</a> in R.</p>\012\012<p><a data-fancybox="" data-type="iframe" href="/projects/traffic/index.html" class="iframe-preview">Open demo</a></p>\012\012<h1 id="alternative-media">~alternative media~</h1>\012\012<h2 id="instagram-filters-20200119">instagram filters (2020.01.19)</h2>\012\012<p>I found out they let <em>just anyone</em> make instagram filters, and their platform is actually really lovely. I just made a few, not very good but i laughed a few times.</p>\012\012<p>First a classic tinyface just to see how it works:</p>\012\012<video controls="" preload="none" style="max-height: 70vh;">\012    <source src="/blog/assets/images/artvol2/tinyface_2.mp4" type="video/mp4" />\012    Your browser doesn''t support HTML5 video tag.\012</video>\012\012<p>The I made a Mitt Romney face (and my housemate used it to watch Sex and the City):</p>\012\012<video controls="" preload="none" style="max-height: 70vh;">\012    <source src="/blog/assets/images/artvol2/mitt.mp4" type="video/mp4" />\012    Your browser doesn''t support HTML5 video tag.\012</video>\012\012<p>And then Hank. Took a lot to make the 3d model of the head and face work together, and to add a lil cherry on top you get a coupla catch phrases when u open your mouth.</p>\012\012<video controls="" preload="none" style="max-height: 70vh;">\012    <source src="/blog/assets/images/artvol2/hank.mp4" type="video/mp4" />\012    Your browser doesn''t support HTML5 video tag.\012</video>\012\012<h2 id="autopotterotica-20200101">Autopotterotica (2020.01.01)</h2>\012\012<p>um.</p>\012\012<p>Where to start with this one.</p>\012\012<p>Fanfiction is, at least to me, one of the strangest but most beautiful human instincts. The raw diversity <em>and volume</em> of wish-fulfillment that happens within the bounds of fanfiction positively fucks up the elevation of my jaw. So I thought it might be interesting to have a neural net generate some.</p>\012\012<p>It turns out fanfiction.net is the largest natural language text corpus that I’ve ever been able to find by orders of magnitude – 1.5T compressed text, hundreds or thousands of wikipedias. The scrape took ~7 weeks of 24/7 scraping.</p>\012\012<p>I’ve never written fanfiction, but I did read a lot of experimental erotica at backyard poetry readings in college, and it quickly became clear what the neural net wanted to write.</p>\012\012<p>These stories are all 100% neural-net generated (finetuned GPT-2) text. They are about 50% fully-random initializations and 50% initializations with seed text, but it didn’t take much. The only editing I do is cutting repetetive text, formatting into paragraphs, and minor fixes to punctuation – I don’t add anything or change its order. These are just a sample, I’m looking to finish the book during this great pause.</p>\012\012<p>So, first, the scraping code for those for whom it would be useful, and then the smut for which I request you not put me in jail for.</p>\012\012<p><code class="language-plaintext highlighter-rouge">list_stories.py</code> - get a list of all available stories and their metadata</p>\012\012<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>\012<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span> <span class="k">as</span> <span class="n">bs</span>\012<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span><span class="p">,</span> <span class="n">trange</span>\012<span class="kn">import</span> <span class="nn">json</span>\012<span class="kn">import</span> <span class="nn">os</span>\012<span class="kn">import</span> <span class="nn">tables</span>\012<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>\012<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>\012<span class="kn">import</span> <span class="nn">pdb</span>\012<span class="kn">import</span> <span class="nn">traceback</span>\012<span class="kn">import</span> <span class="nn">os</span>\012<span class="kn">import</span> <span class="nn">multiprocessing</span> <span class="k">as</span> <span class="n">mp</span>\012\012<span class="kn">import</span> <span class="nn">argparse</span>\012\012\012\012<span class="n">BROWSE_FANFIC</span> <span class="o">=</span> <span class="p">{</span>\012    <span class="s">''anime''</span><span class="p">:</span> <span class="s">''https://www.fanfiction.net/anime/''</span><span class="p">,</span>\012    <span class="s">''book''</span><span class="p">:</span>  <span class="s">''https://www.fanfiction.net/book/''</span><span class="p">,</span>\012    <span class="s">''cartoon''</span><span class="p">:</span> <span class="s">''https://www.fanfiction.net/cartoon/''</span><span class="p">,</span>\012    <span class="s">''comic''</span><span class="p">:</span> <span class="s">''https://www.fanfiction.net/comic/''</span><span class="p">,</span>\012    <span class="s">''game''</span><span class="p">:</span> <span class="s">''https://www.fanfiction.net/game/''</span><span class="p">,</span>\012    <span class="s">''misc''</span><span class="p">:</span> <span class="s">''https://www.fanfiction.net/misc/''</span><span class="p">,</span>\012    <span class="s">''play''</span><span class="p">:</span> <span class="s">''https://www.fanfiction.net/play/''</span><span class="p">,</span>\012    <span class="s">''movie''</span><span class="p">:</span> <span class="s">''https://www.fanfiction.net/movie/''</span><span class="p">,</span>\012    <span class="s">''tv''</span><span class="p">:</span> <span class="s">''https://www.fanfiction.net/tv/''</span>\012<span class="p">}</span>\012\012<span class="k">def</span> <span class="nf">list_universes</span><span class="p">():</span>\012    <span class="s">"""\012    List all story universes available on fanfiction.net and the number of stories they have\012    """</span>\012    <span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>\012    <span class="k">for</span> <span class="n">fanfic_type</span><span class="p">,</span> <span class="n">browse_page</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">BROWSE_FANFIC</span><span class="p">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">position</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>\012\012        <span class="n">page</span> <span class="o">=</span> <span class="n">bs</span><span class="p">(</span><span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">browse_page</span><span class="p">).</span><span class="n">content</span><span class="p">,</span> <span class="s">''lxml''</span><span class="p">)</span>\012        <span class="n">link_groups</span> <span class="o">=</span> <span class="n">page</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s">"list_output"</span><span class="p">).</span><span class="n">find_all</span><span class="p">(</span><span class="s">''div''</span><span class="p">)</span>\012\012        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">link_groups</span><span class="p">,</span> <span class="n">position</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>\012            <span class="n">link</span> <span class="o">=</span> <span class="n">l</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">''a''</span><span class="p">)</span>\012            <span class="n">story_num</span> <span class="o">=</span> <span class="n">l</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">''span''</span><span class="p">).</span><span class="n">text</span><span class="p">.</span><span class="n">lstrip</span><span class="p">(</span><span class="s">''(''</span><span class="p">).</span><span class="n">rstrip</span><span class="p">(</span><span class="s">'')''</span><span class="p">)</span>\012            <span class="k">if</span> <span class="n">story_num</span><span class="p">.</span><span class="n">endswith</span><span class="p">(</span><span class="s">''K''</span><span class="p">):</span>\012                <span class="n">story_num</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">story_num</span><span class="p">.</span><span class="n">rstrip</span><span class="p">(</span><span class="s">''K''</span><span class="p">))</span><span class="o">*</span><span class="mi">1000</span><span class="p">)</span>\012            <span class="k">else</span><span class="p">:</span>\012                <span class="n">story_num</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">story_num</span><span class="p">)</span>\012            <span class="n">rows</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">fanfic_type</span><span class="p">,</span> <span class="n">link</span><span class="p">.</span><span class="n">text</span><span class="p">,</span> <span class="n">story_num</span><span class="p">,</span> <span class="s">''https://www.fanfiction.net''</span><span class="o">+</span><span class="n">link</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">''href''</span><span class="p">)))</span>\012\012    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">from_records</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">(</span><span class="s">''type''</span><span class="p">,</span> <span class="s">''universe''</span><span class="p">,</span> <span class="s">''n_stories''</span><span class="p">,</span> <span class="s">''url''</span><span class="p">))</span>\012\012<span class="k">def</span> <span class="nf">list_stories</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>\012    <span class="s">"""\012    For a particular story universe, list all stories and return their metadata.\012\012    Args:\012        row (tables.Row): row containing metadata from list_universes()\012    """</span>\012    <span class="k">try</span><span class="p">:</span>\012        <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="o">=</span> <span class="n">row</span>\012        <span class="c1"># FIXME: hardcoding base_dir\012</span>        <span class="n">base_dir</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s">''stories''</span><span class="p">)</span>\012        <span class="n">save_fn</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="n">row</span><span class="p">.</span><span class="n">universe</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">''/''</span><span class="p">,</span><span class="s">''-''</span><span class="p">)</span><span class="o">+</span><span class="s">''.pck.gz''</span><span class="p">)</span>\012        <span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="n">save_fn</span><span class="p">):</span>\012            <span class="k">return</span>\012\012        <span class="n">stories</span> <span class="o">=</span> <span class="p">[]</span>\012        <span class="n">first_page</span> <span class="o">=</span> <span class="n">bs</span><span class="p">(</span><span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">row</span><span class="p">.</span><span class="n">url</span><span class="o">+</span><span class="s">"?&amp;srt=1&amp;r=10"</span><span class="p">).</span><span class="n">content</span><span class="p">,</span> <span class="s">''lxml''</span><span class="p">)</span>\012\012\012        <span class="c1"># find last page\012</span>        <span class="k">try</span><span class="p">:</span>\012            <span class="n">last_page_url</span> <span class="o">=</span> <span class="n">first_page</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">''center''</span><span class="p">).</span><span class="n">find</span><span class="p">(</span><span class="s">''a''</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">''Last''</span><span class="p">).</span><span class="n">get</span><span class="p">(</span><span class="s">''href''</span><span class="p">)</span>\012            <span class="n">last_page</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">last_page_url</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">''&amp;p=''</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>\012        <span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>\012            <span class="n">last_page</span> <span class="o">=</span> <span class="mi">1</span>\012\012        <span class="c1"># get current process number to place progress bar\012</span>        <span class="k">try</span><span class="p">:</span>\012            <span class="n">current</span> <span class="o">=</span> <span class="n">mp</span><span class="p">.</span><span class="n">current_process</span><span class="p">()</span>\012            <span class="n">tqdm_position</span> <span class="o">=</span> <span class="n">current</span><span class="p">.</span><span class="n">_identity</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span>\012        <span class="k">except</span><span class="p">:</span>\012            <span class="n">tqdm_position</span> <span class="o">=</span> <span class="mi">0</span>\012\012        <span class="n">story_pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">position</span><span class="o">=</span><span class="n">tqdm_position</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">row</span><span class="p">.</span><span class="n">n_stories</span><span class="p">)</span>\012\012        <span class="c1"># iterate through pages listing stories and get their metadata\012</span>        <span class="k">for</span> <span class="n">page_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">last_page</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>\012            <span class="n">page_url</span> <span class="o">=</span> <span class="n">row</span><span class="p">.</span><span class="n">url</span> <span class="o">+</span> <span class="s">''?&amp;srt=1&amp;r=10&amp;p={}''</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">page_num</span><span class="p">)</span>\012            <span class="n">page</span> <span class="o">=</span> <span class="n">bs</span><span class="p">(</span><span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">page_url</span><span class="p">).</span><span class="n">content</span><span class="p">,</span> <span class="s">''lxml''</span><span class="p">)</span>\012\012            <span class="n">links</span> <span class="o">=</span> <span class="n">page</span><span class="p">.</span><span class="n">find_all</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">''z-list''</span><span class="p">)</span>\012            <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">links</span><span class="p">:</span>\012                <span class="n">story_url</span> <span class="o">=</span> <span class="n">l</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">''stitle''</span><span class="p">).</span><span class="n">get</span><span class="p">(</span><span class="s">''href''</span><span class="p">)</span>\012                <span class="n">story_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">story_url</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">''/''</span><span class="p">)[</span><span class="mi">2</span><span class="p">])</span>\012                <span class="n">story_name</span> <span class="o">=</span> <span class="n">l</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">''stitle''</span><span class="p">).</span><span class="n">text</span>\012                <span class="n">story_url</span> <span class="o">=</span> <span class="s">''https://fanfiction.net''</span> <span class="o">+</span> <span class="n">story_url</span>\012\012                <span class="n">stories</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">row</span><span class="p">.</span><span class="n">universe</span><span class="p">,</span> <span class="n">story_id</span><span class="p">,</span> <span class="n">story_url</span><span class="p">,</span> <span class="n">story_name</span><span class="p">))</span>\012                <span class="n">story_pbar</span><span class="p">.</span><span class="n">update</span><span class="p">()</span>\012\012        <span class="n">story_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">from_records</span><span class="p">(</span><span class="n">stories</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">(</span><span class="s">''universe''</span><span class="p">,</span> <span class="s">''id''</span><span class="p">,</span> <span class="s">''url''</span><span class="p">,</span> <span class="s">''name''</span><span class="p">))</span>\012        <span class="n">story_df</span><span class="p">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="n">save_fn</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s">''gzip''</span><span class="p">)</span>\012    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>\012        <span class="k">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>\012        <span class="n">pdb</span><span class="p">.</span><span class="n">set_trace</span><span class="p">()</span>\012\012<span class="k">def</span> <span class="nf">list_hp</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>\012\012\012    <span class="n">page</span> <span class="o">=</span> <span class="n">bs</span><span class="p">(</span><span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">).</span><span class="n">content</span><span class="p">,</span> <span class="s">''lxml''</span><span class="p">)</span>\012\012    <span class="n">links</span> <span class="o">=</span> <span class="n">page</span><span class="p">.</span><span class="n">find_all</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">''z-list''</span><span class="p">)</span>\012    <span class="n">stories</span> <span class="o">=</span> <span class="p">[]</span>\012    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">links</span><span class="p">:</span>\012        <span class="n">story_url</span> <span class="o">=</span> <span class="n">l</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">''stitle''</span><span class="p">).</span><span class="n">get</span><span class="p">(</span><span class="s">''href''</span><span class="p">)</span>\012        <span class="n">story_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">story_url</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">''/''</span><span class="p">)[</span><span class="mi">2</span><span class="p">])</span>\012        <span class="n">story_name</span> <span class="o">=</span> <span class="n">l</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">''stitle''</span><span class="p">).</span><span class="n">text</span>\012        <span class="n">story_url</span> <span class="o">=</span> <span class="s">''https://fanfiction.net''</span> <span class="o">+</span> <span class="n">story_url</span>\012\012        <span class="n">stories</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="s">''Harry Potter''</span><span class="p">,</span> <span class="n">story_id</span><span class="p">,</span> <span class="n">story_url</span><span class="p">,</span> <span class="n">story_name</span><span class="p">))</span>\012\012    <span class="n">story_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">from_records</span><span class="p">(</span><span class="n">stories</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">(</span><span class="s">''universe''</span><span class="p">,</span> <span class="s">''id''</span><span class="p">,</span> <span class="s">''url''</span><span class="p">,</span> <span class="s">''name''</span><span class="p">))</span>\012    <span class="k">return</span> <span class="n">story_df</span>\012\012\012\012<span class="k">def</span> <span class="nf">list_harry_potter</span><span class="p">():</span>\012    <span class="n">pool</span> <span class="o">=</span> <span class="n">mp</span><span class="p">.</span><span class="n">Pool</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>\012\012    <span class="n">base_url</span> <span class="o">=</span> <span class="s">''https://www.fanfiction.net/book/Harry-Potter/''</span>\012\012    <span class="c1"># FIXME: hardcoding base_dir\012</span>    <span class="n">base_dir</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s">''stories''</span><span class="p">)</span>\012\012    <span class="n">save_fn</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s">''Harry Potter''</span><span class="o">+</span><span class="s">''.pck.gz''</span><span class="p">)</span>\012    <span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="n">save_fn</span><span class="p">):</span>\012        <span class="k">return</span>\012    <span class="n">first_page</span> <span class="o">=</span> <span class="n">bs</span><span class="p">(</span><span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">base_url</span><span class="o">+</span><span class="s">"?&amp;srt=1&amp;r=10"</span><span class="p">).</span><span class="n">content</span><span class="p">,</span> <span class="s">''lxml''</span><span class="p">)</span>\012\012\012    <span class="c1"># find last page\012</span>    <span class="k">try</span><span class="p">:</span>\012        <span class="n">last_page_url</span> <span class="o">=</span> <span class="n">first_page</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">''center''</span><span class="p">).</span><span class="n">find</span><span class="p">(</span><span class="s">''a''</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">''Last''</span><span class="p">).</span><span class="n">get</span><span class="p">(</span><span class="s">''href''</span><span class="p">)</span>\012        <span class="n">last_page</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">last_page_url</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">''&amp;p=''</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>\012    <span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>\012        <span class="n">last_page</span> <span class="o">=</span> <span class="mi">1</span>\012\012    <span class="n">page_urls</span> <span class="o">=</span> <span class="p">[</span><span class="n">base_url</span> <span class="o">+</span> <span class="s">''?&amp;srt=1&amp;r=10&amp;p={}''</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">last_page</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>\012\012    <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">page_urls</span><span class="p">),</span> <span class="n">position</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>\012\012    <span class="n">pdb</span><span class="p">.</span><span class="n">set_trace</span><span class="p">()</span>\012    <span class="n">results</span> <span class="o">=</span> <span class="n">pool</span><span class="p">.</span><span class="n">imap_unordered</span><span class="p">(</span><span class="n">list_hp</span><span class="p">,</span> <span class="n">page_urls</span><span class="p">)</span>\012\012    <span class="n">pages</span> <span class="o">=</span> <span class="p">[]</span>\012    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>\012        <span class="n">result</span> <span class="o">=</span> <span class="n">r</span><span class="p">.</span><span class="n">get</span><span class="p">()</span>\012        <span class="n">pages</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>\012        <span class="n">pbar</span><span class="p">.</span><span class="n">update</span><span class="p">()</span>\012\012    <span class="n">hp_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">(</span><span class="n">pages</span><span class="p">)</span>\012    <span class="n">hp_df</span><span class="p">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="n">save_fn</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s">"gzip"</span><span class="p">)</span>\012\012\012<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>\012    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="p">.</span><span class="n">ArgumentParser</span><span class="p">()</span>\012    <span class="n">parser</span><span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">''--universes''</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s">''location of the universes.json file that tracks which stories we need to reload''</span><span class="p">)</span>\012    <span class="n">parser</span><span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">''--stories''</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s">''location of stories directory - links to all stories''</span><span class="p">)</span>\012    <span class="n">parser</span><span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">''--list''</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s">''only list stories''</span><span class="p">)</span>\012    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="p">.</span><span class="n">parse_args</span><span class="p">()</span>\012\012    <span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="n">universes</span><span class="p">:</span>\012        <span class="n">universe_path</span> <span class="o">=</span> <span class="n">args</span><span class="p">.</span><span class="n">universes</span>\012    <span class="k">else</span><span class="p">:</span>\012        <span class="n">universe_path</span> <span class="o">=</span> <span class="s">''universes.json''</span>\012\012    <span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="n">stories</span><span class="p">:</span>\012        <span class="n">story_path</span> <span class="o">=</span> <span class="n">args</span><span class="p">.</span><span class="n">stories</span>\012    <span class="k">else</span><span class="p">:</span>\012        <span class="n">story_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">getcwd</span><span class="p">(),</span><span class="s">''stories''</span><span class="p">)</span>\012\012    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="n">story_path</span><span class="p">):</span>\012        <span class="n">os</span><span class="p">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">story_path</span><span class="p">)</span>\012\012    <span class="c1"># list universes, if we have a previously available universes file,\012</span>    <span class="c1"># find universes that have more stories than we had last time.\012</span>    <span class="n">universes</span> <span class="o">=</span> <span class="n">list_universes</span><span class="p">()</span>\012    <span class="k">try</span><span class="p">:</span>\012        <span class="n">past_universes</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_json</span><span class="p">(</span><span class="n">universe_path</span><span class="p">)</span>\012        <span class="n">universes</span> <span class="o">=</span> <span class="n">universes</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">universes</span><span class="p">.</span><span class="n">n_stories</span> <span class="o">&gt;</span> <span class="n">past_universes</span><span class="p">.</span><span class="n">n_stories</span><span class="p">,]</span>\012    <span class="k">except</span><span class="p">:</span>\012        <span class="k">print</span><span class="p">(</span><span class="s">''</span><span class="se">\n</span><span class="s">couldnt load old universes directory, loading all</span><span class="se">\n</span><span class="s">''</span><span class="p">)</span>\012\012    <span class="n">universes</span><span class="p">.</span><span class="n">to_json</span><span class="p">(</span><span class="n">universe_path</span><span class="p">)</span>\012\012    <span class="c1"># start a pool of workers to list stories\012</span>    <span class="n">pool</span> <span class="o">=</span> <span class="n">mp</span><span class="p">.</span><span class="n">Pool</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>\012    <span class="c1">#\012</span>    <span class="c1"># list_harry_potter()\012</span>\012    <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">universes</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">position</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>\012\012    <span class="n">results</span> <span class="o">=</span> <span class="n">pool</span><span class="p">.</span><span class="n">imap_unordered</span><span class="p">(</span><span class="n">list_stories</span><span class="p">,</span> <span class="n">universes</span><span class="p">.</span><span class="n">iterrows</span><span class="p">())</span>\012\012    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>\012        <span class="k">try</span><span class="p">:</span>\012            <span class="n">r</span><span class="p">.</span><span class="n">get</span><span class="p">()</span>\012            <span class="n">pbar</span><span class="p">.</span><span class="n">update</span><span class="p">()</span>\012        <span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>\012            <span class="n">pbar</span><span class="p">.</span><span class="n">update</span><span class="p">()</span></code></pre></figure>\012\012<p><code class="language-plaintext highlighter-rouge">scrape_fanfiction.py</code> - scrape all the fanfiction in the universe!!!</p>\012\012<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>\012<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span> <span class="k">as</span> <span class="n">bs</span>\012<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span><span class="p">,</span> <span class="n">trange</span>\012<span class="kn">import</span> <span class="nn">json</span>\012<span class="kn">import</span> <span class="nn">os</span>\012<span class="kn">import</span> <span class="nn">tables</span>\012<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>\012<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>\012<span class="kn">import</span> <span class="nn">pdb</span>\012<span class="kn">import</span> <span class="nn">traceback</span>\012<span class="kn">import</span> <span class="nn">os</span>\012<span class="kn">import</span> <span class="nn">multiprocessing</span> <span class="k">as</span> <span class="n">mp</span>\012\012<span class="kn">import</span> <span class="nn">argparse</span>\012\012\012<span class="k">class</span> <span class="nc">Metadata</span><span class="p">(</span><span class="n">tables</span><span class="p">.</span><span class="n">IsDescription</span><span class="p">):</span>\012    <span class="s">"""\012    Class to describe columns in metadata table\012    """</span>\012    <span class="n">page_id</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">UInt32Col</span><span class="p">()</span>\012    <span class="n">page_title</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>\012    <span class="n">title</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>\012    <span class="n">description</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">2048</span><span class="p">)</span>\012    <span class="n">rating</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>\012    <span class="n">language</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>\012    <span class="n">chapters</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">UInt16Col</span><span class="p">()</span>\012    <span class="n">chapter</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">UInt16Col</span><span class="p">()</span>\012    <span class="n">words</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">UInt64Col</span><span class="p">()</span>\012    <span class="n">reviews</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">UInt32Col</span><span class="p">()</span>\012    <span class="n">favs</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">UInt32Col</span><span class="p">()</span>\012    <span class="n">follows</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">UInt32Col</span><span class="p">()</span>\012    <span class="n">updated</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>\012    <span class="n">published</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>\012    <span class="n">text_idx</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">UInt64Col</span><span class="p">()</span>\012    <span class="n">genre</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">256</span><span class="p">)</span>\012    <span class="n">characters</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>\012    <span class="n">universe</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>\012\012\012<span class="k">def</span> <span class="nf">scrape_page</span><span class="p">(</span><span class="n">page</span><span class="p">,</span> <span class="n">page_id</span><span class="p">,</span> <span class="n">chapter</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">row</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>\012    <span class="s">"""\012    Scrape a single page\012    """</span>\012\012    <span class="c1"># gather page elements with metadata\012</span>    <span class="c1"># small sub element with hyphen-separated descriptors\012</span>    <span class="n">profile</span> <span class="o">=</span> <span class="n">page</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s">"profile_top"</span><span class="p">)</span>\012    <span class="n">subheader</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">profile</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">''xgray xcontrast_txt''</span><span class="p">).</span><span class="n">children</span><span class="p">)</span>\012\012\012    <span class="n">subhead_1</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">subheader</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">split</span><span class="p">(</span><span class="s">''-''</span><span class="p">)]</span>\012    <span class="n">subhead_2</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">subheader</span><span class="p">[</span><span class="mi">4</span><span class="p">].</span><span class="n">split</span><span class="p">(</span><span class="s">''-''</span><span class="p">)]</span>\012\012    <span class="c1">#############################\012</span>    <span class="c1"># gather metadata -- idiosyncratic selection criteria for the page and its format.\012</span>    <span class="c1"># after scraping several thousand pages, there are no obvious failures.\012</span>    <span class="n">metadata</span> <span class="o">=</span> <span class="p">{}</span>\012\012    <span class="c1"># these ones are more or less always present, no position correction needed\012</span>    <span class="n">metadata</span><span class="p">[</span><span class="s">''page_id''</span><span class="p">]</span> <span class="o">=</span> <span class="n">page_id</span>\012    <span class="n">metadata</span><span class="p">[</span><span class="s">"page_title"</span><span class="p">]</span> <span class="o">=</span> <span class="n">page</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">"title"</span><span class="p">).</span><span class="n">text</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">''ascii''</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">"ignore"</span><span class="p">)</span>\012    <span class="c1">#metadata["title"] = profile.find("b").text.encode(''ascii'', errors="ignore")\012</span>    <span class="n">metadata</span><span class="p">[</span><span class="s">"description"</span><span class="p">]</span> <span class="o">=</span> <span class="n">profile</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">''div''</span><span class="p">,</span> <span class="n">recursive</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">text</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">''ascii''</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">"ignore"</span><span class="p">)</span>\012    <span class="n">metadata</span><span class="p">[</span><span class="s">"rating"</span><span class="p">]</span> <span class="o">=</span> <span class="n">subheader</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">text</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">''ascii''</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">"ignore"</span><span class="p">)</span>\012    <span class="n">metadata</span><span class="p">[</span><span class="s">"language"</span><span class="p">],</span> <span class="n">metadata</span><span class="p">[</span><span class="s">"genre"</span><span class="p">],</span> <span class="n">metadata</span><span class="p">[</span><span class="s">"characters"</span><span class="p">]</span> <span class="o">=</span> <span class="n">subhead_1</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">encode</span><span class="p">(</span><span class="s">''ascii''</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">"ignore"</span><span class="p">),</span> <span class="n">subhead_1</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">encode</span><span class="p">(</span><span class="s">''ascii''</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">"ignore"</span><span class="p">),</span> <span class="n">subhead_1</span><span class="p">[</span><span class="mi">3</span><span class="p">].</span><span class="n">encode</span><span class="p">(</span><span class="s">''ascii''</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">"ignore"</span><span class="p">)</span>\012    <span class="n">metadata</span><span class="p">[</span><span class="s">''chapter''</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">chapter</span><span class="p">)</span>\012\012    <span class="c1"># the following might be present, and so they require special checks\012</span>    <span class="k">try</span><span class="p">:</span>\012        <span class="n">metadata</span><span class="p">[</span><span class="s">"chapters"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">strip</span><span class="p">(</span><span class="s">''Chapters: ''</span><span class="p">))</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">subhead_1</span> <span class="k">if</span> <span class="n">c</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">"Chapters:"</span><span class="p">)][</span><span class="mi">0</span><span class="p">]</span>\012    <span class="k">except</span><span class="p">:</span>\012        <span class="n">metadata</span><span class="p">[</span><span class="s">''chapters''</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>\012\012\012    <span class="n">metadata</span><span class="p">[</span><span class="s">"words"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">strip</span><span class="p">(</span><span class="s">''Words: ''</span><span class="p">).</span><span class="n">replace</span><span class="p">(</span><span class="s">'',''</span><span class="p">,</span> <span class="s">''''</span><span class="p">))</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">subhead_1</span> <span class="k">if</span> <span class="n">c</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">"Words: "</span><span class="p">)][</span><span class="mi">0</span><span class="p">]</span>\012\012    <span class="k">try</span><span class="p">:</span>\012        <span class="n">reviews_item</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">subheader</span> <span class="k">if</span> <span class="s">''Reviews''</span> <span class="ow">in</span> <span class="n">r</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>\012        <span class="n">reviews_idx</span> <span class="o">=</span> <span class="n">subheader</span><span class="p">.</span><span class="n">index</span><span class="p">(</span><span class="n">reviews_item</span><span class="p">)</span>\012        <span class="n">metadata</span><span class="p">[</span><span class="s">"reviews"</span><span class="p">]</span> <span class="o">=</span> <span class="n">subheader</span><span class="p">[</span><span class="n">reviews_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">].</span><span class="n">text</span>\012\012    <span class="k">except</span><span class="p">:</span>\012        <span class="k">pass</span>\012\012    <span class="k">try</span><span class="p">:</span>\012        <span class="n">metadata</span><span class="p">[</span><span class="s">"favs"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">strip</span><span class="p">(</span><span class="s">"Favs: "</span><span class="p">).</span><span class="n">replace</span><span class="p">(</span><span class="s">'',''</span><span class="p">,</span> <span class="s">''''</span><span class="p">))</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">subhead_2</span> <span class="k">if</span> <span class="n">c</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">''Favs''</span><span class="p">)][</span><span class="mi">0</span><span class="p">]</span>\012    <span class="k">except</span><span class="p">:</span>\012        <span class="n">metadata</span><span class="p">[</span><span class="s">''favs''</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>\012\012    <span class="k">try</span><span class="p">:</span>\012        <span class="n">metadata</span><span class="p">[</span><span class="s">"follows"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">strip</span><span class="p">(</span><span class="s">"Follows: "</span><span class="p">).</span><span class="n">replace</span><span class="p">(</span><span class="s">'',''</span><span class="p">,</span> <span class="s">''''</span><span class="p">))</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">subhead_2</span> <span class="k">if</span> <span class="n">c</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">''Follows''</span><span class="p">)][</span><span class="mi">0</span><span class="p">]</span>\012    <span class="k">except</span><span class="p">:</span>\012        <span class="n">metadata</span><span class="p">[</span><span class="s">''follows''</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>\012\012    <span class="k">try</span><span class="p">:</span>\012        <span class="n">updated_item</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">subheader</span> <span class="k">if</span> <span class="s">''Published''</span> <span class="ow">in</span> <span class="n">r</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>\012        <span class="n">updated_idx</span> <span class="o">=</span> <span class="n">subheader</span><span class="p">.</span><span class="n">index</span><span class="p">(</span><span class="n">updated_item</span><span class="p">)</span>\012        <span class="n">metadata</span><span class="p">[</span><span class="s">"updated"</span><span class="p">]</span> <span class="o">=</span> <span class="n">subheader</span><span class="p">[</span><span class="n">updated_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">].</span><span class="n">text</span>\012    <span class="k">except</span><span class="p">:</span>\012        <span class="k">pass</span>\012\012    <span class="k">try</span><span class="p">:</span>\012        <span class="n">published_item</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">subheader</span> <span class="k">if</span> <span class="s">''Published''</span> <span class="ow">in</span> <span class="n">r</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>\012        <span class="n">published_idx</span> <span class="o">=</span> <span class="n">subheader</span><span class="p">.</span><span class="n">index</span><span class="p">(</span><span class="n">published_item</span><span class="p">)</span>\012        <span class="n">metadata</span><span class="p">[</span><span class="s">"published"</span><span class="p">]</span> <span class="o">=</span> <span class="n">subheader</span><span class="p">[</span><span class="n">published_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">].</span><span class="n">text</span>\012    <span class="k">except</span><span class="p">:</span>\012        <span class="k">pass</span>\012\012    <span class="c1">#metadata["text_idx"] = texts.nrows\012</span>\012    <span class="c1"># add data from the row\012</span>    <span class="n">metadata</span><span class="p">[</span><span class="s">''universe''</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">.</span><span class="n">universe</span>\012    <span class="n">metadata</span><span class="p">[</span><span class="s">''title''</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s">''name''</span><span class="p">]</span>\012\012\012    <span class="n">text</span> <span class="o">=</span> <span class="n">page</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s">"storytext"</span><span class="p">).</span><span class="n">text</span>\012\012    <span class="k">return</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">text</span>\012\012<span class="k">def</span> <span class="nf">scrape_story</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>\012    <span class="s">"""\012    Scrape all pages of a story, including chapters.\012    """</span>\012    <span class="k">try</span><span class="p">:</span>\012        <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="o">=</span> <span class="n">row</span>\012\012        <span class="k">global</span> <span class="n">do_multi</span>\012        <span class="k">if</span> <span class="n">do_multi</span><span class="p">:</span>\012            <span class="n">current</span> <span class="o">=</span> <span class="n">mp</span><span class="p">.</span><span class="n">current_process</span><span class="p">()</span>\012            <span class="n">tqdm_position</span> <span class="o">=</span> <span class="n">current</span><span class="p">.</span><span class="n">_identity</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span>\012        <span class="k">else</span><span class="p">:</span>\012            <span class="n">tqdm_position</span> <span class="o">=</span> <span class="mi">1</span>\012\012        <span class="k">try</span><span class="p">:</span>\012            <span class="n">url_id</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">row</span><span class="p">.</span><span class="nb">id</span><span class="p">).</span><span class="n">zfill</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>\012        <span class="k">except</span><span class="p">:</span>\012            <span class="n">url_id</span> <span class="o">=</span> <span class="n">row</span><span class="p">.</span><span class="nb">id</span>\012\012        <span class="n">page_url</span> <span class="o">=</span> <span class="s">"https://www.fanfiction.net/s/{}/"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">url_id</span><span class="p">)</span>\012        <span class="n">page</span> <span class="o">=</span> <span class="n">bs</span><span class="p">(</span><span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">page_url</span><span class="p">).</span><span class="n">content</span><span class="p">,</span> <span class="s">''lxml''</span><span class="p">)</span>\012\012        <span class="c1"># determine whether a story is had here, if not skip this page.\012</span>        <span class="k">try</span><span class="p">:</span>\012            <span class="n">warning</span> <span class="o">=</span> <span class="n">page</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">"gui_warning"</span><span class="p">)</span>\012            <span class="k">if</span> <span class="n">warning</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">"Story Not Found"</span><span class="p">):</span>\012                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">''fanfic_log.txt''</span><span class="p">,</span> <span class="s">''a''</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>\012                    <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">"Story not found, id: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">row</span><span class="p">.</span><span class="nb">id</span><span class="p">))</span>\012                <span class="k">return</span> <span class="p">[</span><span class="bp">False</span><span class="p">],</span> <span class="p">[</span><span class="bp">False</span><span class="p">]</span>\012        <span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>\012            <span class="c1"># didn''t find warning, so Nonetype has no ''text''\012</span>            <span class="k">pass</span>\012\012        <span class="k">try</span><span class="p">:</span>\012            <span class="c1"># new error - weird blank page\012</span>            <span class="n">warning</span> <span class="o">=</span> <span class="n">page</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">"gui_normal"</span><span class="p">)</span>\012            <span class="k">if</span> <span class="n">warning</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="n">endswith</span><span class="p">(</span><span class="s">"Please check to see you are not using an outdated url."</span><span class="p">):</span>\012                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">''fanfic_log.txt''</span><span class="p">,</span> <span class="s">''a''</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>\012                    <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">"Outdated URL, id: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">row</span><span class="p">.</span><span class="nb">id</span><span class="p">))</span>\012                <span class="k">return</span> <span class="p">[</span><span class="bp">False</span><span class="p">],</span> <span class="p">[</span><span class="bp">False</span><span class="p">]</span>\012        <span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>\012            <span class="k">pass</span>\012\012        <span class="c1"># figure out if story has chapters\012</span>        <span class="n">chapter_select</span> <span class="o">=</span> <span class="n">page</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s">"chap_select"</span><span class="p">)</span>\012        <span class="k">if</span> <span class="n">chapter_select</span><span class="p">:</span>\012            <span class="n">has_chapters</span> <span class="o">=</span> <span class="bp">True</span>\012        <span class="k">else</span><span class="p">:</span>\012            <span class="n">has_chapters</span> <span class="o">=</span> <span class="bp">False</span>\012\012        <span class="c1"># scrape the first page and save data\012</span>\012        <span class="n">metadata</span> <span class="o">=</span> <span class="p">[]</span>\012        <span class="n">text</span> <span class="o">=</span> <span class="p">[]</span>\012\012        <span class="n">metadata_1</span><span class="p">,</span> <span class="n">text_1</span> <span class="o">=</span> <span class="n">scrape_page</span><span class="p">(</span><span class="n">page</span><span class="p">,</span> <span class="n">page_id</span><span class="o">=</span><span class="n">url_id</span><span class="p">,</span> <span class="n">row</span><span class="o">=</span><span class="n">row</span><span class="p">)</span>\012        <span class="n">metadata</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">metadata_1</span><span class="p">)</span>\012        <span class="n">text</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">text_1</span><span class="p">)</span>\012\012        <span class="c1"># if the text has chapters, iterate.\012</span>        <span class="k">if</span> <span class="n">has_chapters</span><span class="p">:</span>\012            <span class="n">n_chapters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">chapter_select</span><span class="p">.</span><span class="n">children</span><span class="p">))</span>\012            <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">position</span><span class="o">=</span><span class="n">tqdm_position</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">n_chapters</span><span class="p">)</span>\012            <span class="k">for</span> <span class="n">chapter_number</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_chapters</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>\012                <span class="n">chap_url</span> <span class="o">=</span> <span class="n">page_url</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">chapter_number</span><span class="p">)</span> <span class="o">+</span> <span class="s">"/"</span>\012                <span class="n">page</span> <span class="o">=</span> <span class="n">bs</span><span class="p">(</span><span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">chap_url</span><span class="p">).</span><span class="n">content</span><span class="p">,</span> <span class="s">''lxml''</span><span class="p">)</span>\012                <span class="n">metadata_chap</span><span class="p">,</span> <span class="n">text_chap</span> <span class="o">=</span> <span class="n">scrape_page</span><span class="p">(</span><span class="n">page</span><span class="p">,</span> <span class="n">page_id</span><span class="o">=</span><span class="n">url_id</span><span class="p">,</span> <span class="n">chapter</span><span class="o">=</span><span class="n">chapter_number</span><span class="p">,</span> <span class="n">row</span><span class="o">=</span><span class="n">row</span><span class="p">)</span>\012                <span class="n">metadata</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">metadata_chap</span><span class="p">)</span>\012                <span class="n">text</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">text_chap</span><span class="p">)</span>\012                <span class="n">pbar</span><span class="p">.</span><span class="n">update</span><span class="p">()</span>\012\012        <span class="k">return</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">text</span>\012\012    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>\012\012\012        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">''fanfic_log.txt''</span><span class="p">,</span> <span class="s">''a''</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>\012            <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">row</span><span class="p">))</span>\012            <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>\012            <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">traceback</span><span class="p">.</span><span class="n">format_exc</span><span class="p">())</span>\012\012        <span class="k">return</span> <span class="p">[</span><span class="bp">False</span><span class="p">],</span> <span class="p">[</span><span class="bp">False</span><span class="p">]</span>\012\012\012\012<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>\012    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="p">.</span><span class="n">ArgumentParser</span><span class="p">()</span>\012    <span class="n">parser</span><span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">''--list''</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s">''index file''</span><span class="p">)</span>\012    <span class="n">parser</span><span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">''--output''</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s">''output file path''</span><span class="p">)</span>\012    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="p">.</span><span class="n">parse_args</span><span class="p">()</span>\012\012    <span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="nb">list</span><span class="p">:</span>\012        <span class="n">list_path</span> <span class="o">=</span> <span class="n">args</span><span class="p">.</span><span class="nb">list</span>\012    <span class="k">else</span><span class="p">:</span>\012        <span class="n">list_path</span> <span class="o">=</span> <span class="s">''story_idx.pck.gz''</span>\012\012    <span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="n">output</span><span class="p">:</span>\012        <span class="n">output_path</span> <span class="o">=</span> <span class="n">args</span><span class="p">.</span><span class="n">output</span>\012    <span class="k">else</span><span class="p">:</span>\012        <span class="n">output_path</span> <span class="o">=</span> <span class="s">''fanfiction.h5''</span>\012\012    <span class="k">print</span><span class="p">(</span><span class="s">''</span><span class="se">\n</span><span class="s">reading story index''</span><span class="p">)</span>\012    <span class="n">stories</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="n">list_path</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s">''gzip''</span><span class="p">)</span>\012    <span class="k">print</span><span class="p">(</span><span class="s">''</span><span class="se">\n</span><span class="s">story index read, scraping {} stories''</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">stories</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>\012\012    <span class="c1"># open hdf5 file to write to\012</span>\012    <span class="nb">filter</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">Filters</span><span class="p">(</span><span class="n">complib</span><span class="o">=</span><span class="s">''lzo''</span><span class="p">,</span> <span class="n">complevel</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>\012    <span class="n">h5f</span> <span class="o">=</span> <span class="n">tables</span><span class="p">.</span><span class="n">open_file</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"a"</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">"fanfiction.net"</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="nb">filter</span><span class="p">)</span>\012\012    <span class="c1"># if metadata table doesn''t exist, make it, otherwise get the reference to it\012</span>    <span class="k">try</span><span class="p">:</span>\012        <span class="n">tab</span> <span class="o">=</span> <span class="n">h5f</span><span class="p">.</span><span class="n">create_table</span><span class="p">(</span><span class="s">''/''</span><span class="p">,</span> <span class="s">"metadata"</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="n">Metadata</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="nb">filter</span><span class="p">)</span>\012    <span class="k">except</span> <span class="n">tables</span><span class="p">.</span><span class="n">exceptions</span><span class="p">.</span><span class="n">NodeError</span><span class="p">:</span>\012        <span class="n">tab</span> <span class="o">=</span> <span class="n">h5f</span><span class="p">.</span><span class="n">get_node</span><span class="p">(</span><span class="s">''/''</span><span class="p">,</span> <span class="s">"metadata"</span><span class="p">)</span>\012\012    <span class="c1"># same with texts, though we''ll use a variable-length unicode\012</span>    <span class="c1"># format, which can only be a single column array.\012</span>    <span class="k">try</span><span class="p">:</span>\012        <span class="n">texts</span> <span class="o">=</span> <span class="n">h5f</span><span class="p">.</span><span class="n">create_vlarray</span><span class="p">(</span><span class="n">h5f</span><span class="p">.</span><span class="n">root</span><span class="p">,</span> <span class="s">''texts''</span><span class="p">,</span>\012                                   <span class="n">tables</span><span class="p">.</span><span class="n">VLUnicodeAtom</span><span class="p">(),</span> <span class="n">filters</span><span class="o">=</span><span class="nb">filter</span><span class="p">)</span>\012    <span class="k">except</span> <span class="n">tables</span><span class="p">.</span><span class="n">exceptions</span><span class="p">.</span><span class="n">NodeError</span><span class="p">:</span>\012        <span class="n">texts</span> <span class="o">=</span> <span class="n">h5f</span><span class="p">.</span><span class="n">get_node</span><span class="p">(</span><span class="s">''/''</span><span class="p">,</span> <span class="s">''texts''</span><span class="p">)</span>\012\012    <span class="c1"># remove stories that have already been scraped\012</span>    <span class="k">print</span><span class="p">(</span><span class="s">''loading ids of stories that have already been scraped...''</span><span class="p">)</span>\012    <span class="c1">#scraped_ids = tab.col(''page_id'')\012</span>    <span class="n">all_scraped_ids</span> <span class="o">=</span> <span class="p">[]</span>\012    <span class="n">scraped_ids</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>\012    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>\012    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">tab</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">tab</span><span class="p">.</span><span class="n">nrows</span><span class="p">):</span>\012        <span class="k">if</span> <span class="n">i</span><span class="o">&gt;</span><span class="mi">0</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">1000000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>\012            <span class="n">all_scraped_ids</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">scraped_ids</span><span class="p">)</span>\012            <span class="n">scraped_ids</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>\012        <span class="n">scraped_ids</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s">''page_id''</span><span class="p">])</span>\012        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>\012\012    <span class="n">all_scraped_ids</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">scraped_ids</span><span class="p">)</span>\012    <span class="n">scraped_ids</span> <span class="o">=</span> <span class="nb">set</span><span class="p">().</span><span class="n">union</span><span class="p">(</span><span class="o">*</span><span class="n">all_scraped_ids</span><span class="p">)</span>\012\012    <span class="k">print</span><span class="p">(</span><span class="s">''looking for stories that have already been scraped (this might take a minute)...''</span><span class="p">)</span>\012\012    <span class="n">already_got</span> <span class="o">=</span> <span class="n">stories</span><span class="p">[</span><span class="s">''id''</span><span class="p">].</span><span class="n">isin</span><span class="p">(</span><span class="n">scraped_ids</span><span class="p">)</span>\012    <span class="k">print</span><span class="p">(</span><span class="s">''</span><span class="se">\n</span><span class="s">Already have {} stories, skipping those''</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">already_got</span><span class="p">)))</span>\012\012    <span class="n">stories</span> <span class="o">=</span> <span class="n">stories</span><span class="p">[</span><span class="o">~</span><span class="n">already_got</span><span class="p">]</span>\012\012\012    <span class="c1"># the row class allows us to write iteratively to the pytable\012</span>    <span class="n">tab_row</span> <span class="o">=</span> <span class="n">tab</span><span class="p">.</span><span class="n">row</span>\012\012    <span class="c1"># figure out where we start &amp; end. each page number is a 7-8 digit int.\012</span>    <span class="k">global</span> <span class="n">do_multi</span>\012    <span class="n">do_multi</span> <span class="o">=</span> <span class="bp">True</span>\012\012    <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">stories</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">position</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>\012\012    <span class="k">if</span> <span class="ow">not</span> <span class="n">do_multi</span><span class="p">:</span>\012\012        <span class="k">for</span> <span class="n">arow</span> <span class="ow">in</span> <span class="n">stories</span><span class="p">.</span><span class="n">iterrows</span><span class="p">():</span>\012            <span class="n">metadata</span><span class="p">,</span> <span class="n">text</span> <span class="o">=</span> <span class="n">scrape_story</span><span class="p">(</span><span class="n">arow</span><span class="p">)</span>\012            <span class="k">for</span> <span class="n">meta</span><span class="p">,</span> <span class="n">tex</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>\012                <span class="k">if</span> <span class="ow">not</span> <span class="n">meta</span><span class="p">:</span>\012                    <span class="c1">#print(meta, tex)\012</span>                    <span class="k">continue</span>\012                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">meta</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>\012                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>\012                        <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">''ascii''</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">''ignore''</span><span class="p">)</span>\012                    <span class="k">try</span><span class="p">:</span>\012                        <span class="n">tab_row</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>\012                    <span class="k">except</span> <span class="nb">TypeError</span><span class="p">:</span>\012                        <span class="c1"># could be a number with a comma..\012</span>                        <span class="n">v</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">v</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">b</span><span class="s">'',''</span><span class="p">,</span> <span class="sa">b</span><span class="s">''''</span><span class="p">))</span>\012                        <span class="n">tab_row</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>\012\012                <span class="n">tab_row</span><span class="p">.</span><span class="n">append</span><span class="p">()</span>\012                <span class="n">texts</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">tex</span><span class="p">))</span>\012\012            <span class="n">tab</span><span class="p">.</span><span class="n">flush</span><span class="p">()</span>\012            <span class="n">texts</span><span class="p">.</span><span class="n">flush</span><span class="p">()</span>\012            <span class="n">pbar</span><span class="p">.</span><span class="n">update</span><span class="p">()</span>\012\012\012    <span class="k">else</span><span class="p">:</span>\012\012\012\012        <span class="c1"># create pool of workers\012</span>        <span class="n">pool</span> <span class="o">=</span> <span class="n">mp</span><span class="p">.</span><span class="n">Pool</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span>\012\012\012\012        <span class="n">results</span> <span class="o">=</span> <span class="n">pool</span><span class="p">.</span><span class="n">imap_unordered</span><span class="p">(</span><span class="n">scrape_story</span><span class="p">,</span> <span class="n">stories</span><span class="p">.</span><span class="n">iterrows</span><span class="p">())</span>\012\012        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>\012            <span class="k">try</span><span class="p">:</span>\012                <span class="c1">#try:\012</span>                <span class="c1">#pdb.set_trace()\012</span>                <span class="n">metadata</span><span class="p">,</span> <span class="n">text</span> <span class="o">=</span> <span class="n">r</span>\012                <span class="k">for</span> <span class="n">meta</span><span class="p">,</span> <span class="n">tex</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>\012                    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">meta</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="n">tex</span><span class="p">):</span>\012                        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">''fanfic_log.txt''</span><span class="p">,</span> <span class="s">''a''</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>\012                            <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="s">''skipping''</span><span class="p">))</span>\012                        <span class="k">continue</span>\012                    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">meta</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>\012                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>\012                            <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">''ascii''</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">''ignore''</span><span class="p">)</span>\012                        <span class="k">try</span><span class="p">:</span>\012                            <span class="n">tab_row</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>\012                        <span class="k">except</span> <span class="nb">TypeError</span><span class="p">:</span>\012                            <span class="c1"># could be a number with a comma..\012</span>                            <span class="n">v</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">v</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">b</span><span class="s">'',''</span><span class="p">,</span> <span class="sa">b</span><span class="s">''''</span><span class="p">))</span>\012                            <span class="n">tab_row</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>\012                    <span class="n">tab_row</span><span class="p">.</span><span class="n">append</span><span class="p">()</span>\012                    <span class="n">texts</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">tex</span><span class="p">))</span>\012\012                <span class="n">tab</span><span class="p">.</span><span class="n">flush</span><span class="p">()</span>\012                <span class="n">texts</span><span class="p">.</span><span class="n">flush</span><span class="p">()</span>\012                <span class="n">pbar</span><span class="p">.</span><span class="n">update</span><span class="p">()</span>\012\012            <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>\012                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">''fanfic_log.txt''</span><span class="p">,</span> <span class="s">''a''</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>\012                    <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>\012                    <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">traceback</span><span class="p">.</span><span class="n">format_exc</span><span class="p">())</span>\012\012\012    <span class="n">h5f</span><span class="p">.</span><span class="n">flush</span><span class="p">()</span>\012    <span class="n">h5f</span><span class="p">.</span><span class="n">close</span><span class="p">()</span></code></pre></figure>\012\012<p>And the smut itself:</p>\012\012<p>(<a href="/blog/assets/hosted/autopotterotica_excerpts.pdf">download a pdf if the embed doesnt work</a>)</p>\012\012<script src="https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.1.1/pdfobject.min.js" integrity="sha256-rYPX3dXq8Nh532EvCS2foeyTgmzbcC8u+nCk/rEtKXA=" crossorigin="anonymous"></script>\012\012<div id="autopotterotica" style="width:100%;min-height:50vh;"></div>\012\012<script>\012    PDFObject.embed(\012    "/blog/assets/hosted/autopotterotica_excerpts.pdf",\012    "#autopotterotica");\012</script>\012\012<!-- <iframe style="width:100%;min-height:50vh;" src=""></iframe> -->\012\012<h2 id="schillbot-20191003">schillbot (2019.10.03)</h2>\012\012<p>To get under the paper-thin skin of our university’s president while he was trying to balance the budget by taking medicine from graduate workers who make poverty wages, I made a twitter bot to mock him. The bot posted either a real quote or a neural-net generated quote and asked people to vote which one they thought it was.</p>\012\012<p>I scraped all his often off-the-rails emails and writing from his website and trained a transformer model. This was before the proliferation of all these newfangled GPT-2 fine-tuned models, so it’s a little rough, but these are some of my favorites:</p>\012\012<p>Look! even the wonderful Janelle Shane helped out!</p>\012\012<blockquote class="twitter-tweet"><p lang="en" dir="ltr">neural net as activism: Univ of Oregon grad students, negotiating to save their health care benefits, raise awareness by training a bot on their university president&#39;s writing<br /><br />via <a href="https://twitter.com/GTFF_3544?ref_src=twsrc%5Etfw">@GTFF_3544</a> <a href="https://t.co/4Jl1nx5fTo">https://t.co/4Jl1nx5fTo</a></p>&mdash; Janelle Shane (@JanelleCShane) <a href="https://twitter.com/JanelleCShane/status/1180271783993200640?ref_src=twsrc%5Etfw">October 5, 2019</a></blockquote>\012<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>\012\012<blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;first we must provide services and I am committed to extraordinarily egregious cost-reduction goals&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1130263478206210048?ref_src=twsrc%5Etfw">May 20, 2019</a></blockquote>\012<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>\012\012<blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;i know some of you read this, roll your eyes, but any of you who know me know i am a little boy.&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1186729816935956480?ref_src=twsrc%5Etfw">October 22, 2019</a></blockquote>\012<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>\012\012<blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;Full combat provost.&quot;</p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1132499163252314112?ref_src=twsrc%5Etfw">May 26, 2019</a></blockquote>\012<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>\012\012<blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;i am committed to doing everything in my power to cushion the impact of this great university&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1181295022538280960?ref_src=twsrc%5Etfw">October 7, 2019</a></blockquote>\012<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>\012\012<blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;please join me in this effort to address these issues as i apologize.&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1181706316303101952?ref_src=twsrc%5Etfw">October 8, 2019</a></blockquote>\012<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>\012\012<blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;over the past several months, we have experienced enormous churn in our boys by opening the doors of establish world-class research&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1187033715743981568?ref_src=twsrc%5Etfw">October 23, 2019</a></blockquote>\012<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>\012\012<blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;i am announcing these decisions now because i am not know the victim or the pain they will be doing&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1132549248413650946?ref_src=twsrc%5Etfw">May 26, 2019</a></blockquote>\012<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>\012\012<blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;i can go on to become one of the reasons why the university athletic fields will be in command of our state.&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1180510220260274176?ref_src=twsrc%5Etfw">October 5, 2019</a></blockquote>\012<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>\012\012<blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;during the summer months of that year, president michael schill shared his thoughts on the university&#39;s priorities: hard rock, my website&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1183827424758288385?ref_src=twsrc%5Etfw">October 14, 2019</a></blockquote>\012<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>\012\012<h2 id="red-eyes-on-statues-20190803">red eyes on statues (2019.08.03)</h2>\012\012<p>A good friend sent me this:</p>\012\012<p><img src="/blog/assets/images/artvol2/redeyes_inspo.png" alt="redeyes inspo" /></p>\012\012<p>So I copied it.</p>\012\012<p>First I made some led-bombs by rigging them up to a 9V battery w/ a photodiode that turns the light off during the day to make them last longer.</p>\012\012<video controls="" preload="none" style="max-height: 70vh;">\012  <source src="/blog/assets/images/artvol2/redeyes_prototype.mp4" type="video/mp4" />\012</video>\012\012<p>Then I attached them to a few statues around UO. I didn’t really photograph or catch much video of this because I was basically in a fugue state from being deliriously heartbroken and it was maybe a little bit of vandalism.</p>\012\012<video controls="" preload="none">\012  <source src="/blog/assets/images/artvol2/redeyes_install.mp4" type="video/mp4" />\012</video>\012\012<h1 id="design">Design</h1>\012\012<h2 id="autopilot-20191017">Autopilot (2019.10.17)</h2>\012\012<p>I released some <a href="https://auto-pi-lot.com">software</a> and wrote a <a href="https://www.biorxiv.org/content/10.1101/807693v1">paper</a> to describe it, and I spent a lot of time to make a beautiful document. Typography is another art I am working to get better at, and I don’t really want to clutter up this post with a million page excerpts, but I am very proud of the way the figures are integrated with the text.</p>\012\012<p>I will include the documentation logo that I like a lot though.</p>\012\012<video controls="" preload="none">\012  <source src="/blog/assets/images/artvol2/autopilot_logo_loop.mp4" type="video/mp4" />\012</video>\012\012<h2 id="union-propaganda">Union Propaganda</h2>\012\012<p>I don’t contribute enough to my union, but the one thing that I do contribute is a bit of design. These were all made during our most recent round of bargaining, which revealed what an amoral disaster of an institution the University of Oregon is.</p>\012\012<h3 class="no_toc" id="uohellnocom">uohellno.com</h3>\012\012<p>This was the website linked to by the schillbot. It works pretty badly on mobile (it was my first d3 scroller), so it will probably work even worse in this little iframe. may just want to visit <a href="https://uohellno.com">uohellno.com</a></p>\012\012<p><a data-fancybox="" data-type="iframe" href="https://uohellno.com" class="iframe-preview">Open demo</a></p>\012\012<h3 class="no_toc" id="salaries">Salaries</h3>\012\012<p>Data available here: <a href="https://github.com/sneakers-the-rat/uoregon_salary_data">https://github.com/sneakers-the-rat/uoregon_salary_data</a></p>\012\012<p><img src="/blog/assets/images/artvol2/gtff_salary.png" alt="UO exec salary nonsense" /></p>\012\012<h3 class="no_toc" id="uoregons-healthcare-swindle">UOregon’s Healthcare Swindle</h3>\012\012<p><img src="/blog/assets/images/artvol2/gtff_longterm.png" alt="longterm insurance costs" /></p>\012\012<h1 id="stupid-bullshit-projects">stupid bullshit projects</h1>\012\012<p>And finally, a bunch of other assorted scraps and pieces presented more or less without comment.</p>\012\012<p><img src="/blog/assets/images/artvol2/the_great_bumblefuck.png" alt="talking 2 people" /></p>\012\012<p>My department does “bullshit research talks” at our retreats, where someone makes a ridiculous presentation and someone else has to present it. Having someone I look up to very much present this neural-net face swap was one of my finest moments.</p>\012\012<p><img src="/blog/assets/images/artvol2/matt_yashar_slide.png" alt="matt yashar slide" /></p>\012\012<p><img src="/blog/assets/images/artvol2/matt_yashar_presentation.jpg" alt="matt yashar morph presentation" /></p>\012\012<p><img src="/blog/assets/images/artvol2/dolphen.jpg" alt="dolphen" /></p>\012\012<p>someone I love very much loves Selena very much, so this was for them.</p>\012\012<p><img src="/blog/assets/images/artvol2/selena_centaur.png" alt="selena centaur" /></p>\012\012<p><img src="/blog/assets/images/artvol2/MRPEANUT.png" alt="mr peanut" /></p>\012\012<p><img src="/blog/assets/images/artvol2/heavy_breathing.jpg" alt="heavy breathing" /></p>\012\012<p><img src="/blog/assets/images/artvol2/eurovision_heatmap.png" alt="eurovision heatmap" /></p>\012\012<video controls="" preload="none" style="max-height: 70vh;">\012  <source src="/blog/assets/images/artvol2/goyles.mp4" type="video/mp4" />\012</video>\012\012<p>This was a gift I made for a dear dear friend that I unfortunately didn’t ever take a photo of the finished version. These panels stack together and have a few very fond memories in them. In this image:  She is the sun, and i am the moon. one of the first memories I have with her is drunkenly fucking up someone else’s car radio (and it also fit iwth the scene), and nowadays I don’t see her much in part because she is busy all over the world &lt;3.</p>\012\012<p><img src="/blog/assets/images/artvol2/jackie_gift.jpg" alt="jackie''s gift" /></p>\012\012<p><img src="/blog/assets/images/artvol2/pitchforkyrnose7.png" alt="pitchfork yr nose" /></p>\012\012<p>Another dear dear friend got married last summer, and her maid of honor asked us to bring a photo of us together to their wedding. Shitty photoshop, but shitty photoshops are sorta one of the things we have a deep and shared love for.</p>\012\012<p><img src="/blog/assets/images/artvol2/kris_faceswapped.png" alt="matt yashar morph presentation" /></p>','\012',char(10)),NULL,'','2020-03-29 07:00:00','Jonny Saunders blog','',NULL,'2024-01-03 18:04:29','read');
INSERT INTO items VALUES('https://jon-e.net/blog/2019/08/25/NSF-GRFP-Advice-And-My-Annotated-Proposal/','NSF GRFP Advice and My Annotated Proposal',replace('<p>I saw this tweet from Mae with the brilliant idea to share her NSF GRFP materials &amp; give a thread of advice:</p>\n\n<blockquote class="twitter-tweet"><p lang="en" dir="ltr">It&#39;s NSF GRFP season!<br /><br />I wanted to go ahead and share my (rejected) 2014 application and (funded) 2015 application.<br /><br />You can find them both here ⬇️<a href="https://t.co/LdAUXPbJXG">https://t.co/LdAUXPbJXG</a></p>&mdash; Mae is a postdoc? 🏳️‍⚧️ 🌸🌺🐜 (@ukleghoul) <a href="https://twitter.com/ukleghoul/status/1165634795193417728?ref_src=twsrc%5Etfw">August 25, 2019</a></blockquote>\n<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>\n\n<p>I’ve had written some scattered advice for Elliot Berkman’s (<a href="https://twitter.com/Psychologician">@Psychologician</a>) GRFP workshop a few years ago, and thought it was a good time to update that and give an annotated version of my proposal. Hopefully this helps someone :)</p>\n\n<h2 id="the-documents">The documents</h2>\n\n<p>If yr just here for some sweet sweet documents, here was my accepted proposal &amp; personal statement. By opening these documents you hereby are ordered to not make fun of my personal statement ;).</p>\n\n<ul>\n  <li><a href="/blog/assets/hosted/JSaunders_GRFP_Proposal.pdf">GRFP Proposal</a></li>\n  <li><a href="/blog/assets/hosted/JSaunders_GRFP_PersonalStatement.pdf">GRFP Personal Statement</a></li>\n</ul>\n\n<h1 id="annotated-proposal">Annotated Proposal</h1>\n\n<p>I’ve embedded the advice I have regarding formatting as annotations using <a href="https://hypothes.is/">hypothes.is</a>, to see them either click on highlighted text or expand the toolbar on the right with the arrow in the top right corner.</p>\n\n<script src="https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.1.1/pdfobject.min.js" integrity="sha256-rYPX3dXq8Nh532EvCS2foeyTgmzbcC8u+nCk/rEtKXA=" crossorigin="anonymous"></script>\n\n<iframe style="width:100%;min-height:90vh;" src="/blog/plugins/pdfjs_hypothesis/viewer/web/viewer.html?file=/blog/assets/hosted/JSaunders_GRFP_Proposal.pdf"></iframe>\n\n<h1 id="advice">Advice</h1>\n\n<h2 id="proposal">Proposal</h2>\n\n<ul>\n  <li>One very common and important piece of general advice - write your research proposal as a reflection of you as a scientist. they are funding <em>you</em> not a project, so the voice in the research proposal doesn’t need to be so austere, but should capture your humble, albeit muted, reverence for this question and science generally - stop short of the flowers though :p.</li>\n</ul>\n\n<h3 id="topic-choice">Topic Choice</h3>\n\n<ul>\n  <li>you’re sorta bound by your lab, but both for inspiration as well as tailoring your language you should check out your local science twitter. follow the people whose names you keep seeing on papers you like, find threads where they’re replying, get a feel both for the hot shit and what people complain about.</li>\n  <li>''’Do whatever you can to be able to include preliminary data.’’ As I mention in the annotations, I think doing the GRFP in your second year is usually a good tradeoff - you get the possibility of preliminary data at the expense of a more competetive application pool, but my (non-empirical) opinion is that the bonus from the obvious feasibility of your experiment pays off.</li>\n  <li>w.r.t global structure, there’s an acronym from debate that I use to help structure arguments generally: <strong>SHITS</strong> - Significance, Harms, Inherency, Topicality, Solvency. Another implicit part of this framework is Impact, but SHITSI is a bad acronym. This framework is useful at the scale of the whole proposal, but also at the scale of each paragraph:\n    <ul>\n      <li><strong>Significance</strong> - How important is the question/knowledge gap that you’re proposing to answer? This should come through first, briefly, in your introduction, but then heavily in your broader impacts.</li>\n      <li><strong>Harms</strong> - What are we prevented from doing/knowing by having this question/knowledge gap unanswered? Why is your proposal important to fund <em>right now?</em></li>\n      <li><strong>Inherency</strong> - What is inherent in the status quo that has prevented this work from being done. Why hasn’t someone already done your experiment? Why are you uniquely able to do this experiment? This should be at the bottom of your introduction/one of the first sentences in your aims.</li>\n      <li><strong>Topicality</strong> - Not as relevant, but staying on topic. You want to make damn sure you answer all the parts of the call for submissions.</li>\n      <li><strong>Solvency</strong> - How does your experiment answer the question/knowledge gap?  This comes through in your aims.</li>\n      <li><strong>Impacts</strong> - What would the results of your experiments mean for science/the world? This is the intellectual merit/broader impacts section.</li>\n    </ul>\n  </li>\n</ul>\n\n<h3 id="space-allocation">Space Allocation</h3>\n\n<p>I spell a lot of this out in the annotated document, but my general guidelines:</p>\n\n<ul>\n  <li><strong>Intro:</strong> 1/3 page. You want to give them just enough information to motivate your experiment without getting them bogged down in the details. This is easy to overdo - in general if you need more room than this than you aren’t writing generally enough</li>\n  <li><strong>Aims:</strong> 2 1/3 page aims. Pick two specific experiments that you can describe succinctly. You need to 1) introduce the questiont they they answer, 2) describe the experiment in broad strokes 3) describe how it will answer the question and 4) add a little sugar of future directions or alternative analyses. If you get bogged down in methodological details in your aims there’s no chance you’ll be able to do all of those in the space provided. More on this in ‘scope’</li>\n  <li><strong>Future Directions:</strong> 2-3 sentences. Thes are to make clear that a) you have options, and the two aims are just examples of what you can do, and b) that you can think expansively about science and don’t have ‘tunnelvision’ for what <em>might</em> have been handed to your by PI :P</li>\n  <li><strong>Intellectual Merit:</strong> 1/3 page</li>\n  <li><strong>Broader Impact:</strong> 1/3 page - do not shortchange these sections! If it looks like you’re just phoning these in that’s the end of your proposal.</li>\n  <li><strong>Figures:</strong> I usually think the benefit of a figure is not worth the space they take. If you are including data that’s basically a bar chart with different means, just say “my preliminary data says x is greater than y.” I don’t really know when it would be good to include a figure from someone else’s work. If your experiment relies on a reasonably complex, but still visualizable model that’s one of the exceptions that I would consider worth it (if the model is just two boxes with reciprocal arrows between them then imo you’re still better off describing it in words).</li>\n</ul>\n\n<h3 id="scopedetail-of-aims">Scope/Detail of Aims</h3>\n\n<ul>\n  <li>Err on the side of generality - your reviewer should know what you’re talking about and be able to infer some specifics of the experiment, but not much more. Some reasons:\n    <ol>\n      <li><strong>Specific/tricky methods don’t impress in this context</strong> - you always lose the ‘novelty/competence’ race in this proposal. If what you’re describing is ‘cool enough’ to warrant specific description, it’s also probably hard enough that the reader would doubt you’ll be able to pull it off. Not to say simplify your proposed experiments, just that greater detail doesn’t help (read: complicated methods don’t do a good job of demonstrating that ‘you know what you’re talking about’).</li>\n      <li><strong>Specificity generates doubt</strong> - relatedly, the more specifically an experiment is described, the easier it is for the reader to to dismiss as “I don’t think that would work/they could do that.” Don’t give them a shortcut to go to the next proposal. Every specific method you discuss also needs some affirmation that you/your lab is capable of doing it, so you’re always double-dipping on space by going more specific.</li>\n      <li><strong>Focusing on methods to demonstrate competency backfires</strong> - we’ve all seen first science talks that are 10 minutes of too-specific methods and 5 minutes of bar charts because they’re unsure what to do with all those numbers. Don’t give the impression that you’re too focused on the practical elements of <em>what you’re doing</em> at the expense of <em>what it means.</em></li>\n      <li><strong>Give the reviewer room to imagine</strong> - you should give plenty of room for the reader to imagine what else might come up along the way (you should also briefly and explicitly outline what that might be). A dense thicket of methods makes brings the level of their imagination down to practicalities, rather than at the level of ideas.</li>\n    </ol>\n  </li>\n  <li>Structure your aims so that you will get useful information no matter what the results are: if you’re looking for evidence of a theory, describe what that would look like <em>but also</em> explain what failing to find evidence for that would mean.</li>\n</ul>\n\n<h3 id="collaboration">Collaboration</h3>\n\n<ul>\n  <li>talk about it. a lot. especially in neuroscience people want to see you bridging fields (and you should want to anyway because it’s fun), but most science is interdisciplinary and thus benefits from expert input from diverse fields.\n    <ol>\n      <li>Use it as a way of assuaging competency/capability fears. “it sounds like they’ll have a lot of help”</li>\n      <li>use it to offset the generality from the lack of methodological specificity. “one of their collaborators will fill in any blank spots”</li>\n    </ol>\n  </li>\n  <li>accordingly, start reaching out to potential collaborators asap. You don’t have to <em>do</em> everything in your proposal exactly as you describe it, but you <em>definitely don’t</em> want to lie about people you are working with.</li>\n</ul>\n\n<h3 id="formatting">Formatting</h3>\n\n<ul>\n  <li>Don’t be shy about numbering in-paragraph, especially in intellectual merit section, but anywhere where your writing could become “blippy.” eg. you want to cover five distinct ways your work would be important that don’t necessarily flow together.</li>\n  <li>Don’t waste space on whitespace, but keep it readable. Use the formatting slack they give you to your advantage: Head your sections with bold, indented text, but don’t break afterwards - just give four spaces and head into the paragraph</li>\n  <li>You should have to use 2-4 citations, but bring the size down to 10, do in-text citations with numbers, like (2), use an abbreviated format, something like\n    <ul>\n      <li>\n        <ol>\n          <li>Rauschecker JP, Scott SK. <strong>Nat. Neurosci.</strong> (2009) <em>12:718-724</em></li>\n        </ol>\n      </li>\n    </ul>\n  </li>\n</ul>\n\n<h2 id="personal-statement">Personal Statement</h2>\n\n<p>First, I don’t think my personal statement is especially good, so this advice is probably not the greatest, but I’ll include my thoughts just for completeness sake.</p>\n\n<h3 id="style">Style</h3>\n\n<ul>\n  <li>Above all, be sincere. There are two extremes of “robotically listing your CV” and “a dramatic poetic reading of your life,” if you don’t speak like that, don’t write like it.</li>\n  <li>Human-readable but not flowery, watch your adjective frequency.</li>\n  <li>Don’t oversell yourself or appear boastful, but make it clear that you are your reviewer’s sober, capable colleague that doesn’t know everything but can work with people to figure it out.</li>\n  <li>Write about yourself, but for every thought that is a description of yourself, include a few that are your thoughts about other things (you’re already the subject of your sentences, do ya really need to be the object too? :p)</li>\n</ul>\n\n<h3 id="content">Content</h3>\n\n<ul>\n  <li>Good rule-of-thumb guiding questions are\n    <ol>\n      <li>Describe why you are a scientist and</li>\n      <li>why that makes you a good one.</li>\n    </ol>\n  </li>\n  <li>Give a sense of your path in science without being a CV or tale of personal drama and woe. Stopping short of artifice/and um.. lies…, use some quality/etc. as a framework for motivating the moves in your personal history. Compare:\n    <ul>\n      <li>“I have a deep and abiding love of hugs, so I started working in a hug factory where I dove deeper into the principles of warmth and proximity, this led me to studying knot theory… etc.” vs.</li>\n      <li>“I worked in the prestigious hug factory under overseer x, and eventually was able to work my way up the ladder back into the ivory tower to study knot theory.”</li>\n    </ul>\n  </li>\n  <li>Shy away from cliche - “I knew i wanted to be an entomologist since i was 4 and i let a bunch of ants crawl all over my bare belly”</li>\n</ul>\n\n<h3 id="interplay-w-proposal">Interplay w/ Proposal</h3>\n\n<ul>\n  <li>Don’t even give the remotest whiff that you’re using it as an extension of your research proposal, but to set up some of the more basic elements like your propensity for collaboration and your motivation for whatever broader impact you call out. ie. does your personal statement support what you describe as your broader impact?</li>\n  <li>use similar language as a callback (but not repetitively).</li>\n</ul>\n\n<h2 id="writing-generally">Writing Generally:</h2>\n\n<ul>\n  <li>Your writing is the clothes your ideas wear and the dance moves they know, they could be the best ones in the pack but if they look and move like shit the proposal won’t get picked up.</li>\n  <li>Your writing should feel sparse, brisk; the research proposal especially. If there are any sentences you have to read twice, simplify them. If there are any sentences that break over approximately two lines, simplify and split them.</li>\n  <li>To check the rhythm of your writing, read it out loud to yourself, record it, listen to the recording. If there are sections where you feel your words getting twisted around one another, break them up. If the rhythm of your speech, the distribution of empty space - ie. the distribution of sentence lengths and punctuation - is not conversational it will be hard to read.</li>\n  <li>For the love of all that is holy no cliched phrasing or scientific buzzwords\n    <ul>\n      <li>eg. “elucidate the mechanisms of,” “we know a lot about x, but y is poorly understood,” etc.</li>\n    </ul>\n  </li>\n  <li>The book “On Writing Well” by William Zinsser is indispensable for next-leveling your writing. I can provide relevant chapters if requested.</li>\n</ul>\n\n<h1 id="reviews">Reviews</h1>\n\n<table>\n  <thead>\n    <tr>\n      <th>Intellectual Merit Rating</th>\n      <th>Intellectual Merit Comments</th>\n      <th>Broader Impacts Rating</th>\n      <th>Broader Impacts Comments</th>\n      <th>Summary Statement</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Very Good</td>\n      <td>The applicant has a below average academic record compared to the applicant pool. His proposal idea is interesting, however I am skeptical that phonetics can be effectively studied in mice and how that would relate across species. The proposal and preliminary data are pretty innovative!</td>\n      <td>Very Good</td>\n      <td>The applicant has distributed tools to other researchers. He has also took part in teaching and mentoring activities</td>\n      <td>Thinking outside the box and trying to study interesting phenomena is the way to go in neuroscience.</td>\n    </tr>\n    <tr>\n      <td>Excellent</td>\n      <td>Dynamic project involving a new behavior paradigm and cutting-edge technique. Supervisors speak exeptionally well of his lab skills.</td>\n      <td>Excellent</td>\n      <td>Commitment to open science initiatives and data sharing, key aspects of transformative neuroscience.</td>\n      <td>An innovative project, combining neuroscience and some strong engineering skills, with broad relevance in basic science. Really the perfect GRF application.</td>\n    </tr>\n    <tr>\n      <td>Excellent</td>\n      <td>The applicant has great passion, exceptional creativity and hands-on ability on research. During his undergraduate research, he did not only collective data with whole-cell patch clamp technique, but also had deep understanding of the question he was tackling and made interpretation of the results he got. His research experience in his PhD lab shows his outstanding depth of thinking and work ethic. The applicant also got great letters attest his talent on research. The applicant proposed to establish the mouse model for speech perception. This is a very intriguing but challenging project. Impressively, the applicant managed to get promising preliminary data.</td>\n      <td>Excellent</td>\n      <td>The applicant’s goal is to contribute to,the achievement of open publication and free online courses. He plans to share the programs that he wrote and the data that he acquired with the community. He also plans to adapt existing systems to facilitating the distribution of data for smaller labs without expensive servers. His goal and endeavor may profoundly benefit the research community.</td>\n      <td>The applicant is strong in both intellectual merit and broader impact. He is fully prepared for his graduate career. His excellent research ability and commitment to the science education and accessibility will make him a successful scientist.</td>\n    </tr>\n  </tbody>\n</table>','\n',char(10)),NULL,'','2019-08-25 07:00:00','Jonny Saunders blog','',NULL,'2024-01-03 18:04:29','read');
INSERT INTO items VALUES('https://jon-e.net/blog/2019/07/24/Music-of-Music-and-the-Brain/','Music of Music and the Brain',replace('<p>I’m just finishing teaching another Summer Edition (tm) of my Music and the Brain course, and in an fit of raw grading-aversion and sentimentality needed to compile the music we listened to together into a few playlists.</p>\n\n<h1 id="music-of-music-and-the-brain">Music of Music and the Brain</h1>\n\n<p>For some reason every Music &amp; whatever-object-of-psychology-or-neuroscience course needs to only use the classical canon and a healthy dose of dad rock as examples. Probably because they are mostly taught by dads. That’s a shame because if anyone purports to teach some universal principles of “music” and “the brain” but only uses a tiny sliver of the world’s music it seems somewhat inevitable that they’ll be backed into a corner clutching the particularities of that sliver close to your chest as if it contained all the world’s hidden musical universals.</p>\n\n<p>That, and it’s more fun for everyone to listen to music that … they actually listen to.</p>\n\n<iframe src="https://open.spotify.com/embed/playlist/51lKmoGMqIhrnTUNLBmOmY" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>\n\n<p>I’m in the process of remaking the course materials into a website, so when I do that (and actually finish grading the course) I’ll describe how I use each of these tracks.</p>\n\n<h1 id="hip-hop-of-music-and-the-brain">Hip-Hop of Music and the Brain</h1>\n\n<p>The next three playlists are all from my student’s problem sets.</p>\n\n<p>Science and Academia is essentially allergic to hip-hop, so one feature of this course is that it has 100% more hip-hop listening and instruction than is usual. These songs come from a problem set where I asked them to get deep into the rhyme structure of a verse to learn about speech perception/production and auditory working memory</p>\n\n<iframe src="https://open.spotify.com/embed/playlist/1TpGqXHpQoKXNlHj8OARCj" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>\n\n<h1 id="buildups-and-drops-of-music-and-the-brain">Buildups and Drops of Music and the Brain</h1>\n\n<p>This playlist comes from a problem set that teaches about midbrain dopaminergic reward-prediction error signaling and its purported role in musical expectation and pleasure. I asked my students to pick a song with a satisfying (or unsatisfying) buildup and describe how specific moments would translate into an RPE signal and dopamine release (or suppression). Some of these songs are real bangers which made it pretty tricky to stay focused on grading…</p>\n\n<iframe src="https://open.spotify.com/embed/playlist/6ccN5a6MIpgrBn3vPBlwQy" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>\n\n<h1 id="feelings-of-music-and-the-brain">Feelings of Music and the Brain</h1>\n\n<p>My student’s answers to this problem melted my heart for good. I asked them to describe a song that has affected them emotionally – I hoped that leaving it open ended would give them a chance to reflect on the subtlety and intensity of musical emotions, and how our current understanding of the neurophysiology of music doesn’t really come close to explaining it.</p>\n\n<p>I also had no idea that they would be so affected by video game music - I don’t remember it being that good when I played video games - but I guess it’s really matured as an art form, go figure.</p>\n\n<iframe src="https://open.spotify.com/embed/playlist/6y2q4ck6lK9x4x0DAq0QKB" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>\n\n<p>A few quotes that I thought were very sweet (and not too personal):</p>\n\n<h2 id="wicked---for-good">Wicked - For Good</h2>\n\n<blockquote>\n  <p>“When I was in high school in Indonesia, the final project for my English class was to create a drama/musical with my whole class. My class chose to reenact Wicked, but we changed a few things from the plot. Surprisingly, I was casted as Glinda and being a shy person, I was terrified, but I did it anyway. My friend who was casted as Elphaba sang “For Good” with me.\nWhen we had our final rehearsals, we were really emotional because I think we, as a class, just realized that this was our last project together, and so the song made a huge impact on us, emotionally.\nNow, when I listen to it, I feel nostalgic, happy, and sad at the same time. I’m happy that I went through hell with them with rehearsals and stuff, but I’m also sad that that time has passed. Everything was bittersweet.”</p>\n</blockquote>\n\n<h2 id="talking-heads---this-must-be-the-place">Talking Heads - This Must Be The Place</h2>\n\n<blockquote>\n  <p>“This Must Be the Place (Naive Melody) by Talking Heads is definitely one of my favorite songs of all time. For me, it encompasses so many different emotions and that’s what attracts me to it so much. The melody itself is something that gets better every time I listen to it, which is quite often, and David Byrne’s nonsensical lyric writing captures something very surreal about life yet also captures very tangible feelings for me. It is kind of a love song, but also a song about life and knowing David Byrne, you can’t really pinpoint anything that it could be about because he never wrote things for the purpose of being understood. This might be why I love it the most. I’ve experienced a lot in my life that has been both happy and sad at the same time, and trying to find the silver lining in everything has always been important to me. No matter what mood I’m in, this song always seems to speak to me and let me know that everything is happening how it is supposed to.”</p>\n</blockquote>\n\n<h2 id="adele---someone-like-you">Adele - Someone Like You</h2>\n\n<blockquote>\n  <p>“This might be corny or basic, but a song that makes me unconditionally emotional is “Someone Like You” by Adele.  The beat is so gentle in the beginning leading up to the chorus the song it starts to build.  When you truly listen to the lyrics it’ll make you miss someone you don’t really want to miss.  Or sometimes it reminds me of someone I used to be close to and have grown apart from.  I mean Adele could sing about anything and it would probably make me feel some type of way.”</p>\n</blockquote>\n\n<h2 id="the-beatles---hey-jude">The Beatles - Hey Jude</h2>\n\n<blockquote>\n  <p>“One piece of music that affects me emotionally is Hey Jude by the Beatles. When I was in 5th grade my mom told me she wanted me to perform in the talent show, so she hired a guitar teacher to teach me the song. After a few months of lessons, I learned the Beatles song and decided I was up to the challenge of performing in front of an audience. This performance did not go well, causing me to be very embarrassed. To this day, the song still brings back a sense of embarrassment every time I hear it.”</p>\n</blockquote>\n\n<h2 id="the-cinematic-orchestra---to-build-a-home">The Cinematic Orchestra - To Build A Home</h2>\n\n<blockquote>\n  <p>“A piece of music that has affected me emotionally is To Build A Home by Cinematic Orchestra. The song is simple, with just a piano, strings, and a voice. It builds and swells beautifully and the lyrics are all about building a life with someone just for it to be taken away. The first time I heard this song was in an end-of-season marching band recap video, which my brother had made for my senior class, since we had all been in the program for more than 4 years. The combination of videos and photos of us and the music was overwhelming. Our director had also just quit at the end of our season, and we were pretty heartbroken seeing him for the last time in that video. The song is solemn and melancholy on it’s own as well, I believe it’s listed in the top 10 saddest lyrical songs on youtube.”</p>\n</blockquote>\n\n<h2 id="twothirds--laura-brehm---waking-dreams-hellberg-remix">TwoThirds &amp; Laura Brehm - Waking Dreams (Hellberg Remix)</h2>\n\n<blockquote>\n  <p>“Although I generally don’t listen to this kind of music, this particular song has a lot of emotional weight for me, mostly in the form of nostalgia, and I suppose a small amount of “bittersweetness”. It was used for the intro of a YouTube channel that I watched a lot of during my 8th grade year and high school and listening to this song now brings me back to that time in my life, which was much simpler and also more hopeful overall. It was just a time in which a lot of things came together in my life, and I associate it with this song more than anything else.”</p>\n</blockquote>','\n',char(10)),NULL,'','2019-07-24 07:00:00','Jonny Saunders blog','',NULL,'2024-01-03 18:04:29','read');
INSERT INTO items VALUES('https://jon-e.net/blog/2019/07/23/Automating-Poll-Tweets-In-The-New-Layout-Hellscape/','Automating Poll Tweets in the New Layout Hellscape',replace('<p>Yes, the new Twitter layout is so o o bad, but it also broke my bot that uses Selenium to post polls (a weird missing part of the Twitter API).</p>\n\n<p>Here are some new selectors that should be useful.</p>\n\n<p>While I’m at it, I’ll explain a few pieces of rest of this slightly-trickier-than-usual bot. (I’m sure I borrowed most of this code from somewhere but I can’t remember where :(, sorry knowledge hole.)</p>\n\n<p><a href="https://github.com/sneakers-the-rat/schillbot">See the full repo</a></p>\n\n<p>Your bot will do this:</p>\n\n<video controls="">\n  <source src="/blog/assets/images/schillbot_vid.mp4" type="video/mp4" />\n</video>\n\n<h1 id="imports">Imports</h1>\n\n<p>This uses selenium and a few other standards, here’s all them parts</p>\n\n<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">logging</span>\n<span class="kn">import</span> <span class="nn">os</span>\n<span class="kn">import</span> <span class="nn">random</span>\n<span class="kn">import</span> <span class="nn">time</span>\n<span class="kn">import</span> <span class="nn">traceback</span>\n<span class="kn">import</span> <span class="nn">json</span>\n\n<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>\n<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>\n\n<span class="kn">from</span> <span class="nn">selenium</span> <span class="kn">import</span> <span class="n">webdriver</span>\n<span class="kn">from</span> <span class="nn">selenium.common.exceptions</span> <span class="kn">import</span> <span class="n">StaleElementReferenceException</span><span class="p">,</span> <span class="n">TimeoutException</span>\n<span class="kn">from</span> <span class="nn">selenium.webdriver.chrome.options</span> <span class="kn">import</span> <span class="n">Options</span>\n<span class="kn">from</span> <span class="nn">selenium.webdriver.common.by</span> <span class="kn">import</span> <span class="n">By</span>\n<span class="kn">from</span> <span class="nn">selenium.webdriver.common.keys</span> <span class="kn">import</span> <span class="n">Keys</span>\n<span class="kn">from</span> <span class="nn">selenium.webdriver.support</span> <span class="kn">import</span> <span class="n">expected_conditions</span> <span class="k">as</span> <span class="n">EC</span>\n<span class="kn">from</span> <span class="nn">selenium.webdriver.support.wait</span> <span class="kn">import</span> <span class="n">WebDriverWait</span></code></pre></figure>\n\n<h1 id="parameter-classes">Parameter classes</h1>\n\n<p>A few classes to hold our parameters. The primary class here is <code class="language-plaintext highlighter-rouge">TwitterLocator</code>. To manipulate the web zone you need to know what to click on, what to scroll to, heck even what to type in. We use selenium’s <code class="language-plaintext highlighter-rouge">By</code> module and make tuples for each as class attributes. Some of these were pretty heinous to find after the homepage update, so they’ll probably change next week and ymmv.</p>\n\n<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">URL</span><span class="p">:</span>\n    <span class="n">TWITTER</span> <span class="o">=</span> <span class="s">''http://twitter.com''</span>\n\n<span class="k">class</span> <span class="nc">Constants</span><span class="p">:</span>\n    <span class="n">USERNAME</span> <span class="o">=</span> <span class="n">creds</span><span class="p">[</span><span class="s">''USER''</span><span class="p">]</span>\n    <span class="n">PASSWORD</span> <span class="o">=</span> <span class="n">creds</span><span class="p">[</span><span class="s">''PASS''</span><span class="p">]</span>\n    <span class="n">GLOBAL_ENTRY_Q</span> <span class="o">=</span> <span class="s">''#globalentry''</span>\n\n\n<span class="k">class</span> <span class="nc">TwitterLocator</span><span class="p">:</span>\n    <span class="c1"># login stuff\n</span>    <span class="n">login_btn</span>        <span class="o">=</span> <span class="p">(</span><span class="n">By</span><span class="p">.</span><span class="n">CLASS_NAME</span><span class="p">,</span> <span class="s">"StaticLoggedOutHomePage-buttonLogin"</span><span class="p">)</span>\n    <span class="n">username</span>         <span class="o">=</span> <span class="p">(</span><span class="n">By</span><span class="p">.</span><span class="n">CLASS_NAME</span><span class="p">,</span> <span class="s">"js-username-field"</span><span class="p">)</span>\n    <span class="n">password</span>         <span class="o">=</span> <span class="p">(</span><span class="n">By</span><span class="p">.</span><span class="n">CLASS_NAME</span><span class="p">,</span> <span class="s">"js-password-field"</span><span class="p">)</span>\n\n    <span class="c1"># tweet stuff\n</span>    <span class="n">outer_tweet_box</span>  <span class="o">=</span> <span class="p">(</span><span class="n">By</span><span class="p">.</span><span class="n">CLASS_NAME</span><span class="p">,</span> <span class="s">''public-DraftStyleDefault-block''</span><span class="p">)</span>\n    <span class="n">tweet_box</span>        <span class="o">=</span> <span class="p">(</span><span class="n">By</span><span class="p">.</span><span class="n">CLASS_NAME</span><span class="p">,</span> <span class="s">"public-DraftEditor-content"</span><span class="p">)</span>\n    <span class="n">tweet_btn</span>        <span class="o">=</span> <span class="p">(</span><span class="n">By</span><span class="p">.</span><span class="n">XPATH</span><span class="p">,</span> <span class="s">"//*[@data-testid=''toolBar'']//div[2]//div[3]"</span><span class="p">)</span>\n\n    <span class="c1"># poll stuff\n</span>    <span class="n">poll_btn</span>         <span class="o">=</span> <span class="p">(</span><span class="n">By</span><span class="p">.</span><span class="n">XPATH</span><span class="p">,</span> <span class="s">''//div[@aria-label="Add poll"]''</span><span class="p">)</span>\n    <span class="n">option_one</span>       <span class="o">=</span> <span class="p">(</span><span class="n">By</span><span class="p">.</span><span class="n">NAME</span><span class="p">,</span> <span class="s">''Choice1''</span><span class="p">)</span>\n    <span class="n">option_two</span>       <span class="o">=</span> <span class="p">(</span><span class="n">By</span><span class="p">.</span><span class="n">NAME</span><span class="p">,</span> <span class="s">''Choice2''</span><span class="p">)</span>\n\n    <span class="c1"># etc.\n</span>    <span class="n">search_input</span>     <span class="o">=</span> <span class="p">(</span><span class="n">By</span><span class="p">.</span><span class="n">ID</span><span class="p">,</span> <span class="s">"search-query"</span><span class="p">)</span>\n    <span class="n">like_btn</span>         <span class="o">=</span> <span class="p">(</span><span class="n">By</span><span class="p">.</span><span class="n">CLASS_NAME</span><span class="p">,</span> <span class="s">"HeartAnimation"</span><span class="p">)</span>\n    <span class="n">latest_tweets</span>    <span class="o">=</span> <span class="p">(</span><span class="n">By</span><span class="p">.</span><span class="n">PARTIAL_LINK_TEXT</span><span class="p">,</span> <span class="s">''Latest''</span><span class="p">)</span></code></pre></figure>\n\n<h1 id="pollbot-itself">PollBot itself</h1>\n\n<p>It starts innocently enough, loading a basic <a href="http://chromedriver.chromium.org/downloads">Chrome webdriver</a> and loading the homepage. You’ll have to add your chromedriver to your path, eg. <code class="language-plaintext highlighter-rouge">export PATH=$PATH:/path/to/chromedriver/folder</code>. Uncomment the ‘–headless’ line if you don’t want it popping up on you.</p>\n\n<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">PollBot</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>\n\n    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>\n        <span class="bp">self</span><span class="p">.</span><span class="n">locator_dictionary</span> <span class="o">=</span> <span class="n">TwitterLocator</span><span class="p">.</span><span class="n">__dict__</span>\n        <span class="bp">self</span><span class="p">.</span><span class="n">chrome_options</span> <span class="o">=</span> <span class="n">Options</span><span class="p">()</span>\n        <span class="c1">#self.chrome_options.add_argument("--headless")\n</span>        <span class="bp">self</span><span class="p">.</span><span class="n">browser</span> <span class="o">=</span> <span class="n">webdriver</span><span class="p">.</span><span class="n">Chrome</span><span class="p">(</span><span class="n">chrome_options</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">chrome_options</span><span class="p">)</span>\n        <span class="bp">self</span><span class="p">.</span><span class="n">browser</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">URL</span><span class="p">.</span><span class="n">TWITTER</span><span class="p">)</span>\n        <span class="bp">self</span><span class="p">.</span><span class="n">timeout</span> <span class="o">=</span> <span class="mi">2</span>\n        </code></pre></figure>\n\n<p>The guts of the class uses the <code class="language-plaintext highlighter-rouge">TwitterLocator</code> class to navigate the site by overloading the <code class="language-plaintext highlighter-rouge">__getattr__</code>. We use a few <code class="language-plaintext highlighter-rouge">WebDriverWait</code>s to make sure the thing we’re looking for is on the page, and then <code class="language-plaintext highlighter-rouge">find_element</code></p>\n\n<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="k">def</span> <span class="nf">_find_element</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">loc</span><span class="p">):</span>\n        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">browser</span><span class="p">.</span><span class="n">find_element</span><span class="p">(</span><span class="o">*</span><span class="n">loc</span><span class="p">)</span>\n\n    <span class="k">def</span> <span class="nf">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">what</span><span class="p">):</span>\n        <span class="k">try</span><span class="p">:</span>\n            <span class="k">if</span> <span class="n">what</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">locator_dictionary</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>\n                <span class="k">try</span><span class="p">:</span>\n                    <span class="n">element</span> <span class="o">=</span> <span class="n">WebDriverWait</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">browser</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">timeout</span><span class="p">).</span><span class="n">until</span><span class="p">(</span>\n                        <span class="n">EC</span><span class="p">.</span><span class="n">presence_of_element_located</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">locator_dictionary</span><span class="p">[</span><span class="n">what</span><span class="p">])</span>\n                    <span class="p">)</span>\n                <span class="k">except</span><span class="p">(</span><span class="n">TimeoutException</span><span class="p">,</span> <span class="n">StaleElementReferenceException</span><span class="p">):</span>\n                    <span class="n">traceback</span><span class="p">.</span><span class="n">print_exc</span><span class="p">()</span>\n\n                <span class="k">try</span><span class="p">:</span>\n                    <span class="n">element</span> <span class="o">=</span> <span class="n">WebDriverWait</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">browser</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">timeout</span><span class="p">).</span><span class="n">until</span><span class="p">(</span>\n                        <span class="n">EC</span><span class="p">.</span><span class="n">visibility_of_element_located</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">locator_dictionary</span><span class="p">[</span><span class="n">what</span><span class="p">])</span>\n                    <span class="p">)</span>\n                <span class="k">except</span><span class="p">(</span><span class="n">TimeoutException</span><span class="p">,</span> <span class="n">StaleElementReferenceException</span><span class="p">):</span>\n                    <span class="n">traceback</span><span class="p">.</span><span class="n">print_exc</span><span class="p">()</span>\n                <span class="c1"># I could have returned element, however because of lazy loading, I am seeking the element before return\n</span>                <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_find_element</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">locator_dictionary</span><span class="p">[</span><span class="n">what</span><span class="p">])</span>\n        <span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>\n            <span class="nb">super</span><span class="p">(</span><span class="n">PollBot</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__getattribute__</span><span class="p">(</span><span class="s">"method_missing"</span><span class="p">)(</span><span class="n">what</span><span class="p">)</span></code></pre></figure>\n\n<p>We’ll chain together two methods and I guess quit too.</p>\n\n<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">post_text</span><span class="p">):</span>\n        <span class="bp">self</span><span class="p">.</span><span class="n">login</span><span class="p">()</span>\n        <span class="bp">self</span><span class="p">.</span><span class="n">tweet_poll</span><span class="p">(</span><span class="n">post_text</span><span class="p">)</span>\n        <span class="bp">self</span><span class="p">.</span><span class="n">browser</span><span class="p">.</span><span class="n">quit</span><span class="p">()</span></code></pre></figure>\n\n<h2 id="login">Login</h2>\n\n<p>So when we do things like <code class="language-plaintext highlighter-rouge">.login()</code> we just chain together a bunch of attribute calls - calling <code class="language-plaintext highlighter-rouge">self.login_btn</code> calls <code class="language-plaintext highlighter-rouge">self.__getattr__(self, ''login_btn'')</code> - and selenium commands. We get pretty sleepy through all these methods because this bot doesn’t care about FAST POSTS and has bad internet.</p>\n\n<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="k">def</span> <span class="nf">login</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">username</span><span class="o">=</span><span class="n">Constants</span><span class="p">.</span><span class="n">USERNAME</span><span class="p">,</span> <span class="n">password</span><span class="o">=</span><span class="n">Constants</span><span class="p">.</span><span class="n">PASSWORD</span><span class="p">):</span>\n        <span class="bp">self</span><span class="p">.</span><span class="n">login_btn</span><span class="p">.</span><span class="n">click</span><span class="p">()</span>\n        <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\n        <span class="bp">self</span><span class="p">.</span><span class="n">username</span><span class="p">.</span><span class="n">click</span><span class="p">()</span>\n        <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>\n        <span class="bp">self</span><span class="p">.</span><span class="n">username</span><span class="p">.</span><span class="n">send_keys</span><span class="p">(</span><span class="n">username</span><span class="p">)</span>\n        <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>\n        <span class="bp">self</span><span class="p">.</span><span class="n">password</span><span class="p">.</span><span class="n">click</span><span class="p">()</span>\n        <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>\n        <span class="bp">self</span><span class="p">.</span><span class="n">password</span><span class="p">.</span><span class="n">send_keys</span><span class="p">(</span><span class="n">password</span><span class="p">)</span>\n        <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>\n        <span class="bp">self</span><span class="p">.</span><span class="n">browser</span><span class="p">.</span><span class="n">find_elements_by_css_selector</span><span class="p">(</span><span class="s">".clearfix&gt;.submit"</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">click</span><span class="p">()</span>\n        <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span></code></pre></figure>\n\n<h2 id="tweet-poll">Tweet poll</h2>\n\n<p>Once we’re logged in, go ahead and tweet the poll already. More of the same song and dance.</p>\n\n<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="k">def</span> <span class="nf">tweet_poll</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">post_text</span><span class="p">):</span>\n\n        <span class="c1"># click the tweet box\n</span>        <span class="bp">self</span><span class="p">.</span><span class="n">outer_tweet_box</span><span class="p">.</span><span class="n">click</span><span class="p">()</span>\n        <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\n\n        <span class="c1"># type the tweet\n</span>        <span class="bp">self</span><span class="p">.</span><span class="n">tweet_box</span><span class="p">.</span><span class="n">send_keys</span><span class="p">(</span><span class="s">''</span><span class="se">\"</span><span class="s">''</span> <span class="o">+</span> <span class="n">post_text</span><span class="p">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">+</span> <span class="s">''</span><span class="se">\"</span><span class="s"> uohellno.com''</span><span class="p">)</span>\n        <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\n\n        <span class="c1"># make the poll\n</span>        <span class="bp">self</span><span class="p">.</span><span class="n">poll_btn</span><span class="p">.</span><span class="n">click</span><span class="p">()</span>\n        <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>\n        <span class="bp">self</span><span class="p">.</span><span class="n">option_one</span><span class="p">.</span><span class="n">click</span><span class="p">()</span>\n        <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>\n        <span class="bp">self</span><span class="p">.</span><span class="n">option_one</span><span class="p">.</span><span class="n">send_keys</span><span class="p">(</span><span class="s">''human schill''</span><span class="p">)</span>\n        <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>\n        <span class="bp">self</span><span class="p">.</span><span class="n">option_two</span><span class="p">.</span><span class="n">click</span><span class="p">()</span>\n        <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>\n        <span class="bp">self</span><span class="p">.</span><span class="n">option_two</span><span class="p">.</span><span class="n">send_keys</span><span class="p">(</span><span class="s">''robot schill''</span><span class="p">)</span>\n        <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>\n\n        <span class="c1"># send the tweet\n</span>        <span class="bp">self</span><span class="p">.</span><span class="n">tweet_btn</span><span class="p">.</span><span class="n">click</span><span class="p">()</span>\n        <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span></code></pre></figure>\n\n<h1 id="fin">fin</h1>\n\n<p>And there you have it. The rest of the code in the repo is just badly made code to randomly choose a tweet from some <a href="https://twitter.com/schillbot3000">neural net that mocks the President of the University of Oregon</a>.</p>','\n',char(10)),NULL,'','2019-07-23 07:00:00','Jonny Saunders blog','',NULL,'2024-01-03 18:04:29','read');
INSERT INTO items VALUES('https://jon-e.net/blog/2019/04/09/Adversarial-Analysis-of-Zhou-Firestone_render/','An Adversarial (re)Analysis of Zhou/Firestone 2019',replace('<p>This post is a reanalysis of Zhenglong Zhou and Chaz Firestone’s paper “Humans can deciper adversarial images,” so let’s get some links out of the way</p>\n\n<ul>\n  <li><strong>Paper</strong> - Zhou Z, Firestone C. <a href="https://www.nature.com/articles/s41467-019-08931-6">Humans can deciper adversarial images</a>. <em>Nature Communications</em> 10(1):1334  p.2041-1723, DOI:10.1038/s41467-019-08931-6</li>\n  <li><a href="https://arxiv.org/abs/1809.04120"><strong>Preprint</strong></a></li>\n  <li><a href="https://osf.io/uknbh/"><strong>Data and Code on OSF</strong></a></li>\n</ul>\n\n<h1 id="overview">Overview</h1>\n\n<p>Chaz Firestone came and presented this data at the UO’s cognitive neuroscience seminar series this winter just before the paper came out. The idea is compelling: Convolutional neural nets trained to classify images are vulnerable to adversarial attacks where images can be manipulated or synthesized to trigger a specific categorization.</p>\n\n<p>On their face, these adversarial images highlight the dramatic differences between the human/mammalian visual system – the types of things that fool us are very different than tactically adding static throughout an image. However if there were any overlap between the types of adversarial image manipulations that fool us and fool CNNs, they argue it would point to a <em>possible</em> mechanistic overlap.</p>\n\n<p>They use two types of adversarial images:</p>\n\n<blockquote>\n  <p><strong>Fooling images</strong> are otherwise meaningless patterns that are classified as familiar objects by a machine-vision system.</p>\n</blockquote>\n\n<p><img src="/blog/assets/images/fooling_image.png" alt="o ya u got me" />\n<em>ya fooled me doc</em></p>\n\n<p>and</p>\n\n<blockquote>\n  <p><strong>Perturbed images</strong> are images that would normally be classified accurately and straightforwardly […] but that are perturbed only slightly to produce a completely different classification by the machine</p>\n</blockquote>\n\n<p><img src="/blog/assets/images/perturbed_image.png" alt="youch i am tricked!" />\n<em>youch wat trickery!</em></p>\n\n<p>They present 8 experiments with 5 image sets that mostly ask human subjects to guess what a computer would classify the images as – what they call “machine theory of mind” – although the degree to which that is different than just having people classify images is ambiguous in their data.</p>\n\n<h1 id="clarifying-hypotheses">Clarifying Hypotheses</h1>\n\n<p>There seems to be an abnormally high airgap between data and interpretation here that I think is worthy of careful handling. The ultimate motivation here is to detect some similarity between CNNs and mammalian/human visual systems, and since CNNs seem to be vulnerable to adversarially manipulated images, if there is mechanistic overlap humans should be too. The authors aim to fill the empirical gap where, according to them, no one has actually tested whether humans misclassify these images</p>\n\n<blockquote>\n  <p>A primary factor that makes adversarial images so intriguing is the intuitive assumption that a human would not classify the image as the machine does. (Indeed, this is part of what makes animage“adversarial”in thefirst place, though that definition is notyet fully settled.) However, surprisingly little work has actively explored this assumption by testing human performance on such images, even though it is often asserted that adversarial images are “totally unrecognizable to human eyes”</p>\n</blockquote>\n\n<p>There are a number of <em>very similar</em> hypotheses and results that are possible here, we should delineate between them.</p>\n\n<p>The most straightforward test of a hypothesis would be:</p>\n\n<ol>\n  <li>\n    <p>Base image, well classified by humans and CNNs -&gt; Perturbed image, CNNs consistent misclassify -&gt; If humans misclassify in the same way and at same rate, implied mechanistic similarity.</p>\n\n    <p>A critical component of this is that the image is <em>mis</em>classified according to humans, or classified in a way that is not “what is looks like.” There is a tautology that makes this experiment impossible (as the authors note) - if the adversarially manipulated image didn’t still “look like” the base image, it wouldn’t be an adversarially useful image. A less strong test of the hypothesis would be to relax the requirement that there be some well-classified base image</p>\n  </li>\n  <li>\n    <p>Generated or perturbed image not obviously classified by humans, CNNs consistently classify -&gt; when forced, if humans classify in same way at same rate, implied mechanistic similarity. (similar to experiments 3a, 3b)</p>\n\n    <p>In this case, the images <strong>cannot</strong> obviously resemble the classes they are assigned by the CNN, as that would just mean the CNNs correctly learned some abstract representation of the way images look to humans. Such a result is not <strong>un</strong>interesting, it is just the same as finding that CNNs can classify images, and we know that already. To the degree than an image resembles the class that the CNN assigned it, that image is not suitable to test this hypothesis. Another subtlety here is that the humans should have to classify in the same way as the CNNs, ie. choose from a list of all possible categories. Giving additional structure to the humans would require giving the same to the CNNs to make the results comparable.</p>\n\n    <p>There are several implicit hypotheses tested in this paper that are essentially unrelated to the central question of machine/human overlap.</p>\n  </li>\n  <li>\n    <p>Humans are told images were misclassified, choose the misclassification from an array of all possible image classes. If misclassification correctly identified, humans can recognize visual features that drive misclassifications in CNNs. (experiment 5)</p>\n\n    <p>This is a distinct hypothesis from ‘humans have the same visual processing as CNNs,’ in this case since the human subjects are told there is a misclassification, they are looking not for what they think the image actually is, but for what would have driven the mistake. The interpretation should be that humans are capable of inferring what makes a machine misclassify an image, not that we process images similarly.</p>\n  </li>\n  <li>\n    <p>Humans are given an image class and examples, if they choose the image that was categorized as that class, they can recognize some element of the image class in the adversarial image. (experiment 4)</p>\n\n    <p>This is another separate question – in this case the subjects are asked to recognize some feature from the example images in the perturbed images. Their being able to see those features is not indicative that they process the images in the same way as the CNN, but amongst an array of imperfect examples they can see the image that is the most similar to the example images.</p>\n  </li>\n</ol>\n\n<p>The optimal outcome for all of these experiments is</p>\n\n<ol>\n  <li>The subject all categorize with high accuracy - the subjects should all have the same performance as the machine to affirm the hypothesis.</li>\n  <li>The images are all categorized with equal accuracy - since the question is about human/machine agreement <em>in general</em>, that overlap should be true of all images. Having images with wildly different accuracy rates is useful to assess the visual features that drive human/machine, but for the same reason points to some specific qualities of the images that make the more and less accurately categorized rather than a general similarity between human/machine overlap. Remember – the machines classify <strong>all</strong> of these images incorrectly with a high degree of confidence, so humans should too.</li>\n</ol>\n\n<h1 id="reanalysis-details">Reanalysis Details</h1>\n\n<p>Aside from the structure of the hypotheses, I had questions about the data analysis itself. During his presentation I was confused about why the data was reported as it was – the main results they report are the % of subjects whose categorization agreed with the machine and % of images where the majority categorization agreed with the machine. It seemed like that analysis would obscure the actual rates of categorization – ie. the actual rate of “correct” responses grouped by subject and image. The percents of subject and image agreement were also counted just by their mean categorization being above chance rather than being statistically distinguishable from chance (ie. confidence intervals exclude the chance threshold), I will also report those as “adjusted accuracies” using pearson-klopper binomial 95% confidence intervals.</p>\n\n<p>Because I think this is such a potentially cool line of research I thought I would do the reanalysis myself. Thankfully, the authors released their (very clean!) data. I think the results are quite a bit more subtle than initially reported.</p>\n\n<h1 id="code-boilerplate">Code Boilerplate</h1>\n\n<p>We’ll use the following libraries</p>\n\n<!-- <details><summary style="background-color: #272822; color: #f8f8f2;">Expand/Collapse Code</summary> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span><span class="w">\n</span><span class="n">library</span><span class="p">(</span><span class="n">lme4</span><span class="p">)</span><span class="w">\n</span><span class="n">library</span><span class="p">(</span><span class="n">rio</span><span class="p">)</span><span class="w">\n</span><span class="n">library</span><span class="p">(</span><span class="n">binom</span><span class="p">)</span><span class="w">\n</span><span class="n">library</span><span class="p">(</span><span class="n">here</span><span class="p">)</span><span class="w">\n</span><span class="n">library</span><span class="p">(</span><span class="n">caret</span><span class="p">)</span></code></pre></figure>\n\n<!-- </details> -->\n\n<p>I’ve put the data in a directory in my website structure, “/assets/data/adv”. We’ll load them all into variable names <code class="language-plaintext highlighter-rouge">expt_1</code>, <code class="language-plaintext highlighter-rouge">expt_2</code>, etc. and do some cleanup.</p>\n\n<!-- <details><summary style="background-color: #272822; color: #f8f8f2;">Expand/Collapse Code</summary> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># list experiment data files</span><span class="w">\n</span><span class="n">experiment_dirs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">list.dirs</span><span class="p">(</span><span class="n">here</span><span class="p">(</span><span class="s1">''assets''</span><span class="p">,</span><span class="w"> </span><span class="s1">''data''</span><span class="p">,</span><span class="w"> </span><span class="s1">''adv''</span><span class="p">),</span><span class="w"> </span><span class="n">full.names</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">recursive</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span><span class="w">\n\n</span><span class="c1"># name each dataset according to its number</span><span class="w">\n</span><span class="n">experiment_names</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"expt_1"</span><span class="p">,</span><span class="w"> </span><span class="s2">"expt_2"</span><span class="p">,</span><span class="w"> </span><span class="s2">"expt_3a"</span><span class="p">,</span><span class="w"> </span><span class="s2">"expt_3b"</span><span class="p">,</span><span class="w"> </span><span class="s2">"expt_4"</span><span class="p">,</span><span class="w"> </span><span class="s2">"expt_5"</span><span class="p">,</span><span class="w"> </span><span class="s2">"expt_6"</span><span class="p">,</span><span class="w"> </span><span class="s2">"expt_7"</span><span class="p">)</span><span class="w">\n\n</span><span class="c1"># list the datafiles</span><span class="w">\n</span><span class="n">data_files</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">()</span><span class="w">\n</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">seq</span><span class="p">(</span><span class="nf">length</span><span class="p">(</span><span class="n">experiment_dirs</span><span class="p">))){</span><span class="w">\n  </span><span class="n">data_files</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">list.files</span><span class="p">(</span><span class="n">here</span><span class="p">(</span><span class="s1">''assets''</span><span class="p">,</span><span class="w"> </span><span class="s1">''data''</span><span class="p">,</span><span class="w"> </span><span class="s1">''adv''</span><span class="p">,</span><span class="w"> </span><span class="n">experiment_dirs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="s2">"data"</span><span class="p">),</span><span class="w"> </span><span class="n">full.names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)[</span><span class="m">1</span><span class="p">]</span><span class="w">\n</span><span class="p">}</span><span class="w">\n\n</span><span class="c1"># load experiments</span><span class="w">\n</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">seq</span><span class="p">(</span><span class="nf">length</span><span class="p">(</span><span class="n">data_files</span><span class="p">))){</span><span class="w">\n  </span><span class="n">assign</span><span class="p">(</span><span class="n">experiment_names</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w">\n         </span><span class="n">as.tbl</span><span class="p">(</span><span class="n">import_list</span><span class="p">(</span><span class="n">data_files</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">$</span><span class="n">Data</span><span class="p">))</span><span class="w">\n</span><span class="p">}</span><span class="w">\n\n</span><span class="c1">##########################</span><span class="w">\n</span><span class="c1">## clean data</span><span class="w">\n\n</span><span class="c1"># rename columns</span><span class="w">\n</span><span class="nf">names</span><span class="p">(</span><span class="n">expt_1</span><span class="p">)[</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">9</span><span class="p">,</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="m">11</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"subject"</span><span class="p">,</span><span class="w"> </span><span class="s2">"correct"</span><span class="p">,</span><span class="w"> </span><span class="s2">"rt_pass"</span><span class="p">,</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">)</span><span class="w">\n</span><span class="nf">names</span><span class="p">(</span><span class="n">expt_2</span><span class="p">)[</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">9</span><span class="p">,</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="m">11</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"subject"</span><span class="p">,</span><span class="w"> </span><span class="s2">"correct"</span><span class="p">,</span><span class="w"> </span><span class="s2">"rt_pass"</span><span class="p">,</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">)</span><span class="w">\n</span><span class="nf">names</span><span class="p">(</span><span class="n">expt_3a</span><span class="p">)[</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">6</span><span class="p">,</span><span class="w"> </span><span class="m">7</span><span class="p">,</span><span class="w"> </span><span class="m">8</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"subject"</span><span class="p">,</span><span class="w"> </span><span class="s2">"correct"</span><span class="p">,</span><span class="w"> </span><span class="s2">"rt_pass"</span><span class="p">,</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">)</span><span class="w">\n</span><span class="nf">names</span><span class="p">(</span><span class="n">expt_3b</span><span class="p">)[</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">6</span><span class="p">,</span><span class="w"> </span><span class="m">7</span><span class="p">,</span><span class="w"> </span><span class="m">8</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"subject"</span><span class="p">,</span><span class="w"> </span><span class="s2">"correct"</span><span class="p">,</span><span class="w"> </span><span class="s2">"rt_pass"</span><span class="p">,</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">)</span><span class="w">\n</span><span class="nf">names</span><span class="p">(</span><span class="n">expt_4</span><span class="p">)[</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">6</span><span class="p">,</span><span class="m">7</span><span class="p">,</span><span class="m">8</span><span class="p">,</span><span class="m">9</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"subject"</span><span class="p">,</span><span class="w"> </span><span class="s2">"correct"</span><span class="p">,</span><span class="w"> </span><span class="s2">"rt_pass"</span><span class="p">,</span><span class="w"> </span><span class="s2">"rt_allpass"</span><span class="p">,</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">)</span><span class="w">\n</span><span class="nf">names</span><span class="p">(</span><span class="n">expt_5</span><span class="p">)[</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">7</span><span class="p">,</span><span class="m">8</span><span class="p">,</span><span class="m">9</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"subject"</span><span class="p">,</span><span class="w"> </span><span class="s2">"correct"</span><span class="p">,</span><span class="w"> </span><span class="s2">"rt_pass"</span><span class="p">,</span><span class="w">  </span><span class="s2">"complete"</span><span class="p">)</span><span class="w">\n</span><span class="nf">names</span><span class="p">(</span><span class="n">expt_6</span><span class="p">)[</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">10</span><span class="p">,</span><span class="m">11</span><span class="p">,</span><span class="m">12</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"subject"</span><span class="p">,</span><span class="w"> </span><span class="s2">"correct"</span><span class="p">,</span><span class="w"> </span><span class="s2">"rt_pass"</span><span class="p">,</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">)</span><span class="w">\n</span><span class="nf">names</span><span class="p">(</span><span class="n">expt_7</span><span class="p">)[</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">10</span><span class="p">,</span><span class="m">11</span><span class="p">,</span><span class="m">12</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"subject"</span><span class="p">,</span><span class="w"> </span><span class="s2">"correct"</span><span class="p">,</span><span class="w"> </span><span class="s2">"rt_pass"</span><span class="p">,</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">)</span><span class="w">\n\n</span><span class="c1"># retype columns</span><span class="w">\n</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">expt_name</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">experiment_names</span><span class="p">){</span><span class="w">\n  </span><span class="c1"># use get to refer to the object with its character name not its symbol name</span><span class="w">\n  </span><span class="n">xpt</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">get</span><span class="p">(</span><span class="n">expt_name</span><span class="p">)</span><span class="w">\n  \n    </span><span class="c1"># subset incomplete subjects</span><span class="w">\n  </span><span class="n">xpt</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">xpt</span><span class="p">[</span><span class="n">xpt</span><span class="o">$</span><span class="n">complete</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,]</span><span class="w">\n  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="s2">"rt_allpass"</span><span class="w"> </span><span class="o">%in%</span><span class="w"> </span><span class="nf">names</span><span class="p">(</span><span class="n">xpt</span><span class="p">)){</span><span class="w">\n    </span><span class="n">xpt</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">xpt</span><span class="p">[</span><span class="n">xpt</span><span class="o">$</span><span class="n">rt_allpass</span><span class="o">==</span><span class="kc">TRUE</span><span class="p">,]</span><span class="w">\n  </span><span class="p">}</span><span class="w">\n  \n  </span><span class="c1"># first columns present in all dfs</span><span class="w">\n  </span><span class="n">xpt</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">xpt</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">mutate</span><span class="p">(</span><span class="w">\n    </span><span class="n">subject</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">as.factor</span><span class="p">(</span><span class="n">subject</span><span class="p">),</span><span class="w">\n    </span><span class="n">correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.logical</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n    </span><span class="n">rt_pass</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.logical</span><span class="p">(</span><span class="n">rt_pass</span><span class="p">),</span><span class="w">\n    </span><span class="n">complete</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.logical</span><span class="p">(</span><span class="n">complete</span><span class="p">)</span><span class="w">\n  </span><span class="p">)</span><span class="w">\n  \n  </span><span class="c1"># then specifics</span><span class="w">\n  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="s2">"image"</span><span class="w"> </span><span class="o">%in%</span><span class="w"> </span><span class="nf">names</span><span class="p">(</span><span class="n">xpt</span><span class="p">)){</span><span class="w">\n    </span><span class="n">xpt</span><span class="o">$</span><span class="n">image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.factor</span><span class="p">(</span><span class="n">xpt</span><span class="o">$</span><span class="n">image</span><span class="p">)</span><span class="w">\n  </span><span class="p">}</span><span class="w">\n  \n  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="s2">"response"</span><span class="w"> </span><span class="o">%in%</span><span class="w"> </span><span class="nf">names</span><span class="p">(</span><span class="n">xpt</span><span class="p">)){</span><span class="w">\n    </span><span class="n">xpt</span><span class="o">$</span><span class="n">response</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.factor</span><span class="p">(</span><span class="n">xpt</span><span class="o">$</span><span class="n">response</span><span class="p">)</span><span class="w">\n  </span><span class="p">}</span><span class="w">\n  \n\n  \n  \n  </span><span class="c1"># assign back to name</span><span class="w">\n  \n  </span><span class="n">assign</span><span class="p">(</span><span class="n">expt_name</span><span class="p">,</span><span class="w">\n         </span><span class="n">xpt</span><span class="p">)</span><span class="w">\n</span><span class="p">}</span></code></pre></figure>\n\n<!-- </details> -->\n\n<h2 id="summarizing-functions">Summarizing Functions</h2>\n\n<p>Since so much of the data has the same structure, we’ll write functions to summarize the image responses by image and subject. They’ll return</p>\n\n<ul>\n  <li><code class="language-plaintext highlighter-rouge">n_trials</code> - the number of trials per group</li>\n  <li><code class="language-plaintext highlighter-rouge">n_correct</code> - the number of “correct,” or matching the categorization of the CNN, trials</li>\n  <li><code class="language-plaintext highlighter-rouge">meancx</code> - the proportion of correct answers per group</li>\n  <li><code class="language-plaintext highlighter-rouge">cilo</code>, <code class="language-plaintext highlighter-rouge">cihi</code> - the 95% confidence interval around the mean correct.</li>\n</ul>\n\n<!-- <details><summary style="background-color: #272822; color: #f8f8f2;">Expand/Collapse Code</summary> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">summarize_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">data</span><span class="p">){</span><span class="w">\n\n  </span><span class="n">summary_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">\n  </span><span class="n">summarize</span><span class="p">(</span><span class="n">n_trials</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n            </span><span class="n">n_correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n            </span><span class="n">meancx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_correct</span><span class="o">/</span><span class="n">n_trials</span><span class="p">,</span><span class="w">\n            </span><span class="n">meanrt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">rt</span><span class="p">),</span><span class="w">\n            </span><span class="n">sdrt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sd</span><span class="p">(</span><span class="n">rt</span><span class="p">),</span><span class="w">\n            </span><span class="n">cilo</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                  </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.95</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">)[[</span><span class="m">5</span><span class="p">]],</span><span class="w">\n            </span><span class="n">cihi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                  </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.95</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">)[[</span><span class="m">6</span><span class="p">]])</span><span class="w">\n\n  </span><span class="n">summary_image</span><span class="o">$</span><span class="n">image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ordered</span><span class="p">(</span><span class="n">summary_image</span><span class="o">$</span><span class="n">image</span><span class="p">,</span><span class="w"> \n                              </span><span class="n">levels</span><span class="o">=</span><span class="n">summary_image</span><span class="o">$</span><span class="n">image</span><span class="p">[</span><span class="n">order</span><span class="p">(</span><span class="n">summary_image</span><span class="o">$</span><span class="n">meancx</span><span class="p">)])</span><span class="w">\n  \n  </span><span class="n">summary_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">subject</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">\n    </span><span class="n">summarize</span><span class="p">(</span><span class="n">n_trials</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n              </span><span class="n">n_correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n              </span><span class="n">meancx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_correct</span><span class="o">/</span><span class="n">n_trials</span><span class="p">,</span><span class="w">\n              </span><span class="n">meanrt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">rt</span><span class="p">),</span><span class="w">\n              </span><span class="n">sdrt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sd</span><span class="p">(</span><span class="n">rt</span><span class="p">),</span><span class="w">\n              </span><span class="n">cilo</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                   </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.95</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">)[[</span><span class="m">5</span><span class="p">]],</span><span class="w">\n              </span><span class="n">cihi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                   </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.95</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">)[[</span><span class="m">6</span><span class="p">]])</span><span class="w">\n  \n  </span><span class="n">summary_subject</span><span class="o">$</span><span class="n">subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ordered</span><span class="p">(</span><span class="n">summary_subject</span><span class="o">$</span><span class="n">subject</span><span class="p">,</span><span class="w"> \n                                     </span><span class="n">levels</span><span class="o">=</span><span class="n">summary_subject</span><span class="o">$</span><span class="n">subject</span><span class="p">[</span><span class="n">order</span><span class="p">(</span><span class="n">summary_subject</span><span class="o">$</span><span class="n">meancx</span><span class="p">)])</span><span class="w">\n  \n  </span><span class="nf">return</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="s2">"image"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">summary_image</span><span class="p">,</span><span class="w">\n              </span><span class="s2">"subject"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">summary_subject</span><span class="p">))</span><span class="w">\n\n</span><span class="p">}</span><span class="w">\n\n</span><span class="n">summarize_e4</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">e4</span><span class="p">){</span><span class="w">\n  </span><span class="nf">names</span><span class="p">(</span><span class="n">e4</span><span class="p">)[</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">6</span><span class="p">,</span><span class="m">7</span><span class="p">,</span><span class="m">8</span><span class="p">,</span><span class="m">9</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"subject"</span><span class="p">,</span><span class="w"> </span><span class="s2">"correct"</span><span class="p">,</span><span class="w"> </span><span class="s2">"rt_pass"</span><span class="p">,</span><span class="w"> </span><span class="s2">"rt_allpass"</span><span class="p">,</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">)</span><span class="w">\n  </span><span class="n">e4</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e4</span><span class="p">[(</span><span class="n">e4</span><span class="o">$</span><span class="n">complete</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">e4</span><span class="o">$</span><span class="n">rt_allpass</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">),]</span><span class="w">\n  </span><span class="n">e4</span><span class="o">$</span><span class="n">subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.factor</span><span class="p">(</span><span class="n">e4</span><span class="o">$</span><span class="n">subject</span><span class="p">)</span><span class="w">\n  </span><span class="n">e4</span><span class="o">$</span><span class="n">target</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.factor</span><span class="p">(</span><span class="n">e4</span><span class="o">$</span><span class="n">target</span><span class="p">)</span><span class="w">\n  </span><span class="n">e4</span><span class="o">$</span><span class="n">response</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.factor</span><span class="p">(</span><span class="n">e4</span><span class="o">$</span><span class="n">response</span><span class="p">)</span><span class="w">\n  </span><span class="n">e4</span><span class="o">$</span><span class="n">trialNum</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">as.integer</span><span class="p">(</span><span class="n">e4</span><span class="o">$</span><span class="n">trialNum</span><span class="p">)</span><span class="w">\n  \n  </span><span class="n">e4_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e4</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">target</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">\n    </span><span class="n">summarize</span><span class="p">(</span><span class="n">n_trials</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n              </span><span class="n">n_correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n              </span><span class="n">meancx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_correct</span><span class="o">/</span><span class="n">n_trials</span><span class="p">,</span><span class="w">\n              </span><span class="n">cilo</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                   </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                   </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">5</span><span class="p">]],</span><span class="w">\n              </span><span class="n">cihi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                   </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                   </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">6</span><span class="p">]])</span><span class="w">\n  \n  </span><span class="n">e4_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e4</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">subject</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">\n    </span><span class="n">summarize</span><span class="p">(</span><span class="n">n_trials</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n              </span><span class="n">n_correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n              </span><span class="n">meancx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_correct</span><span class="o">/</span><span class="n">n_trials</span><span class="p">,</span><span class="w">\n              </span><span class="n">cilo</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                   </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                   </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">5</span><span class="p">]],</span><span class="w">\n              </span><span class="n">cihi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                   </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                   </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">6</span><span class="p">]])</span><span class="w">\n  \n  </span><span class="n">e4_trial</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e4</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">trialNum</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">\n    </span><span class="n">summarize</span><span class="p">(</span><span class="n">n_trials</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n              </span><span class="n">n_correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n              </span><span class="n">meancx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_correct</span><span class="o">/</span><span class="n">n_trials</span><span class="p">,</span><span class="w">\n              </span><span class="n">cilo</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                   </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                   </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">5</span><span class="p">]],</span><span class="w">\n              </span><span class="n">cihi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                   </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                   </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">6</span><span class="p">]])</span><span class="w">\n  \n  </span><span class="n">e4_image</span><span class="o">$</span><span class="n">target</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ordered</span><span class="p">(</span><span class="n">e4_image</span><span class="o">$</span><span class="n">target</span><span class="p">,</span><span class="w"> </span><span class="n">levels</span><span class="o">=</span><span class="n">e4_image</span><span class="o">$</span><span class="n">target</span><span class="p">[</span><span class="n">order</span><span class="p">(</span><span class="n">e4_image</span><span class="o">$</span><span class="n">meancx</span><span class="p">)])</span><span class="w">\n  </span><span class="n">e4_image</span><span class="o">$</span><span class="n">image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e4_image</span><span class="o">$</span><span class="n">target</span><span class="w">\n  </span><span class="n">e4_subject</span><span class="o">$</span><span class="n">subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ordered</span><span class="p">(</span><span class="n">e4_subject</span><span class="o">$</span><span class="n">subject</span><span class="p">,</span><span class="w"> </span><span class="n">levels</span><span class="o">=</span><span class="n">e4_subject</span><span class="o">$</span><span class="n">subject</span><span class="p">[</span><span class="n">order</span><span class="p">(</span><span class="n">e4_subject</span><span class="o">$</span><span class="n">meancx</span><span class="p">)])</span><span class="w">\n  </span><span class="nf">return</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="s2">"image"</span><span class="o">=</span><span class="n">e4_image</span><span class="p">,</span><span class="w">\n              </span><span class="s2">"subject"</span><span class="o">=</span><span class="n">e4_subject</span><span class="p">,</span><span class="w">\n              </span><span class="s2">"trial"</span><span class="o">=</span><span class="n">e4_trial</span><span class="p">))</span><span class="w">\n</span><span class="p">}</span><span class="w">\n\n</span><span class="n">summarize_e5</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">e5</span><span class="p">){</span><span class="w">\n  \n</span><span class="n">e5_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e5</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">target</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">\n  </span><span class="n">summarize</span><span class="p">(</span><span class="n">n_trials</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n            </span><span class="n">n_correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n            </span><span class="n">meancx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_correct</span><span class="o">/</span><span class="n">n_trials</span><span class="p">,</span><span class="w">\n            </span><span class="n">n_eight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">response</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">"8"</span><span class="p">),</span><span class="w">\n            </span><span class="n">meaneight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_eight</span><span class="o">/</span><span class="n">n_trials</span><span class="p">,</span><span class="w">\n            </span><span class="n">cilo8</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="n">n_eight</span><span class="p">,</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                  </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                  </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">5</span><span class="p">]],</span><span class="w">\n            </span><span class="n">cihi8</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="n">n_eight</span><span class="p">,</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                  </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                  </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">6</span><span class="p">]],</span><span class="w">\n            </span><span class="n">cilo</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                 </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                 </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">5</span><span class="p">]],</span><span class="w">\n            </span><span class="n">cihi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                 </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                 </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">6</span><span class="p">]])</span><span class="w">\n\n\n</span><span class="n">e5_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e5</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">subject</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">\n  </span><span class="n">summarize</span><span class="p">(</span><span class="n">n_trials</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n            </span><span class="n">n_correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n            </span><span class="n">meancx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_correct</span><span class="o">/</span><span class="n">n_trials</span><span class="p">,</span><span class="w">\n            </span><span class="n">cilo</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                 </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                 </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">5</span><span class="p">]],</span><span class="w">\n            </span><span class="n">cihi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                 </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                 </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">6</span><span class="p">]])</span><span class="w">\n\n\n</span><span class="n">e5_image</span><span class="o">$</span><span class="n">target</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ordered</span><span class="p">(</span><span class="n">e5_image</span><span class="o">$</span><span class="n">target</span><span class="p">,</span><span class="w"> </span><span class="n">levels</span><span class="o">=</span><span class="n">e5_image</span><span class="o">$</span><span class="n">target</span><span class="p">[</span><span class="n">order</span><span class="p">(</span><span class="n">e5_image</span><span class="o">$</span><span class="n">meancx</span><span class="p">)])</span><span class="w">\n</span><span class="n">e5_subject</span><span class="o">$</span><span class="n">subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ordered</span><span class="p">(</span><span class="n">e5_subject</span><span class="o">$</span><span class="n">subject</span><span class="p">,</span><span class="w"> </span><span class="n">levels</span><span class="o">=</span><span class="n">e5_subject</span><span class="o">$</span><span class="n">subject</span><span class="p">[</span><span class="n">order</span><span class="p">(</span><span class="n">e5_subject</span><span class="o">$</span><span class="n">meancx</span><span class="p">)])</span><span class="w">\n</span><span class="nf">return</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="s2">"image"</span><span class="o">=</span><span class="n">e5_image</span><span class="p">,</span><span class="w">\n            </span><span class="s2">"subject"</span><span class="o">=</span><span class="n">e5_subject</span><span class="p">))</span><span class="w">\n</span><span class="p">}</span><span class="w">\n\n</span><span class="n">summarize_6</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">e6</span><span class="p">){</span><span class="w">\n  \n</span><span class="n">e6_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e6</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">target</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">\n  </span><span class="n">summarize</span><span class="p">(</span><span class="n">n_trials</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n            </span><span class="n">n_correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n            </span><span class="n">meancx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_correct</span><span class="o">/</span><span class="n">n_trials</span><span class="p">,</span><span class="w">\n            </span><span class="n">cilo</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                 </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                 </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">5</span><span class="p">]],</span><span class="w">\n            </span><span class="n">cihi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                 </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                 </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">6</span><span class="p">]])</span><span class="w">\n\n\n</span><span class="n">e6_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e6</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">subject</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">\n  </span><span class="n">summarize</span><span class="p">(</span><span class="n">n_trials</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n            </span><span class="n">n_correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n            </span><span class="n">meancx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_correct</span><span class="o">/</span><span class="n">n_trials</span><span class="p">,</span><span class="w">\n            </span><span class="n">cilo</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                 </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                 </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">5</span><span class="p">]],</span><span class="w">\n            </span><span class="n">cihi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                 </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                 </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">6</span><span class="p">]])</span><span class="w">\n\n\n</span><span class="n">e6_image</span><span class="o">$</span><span class="n">target</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ordered</span><span class="p">(</span><span class="n">e6_image</span><span class="o">$</span><span class="n">target</span><span class="p">,</span><span class="w"> </span><span class="n">levels</span><span class="o">=</span><span class="n">e6_image</span><span class="o">$</span><span class="n">target</span><span class="p">[</span><span class="n">order</span><span class="p">(</span><span class="n">e6_image</span><span class="o">$</span><span class="n">meancx</span><span class="p">)])</span><span class="w">\n</span><span class="n">e6_subject</span><span class="o">$</span><span class="n">subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ordered</span><span class="p">(</span><span class="n">e6_subject</span><span class="o">$</span><span class="n">subject</span><span class="p">,</span><span class="w"> </span><span class="n">levels</span><span class="o">=</span><span class="n">e6_subject</span><span class="o">$</span><span class="n">subject</span><span class="p">[</span><span class="n">order</span><span class="p">(</span><span class="n">e6_subject</span><span class="o">$</span><span class="n">meancx</span><span class="p">)])</span><span class="w">\n</span><span class="nf">return</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="s2">"image"</span><span class="o">=</span><span class="n">e6_image</span><span class="p">,</span><span class="w">\n            </span><span class="s2">"subject"</span><span class="o">=</span><span class="n">e6_subject</span><span class="p">))</span><span class="w">\n  \n</span><span class="p">}</span><span class="w">\n\n\n</span><span class="n">summarize_7</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">e7</span><span class="p">){</span><span class="w">\n  \n</span><span class="n">e7_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e7</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">imageName</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">\n  </span><span class="n">summarize</span><span class="p">(</span><span class="n">n_trials</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n            </span><span class="n">n_correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n            </span><span class="n">meancx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_correct</span><span class="o">/</span><span class="n">n_trials</span><span class="p">,</span><span class="w">\n            </span><span class="n">target</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">target</span><span class="p">[</span><span class="m">1</span><span class="p">],</span><span class="w">\n            </span><span class="n">cilo</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                 </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                 </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">5</span><span class="p">]],</span><span class="w">\n            </span><span class="n">cihi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                 </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                 </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">6</span><span class="p">]])</span><span class="w">\n\n\n</span><span class="n">e7_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e7</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">group_by</span><span class="p">(</span><span class="n">subject</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">\n  </span><span class="n">summarize</span><span class="p">(</span><span class="n">n_trials</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n            </span><span class="n">n_correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n            </span><span class="n">meancx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_correct</span><span class="o">/</span><span class="n">n_trials</span><span class="p">,</span><span class="w">\n            </span><span class="n">cilo</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                 </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                 </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">5</span><span class="p">]],</span><span class="w">\n            </span><span class="n">cihi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binom.confint</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="nf">length</span><span class="p">(</span><span class="n">correct</span><span class="p">),</span><span class="w">\n                                 </span><span class="n">conf.level</span><span class="o">=</span><span class="m">0.99</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">"exact"</span><span class="p">,</span><span class="w">\n                                 </span><span class="n">alternative</span><span class="o">=</span><span class="s2">"greater"</span><span class="p">)[[</span><span class="m">6</span><span class="p">]])</span><span class="w">\n\n\n</span><span class="n">e7_image</span><span class="o">$</span><span class="n">imageName</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ordered</span><span class="p">(</span><span class="n">e7_image</span><span class="o">$</span><span class="n">imageName</span><span class="p">,</span><span class="w"> </span><span class="n">levels</span><span class="o">=</span><span class="n">e7_image</span><span class="o">$</span><span class="n">imageName</span><span class="p">[</span><span class="n">order</span><span class="p">(</span><span class="n">e7_image</span><span class="o">$</span><span class="n">meancx</span><span class="p">)])</span><span class="w">\n</span><span class="n">e7_subject</span><span class="o">$</span><span class="n">subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ordered</span><span class="p">(</span><span class="n">e7_subject</span><span class="o">$</span><span class="n">subject</span><span class="p">,</span><span class="w"> </span><span class="n">levels</span><span class="o">=</span><span class="n">e7_subject</span><span class="o">$</span><span class="n">subject</span><span class="p">[</span><span class="n">order</span><span class="p">(</span><span class="n">e7_subject</span><span class="o">$</span><span class="n">meancx</span><span class="p">)])</span><span class="w">\n</span><span class="nf">return</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="s2">"image"</span><span class="o">=</span><span class="n">e7_image</span><span class="p">,</span><span class="w">\n            </span><span class="s2">"subject"</span><span class="o">=</span><span class="n">e7_subject</span><span class="p">))</span><span class="w">\n  \n</span><span class="p">}</span><span class="w">\n\n</span><span class="c1"># and some convenience functions to make our basic plots</span><span class="w">\n</span><span class="n">plot_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">ex_image</span><span class="p">,</span><span class="w"> </span><span class="n">ex_num</span><span class="p">){</span><span class="w">\n  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ex_num</span><span class="w"> </span><span class="o">%in%</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"3a"</span><span class="p">,</span><span class="w"> </span><span class="s2">"3b"</span><span class="p">)){</span><span class="w">\n    </span><span class="n">y_height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="m">48</span><span class="w">\n  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ex_num</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">"4"</span><span class="p">){</span><span class="w">\n    </span><span class="n">y_height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="m">8</span><span class="w">\n  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ex_num</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">"5"</span><span class="p">){</span><span class="w">\n    </span><span class="n">y_height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="m">9</span><span class="w">\n  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="w">\n    </span><span class="n">y_height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="w">\n  </span><span class="p">}</span><span class="w">\n  \n  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ex_num</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">"7"</span><span class="p">){</span><span class="w">\n    </span><span class="n">ex_image</span><span class="o">$</span><span class="n">image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">paste</span><span class="p">(</span><span class="n">ex_image</span><span class="o">$</span><span class="n">image</span><span class="p">,</span><span class="w"> </span><span class="n">ex_image</span><span class="o">$</span><span class="n">target</span><span class="p">,</span><span class="w"> </span><span class="n">sep</span><span class="o">=</span><span class="s2">" - "</span><span class="p">)</span><span class="w">\n    </span><span class="n">ex_image</span><span class="o">$</span><span class="n">image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ordered</span><span class="p">(</span><span class="n">ex_image</span><span class="o">$</span><span class="n">image</span><span class="p">,</span><span class="w"> </span><span class="n">levels</span><span class="o">=</span><span class="n">ex_image</span><span class="o">$</span><span class="n">image</span><span class="p">[</span><span class="n">order</span><span class="p">(</span><span class="n">ex_image</span><span class="o">$</span><span class="n">meancx</span><span class="p">)])</span><span class="w">\n  </span><span class="p">}</span><span class="w">\n  \n  </span><span class="n">g.image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ggplot</span><span class="p">(</span><span class="n">ex_image</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">image</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">meancx</span><span class="p">,</span><span class="w"> </span><span class="n">ymin</span><span class="o">=</span><span class="n">cilo</span><span class="p">,</span><span class="w"> </span><span class="n">ymax</span><span class="o">=</span><span class="n">cihi</span><span class="p">))</span><span class="o">+</span><span class="w">\n  </span><span class="n">geom_pointrange</span><span class="p">()</span><span class="o">+</span><span class="w">\n  </span><span class="n">geom_hline</span><span class="p">(</span><span class="n">yintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y_height</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s2">"red"</span><span class="p">)</span><span class="o">+</span><span class="w">\n  </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">paste</span><span class="p">(</span><span class="s2">"Experiment"</span><span class="p">,</span><span class="w"> </span><span class="n">ex_num</span><span class="p">,</span><span class="w"> </span><span class="s2">"- Mean Accuracy of Images"</span><span class="p">),</span><span class="w">\n       </span><span class="n">y</span><span class="o">=</span><span class="s2">"Mean accuracy across subjects"</span><span class="p">)</span><span class="o">+</span><span class="w">\n  </span><span class="n">theme</span><span class="p">(</span><span class="n">axis.text</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">element_text</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">unit</span><span class="p">(</span><span class="m">14</span><span class="p">,</span><span class="s2">"pt"</span><span class="p">)),</span><span class="w">\n        </span><span class="n">axis.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">element_text</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">unit</span><span class="p">(</span><span class="m">20</span><span class="p">,</span><span class="s2">"pt"</span><span class="p">)),</span><span class="w">\n    </span><span class="n">axis.text.x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">element_text</span><span class="p">(</span><span class="n">angle</span><span class="o">=</span><span class="m">45</span><span class="p">,</span><span class="w"> </span><span class="n">hjust</span><span class="o">=</span><span class="m">1</span><span class="p">))</span><span class="w">\n  \n  </span><span class="nf">return</span><span class="p">(</span><span class="n">g.image</span><span class="p">)</span><span class="w">\n</span><span class="p">}</span><span class="w">\n\n</span><span class="n">plot_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">ex_subject</span><span class="p">,</span><span class="w"> </span><span class="n">ex_num</span><span class="p">){</span><span class="w">\n  \n  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ex_num</span><span class="w"> </span><span class="o">%in%</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"3a"</span><span class="p">,</span><span class="w"> </span><span class="s2">"3b"</span><span class="p">)){</span><span class="w">\n    </span><span class="n">y_height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="m">48</span><span class="w">\n  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ex_num</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">"4"</span><span class="p">){</span><span class="w">\n    </span><span class="n">y_height</span><span class="o">=</span><span class="m">1</span><span class="o">/</span><span class="m">8</span><span class="w">\n  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ex_num</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">"5"</span><span class="p">){</span><span class="w">\n    </span><span class="n">y_height</span><span class="o">=</span><span class="m">1</span><span class="o">/</span><span class="m">9</span><span class="w">\n  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="w">\n    </span><span class="n">y_height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="w">\n  </span><span class="p">}</span><span class="w">\n  \n  </span><span class="n">g.subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ggplot</span><span class="p">(</span><span class="n">ex_subject</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">subject</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">meancx</span><span class="p">,</span><span class="w"> </span><span class="n">ymin</span><span class="o">=</span><span class="n">cilo</span><span class="p">,</span><span class="w"> </span><span class="n">ymax</span><span class="o">=</span><span class="n">cihi</span><span class="p">))</span><span class="o">+</span><span class="w">\n  </span><span class="n">geom_pointrange</span><span class="p">()</span><span class="o">+</span><span class="w">\n  </span><span class="n">geom_hline</span><span class="p">(</span><span class="n">yintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y_height</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s2">"red"</span><span class="p">)</span><span class="o">+</span><span class="w">\n  </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">paste</span><span class="p">(</span><span class="s2">"Experiment"</span><span class="p">,</span><span class="w"> </span><span class="n">ex_num</span><span class="p">,</span><span class="w"> </span><span class="s2">"- Mean Accuracy of Subject"</span><span class="p">),</span><span class="w">\n       </span><span class="n">y</span><span class="o">=</span><span class="s2">"Mean accuracy across images"</span><span class="p">)</span><span class="o">+</span><span class="w">\n  </span><span class="n">theme</span><span class="p">(</span><span class="n">axis.text.x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">element_blank</span><span class="p">())</span><span class="w">\n\n  </span><span class="nf">return</span><span class="p">(</span><span class="n">g.subject</span><span class="p">)</span><span class="w">\n</span><span class="p">}</span><span class="w">\n\n</span><span class="c1"># and to compute subject and image accuracies using confidence intervals instead of means</span><span class="w">\n</span><span class="n">adjusted_accuracy</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">ex_image</span><span class="p">,</span><span class="w"> </span><span class="n">ex_subject</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="o">=</span><span class="m">0.5</span><span class="p">){</span><span class="w">\n  </span><span class="n">ex_img_accuracy</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">nrow</span><span class="p">(</span><span class="n">ex_image</span><span class="p">[</span><span class="n">ex_image</span><span class="o">$</span><span class="n">cilo</span><span class="o">&gt;</span><span class="n">level</span><span class="p">,])</span><span class="o">/</span><span class="n">nrow</span><span class="p">(</span><span class="n">ex_image</span><span class="p">)</span><span class="w">\n  </span><span class="n">ex_subject_accuracy</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">nrow</span><span class="p">(</span><span class="n">ex_subject</span><span class="p">[</span><span class="n">ex_subject</span><span class="o">$</span><span class="n">cilo</span><span class="o">&gt;</span><span class="n">level</span><span class="p">,])</span><span class="o">/</span><span class="n">nrow</span><span class="p">(</span><span class="n">ex_subject</span><span class="p">)</span><span class="w">\n\n</span><span class="c1"># round for inclusion in the text</span><span class="w">\n</span><span class="n">ex_img_accuracy</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">ex_img_accuracy</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="o">*</span><span class="m">100</span><span class="w">\n</span><span class="n">ex_subject_accuracy</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">ex_subject_accuracy</span><span class="p">,</span><span class="m">3</span><span class="p">)</span><span class="o">*</span><span class="m">100</span><span class="w">\n\n  </span><span class="nf">return</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="n">image</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ex_img_accuracy</span><span class="p">,</span><span class="w">\n              </span><span class="n">subject</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ex_subject_accuracy</span><span class="p">))</span><span class="w">\n</span><span class="p">}</span></code></pre></figure>\n\n<!-- </details> -->\n\n<h1 id="experiment-1">Experiment 1</h1>\n\n<p>The first image uses images from <a href="https://arxiv.org/abs/1412.1897">Nguyen A, et al 2014</a>, which were generated using a “compositional pattern-producing network” that</p>\n\n<blockquote>\n  <p>can produce images that both humans and DNNs can recognize.</p>\n</blockquote>\n\n<p>Importantly though,</p>\n\n<blockquote>\n  <p>These images were produced on PicBreeder.org, a site where users serve as the fitness function in an evolutionary algorithm by selecting images they like, which become the parents of the next generation.</p>\n</blockquote>\n\n<p>So using these images may make the results particularly difficult to interpret, as it’s not clear how aesthetic preference interacts with the preference for recognizable objects. It could be the case that people pick images to preserve in the image generation process that look like real objects, so they aren’t “adversarial” images, strictly speaking. Indeed, the authors of the image-generation paper note</p>\n\n<blockquote>\n  <p>the generated images do often contain some features of the target class</p>\n</blockquote>\n\n<p>so a human classifying an image as the same class as a machine might be unsurprising for these images. Since some of the images do indeed resemble the ‘target’ classes, those images are unsuitable for assessing the degree to which the human visual system makes the same ‘errors’ as machine vision.</p>\n\n<p>The subjects in this task saw one of 48 “fooling images,” and were presented with the “correct” label and a randomly selected label from the other 47 images. The primary result the report for this experiment is that</p>\n<blockquote>\n  <p>98% of observers chose the machine’s label at above-chance rates. […] Additionally, 94% of the images showed above-chance human-machine agreement</p>\n</blockquote>\n\n<p>Reanalyzing by image and subject, however…</p>\n\n<!-- <details><summary style="background-color: #272822; color: #f8f8f2;">Expand/Collapse Code</summary> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># summarize the data and expand list to new</span><span class="w">\n</span><span class="n">sum_1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">summarize_data</span><span class="p">(</span><span class="n">expt_1</span><span class="p">)</span><span class="w">\n</span><span class="n">e1_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sum_1</span><span class="o">$</span><span class="n">image</span><span class="w">\n</span><span class="n">e1_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sum_1</span><span class="o">$</span><span class="n">subject</span></code></pre></figure>\n\n<!-- </details> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">g.e1_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">plot_image</span><span class="p">(</span><span class="n">e1_image</span><span class="p">,</span><span class="w"> </span><span class="s2">"1"</span><span class="p">)</span><span class="w">\n</span><span class="n">g.e1_image</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-1-1.png" alt="plot of chunk unnamed-chunk-1" /></p>\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">g.e1_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">plot_subject</span><span class="p">(</span><span class="n">e1_subject</span><span class="p">,</span><span class="w"> </span><span class="s2">"1"</span><span class="p">)</span><span class="w">\n</span><span class="n">g.e1_subject</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/expt_1_2-1.png" alt="plot of chunk expt_1_2" /></p>\n\n<p>So far so good, although if we use the binomial confidence intervals rather than just the mean response rate – what I’ll call corrected accuracies – we get a more valid description of above-chance accuracy</p>\n\n<!-- <details><summary style="background-color: #272822; color: #f8f8f2;">Expand/Collapse Code</summary> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">e1_accs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">adjusted_accuracy</span><span class="p">(</span><span class="n">e1_image</span><span class="p">,</span><span class="w"> </span><span class="n">e1_subject</span><span class="p">)</span></code></pre></figure>\n\n<!-- </details> -->\n\n<p>Only 85.4% of images were categorized above chance, and 81.2% of subjects did, as opposed to the reported 94% and 98%, respectively.</p>\n\n<h1 id="experiment-2---1st-vs-2nd-best-labels">Experiment 2 - 1st vs 2nd best labels</h1>\n\n<p>Of course, not all foil labels are created equal, so a more conservative test for human/machine overlap is to compare the highest and second highest labels predicted by the machine.</p>\n\n<!-- <details><summary style="background-color: #272822; color: #f8f8f2;">Expand/Collapse Code</summary> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">e2_summary</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">summarize_data</span><span class="p">(</span><span class="n">expt_2</span><span class="p">)</span><span class="w">\n</span><span class="n">e2_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e2_summary</span><span class="o">$</span><span class="n">image</span><span class="w">\n</span><span class="n">e2_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e2_summary</span><span class="o">$</span><span class="n">subject</span></code></pre></figure>\n\n<!-- </details> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">g.e2_img</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">plot_image</span><span class="p">(</span><span class="n">e2_image</span><span class="p">,</span><span class="w"> </span><span class="s2">"2"</span><span class="p">)</span><span class="w">\n</span><span class="n">g.e2_img</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-2-1.png" alt="plot of chunk unnamed-chunk-2" /></p>\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">g.e2_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">plot_subject</span><span class="p">(</span><span class="n">e2_subject</span><span class="p">,</span><span class="w"> </span><span class="s2">"2"</span><span class="p">)</span><span class="w">\n</span><span class="n">g.e2_subject</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-3-1.png" alt="plot of chunk unnamed-chunk-3" /></p>\n\n<p>This looks much worse, and the corrected accuracies reflect that</p>\n\n<!-- <details><summary style="background-color: #272822; color: #f8f8f2;">Expand/Collapse Code</summary> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">e2_accs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">adjusted_accuracy</span><span class="p">(</span><span class="n">e2_image</span><span class="p">,</span><span class="w"> </span><span class="n">e2_subject</span><span class="p">)</span><span class="w">\n\n</span><span class="n">total_acc</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">nrow</span><span class="p">(</span><span class="n">expt_2</span><span class="p">[</span><span class="n">expt_2</span><span class="o">$</span><span class="n">correct</span><span class="o">==</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,])</span><span class="o">/</span><span class="n">nrow</span><span class="p">(</span><span class="n">expt_2</span><span class="p">)</span><span class="w">\n</span><span class="n">total_acc</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">total_acc</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="m">100</span></code></pre></figure>\n\n<!-- </details> -->\n\n<p>Only 54.2% of images and 31.3% of subjects classified above chance, as opposed to the reported 71% and 91%, respectively.</p>\n\n<p>Collapsing across all images and subjects, only 60.6% of responses agreed with the top category of the CNN.</p>\n\n<p>We can see the accuracy-inflating strength of having bad foils by comparing experiment 1 vs 2. Images whose classifications remained high in experiment 2 are robust to their next-best label, while those that are significantly worse in experiment 2 are vulnerable.</p>\n\n<!-- <details><summary style="background-color: #272822; color: #f8f8f2;">Expand/Collapse Code</summary> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">e12_images</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">left_join</span><span class="p">(</span><span class="n">e1_image</span><span class="p">,</span><span class="w"> </span><span class="n">e2_image</span><span class="p">,</span><span class="w"> </span><span class="n">by</span><span class="o">=</span><span class="s2">"image"</span><span class="p">)</span></code></pre></figure>\n\n<figure class="highlight"><pre><code class="language-text" data-lang="text">## Warning: Column `image` joining factors with different levels, coercing to\n## character vector</code></pre></figure>\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">e12_images</span><span class="o">$</span><span class="n">image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ordered</span><span class="p">(</span><span class="n">e12_images</span><span class="o">$</span><span class="n">image</span><span class="p">,</span><span class="w"> </span><span class="n">levels</span><span class="o">=</span><span class="n">e12_images</span><span class="o">$</span><span class="n">image</span><span class="p">[</span><span class="n">order</span><span class="p">(</span><span class="n">e12_images</span><span class="o">$</span><span class="n">meancx.x</span><span class="p">)])</span></code></pre></figure>\n\n<!-- </details> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">ggplot</span><span class="p">(</span><span class="n">e12_images</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">image</span><span class="p">,</span><span class="w"> </span><span class="n">ymin</span><span class="o">=</span><span class="n">cilo.x</span><span class="p">,</span><span class="w"> </span><span class="n">ymax</span><span class="o">=</span><span class="n">cihi.x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">meancx.x</span><span class="p">))</span><span class="o">+</span><span class="w">\n  </span><span class="n">geom_pointrange</span><span class="p">()</span><span class="o">+</span><span class="w">\n  </span><span class="n">geom_pointrange</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">ymin</span><span class="o">=</span><span class="n">cilo.y</span><span class="p">,</span><span class="w"> </span><span class="n">ymax</span><span class="o">=</span><span class="n">cihi.y</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">meancx.y</span><span class="p">),</span><span class="n">color</span><span class="o">=</span><span class="s2">"red"</span><span class="p">)</span><span class="o">+</span><span class="w">\n  </span><span class="n">geom_hline</span><span class="p">(</span><span class="n">yintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s2">"red"</span><span class="p">)</span><span class="o">+</span><span class="w">\n  </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Experiment 1 vs Experiment 2 - Mean Accuracy of Images"</span><span class="p">,</span><span class="w">\n       </span><span class="n">y</span><span class="o">=</span><span class="s2">"Mean accuracy across subjects"</span><span class="p">)</span><span class="o">+</span><span class="w">\n  </span><span class="n">theme</span><span class="p">(</span><span class="n">axis.text.x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">element_text</span><span class="p">(</span><span class="n">angle</span><span class="o">=</span><span class="m">45</span><span class="p">,</span><span class="w"> </span><span class="n">hjust</span><span class="o">=</span><span class="m">1</span><span class="p">))</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-6-1.png" alt="plot of chunk unnamed-chunk-6" /></p>\n\n<h1 id="experiments-3a-and-3b">Experiments 3a and 3b</h1>\n\n<p>Experiments 3a and 3b presented all possible labels instead of two. 3a was the “machine theory of mind” task, and 3b asked subjects to rate what <em>they</em> thought the images were. First, the overall summaries of 3a</p>\n\n<!-- <details><summary style="background-color: #272822; color: #f8f8f2;">Expand/Collapse Code</summary> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">e3a_summary</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">summarize_data</span><span class="p">(</span><span class="n">expt_3a</span><span class="p">)</span><span class="w">\n</span><span class="n">e3a_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e3a_summary</span><span class="o">$</span><span class="n">image</span><span class="w">\n</span><span class="n">e3a_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e3a_summary</span><span class="o">$</span><span class="n">subject</span><span class="w">\n\n\n</span><span class="n">e3b_summary</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">summarize_data</span><span class="p">(</span><span class="n">expt_3b</span><span class="p">)</span><span class="w">\n</span><span class="n">e3b_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e3b_summary</span><span class="o">$</span><span class="n">image</span><span class="w">\n</span><span class="n">e3b_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e3b_summary</span><span class="o">$</span><span class="n">subject</span></code></pre></figure>\n\n<!-- </details> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">g.e3a_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">plot_image</span><span class="p">(</span><span class="n">e3a_image</span><span class="p">,</span><span class="w"> </span><span class="s2">"3a"</span><span class="p">)</span><span class="w">\n</span><span class="n">g.e3a_image</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-8-1.png" alt="plot of chunk unnamed-chunk-8" /></p>\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">g.e3a_sub</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">plot_subject</span><span class="p">(</span><span class="n">e3a_subject</span><span class="p">,</span><span class="w"> </span><span class="s2">"3a"</span><span class="p">)</span><span class="w">\n</span><span class="n">g.e3a_sub</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-9-1.png" alt="plot of chunk unnamed-chunk-9" /></p>\n\n<!-- <details><summary style="background-color: #272822; color: #f8f8f2;">Expand/Collapse Code</summary> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">e3a_acc</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">adjusted_accuracy</span><span class="p">(</span><span class="n">e3a_image</span><span class="p">,</span><span class="w"> </span><span class="n">e3a_subject</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="o">=</span><span class="m">1</span><span class="o">/</span><span class="m">48</span><span class="p">)</span></code></pre></figure>\n\n<!-- </details> -->\n\n<p>Again, only 60.4% of images and 47.4% of subjects were above chance accuracy of 1/48, as opposed to the reported 79% and 88%, respectively. Experiment 3b has qualitatively the same results, but their interpretation doesn’t necessarily follow from the data:</p>\n\n<blockquote>\n  <p>These  results  suggest that the humans’ability to decipher adversarial images doesn’t depend on the peculiarities of our machine-theory-of-mind task, and that human performance reflects a more general agreement with machine (mis)classification.</p>\n</blockquote>\n\n<p>There are actually two degenerate interpretations here: either human performance is the same as machine performance, or the subjects were just rating what they thought the images were in all tasks. No further differentiating experiments were done to tease these interpretations apart, so this point is a wash.</p>\n\n<p>Further, if one looks at the most accurately categorized images…</p>\n\n<p><img src="/blog/assets/images/chainlink_fence.png" alt="chainlink fence" /></p>\n<blockquote>\n  <p>Chainlink fence</p>\n</blockquote>\n\n<p><img src="/blog/assets/images/spotlight.png" alt="spotlight" /></p>\n<blockquote>\n  <p>Spotlight</p>\n</blockquote>\n\n<p><img src="/blog/assets/images/monarch_butterfly.png" alt="monarch butterfly" /></p>\n<blockquote>\n  <p>Monarch Butterfly</p>\n</blockquote>\n\n<p>… we can easily see why they were. Remember the argument here is that these are supposedly adversarial images that fool a classifier. A finding that humans and image classification algorithms similarly categorize things that really do look like those categories is unremarkable.</p>\n\n<h1 id="experiment-4---static-images">Experiment 4 - Static images</h1>\n\n<p>Experiment 4 uses “static” images (from the same source paper), but also changes the task in a meaningful way. Rather than asking what category an image was, the subject is presented with the category and a set of representative images and asked “which image has this category?”</p>\n\n<p><img src="/blog/assets/images/static_task.png" alt="static image task" /></p>\n\n<p>This experiment only has 8 images in the set of static images, and each is presented in every trial. The authors note that</p>\n\n<blockquote>\n  <p>upon very close inspection, you may notice a small, often central,‘object’ within each image.</p>\n</blockquote>\n\n<p>and they are actually quite pronounced. Even if the central “objects” don’t look recognizably like the categorized object, they are distinguishable that subjects should be able to recognize them between trials. Since the subjects are asked to choose one category for each of the images, it seems possible for them to use that information to exclude images from later trials. In other words, the trials are not independent. This is reflected in the positive slope of accuracy over trial number</p>\n\n<!-- <details><summary style="background-color: #272822; color: #f8f8f2;">Expand/Collapse Code</summary> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">e4_sum</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">summarize_e4</span><span class="p">(</span><span class="n">expt_4</span><span class="p">)</span><span class="w">\n</span><span class="n">e4_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e4_sum</span><span class="o">$</span><span class="n">image</span><span class="w">\n</span><span class="n">e4_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e4_sum</span><span class="o">$</span><span class="n">subject</span><span class="w">\n</span><span class="n">e4_trial</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e4_sum</span><span class="o">$</span><span class="n">trial</span><span class="w">\n\n</span><span class="n">e4_accs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">adjusted_accuracy</span><span class="p">(</span><span class="n">e4_image</span><span class="p">,</span><span class="w"> </span><span class="n">e4_subject</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="o">=</span><span class="m">1</span><span class="o">/</span><span class="m">8</span><span class="p">)</span></code></pre></figure>\n\n<!-- </details> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">ggplot</span><span class="p">(</span><span class="n">e4_trial</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">trialNum</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">meancx</span><span class="p">))</span><span class="o">+</span><span class="w">\n  </span><span class="n">geom_pointrange</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">ymin</span><span class="o">=</span><span class="n">cilo</span><span class="p">,</span><span class="w"> </span><span class="n">ymax</span><span class="o">=</span><span class="n">cihi</span><span class="p">))</span><span class="o">+</span><span class="w">\n  </span><span class="n">geom_smooth</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">"lm"</span><span class="p">)</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-12-1.png" alt="plot of chunk unnamed-chunk-12" /></p>\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">e4_lm</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">meancx</span><span class="o">~</span><span class="n">trialNum</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">e4_trial</span><span class="p">)</span><span class="w">\n</span><span class="n">summary</span><span class="p">(</span><span class="n">e4_lm</span><span class="p">)</span></code></pre></figure>\n\n<figure class="highlight"><pre><code class="language-text" data-lang="text">## \n## Call:\n## lm(formula = meancx ~ trialNum, data = e4_trial)\n## \n## Residuals:\n##       Min        1Q    Median        3Q       Max \n## -0.040277 -0.022918 -0.000463  0.023489  0.044197 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) 0.233034   0.021472  10.853 3.63e-05 ***\n## trialNum    0.016182   0.005133   3.153   0.0197 *  \n## ---\n## Signif. codes:  0 ''***'' 0.001 ''**'' 0.01 ''*'' 0.05 ''.'' 0.1 '' '' 1\n## \n## Residual standard error: 0.03326 on 6 degrees of freedom\n## Multiple R-squared:  0.6236,	Adjusted R-squared:  0.5608 \n## F-statistic: 9.939 on 1 and 6 DF,  p-value: 0.01975</code></pre></figure>\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">g.e4_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">plot_image</span><span class="p">(</span><span class="n">e4_image</span><span class="p">,</span><span class="w"> </span><span class="s2">"4"</span><span class="p">)</span><span class="w">\n</span><span class="n">g.e4_image</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-14-1.png" alt="plot of chunk unnamed-chunk-14" /></p>\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">g.e4_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">plot_subject</span><span class="p">(</span><span class="n">e4_subject</span><span class="p">,</span><span class="w"> </span><span class="s2">"4"</span><span class="p">)</span><span class="w">\n</span><span class="n">g.e4_subject</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-15-1.png" alt="plot of chunk unnamed-chunk-15" /></p>\n\n<p>Again, the corrected accuracies are much lower than they report, accounting for uncertainty, only 75% of images and 8.4% of subjects had accuracies above chance, rather than the reported 100% and 81%, respectively.  This is exceptionally troubling for their interpretation of their results, as it is <em>subject</em> accuracy that matters, not <em>image</em> accuracy.</p>\n\n<h1 id="experiment-5---digit-classification">Experiment 5 - Digit classification</h1>\n\n<p>In this experiment, perturbed MNIST digits are given, and the subjects are told they were miscategorized – ie. choose the mistaken digit NOT the one that it looks like.</p>\n\n<p>As a first pass, things look ok…</p>\n\n<!-- <details><summary style="background-color: #272822; color: #f8f8f2;">Expand/Collapse Code</summary> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">e5_sum</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">summarize_e5</span><span class="p">(</span><span class="n">expt_5</span><span class="p">)</span><span class="w">\n</span><span class="n">e5_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e5_sum</span><span class="o">$</span><span class="n">image</span><span class="w">\n</span><span class="n">e5_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e5_sum</span><span class="o">$</span><span class="n">subject</span><span class="w">\n</span><span class="n">e5_image</span><span class="o">$</span><span class="n">image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e5_image</span><span class="o">$</span><span class="n">target</span><span class="w">\n\n</span><span class="n">e5_accs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">adjusted_accuracy</span><span class="p">(</span><span class="n">e5_image</span><span class="p">,</span><span class="w"> </span><span class="n">e5_subject</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="o">=</span><span class="m">1</span><span class="o">/</span><span class="m">9</span><span class="p">)</span></code></pre></figure>\n\n<!-- </details> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">g.e5_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">plot_image</span><span class="p">(</span><span class="n">e5_image</span><span class="p">,</span><span class="w"> </span><span class="s2">"5"</span><span class="p">)</span><span class="w">\n</span><span class="n">g.e5_image</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-17-1.png" alt="plot of chunk unnamed-chunk-17" /></p>\n\n<p>But something is off with the confusion matrix</p>\n\n<!-- <details><summary style="background-color: #272822; color: #f8f8f2;">Expand/Collapse Code</summary> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">expt_5</span><span class="o">$</span><span class="n">response</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.factor</span><span class="p">(</span><span class="n">expt_5</span><span class="o">$</span><span class="n">response</span><span class="p">)</span><span class="w">\n</span><span class="n">expt_5</span><span class="o">$</span><span class="n">target</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.factor</span><span class="p">(</span><span class="n">expt_5</span><span class="o">$</span><span class="n">target</span><span class="p">)</span><span class="w">\n</span><span class="n">cm5</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">caret</span><span class="o">::</span><span class="n">confusionMatrix</span><span class="p">(</span><span class="n">expt_5</span><span class="o">$</span><span class="n">response</span><span class="p">,</span><span class="w"> </span><span class="n">expt_5</span><span class="o">$</span><span class="n">target</span><span class="p">)</span><span class="w">\n</span><span class="n">cm5</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">reshape2</span><span class="o">::</span><span class="n">melt</span><span class="p">(</span><span class="n">cm5</span><span class="o">$</span><span class="n">table</span><span class="p">)</span></code></pre></figure>\n\n<!-- </details> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">ggplot</span><span class="p">(</span><span class="n">cm5</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">as.factor</span><span class="p">(</span><span class="n">Reference</span><span class="p">),</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">as.factor</span><span class="p">(</span><span class="n">Prediction</span><span class="p">),</span><span class="w"> </span><span class="n">fill</span><span class="o">=</span><span class="n">value</span><span class="p">))</span><span class="o">+</span><span class="w">\n  </span><span class="n">geom_tile</span><span class="p">()</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-19-1.png" alt="plot of chunk unnamed-chunk-19" /></p>\n\n<p>It looks like everyone just said everything was an 8. In the plot below, the rate of “8” responses is colored in red.</p>\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">ggplot</span><span class="p">(</span><span class="n">e5_image</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">target</span><span class="p">,</span><span class="w"> </span><span class="n">ymin</span><span class="o">=</span><span class="n">cilo</span><span class="p">,</span><span class="w"> </span><span class="n">ymax</span><span class="o">=</span><span class="n">cihi</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">meancx</span><span class="p">))</span><span class="o">+</span><span class="w">\n  </span><span class="n">geom_pointrange</span><span class="p">()</span><span class="o">+</span><span class="w">\n  </span><span class="n">geom_pointrange</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">ymin</span><span class="o">=</span><span class="n">cilo8</span><span class="p">,</span><span class="w"> </span><span class="n">ymax</span><span class="o">=</span><span class="n">cihi8</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">meaneight</span><span class="p">),</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s2">"red"</span><span class="p">)</span><span class="o">+</span><span class="w">\n  </span><span class="n">geom_hline</span><span class="p">(</span><span class="n">yintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="m">9</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s2">"red"</span><span class="p">)</span><span class="o">+</span><span class="w">\n  </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Experiment 5 - black = mean correct responses, red = mean 8 responses"</span><span class="p">)</span><span class="o">+</span><span class="w">\n  </span><span class="n">theme</span><span class="p">(</span><span class="n">axis.text.x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">element_text</span><span class="p">(</span><span class="n">angle</span><span class="o">=</span><span class="m">45</span><span class="p">,</span><span class="w"> </span><span class="n">hjust</span><span class="o">=</span><span class="m">1</span><span class="p">))</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-20-1.png" alt="plot of chunk unnamed-chunk-20" /></p>\n\n<p>The interpretation of this experiment given in the paper is straightforwardly inaccurate. Most subjects did <em>not</em> agree with the machine classification, they just classified everything as an 8. The “above chance accuracy” of the target labels was only due to the very low rates of other digit responses.</p>\n\n<p>This is reflected in the subject accuracy, where only 15.1% of subjects had accuracies significantly better than chance.</p>\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">g.e5_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">plot_subject</span><span class="p">(</span><span class="n">e5_subject</span><span class="p">,</span><span class="w"> </span><span class="s2">"5"</span><span class="p">)</span><span class="w">\n</span><span class="n">g.e5_subject</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-21-1.png" alt="plot of chunk unnamed-chunk-21" /></p>\n\n<h1 id="experiment-6">Experiment 6</h1>\n\n<!-- <details><summary style="background-color: #272822; color: #f8f8f2;">Expand/Collapse Code</summary> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">e6_sum</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">summarize_6</span><span class="p">(</span><span class="n">expt_6</span><span class="p">)</span><span class="w">\n</span><span class="n">e6_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e6_sum</span><span class="o">$</span><span class="n">image</span><span class="w">\n</span><span class="n">e6_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e6_sum</span><span class="o">$</span><span class="n">subject</span><span class="w">\n</span><span class="n">e6_image</span><span class="o">$</span><span class="n">image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e6_image</span><span class="o">$</span><span class="n">target</span><span class="w">\n\n</span><span class="n">e6_accs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">adjusted_accuracy</span><span class="p">(</span><span class="n">e6_image</span><span class="p">,</span><span class="w"> </span><span class="n">e6_subject</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="o">=</span><span class="m">0.5</span><span class="p">)</span></code></pre></figure>\n\n<!-- </details> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">g.e6_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">plot_image</span><span class="p">(</span><span class="n">e6_image</span><span class="p">,</span><span class="w"> </span><span class="s2">"6"</span><span class="p">)</span><span class="w">\n</span><span class="n">g.e6_image</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-23-1.png" alt="plot of chunk unnamed-chunk-23" /></p>\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">g.e6_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">plot_subject</span><span class="p">(</span><span class="n">e6_subject</span><span class="p">,</span><span class="w"> </span><span class="s2">"6"</span><span class="p">)</span><span class="w">\n</span><span class="n">g.e6_subject</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-24-1.png" alt="plot of chunk unnamed-chunk-24" /></p>\n\n<p>These images have surprisingly high accuracy! At last! This one seems solid.</p>\n\n<p>However, the image perturbation introduces small images <em>that look exactly like the target category</em> into the images.  Some examples:</p>\n\n<p>The “rock beauty” fish with the highest accuracy:\n<img src="/blog/assets/images/perturb_fish.png" alt="perturbed fish" /></p>\n\n<p>and the milk jug\n<img src="/blog/assets/images/perturb_milk.png" alt="perturbed milk" /></p>\n\n<p>This is especially problematic since the task was to choose one of two labels – as was the case in experiment 1 as compared to 2, even when the primary label isn’t immediately obvious, if the foil label is significantly worse the categorization becomes trivial.</p>\n\n<h1 id="experiment-7">Experiment 7</h1>\n\n<!-- <details><summary style="background-color: #272822; color: #f8f8f2;">Expand/Collapse Code</summary> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">e7_sum</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">summarize_7</span><span class="p">(</span><span class="n">expt_7</span><span class="p">)</span><span class="w">\n</span><span class="n">e7_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e7_sum</span><span class="o">$</span><span class="n">image</span><span class="w">\n</span><span class="n">e7_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e7_sum</span><span class="o">$</span><span class="n">subject</span><span class="w">\n</span><span class="n">e7_image</span><span class="o">$</span><span class="n">image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e7_image</span><span class="o">$</span><span class="n">imageName</span><span class="w">\n</span><span class="n">e7_accs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">adjusted_accuracy</span><span class="p">(</span><span class="n">e7_image</span><span class="p">,</span><span class="w"> </span><span class="n">e7_subject</span><span class="p">,</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w">\n\n</span><span class="n">e7_total</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">expt_7</span><span class="o">$</span><span class="n">correct</span><span class="p">)</span><span class="o">/</span><span class="n">nrow</span><span class="p">(</span><span class="n">expt_7</span><span class="p">),</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="o">*</span><span class="m">100</span></code></pre></figure>\n\n<!-- </details> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">g.e7_image</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">plot_image</span><span class="p">(</span><span class="n">e7_image</span><span class="p">,</span><span class="w"> </span><span class="s2">"7"</span><span class="p">)</span><span class="w">\n</span><span class="n">g.e7_image</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-26-1.png" alt="plot of chunk unnamed-chunk-26" /></p>\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">g.e7_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">plot_subject</span><span class="p">(</span><span class="n">e7_subject</span><span class="p">,</span><span class="w"> </span><span class="s2">"7"</span><span class="p">)</span><span class="w">\n</span><span class="n">g.e7_subject</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-27-1.png" alt="plot of chunk unnamed-chunk-27" /></p>\n\n<p>Again, only 44.3% of images and 16.3% of subjects had accuracy significantly above chance, as opposed to the reported 78% of images and 83% of subjects. Overall, across all images and subjects, the total accuracy was 58.9%.</p>\n\n<p>The image synthesis technique is tuned to minimize perceptual perturbations, but does impart a recognizable texture to the objects in the image. This was especially problematic in examples where the original image and the target class were semantically related, or had a similar texture, for example</p>\n\n<p><img src="/blog/assets/images/dog_191_1.png" alt="dog 191_1" /></p>\n\n<p>A dog_191, whose adversarial target was “airedale”</p>\n\n<p>In others, the texture was so obvious that it is no longer visually undetectable.</p>\n\n<p><img src="/blog/assets/images/dog_63_1.png" alt="dog 61_1" />\nDog 63, whose adversarial target was “indian cobra.”</p>\n\n<!-- <details><summary style="background-color: #272822; color: #f8f8f2;">Expand/Collapse Code</summary> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">e7_acc_total</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">expt_7</span><span class="o">$</span><span class="n">correct</span><span class="p">)</span><span class="o">/</span><span class="n">nrow</span><span class="p">(</span><span class="n">expt_7</span><span class="p">)</span></code></pre></figure>\n\n<!-- </details> -->\n\n<h1 id="overall-summary">Overall summary</h1>\n<!-- <details><summary style="background-color: #272822; color: #f8f8f2;">Expand/Collapse Code</summary> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">e4_image</span><span class="o">$</span><span class="n">meanrt</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kc">NA</span><span class="w">\n</span><span class="n">e5_image</span><span class="o">$</span><span class="n">meanrt</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kc">NA</span><span class="w">\n</span><span class="n">e6_image</span><span class="o">$</span><span class="n">meanrt</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kc">NA</span><span class="w">\n</span><span class="n">e7_image</span><span class="o">$</span><span class="n">meanrt</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kc">NA</span><span class="w">\n\n</span><span class="n">e5_sub</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e5_image</span><span class="p">[,</span><span class="o">-</span><span class="nf">c</span><span class="p">(</span><span class="m">5</span><span class="p">,</span><span class="m">6</span><span class="p">,</span><span class="m">7</span><span class="p">,</span><span class="m">8</span><span class="p">)]</span><span class="w">\n</span><span class="n">e3a_accs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">adjusted_accuracy</span><span class="p">(</span><span class="n">e3a_image</span><span class="p">,</span><span class="w"> </span><span class="n">e3a_subject</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="o">=</span><span class="m">1</span><span class="o">/</span><span class="m">48</span><span class="p">)</span><span class="w">\n</span><span class="n">e3b_accs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">adjusted_accuracy</span><span class="p">(</span><span class="n">e3b_image</span><span class="p">,</span><span class="w"> </span><span class="n">e3b_subject</span><span class="p">,</span><span class="n">level</span><span class="o">=</span><span class="m">1</span><span class="o">/</span><span class="m">48</span><span class="p">)</span><span class="w">\n</span><span class="n">all_images</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">bind_rows</span><span class="p">(</span><span class="s2">"expt_1"</span><span class="o">=</span><span class="n">e1_accs</span><span class="p">,</span><span class="w"> \n                    </span><span class="s2">"expt_2"</span><span class="o">=</span><span class="n">e2_accs</span><span class="p">,</span><span class="w"> \n                    </span><span class="s2">"expt_3a"</span><span class="o">=</span><span class="n">e3a_accs</span><span class="p">,</span><span class="w"> \n                    </span><span class="s2">"expt_3b"</span><span class="o">=</span><span class="n">e3b_accs</span><span class="p">,</span><span class="w">\n                    </span><span class="s2">"expt_4"</span><span class="o">=</span><span class="n">e4_accs</span><span class="p">,</span><span class="w">\n                    </span><span class="s2">"expt_5"</span><span class="o">=</span><span class="n">e5_accs</span><span class="p">,</span><span class="w">\n                    </span><span class="s2">"expt_6"</span><span class="o">=</span><span class="n">e6_accs</span><span class="p">,</span><span class="w">\n                    </span><span class="s2">"expt_7"</span><span class="o">=</span><span class="n">e7_accs</span><span class="p">,</span><span class="w">\n                    </span><span class="n">.id</span><span class="o">=</span><span class="s2">"expt"</span><span class="p">)</span><span class="w">\n\n</span><span class="n">all_images</span><span class="o">$</span><span class="n">reported_img</span><span class="w"> </span><span class="o">&lt;-</span><span class="w">     </span><span class="nf">c</span><span class="p">(</span><span class="m">94</span><span class="p">,</span><span class="w"> </span><span class="m">71</span><span class="p">,</span><span class="w"> </span><span class="m">79</span><span class="p">,</span><span class="w"> </span><span class="m">81</span><span class="p">,</span><span class="w"> </span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="m">73</span><span class="p">,</span><span class="w"> </span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="m">78</span><span class="p">)</span><span class="w">\n</span><span class="n">all_images</span><span class="o">$</span><span class="n">reported_subject</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">98</span><span class="p">,</span><span class="w"> </span><span class="m">91</span><span class="p">,</span><span class="w"> </span><span class="m">88</span><span class="p">,</span><span class="w"> </span><span class="m">90</span><span class="p">,</span><span class="w"> </span><span class="m">81</span><span class="p">,</span><span class="w">  </span><span class="m">89</span><span class="p">,</span><span class="w"> </span><span class="m">87</span><span class="p">,</span><span class="w">  </span><span class="m">83</span><span class="p">)</span><span class="w">\n\n</span><span class="n">all_im_melt</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">reshape2</span><span class="o">::</span><span class="n">melt</span><span class="p">(</span><span class="n">all_images</span><span class="p">,</span><span class="w"> </span><span class="n">measure.vars</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s2">"image"</span><span class="p">,</span><span class="w"> </span><span class="s2">"subject"</span><span class="p">,</span><span class="w"> </span><span class="s2">"reported_img"</span><span class="p">,</span><span class="w"> </span><span class="s2">"reported_subject"</span><span class="p">))</span><span class="w">\n\n</span><span class="n">all_im_melt</span><span class="o">$</span><span class="n">type</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"image"</span><span class="w">\n</span><span class="n">all_im_melt</span><span class="p">[</span><span class="n">all_im_melt</span><span class="o">$</span><span class="n">variable</span><span class="w"> </span><span class="o">%in%</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"subject"</span><span class="p">,</span><span class="w"> </span><span class="s2">"reported_subject"</span><span class="p">),]</span><span class="o">$</span><span class="n">type</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"subject"</span><span class="w">\n\n</span><span class="n">all_im_melt</span><span class="o">$</span><span class="n">which</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"adjusted"</span><span class="w">\n</span><span class="n">all_im_melt</span><span class="p">[</span><span class="n">all_im_melt</span><span class="o">$</span><span class="n">variable</span><span class="w"> </span><span class="o">%in%</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"reported_subject"</span><span class="p">,</span><span class="w"> </span><span class="s2">"reported_img"</span><span class="p">),]</span><span class="o">$</span><span class="n">which</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"reported"</span><span class="w">\n\n</span><span class="n">all_im_melt</span><span class="o">$</span><span class="n">expt</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ordered</span><span class="p">(</span><span class="n">all_im_melt</span><span class="o">$</span><span class="n">expt</span><span class="p">,</span><span class="w"> </span><span class="n">levels</span><span class="o">=</span><span class="n">experiment_names</span><span class="p">)</span><span class="w">\n</span><span class="n">all_im_melt</span><span class="o">$</span><span class="n">type</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ordered</span><span class="p">(</span><span class="n">all_im_melt</span><span class="o">$</span><span class="n">type</span><span class="p">,</span><span class="w"> </span><span class="n">levels</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s2">"image"</span><span class="p">,</span><span class="w"> </span><span class="s2">"subject"</span><span class="p">))</span><span class="w">\n</span><span class="n">all_im_melt</span><span class="o">$</span><span class="n">which</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ordered</span><span class="p">(</span><span class="n">all_im_melt</span><span class="o">$</span><span class="n">which</span><span class="p">,</span><span class="w"> </span><span class="n">levels</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s2">"reported"</span><span class="p">,</span><span class="w"> </span><span class="s2">"adjusted"</span><span class="p">))</span><span class="w">\n\n</span><span class="n">all_im_melt</span><span class="o">$</span><span class="n">which_type</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">paste</span><span class="p">(</span><span class="n">all_im_melt</span><span class="o">$</span><span class="n">type</span><span class="p">,</span><span class="w"> </span><span class="n">all_im_melt</span><span class="o">$</span><span class="n">which</span><span class="p">)</span><span class="w">\n</span><span class="n">all_im_melt</span><span class="o">$</span><span class="n">which_type</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ordered</span><span class="p">(</span><span class="n">all_im_melt</span><span class="o">$</span><span class="n">which_type</span><span class="p">,</span><span class="w"> </span><span class="n">levels</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s2">"image reported"</span><span class="p">,</span><span class="w"> </span><span class="s2">"subject reported"</span><span class="p">,</span><span class="w"> </span><span class="s2">"image adjusted"</span><span class="p">,</span><span class="w"> </span><span class="s2">"subject adjusted"</span><span class="p">))</span></code></pre></figure>\n\n<!-- </details> -->\n\n<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">ggplot</span><span class="p">(</span><span class="n">all_im_melt</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">expt</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">value</span><span class="p">,</span><span class="w"> \n                        </span><span class="n">fill</span><span class="o">=</span><span class="n">which_type</span><span class="p">))</span><span class="o">+</span><span class="w">\n  </span><span class="n">geom_col</span><span class="p">(</span><span class="n">position</span><span class="o">=</span><span class="s2">"dodge"</span><span class="p">)</span><span class="o">+</span><span class="w">\n  </span><span class="n">scale_fill_brewer</span><span class="p">(</span><span class="n">palette</span><span class="o">=</span><span class="s2">"Paired"</span><span class="p">)</span><span class="o">+</span><span class="w">\n  </span><span class="n">theme</span><span class="p">(</span><span class="n">axis.text.x</span><span class="o">=</span><span class="n">element_text</span><span class="p">(</span><span class="n">angle</span><span class="o">=</span><span class="m">45</span><span class="p">,</span><span class="n">hjust</span><span class="o">=</span><span class="m">1</span><span class="p">))</span></code></pre></figure>\n\n<p><img src="/blog/assets/images/2019-04-09-Adversarial-Analysis-of-Zhou-Firestone/unnamed-chunk-30-1.png" alt="plot of chunk unnamed-chunk-30" /></p>','\n',char(10)),NULL,'','2019-04-09 07:00:00','Jonny Saunders blog','',NULL,'2024-01-03 18:04:29','read');
INSERT INTO items VALUES('https://jon-e.net/blog/2019/03/12/Correlation-Isnt-Connectivity/','Correlation Isn''t Connectivity',replace('<p>In a network analysis class this fall, I was unsurprised but more than a little annoyed to learn that the widespread practice of measuring “functional connectivity” by correlating voxelwise fMRI timeseries was essentially unvalidated.</p>\n\n<p>Of course, there’s no reason to believe that taking a linear measurement like the pearson correlation would reflect the highly nonlinear dynamics of the brain (even if you ignore the problems with taking simple correlations of timeseries), but at the time I thought it was worth simulating.</p>\n\n<p>The simulations are for another post, but this morning it occurred to me that we actually do have ground truth data to assess the relationship between connectivity and activity correlation – we have the C. Elegans connectome (well at least we have <em>one</em>) and recently folks have been doing whole-brain GCaMP imaging.</p>\n\n<p>Borrowing data from <a href="https://doi.org/10.1016/j.cell.2015.09.034">this lovely paper</a> and the connectome, helpfully stored in <a href="https://github.com/theideasmith/network">this squirrely little repo</a>… Well I won’t hold you in suspense.</p>\n\n<h1 id="hashtag-no-resemblance">hashtag no resemblance.</h1>\n\n<p>Comparing the correlation and connectivity matrices</p>\n\n<p><img src="/blog/assets/images/corr/mats.png" alt="comparing matrices" /></p>\n\n<p>And ROC curve relating binary connectedness to absolute value of correlation</p>\n\n<p><img src="/blog/assets/images/corr/roc.png" alt="auc" /></p>\n\n<p><strong>Let me be clear</strong> I do indeed believe there is statistical dependency between voxels, and I don’t believe the people who do “functional connectivity” with simple correlation are bad or stupid people. I just think we get so busy with the dogma that we don’t take the time to learn math or validate our analyses.</p>\n\n<div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;">\n  <div class="jupyter-notebook-iframe-container">\n    <iframe src="../../../../assets/notebooks/correlation_aint_connectivity.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + ''px''"></iframe>\n  </div>\n</div>','\n',char(10)),NULL,'','2019-03-12 07:00:00','Jonny Saunders blog','',NULL,'2024-01-03 18:04:29','read');
INSERT INTO items VALUES('https://jon-e.net/blog/2019/03/12/Crudely-Converting-OpenEphys-to-Neurodata-Without-Borders/','Crudely converting OpenEphys to Neurodata Without Borders',replace('<p>Our lab is toying with the idea of moving our data to <a href="https://www.nwb.org/">Neurodata Without Borders</a>. Turns out it won’t be such a monumental task after all. I figured someone would have written a guide for converting the old OpenEphys <code class="language-plaintext highlighter-rouge">.continuous</code> style of data, but I couldn’t find any. Behold, converting my lab’s cryptic metadata and OE data to NWB.</p>\n\n<h1 id="links">Links</h1>\n\n<ul>\n  <li><a href="../../../../assets/notebooks/nwb_convert.ipynb">notebook</a></li>\n  <li><a href="../../../../assets/data/nwb.zip">data</a></li>\n  <li><a href="../../../../assets/notebooks/OpenEphys.py">bugfixed OE loading script</a></li>\n  <li><a href="../../../../assets/notebooks/convert_example.nwb">generated .nwb file</a></li>\n</ul>\n\n<h1 id="the-outcome">The Outcome…</h1>\n\n<p>Before we wade into some code, let us fortify ourselves with the satisfaction of our endpoint.</p>\n\n<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/root\n├── acquisition\n│   ├── CH5\n│   │   ├── data\n│   │   └── starting_time\n│   ├── CH6\n│   │   ├── data\n│   │   └── starting_time\n│   ├── CH7\n│   │   ├── data\n│   │   └── starting_time\n│   └── CH8\n│       ├── data\n│       └── starting_time\n├── analysis\n├── file_create_date\n├── general\n│   ├── experimenter\n│   ├── institution\n│   ├── lab\n│   ├── pharmacology\n│   └── subject\n│       ├── date_of_birth\n│       ├── genotype\n│       ├── sex\n│       ├── species\n│       └── subject_id\n├── identifier\n├── intervals\n│   └── trials\n│       ├── LaserOnOff\n│       ├── amplitude\n│       ├── duration\n│       ├── gapdelay\n│       ├── gapdur\n│       ├── id\n│       ├── laser\n│       ├── loop_flg\n│       ├── next\n│       ├── pulseamp\n│       ├── pulsedur\n│       ├── ramp\n│       ├── seamless\n│       ├── soa\n│       ├── soaflag\n│       ├── start_time\n│       ├── stop_time\n│       └── type\n├── processing\n├── session_description\n├── session_start_time\n├── stimulus\n│   ├── presentation\n│   └── templates\n├── timestamps_reference_time\n└── units\n    ├── channel\n    ├── cluster\n    ├── id\n    ├── spike_times\n    ├── spike_times_index\n    └── tetrode\n\n11 directories, 50 files\n</code></pre></div></div>\n\n<p>ooo aaaaahhhh…</p>\n\n<p>so without further ado.</p>\n\n<h1 id="the-code">The Code…</h1>\n\n<div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;">\n  <div class="jupyter-notebook-iframe-container">\n    <iframe src="../../../../assets/notebooks/nwb_convert.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + ''px''"></iframe>\n  </div>\n</div>','\n',char(10)),NULL,'','2019-03-12 07:00:00','Jonny Saunders blog','',NULL,'2024-01-03 18:04:29','read');
INSERT INTO items VALUES('https://jon-e.net/blog/2018/11/01/Past-Art-Vol-1/','Past Art, Vol. 1: Insomia',replace('<p>I can’t sleep most nights, but some rare nights are useful. Sometimes I spend more time finishing things, but other times I spend a dozen unblinking hours baking something halfway. A few selected one-shot art pieces from the past few years.</p>\n\n<p>This is the first of my attempts to remember what I do by cataloguing my art. I can roughly divide the rest of it into brain-related art, large-scale art worthy of more description, and smaller-scale art worthy of nothing. Those will be other posts.</p>\n\n<p>Ordered by chronology, not quality. Actually the older stuff is worse because I didn’t really have control over my life through most of it. They all speak tender nothings to me though.</p>\n\n<h1 id="feb-13-2015---audio-glitches">Feb 13, 2015 - Audio Glitches</h1>\n\n<p>I know this was a product of insomina. I think the insomnia was a product of some angst over my then partner. I’m not sure why they’re related.</p>\n\n<p>I had taken a pretty unremarkable picture out riding my bike in the farmland surrounding Salem OR.</p>\n\n<p><img src="/blog/assets/images/artvol1/audioedit_orig.jpg" alt="nothing to see here" /></p>\n<blockquote>\n  <p><em>nothing to see here</em></p>\n</blockquote>\n\n<p>I had just read <a href="http://rosa-menkman.blogspot.com">Rosa Menkman</a>’s excellent <a href="https://beyondresolution.info/A-Vernacular-of-File-Formats">“Vernacular of File Formats”</a> which will put you in touch with the numerical reality of photos. This was the blessed time before I knew anything about programming. I knew audio tools. I wanted to use audio tools.</p>\n\n<p>The process is completely lost, but it involved opening the image in a text editor and using reverb. It is one of my favorites.</p>\n\n<p>If you use it as a background, people worry about your screen.</p>\n\n<p><img src="/blog/assets/images/artvol1/audioedit.png" alt="audio edit" /></p>\n\n<h1 id="april-4th-2016---stichky-slug">April 4th, 2016 - Stichky Slug</h1>\n\n<p><strong>this video has bright flashing colors and might be unsuitable for people with epilepsy</strong></p>\n\n<p>My garden was only flowers this spring, and the slugs were eating my violas. I didn’t mind. I loved catching them at it in the dark.</p>\n\n<p>I’d like to find the code for this. From what I recall I propagated pixel values across frames if they were getting brighter, but I had just started programming and the result is more likely from some deep secret in the convolutions of hundreds of lines of bad python. Mix in a few compression artifacts…</p>\n\n<video controls="" preload="none">\n  <source src="/blog/assets/images/artvol1/stichky_slug.mp4" type="video/mp4" />\n</video>\n\n<h1 id="jan-21-2017---the-last-wild-forest-bambi">Jan 21, 2017 - The Last Wild Forest Bambi</h1>\n\n<p>I get sad about the way people write about climate change on the internet. I was drinking a lot. This was a hard winter. I had just downloaded a pirated copy of photoshop and this sentence seemed like just as good music as any.</p>\n\n<p><img src="/blog/assets/images/artvol1/bambino.png" alt="bambino" /></p>\n\n<h1 id="feb-23-2017---yll-shoot-yr-eye-out">Feb 23, 2017 - yll shoot yr eye out</h1>\n\n<p>This isn’t so much my art as it is being depressed and watching movies rendered as ASCII.</p>\n\n<video controls="" preload="none">\n  <source src="/blog/assets/images/artvol1/yllshootyreye.mp4" type="video/mp4" />\n</video>\n\n<h1 id="feb-27-2017---no">Feb 27, 2017 - no</h1>\n\n<p>Created under similar circumstances, I was watching a lot of educational films from the 1940’s. The audio is important.</p>\n\n<video controls="" preload="none">\n  <source src="/blog/assets/images/artvol1/nooo.mp4" type="video/mp4" />\n</video>\n\n<p>There’s a big gap in time here as I started to make more brain-focused art and put myself back together. More of that to come.</p>\n\n<h1 id="april-28-2018---coop-logos">April 28, 2018 - Coop Logos</h1>\n\n<p><strong>these videos have bright flashing colors and might be unsuitable for people with epilepsy</strong></p>\n\n<p>I maintain the website for my coop, and it needed a background. Pictures are boring. Cellular automata and the belousov-zhabotinsky reaction are beautiful. A few videos generated using this basic code structure (sorry for the um utter unreadability… writing unsustainable and cryptic code is sort of in the nature of insomia art):</p>\n\n<pre><code class="python">\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage import morphology\nfrom tqdm import trange, tqdm\nfrom scipy.signal import convolve2d\nimport matplotlib.pyplot as plt\nfrom matplotlib import animation, cm, colors\n\n\nimg = Image.open(''/some/image.png'')\nimg = np.array(img)\n\n# remove alpha channel\nif img.shape[2] == 4:\n    img = img[:,:,0:3]\n\n# compress\nimg_comp  = morphology.label(img, return_num=True)\n\n\n#flatten colors\nimg_flat = np.sum(img, axis=2)\nimcolors, counts = np.unique(img_flat.flatten(), return_counts=True)\nimcolors = imcolors[np.argsort(counts)[-3:-1]]\n\nimg_flat[~np.isin(img_flat, imcolors)] = 0\n\n# the two next-to-most-frequent are the lighter greens\nrgbcolors_1, rgbcounts = np.unique(img.reshape(-1,3), return_counts=True, axis=0)\nrgbcolors = rgbcolors_1[np.argsort(rgbcounts)[-3:-1]]\nback_color = rgbcolors_1[np.argsort(rgbcounts)[-1]]\n\n# make masks\nmask1 = np.zeros_like(img_flat, dtype = np.bool)\nmask2 = np.zeros_like(img_flat, dtype = np.bool)\n\nmask1[np.where(img_flat==imcolors[1])] = True\nmask2[np.where(img_flat==imcolors[0])] = True\n\n##################\n# Initialize the array with random amounts of A, B and C.\nimg_bz = np.zeros_like(img, dtype=np.float)\nimg_bz[:,:,0] = 0.50\nimg_bz[mask1,0] = 0.55\nimg_bz[mask2,0] = 0.6\nimg_bz[:,:,1] = 0.50-np.random.rand(img_bz.shape[0], img_bz.shape[1])/10.\nimg_bz[mask1,1] = 0.55-np.random.rand(img_bz[mask1,1].shape[0])/10.\nimg_bz[mask2,1] = 0.6-np.random.rand(img_bz[mask2,1].shape[0])/10.\nimg_bz[:,:,2] = 0.50+np.random.rand(img_bz.shape[0], img_bz.shape[1])/10.\nimg_bz[mask1,2] = 0.55+np.random.rand(img_bz[mask1,1].shape[0])/10.\nimg_bz[mask2,2] = 0.6+np.random.rand(img_bz[mask2,1].shape[0])/10.\nimg_bz = np.clip(img_bz, 0, 1)\n\nimg_bz = np.rollaxis(img_bz,2)\narr = np.stack([img_bz, img_bz])\n\nny, nx = arr.shape[2], arr.shape[3]\n\n# Reaction parameters.\nalpha, beta, gamma = .2, .1, .1\n\ndef update(p,arr):\n    """Update arr[p] to arr[q] by evolving in time."""\n\n    # Count the average amount of each species in the 9 cells around each cell\n    # by convolution with the 3x3 array m.\n    q = (p+1) % 2\n    s = np.zeros((3, ny,nx))\n    m = np.ones((3,3)) / 9\n    for k in range(3):\n        s[k] = convolve2d(arr[p,k], m, mode=''same'', boundary=''wrap'')\n    # Apply the reaction equations\n    arr[q,0] = s[0] + s[0]*(alpha*s[1] - gamma*s[2])\n    arr[q,1] = s[1] + s[1]*(beta*s[2] - alpha*s[0])\n    arr[q,2] = s[2] + s[2]*(gamma*s[0] - beta*s[1])\n    # Ensure the species concentrations are kept within [0,1].\n    np.clip(arr[q], 0, 1, arr[q])\n    #arr = arr % 1.\n    return arr\n\n\n# Set up the image\nfig, ax = plt.subplots()\nim = ax.imshow(arr[0,0], norm=colors.NoNorm())\nax.axis(''off'')\nn_frames = 2000\n\npbar = tqdm(total = n_frames)\n\ndef animate(i, arr):\n    """Update the image for iteration i of the Matplotlib animation."""\n\n    if i == 100:\n        alpha, beta, gamma = 1.2, 1., 1.\n        print(''changed'')\n    arr = update(i % 2, arr)\n    im.set_array(arr[i % 2, 0])\n    #im.set_array(arr[0, 0])\n    pbar.update()\n    return [im]\n\nWriter = animation.writers[''ffmpeg'']\nwriter = Writer(fps=30, metadata=dict(artist=''Me''), bitrate=1800,\n                extra_args=[''-vcodec'', ''libx264''])\n\nanim = animation.FuncAnimation(fig, animate, frames=2000, interval=5,\n                               blit=True, fargs=(arr,))\nplt.show()\nanim.save(''/some/video.mp4'', writer=writer)\n\n\n</code></pre>\n\n<video controls="" preload="none">\n  <source src="/blog/assets/images/artvol1/logo1.mp4" type="video/mp4" />\n</video>\n\n<p>I think this second one evolved to the left faster for pixels with larger brightness values. The only thing I know for sure is that it starts to look like melted plastic.</p>\n\n<video controls="" preload="none">\n  <source src="/blog/assets/images/artvol1/logo2.mp4" type="video/mp4" />\n</video>\n\n<p>This video enters my void.</p>\n\n<video controls="" preload="none">\n  <source src="/blog/assets/images/artvol1/logo3.mp4" type="video/mp4" />\n</video>','\n',char(10)),NULL,'','2018-11-01 07:00:00','Jonny Saunders blog','',NULL,'2024-01-03 18:04:29','read');
INSERT INTO items VALUES('https://jon-e.net/blog/2018/10/18/northern-lights/','Northern Lights',replace('<style>\n    body {\n        background-color: black;\n        color: #F5F5F5;\n    }\n\n    .header {\n        background-color: #00000090;\n        color: #F0F0F0;\n    }\n    .header__title {\n        color: #F0F0F0;\n    }\n\n    .header__list a,\n    .header__list span{\n        color: #F0F0F0;\n    }\n\n    #markdown a {\n    color: #B951D1;\n    border-bottom: 2px solid #888888;\n    -webkit-box-shadow: inset 0 -3px 0 #222222;\n    box-shadow: inset 0 -3px 0 #222222;\n    }\n\n    blockquote, q {\n    margin: 0 0 1.5rem;\n    font-family: Lora,serif;\n    font-weight: 400;\n    font-size: 1.25em;\n    color: #888888;\n    line-height: 1.4;\n    }\n\n    .post__author a {\n    color: #B951D1;\n    -webkit-transition: color .2s ease-in-out;\n    transition: color .2s ease-in-out;\n    }\n</style>\n\n<p>I needed to build the northern lights in my kitchen. (localized entirely within my kitchen).</p>\n\n<p>They look like this:</p>\n<video controls="">\n  <source src="/blog/assets/images/nlights.mp4" type="video/mp4" />\n</video>\n\n<p>And they also twinkle:</p>\n\n<video controls="" preload="none">\n  <source src="/blog/assets/images/twinkle.mp4" type="video/mp4" />\n</video>\n\n<p>They only turn on rarely because they are magic, but if you need them on to feel the close glow of the north pole you can enter the secret code…</p>\n\n<video controls="" preload="none">\n  <source src="/blog/assets/images/onoff.mp4" type="video/mp4" />\n</video>\n\n<h1 id="ingredients">Ingredients</h1>\n\n<table>\n  <thead>\n    <tr>\n      <th>Object</th>\n      <th>Link</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>LED Strips</td>\n      <td><a href="https://www.aliexpress.com/item/WS2811-IC-Strip-Vedio-show-addressable-individually-ip30-or-waterproof-ip67-5050-RGB-SMD-30/32624331128.html?spm=a2g0s.9042311.0.0.77624c4dozuwtS">get some leds</a></td>\n    </tr>\n    <tr>\n      <td>LED Stands (3d mesh)</td>\n      <td><a href="https://jon-e.net/blog/assets/hosted/fat_led_stand.stl">download an stl</a></td>\n    </tr>\n    <tr>\n      <td>Arduino Uno</td>\n      <td><a href="https://store.arduino.cc/usa/arduino-uno-rev3">arduinos here</a></td>\n    </tr>\n    <tr>\n      <td>Photodiode</td>\n      <td><a href="https://www.digikey.com/products/en/sensors-transducers/optical-sensors-photodiodes/543">idk found in the lab try digikey</a></td>\n    </tr>\n    <tr>\n      <td>12V 3A DC Power Supply</td>\n      <td> </td>\n    </tr>\n    <tr>\n      <td>200 Ohm Resistor</td>\n      <td> </td>\n    </tr>\n  </tbody>\n</table>\n\n<h1 id="makin-it">Makin it</h1>\n\n<p>is simple.</p>\n\n<h2 id="step-1-board-of-leds">Step 1: Board of LEDs</h2>\n\n<p><em>Print a bunch of these <a href="https://jon-e.net/blog/assets/hosted/fat_led_stand.stl">little stands</a></em></p>\n\n<p><img src="https://jon-e.net/blog/assets/images/led_stand.png" alt="led stand" /></p>\n<blockquote>\n  <p><em>moody as your mahogany past</em></p>\n</blockquote>\n\n<p>and glue them onto a board thusly</p>\n\n<p><img src="https://jon-e.net/blog/assets/images/led_build_1.jpg" alt="glued to board" /></p>\n\n<h2 id="step-2-wire-it-up">Step 2: Wire it up</h2>\n\n<p>Like this. You need to</p>\n\n<ol>\n  <li>Power the LEDs, in my case with 12V and 3A split between 3 banks of 66 lights.</li>\n  <li>Wire the DMX input lines to the arduino through some resistors and</li>\n  <li>Attach a photodiode to sense when it gets dark. I used a 4.7kOhm resistor to get the photodiode in the luminance range of my kitchen, this will vary depending on your diode and ambient lighting conditions.</li>\n</ol>\n\n<p><img src="https://jon-e.net/blog/assets/images/led_build_circuit.png" alt="yeah like this i said" /></p>\n\n<p>Do not do as I do, and behold this as a warning. This style of circuit is built to cause fires and generate solder fumes. I epoxied over the exposed solder and wire to avoid dust combustion. Disregard the capacitor, it proved to explode.</p>\n\n<p><img src="https://jon-e.net/blog/assets/images/led_build_wired.jpg" alt="disregard this" /></p>\n\n<h2 id="step-3-code">Step 3: Code</h2>\n\n<p>I stole a lot of this, hopefully I attributed as I went because I do not remember where it came from now. You will need the <a href="http://fastled.io">FastLED library</a>.</p>\n\n<p>The idea is that we want to turn the lights on when the ambient light gets below a certain level. Except we don’t want to just turn on, that would be too predictable for a lightswitch. Instead, we pick a random delay up to an hour and wait to turn on. You catch the northern lights by chance.</p>\n\n<p>But if you can’t wait for luck, you make your own. Flicking the light on and off three times will trigger the light.</p>\n\n<p>Right now there are two modes, the northern lights, and twinkling. One picks a max value/saturation color in HSV space and fades its neighbors towards it. The other twinkles white lights. Who knows which is which. Each time the light turns on it picks a program at random.</p>\n\n<pre><code class="c">\n#include &lt;FastLED.h&gt;\n\n#define NUM_STRIPS 3\n#define NUM_PER_STRIP 22\n#define NUM_LEDS NUM_STRIPS*NUM_PER_STRIP\n\n// led array\nCRGB leds[NUM_LEDS];\n\n// https://learn.adafruit.com/photocells/arduino-code\nint photocellPin = 0;     // the cell and 10K pulldown are connected to a0\nint photocellReading;     // the analog reading from the sensor divider\n#define DATA_PIN_1 2\n#define DATA_PIN_2 3\n#define DATA_PIN_3 4\n\n// array to hold times since last light flick\n// initialize to above threshold so we don''t autostart the first time\nlong codetimes[3] = {10000, 10000, 10000};\n\n// some logic variables to tell what state we''re in.\n// it''s crude but it works damn it\nbool ison;                // are the LEDs on?\nbool isdark;              // did it go dark?\nint program=1;            // which program are we running?\nunsigned long wentdark=0; // did we just go dark?\nlong waittime;            // how long should we wait to turn the lights on?\nunsigned long ontime;     // how long should the lights stay on?\nlong darktime;            // how long was it dark?\n\n// idiosyncratic lighting variables\nint lightthresh=200;\nint flicklength=5000;\nint framedelay=30;\n\n\nvoid loop() {\n  photocellReading = analogRead(photocellPin);\n  //Serial.print("Analog reading = ");\n  //Serial.println(photocellReading);     // the raw analog reading\n\n  if (photocellReading &gt; lightthresh){\n    // if we''re just getting light, turn the lights off.\n    if (isdark == true){\n      for(int i=0; i&lt;NUM_LEDS; i++){\n        leds[i] = CRGB(0, 0, 0);\n\n      }\n      LEDS.setBrightness(0);\n      LEDS.show();\n      isdark = false;\n      ison = false;\n\n      // stash the code\n      // record the length of time that the light was off\n      codetimes[0] = codetimes[1];\n      codetimes[1] = codetimes[2];\n\n      darktime = millis()-wentdark;\n      codetimes[2] = darktime;\n    }\n    return;\n  } else {\n    if (isdark == false){\n      // when it first gets dark...\n      // pick a program\n      if (random8()&lt;128){\n        program = 1;\n      } else {\n        program = 2;\n      }\n\n      // get time off\n      wentdark = millis();\n\n      // if we are getting manually turned on, the wait time is zero\n      if (codetimes[2] &lt; flicklength &amp;&amp; codetimes[1] &lt; flicklength){\n        waittime = 0;\n      } else {\n        // otherwise get delay between now and an hour\n        waittime = random(0, 3600000);\n      }\n\n      // turn the lights on\n      isdark = true;\n      ison = false;\n    }\n\n    if (millis()&lt;wentdark || millis()&lt;ontime){\n      // arduino clock flipped back to zero\n      wentdark = 0;\n      ontime = 0;\n    }\n\n\n    if (ison == false &amp;&amp; (millis()-wentdark)&gt;waittime){\n      // we''re just turning on of our own accord\n      // pick a program\n      if (random8()&lt;128){\n        program = 1;\n      } else {\n        program = 2;\n      }\n\n      // when did we go on? how long will we go?\n      ontime = millis();\n      waittime = random(600000, 3600000);\n\n      // if we have waited long enough...\n      LEDS.setBrightness(255);\n      ison = true;\n\n    }\n\n\n    // if the light turns back on turn off.\n    if (ison == true &amp;&amp; (millis()-ontime)&gt;waittime){\n      for(int i=0; i&lt;NUM_LEDS; i++){\n        leds[i] = CRGB(0, 0, 0);\n\n      }\n      LEDS.setBrightness(0);\n      LEDS.show();\n      wentdark = millis();\n      waittime = random(600000, 3600000);\n      //waittime = 5000;\n      LEDS.setBrightness(0);\n      ison = false;\n    }\n\n\n    // finally if we''re on, do the thing.\n    if (ison == true){\n      if (program == 1){\n        northernLights(leds);\n      } else {\n        twinkle(leds);\n      }\n    }\n\n\n    LEDS.show();\n  }\n\n\n  delay(framedelay);\n\n\n}\n\n\nvoid setup() {\n  // init values\n  ison = false;\n  isdark = false;\n\n  random16_set_seed(8934);\n  random16_add_entropy(analogRead(3));\n\n  // start up serial if ya want it\n  //Serial.begin(9600);\n  //Serial.println("resetting!");\n\n  // setup leds\n  delay(1000);\n  LEDS.addLeds&lt;WS2811,DATA_PIN_1,BRG&gt;(leds,0, NUM_PER_STRIP);\n  LEDS.addLeds&lt;WS2811,DATA_PIN_2,BRG&gt;(leds,NUM_PER_STRIP, NUM_PER_STRIP);\n  LEDS.addLeds&lt;WS2811,DATA_PIN_3,BRG&gt;(leds,NUM_PER_STRIP*2,NUM_PER_STRIP);\n  LEDS.setBrightness(255);\n\n  for(int i=0; i&lt;NUM_LEDS; i++){\n        leds[i] = CRGB(0, 0, 0);\n\n  }\n  LEDS.setBrightness(0);\n  LEDS.show();\n}\n\n\n\nvoid northernLights(CRGB* leds){\n  for(int i=0; i&lt;NUM_LEDS; i++){\n\n    if (i == NUM_LEDS-1) {\n      fadeTowardColor(leds[i],leds[i-1],5);\n    }\n    else if (i==0){\n      fadeTowardColor(leds[i],leds[i+1],5);\n    }\n    else{\n      fadeTowardColor(leds[i],(leds[i+1]+leds[i-1])/2,5);\n    }\n\n    if(random16()&lt;40){\n        CRGB color = CHSV( random8(), 255, 255);\n        fadeTowardColor(leds[i], color, 255);\n  }\n  //leds[i] %= 225;\n  }\n  //delay(30);\n}\n\nvoid twinkle(CRGB* leds){\n  for(int i=0; i&lt;NUM_LEDS; i++){\n\n    fadeTowardColor(leds[i],CRGB(0,0,0),16);\n\n    if(random16()&lt;50){\n        fadeTowardColor(leds[i], CRGB(255,255,255), 255);\n    }\n  }\n}\n\nvoid nblendU8TowardU8( uint8_t&amp; cur, const uint8_t target, uint8_t amount)\n{\n  if( cur == target) return;\n\n  if( cur &lt; target ) {\n    uint8_t delta = target - cur;\n    delta = scale8_video( delta, amount);\n    cur += delta;\n  } else {\n    uint8_t delta = cur - target;\n    delta = scale8_video( delta, amount);\n    cur -= delta;\n  }\n}\n\n// Blend one CRGB color toward another CRGB color by a given amount.\n// Blending is linear, and done in the RGB color space.\n// This function modifies ''cur'' in place.\nCRGB fadeTowardColor( CRGB&amp; cur, const CRGB&amp; target, uint8_t amount)\n{\n  nblendU8TowardU8( cur.red,   target.red,   amount);\n  nblendU8TowardU8( cur.green, target.green, amount);\n  nblendU8TowardU8( cur.blue,  target.blue,  amount);\n  return cur;\n}\n\n</code></pre>\n\n<p>Viola.</p>\n\n<video controls="" preload="none">\n  <source src="/blog/assets/images/lightzoom.mp4" type="video/mp4" />\n</video>','\n',char(10)),NULL,'','2018-10-18 07:00:00','Jonny Saunders blog','',NULL,'2024-01-03 18:04:29','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/650241','Fundamentals of failure in topologically interlocked structures','Koureas, Ioannis',NULL,'','2023-12-13 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-03 19:12:44','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/650240','Decentralized Attack Search and the Design of Bug Bounty Schemes','Gersbach, Hans; Mamageishvili, Akaki; Pitsuwan, Fikri',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-03 19:12:44','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/650239','Crowdsearch','Gersbach, Hans; Mamageishvili, Akaki; Pitsuwan, Fikri',NULL,'','2023-10-16 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-03 19:12:44','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/650238','Fraumünsterpost:  Life Cycle Assessment and Indoor Hygrothermal Monitoring','Priore, Yasmine; Posani, Magda; Habert, Guillaume',NULL,'','2023-12-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-03 19:12:44','read');
INSERT INTO items VALUES('https://www.arl.org/day-in-review/day-in-review-january-3-4/','Day in Review (January 3–4)',replace('<p>Last Updated on January 9, 2024, 11:19 am ET Sign up to receive the Day in Review by email. Jump to: Thursday, January 4 Wednesday, January 3 Top o’ the...</p>\n<p>The post <a href="https://www.arl.org/day-in-review/day-in-review-january-3-4/">Day in Review (January 3–4)</a> appeared first on <a href="https://www.arl.org">Association of Research Libraries</a>.</p>\n','\n',char(10)),NULL,'','2024-01-03 21:05:46','Association of Research Libraries News','',NULL,'2024-01-04 01:26:57','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2024/01/04/guest-post-the-truth-is-in-there-the-library-of-babel-and-generative-ai/','Guest Post — The Truth Is in There: The Library of Babel and Generative AI',replace('<p>The short story “The Library of Babel” by Jorge Luis Borges provides an opportunity to consider the veracity of AI-generated information.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2024/01/04/guest-post-the-truth-is-in-there-the-library-of-babel-and-generative-ai/">Guest Post &#8212; The Truth Is in There: The Library of Babel and Generative AI</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2024-01-04 10:30:22','Scholarly Kitchen','',NULL,'2024-01-05 02:41:03','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/650482','Enough Liquidity with Enough Capital-and Vice Versa?','Haller, Hans; Zelzner, Sebastian; Gersbach, Hans',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-05 02:41:05','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/649929','Topological Matter by Inverse Design','Bösch, Cyrill',NULL,'','2024-03-05 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-05 02:41:05','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/647553','Bipolar outflows out to 10 kpc for massive galaxies at redshift z ≈ 1','Guo, Yucheng; Bacon, Roland; Bouché, Nicolas F.; Wisotzki, Lutz; Schaye, Joop; Blaizot, Jérémy; Verhamme, Anne; Cantalupo, Sebastiano; Boogaard, Leindert A.; Brinchmann, Jarle; Cherrey, Maxime; Kusakabe, Haruka; Langan, Ivanna; Leclercq, Floriane; Matthee, Jorryt; Michel-Dansac, Léo; Schroetter, Ilane; Wendt, Martin',NULL,'','2023-12-07 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-05 02:41:05','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/647566','Prioritizing biomaterials for spinal disc implants by a fuzzy AHP and TOPSIS decision making method','Ansaripour, Hossein; Haeussler, Kim Lars; Ferguson, Stephen J.; Flohr, Markus',NULL,'','2023-12-06 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-05 02:41:06','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/650615','Laser-scanning Survey of water management infrastructure around Anosizato in Antananarivo, Madagascar','Urech, Philipp',NULL,'','2022-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-05 17:58:25','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/621948','Wireless Channel Charting: Theory, Practice, and Applications','Ferrand, Paul; Guillaud, Maxime; Studer, Christoph; Tirkkonen, Olav',NULL,'','2023-06-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-05 17:58:25','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/623491','An Energy-Efficient GeMM-Based Convolution Accelerator With On-the-Fly im2col','Fornt, Jordi; Fontova-Musté, Pau; Caro, Martí; Abella, Jaume; Moll, Francesc; Altet, Josep; Studer, Christoph',NULL,'','2023-11-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-05 17:58:25','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/634151','A search for new physics in central exclusive production using the missing mass technique with the CMS detector and the CMS-TOTEM precision proton spectrometer','CMS and TOTEM Collaborations; Tumasyan, Armen; Aarrestad, Thea; Androsov, Konstantin; Backhaus, Malte; Berger, Philipp; Calandri, Alessandro; Datta, Kaustuv; de Cosa, Annapaola; Dissertori, Günther; Dittmar, M.; Donegà, Mauro; Eble, Florian; Galli, Massimiliano; Gedia, Krunal; Glessgen, Franz; Gomez Espinosa, Tirso Alejandro; Grab, Christophorus; Hits, Dmitry Alexandrovich; Lustermann, Werner; Lyon, A.-M.; Manzoni, Riccardo Andrea; Marchese, Luigi; Martin Perez, Cristina; Mascellani, Anna; Meinhard, Maren Tabea; Nessi-Tedaldi, Francesca; Niedziela, Jeremi; Pauss, Felicitas; Perovic, Vasilije; Pigazzini, Simone; Ratti, Maria Giulia; Reichmann, Michael; Reissel, Christina; Reitenspiess, Thomas; Ristic, Branislav; Riti, Federica; Ruini, D.; Sanz-Becerra, Diego A.; Steggemann, Jan; Valsecchi, Davide; Wallny, Rainer; et al.',NULL,'','2023-09-20 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-05 17:58:25','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2024/01/05/a-primer-on-logical-fallacies/','A Primer on Logical Fallacies',replace('<p>Sure to come in handy this year, a primer on logical fallacies.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2024/01/05/a-primer-on-logical-fallacies/">A Primer on Logical Fallacies</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2024-01-05 10:30:16','Scholarly Kitchen','',NULL,'2024-01-05 17:58:28','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/bertrand-russell/roads-to-freedom','Roads to Freedom, by Bertrand Russell','Bertrand Russell investigates the merits and potential shortcomings of different socialist tendencies.',NULL,'','2024-01-03 21:03:46','Standard Ebooks, new releaases','',NULL,'2024-01-05 18:17:19','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/walt-whitman/leaves-of-grass','Leaves of Grass, by Walt Whitman','The definitive collection of Walt Whitman’s poetry.',NULL,'','2024-01-02 19:53:47','Standard Ebooks, new releaases','',NULL,'2024-01-05 18:17:19','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/virginia-woolf/orlando','Orlando, by Virginia Woolf','A young Elizabethan poet for whom success is elusive becomes a woman and embraces the spirit of the age.',NULL,'','2024-01-01 17:33:15','Standard Ebooks, new releaases','',NULL,'2024-01-05 18:17:19','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/evelyn-waugh/decline-and-fall','Decline and Fall, by Evelyn Waugh','A young man is drummed out of his College and in turn becomes a schoolmaster.',NULL,'','2024-01-01 17:32:52','Standard Ebooks, new releaases','',NULL,'2024-01-05 18:17:19','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/dorothy-l-sayers/the-unpleasantness-at-the-bellona-club','The Unpleasantness at the Bellona Club, by Dorothy L. Sayers','The discovery of the quiet death of an elderly man at an exclusive club leads to unexpected complications.',NULL,'','2024-01-01 17:32:35','Standard Ebooks, new releaases','',NULL,'2024-01-05 18:17:19','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/dorothy-l-sayers/lord-peter-views-the-body','Lord Peter Views the Body, by Dorothy L. Sayers','A collection of short stories in which an aristocratic amateur detective solves a variety of crimes.',NULL,'','2024-01-01 17:31:56','Standard Ebooks, new releaases','',NULL,'2024-01-05 18:17:19','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/agatha-christie/the-mystery-of-the-blue-train','The Mystery of the Blue Train, by Agatha Christie','Retired detective Hercule Poirot finds himself at the scene of a murder aboard a French locomotive.',NULL,'','2024-01-01 17:31:37','Standard Ebooks, new releaases','',NULL,'2024-01-05 18:17:19','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/fred-m-white/the-midnight-guest','The Midnight Guest, by Fred M. White','A brilliant lord struggles to hold his personal life together after his friend’s murder set off a chain of events that threatens to expose his dark secrets.',NULL,'','2023-12-27 17:06:58','Standard Ebooks, new releaases','',NULL,'2024-01-05 18:17:19','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/william-dean-howells/indian-summer','Indian Summer, by William Dean Howells','A middle-aged Midwestern newspaperman returns to Florence, where twenty years before he had his heart broken.',NULL,'','2023-12-26 22:30:50','Standard Ebooks, new releaases','',NULL,'2024-01-05 18:17:19','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/george-bernard-shaw/short-plays','Short Plays, by George Bernard Shaw','A collection of sixteen short plays by George Bernard Shaw.',NULL,'','2023-12-21 21:32:19','Standard Ebooks, new releaases','',NULL,'2024-01-05 18:17:19','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/mark-twain/puddnhead-wilson','Pudd’nhead Wilson, by Mark Twain','A small-town lawyer unravels a complex web of switched identities and exposes the true nature of individuals in a racially divided society.',NULL,'','2023-12-21 20:53:53','Standard Ebooks, new releaases','',NULL,'2024-01-05 18:17:19','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/virgil/the-georgics/john-dryden','The Georgics, by Virgil','Virgil explores rural life, providing practical advice on agriculture, arboriculture, viticulture, animal husbandry, and beekeeping.',NULL,'','2023-12-14 16:40:38','Standard Ebooks, new releaases','',NULL,'2024-01-05 18:17:19','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/sylvia-townsend-warner/lolly-willowes','Lolly Willowes, by Sylvia Townsend Warner','A middle-aged spinster leaves her controlling relatives in London for a life of independence in rural England, where she enters into a pact with Satan.',NULL,'','2023-12-14 16:31:37','Standard Ebooks, new releaases','',NULL,'2024-01-05 18:17:19','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/ralph-waldo-emerson/essays','Essays, by Ralph Waldo Emerson','A collection of Ralph Waldo Emerson’s essays.',NULL,'','2023-12-08 19:23:49','Standard Ebooks, new releaases','',NULL,'2024-01-05 18:17:19','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/honore-de-balzac/albert-savarus/ellen-marriage','Albert Savarus, by Honoré de Balzac','A mysterious lawyer shows up in a town, opens a practice, and starts a newspaper.',NULL,'','2023-12-08 18:13:18','Standard Ebooks, new releaases','',NULL,'2024-01-05 18:17:19','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/650717','The Invention of Housing: Comparative Studies of Early Mass Housing in Europe','Davidovici, Irina',NULL,'','2023-11-02 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-07 19:17:19','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/650716','Anatomy of a Deep Subduction Megathrust: Insights from the Kampos Belt of Northern Syros, Greece','Hildebrandt, Dominic',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-07 19:17:19','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/650715','Guarding Dual Natures. The Synthes Headquarters by Studio Märkli.','Azzariti, Giorgio',NULL,'','2023-05-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-07 19:17:19','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/650714','Inherited Legacies. Peter Märkli''s Education, Praxis, and Teaching.','Azzariti, Giorgio',NULL,'','2023-09-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-07 19:17:19','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/mary-seacole/wonderful-adventures-of-mrs-seacole-in-many-lands','Wonderful Adventures of Mrs. Seacole in Many Lands, by Mary Seacole','A British Creole woman provides medical assistance during the Crimean War after her travels around Panama.',NULL,'','2024-01-07 03:07:47','Standard Ebooks, new releaases','',NULL,'2024-01-07 19:17:21','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/knut-hamsun/hunger/george-egerton','Hunger, by Knut Hamsun','Starvation drives an aspiring writer to the brink of insanity as he struggles to escape extreme poverty, and simultaneously to pursue a woman, in late nineteenth-century Christiania.',NULL,'','2024-01-05 21:57:50','Standard Ebooks, new releaases','',NULL,'2024-01-07 19:17:21','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/edgar-wallace/the-four-just-men','The Four Just Men, by Edgar Wallace','To prevent the passage of a controversial government bill, four vigilantes take the law into their own hands.',NULL,'','2024-01-05 20:09:16','Standard Ebooks, new releaases','',NULL,'2024-01-07 19:17:21','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/oscar-wilde/poetry','Poetry, by Oscar Wilde','A collection of poems by Oscar Wilde.',NULL,'','2024-01-05 19:32:01','Standard Ebooks, new releaases','',NULL,'2024-01-07 19:17:21','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2024/01/08/guest-post-hanging-in-the-balance-generative-ai-versus-scholarly-publishing/','Guest Post — Hanging in the Balance: Generative AI Versus Scholarly Publishing',replace('<p>Balancing the anxiety and the excitement over the use of Large Language Models (LLMs) in scholarly publishing.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2024/01/08/guest-post-hanging-in-the-balance-generative-ai-versus-scholarly-publishing/">Guest Post &#8212; Hanging in the Balance: Generative AI Versus Scholarly Publishing</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2024-01-08 10:30:16','Scholarly Kitchen','',NULL,'2024-01-08 16:07:22','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/650909','Distance, transmission, and journey in the collective construction of an Itaaká','Terena, Irineu Nje''a; Moreschi, Bruno',NULL,'','2023-12-21 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-08 16:07:23','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/591616','Stability and Performance Analysis of NMPC: Detectable Stage Costs and General Terminal Costs','Köhler, Johannes; Zeilinger, Melanie N.; Grüne, Lars',NULL,'','2023-10-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-08 16:07:23','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/650913','Five Experimentations in Computer Vision','Moreschi, Bruno',NULL,'','2023-12-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-08 16:07:23','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/651116','PV cutoff masks and associated precipitation for Dissertation Portmann (2020)','Portmann, Raphael; Wernli, Heini; Sprenger, Michael',NULL,'','2024-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-08 16:07:23','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/651029','Assessing the alignment between geometry and colors in TLS colored point',replace('Wang, Zhaoyi; Varga, Matej; Medic, Tomislav; Wieser, Andreas\nBoehm, Jan; Yang, Bisheng; Weinmann, Martin; Anders, Katharina; Wang, Ruisheng','\n',char(10)),NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-09 16:25:56','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/651512','A Model-Based Bayesian Inference Approach for On-Board Monitoring of Rail Roughness Profiles: Application on Field Measurement Data of the Swiss Federal Railways Network','Stoura, Charikleia D.; Dertimanis, Vasilis K.; Hoelzl, Cyprien; Kossmann, Claudia; Cigada, Alfredo; Chatzi, Eleni N.',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-09 16:25:56','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/651521','Rail Roughness Profile Identification from Vibration Data via Mixing of Reduced-Order Train Models and Bayesian Filtering','Stoura, Charikleia D.; Tatsis, Konstantinos E.; Chatzi, Eleni N.',NULL,'','2023-06-19 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-09 16:25:56','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/651520','Climate is a Wretch: Mary Shelley’s Frankenstein and the Science of Catastrophe','Carbonell Guillon, Tatiana',NULL,'','2023-09-14 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-09 16:25:56','read');
INSERT INTO items VALUES('https://www.arl.org/day-in-review/day-in-review-january-9-12-2/','Day in Review (January 8–11)',replace('<p>Last Updated on January 11, 2024, 4:04 pm ET Sign up to receive the Day in Review by email. Jump to: Tuesday, January 9 &#124; Wednesday, January 10 &#124; Thursday,...</p>\n<p>The post <a href="https://www.arl.org/day-in-review/day-in-review-january-9-12-2/">Day in Review (January 8–11)</a> appeared first on <a href="https://www.arl.org">Association of Research Libraries</a>.</p>\n','\n',char(10)),NULL,'','2024-01-09 15:48:19','Association of Research Libraries News','',NULL,'2024-01-09 16:25:57','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2024/01/09/trust-in-scholarly-publishing/','Trust in Scholarly Publishing',replace('<p>How do we define, track, and measure trust in scholarly publishing?</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2024/01/09/trust-in-scholarly-publishing/">Trust in Scholarly Publishing</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2024-01-09 10:30:46','Scholarly Kitchen','',NULL,'2024-01-09 16:25:57','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/646002','Code for Model-Free Nonlinear Feedback Optimization','He, Zhiyu',NULL,'','2024-07-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-09 22:41:26','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/651552','Recent human-induced atmospheric drying across Europe unprecedented in the last 400 years','Treydte, Kerstin',NULL,'','2023-12-27 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-09 22:41:26','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/651551','The socio-economic impacts of extreme events in a changing climate. From direct asset damage to long-term effects on well-being','Sauer, Inga',NULL,'','2023-12-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-09 22:41:26','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/651550','Using radiocarbon to identify the impact of climate and mineralogy on soil organic matter turnover','Moreno Duborgel, Margaux; Minich, Luisa Isabell; Haghipour, Negar; González-Domíngez, Beatriz; Eglinton, Timothy; Hagedorn, Frank',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-09 22:41:26','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/651465','Dexterous helical magnetic robot for improved endovascular access','Dreyfus, Roland',NULL,'','2024-01-10 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-10 16:38:39','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/651658','Towards Robust Object Detection Invariant to Real-world Domain Shifts','Fan, Qi; Segu, Mattia; Tai, Yu-Wing; Yu, Fisher; Tang, Chi-Keung; Schiele, Bernt; Dai, Dengxin',NULL,'','2023-02-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-10 16:38:39','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/625630','Boundless Metamaterial Experimentation: Physical Realization of a Unidirectional Virtual Periodic Boundary Condition','Thomsen, Henrik R.; Zhao, Bao; Colombi, Andrea',NULL,'','2023-06-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-10 16:38:39','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/651787','Probing small Bjorken-x nuclear gluonic structure via coherent J/ψ photoproduction in ultraperipheral PbPb collisions at √sNN = 5.02 TeV','Wallny, Rainer; Dissertori, Günther; de Cosa, Annapaola',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-10 16:38:39','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2024/01/10/guest-post-study-questions-whether-research-institutions-are-the-appropriate-entity-to-investigate-authorship-disputes-in-all-cases/','Guest Post — Study Questions Whether Research Institutions Are the Appropriate Entity to Investigate Authorship Disputes in All Cases',replace('<p>Should the authors'' institution make decisions regarding authorship disputes on a paper?</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2024/01/10/guest-post-study-questions-whether-research-institutions-are-the-appropriate-entity-to-investigate-authorship-disputes-in-all-cases/">Guest Post &#8212; Study Questions Whether Research Institutions Are the Appropriate Entity to Investigate Authorship Disputes in All Cases</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2024-01-10 10:30:02','Scholarly Kitchen','',NULL,'2024-01-10 16:38:42','read');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/langston-hughes/poetry','Poetry, by Langston Hughes','A collection of poems by Langston Hughes.',NULL,'','2024-01-11 22:18:02','Standard Ebooks, new releaases','',NULL,'2024-01-11 22:42:32','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2024/01/11/guest-post-beyond-generative-ai-the-indispensable-role-of-bert-in-scholarly-publishing/','Guest Post — Beyond Generative AI: The Indispensable Role of BERT in Scholarly Publishing',replace('<p>ChatGPT has popularized generative AI, but interpretive AI has quietly remained in the shadows. Interpretive AI offers profound insights into content and audience engagement, a critical tool for publishers aiming to harness the full potential of AI.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2024/01/11/guest-post-beyond-generative-ai-the-indispensable-role-of-bert-in-scholarly-publishing/">Guest Post &#8212; Beyond Generative AI: The Indispensable Role of BERT in Scholarly Publishing</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2024-01-11 10:30:26','Scholarly Kitchen','',NULL,'2024-01-11 22:42:32','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/652083','Bundesgerichtsurteile nutzen: Das Swiss Federal Supreme Court Dataset (SCD)','Merane, Jakob; Geering, Florian',NULL,'','2023-09-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-11 22:42:34','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/652082','Would Humans Trust an A.I. Judge? More Easily Than You Think.','Stremitzer, Alexander; Chen, Benjamin M.; Tobia, Kevin',NULL,'','2023-02-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-11 22:42:34','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/652081','The Thermal Emission and Time-Variability of Earth as an Exoplanet','Mettler, Jean-Noël',NULL,'','2023-12-15 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-11 22:42:34','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/651807','Multimodal Representation Learning under Weak Supervision','Daunhawer, Imant',NULL,'','2023-12-18 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-11 22:42:34','read');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2024/01/12/when-contractions-dont-work/','When Contractions Don’t Work',replace('<p>Why do some contractions work and others don''t?</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2024/01/12/when-contractions-dont-work/">When Contractions Don&#8217;t Work</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2024-01-12 10:30:09','Scholarly Kitchen','',NULL,'2024-01-12 15:58:57','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/652260','Reales und ideales Sehen. Sehtheorie und Linearperspektive',replace('Hub, Berthold\nFrommel, Sabine; Pfisterer, Ulrich','\n',char(10)),NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-12 15:58:58','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/652255','Ein florentiner Architekt unter lombardischen Baumeistern. ‚Modo fiorentino‘ und ‚modo moderno’ zur Mitte des 15. Jahrhunderts','Hub, Berthold',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-12 15:58:58','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/652145','Experimental Validation for Distributed Control of Energy Hubs','Behrunani, Varsha; Heer, Philipp; Lygeros, John',NULL,'','2023-11-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-12 15:58:58','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/651752','Neurofeedback for precision rehabilitation of Parkinson’s patients','Salzmann, Lena; Bichsel, Oliver; Ravi, Deepak Kumar; Lestoille, Mathilde; Awai Easthope, Chris; Baumann, Christian; Luft, Andreas; Taylor, William R.; Gassert, Roger; Lambercy, Olivier',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-12 15:58:58','read');
INSERT INTO items VALUES('https://blog.scielo.org/en/2024/01/12/preprints-in-debate-six-years-later/','Preprints in debate… six years later',replace('<p>Six years have passed since social science publishers began debating preprints. A look back shows that the "risks" and "promises" raised in that debate rested on an inadequate understanding of the nature of preprints in the field. The SciELO preprints server, however, ended up showing some unexpected benefits. <span class="ellipsis">&#8230;</span> <span class="more-link-wrap"><a href="https://blog.scielo.org/en/2024/01/12/preprints-in-debate-six-years-later/" class="more-link"><span>Read More &#8594;</span></a></span></p>\n<p>The post <a href="https://blog.scielo.org/en/2024/01/12/preprints-in-debate-six-years-later/">Preprints in debate… six years later</a> first appeared on <a href="https://blog.scielo.org/en">SciELO in Perspective</a>.</p>','\n',char(10)),NULL,'','2024-01-12 19:00:15','SciELO in Perspective','',NULL,'2024-01-13 22:31:54','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/638984','ITA: An Energy-Efficient Attention and Softmax Accelerator for Quantized Transformers','Islamoglu, Gamze; Scherer, Moritz; Paulin, Gianna; Fischer, Tim; Jung, Victor J.B.; Garofalo, Angelo; Benini, Luca',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-13 22:31:55','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/652320','"El San Cristóbal tiene sed": primeras obras de regadío por tubería Santiago de Chile (1917-1939)',replace('Carbonell Guillon, Tatiana\nBooth, Rodrigo; Silva, Barbara; Sanhueza Cerda, Carlos; Velderrama, Lorena','\n',char(10)),NULL,'','2023-10-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-13 22:31:55','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/642556','Tunable Synthesis of Metal–Organic Chalcogenide Semiconductor Nanocrystals','Hernandez Oendra, Alexander C.; Aspect, Maximilian A.; Jaeggi, Julia L.; Baumann, Janik; Lightner, Carin R.; Pun, Andrew B.; Norris, David J.',NULL,'','2023-11-14 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-13 22:31:55','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/652318','From Distributed Algorithms to Machine Learning and Back','Wattenhofer, Roger',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-13 22:31:55','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/652386','Wetter climate favouring early Lapita horticulture in Remote Oceania','Camperio, Giorgia; Ladd, Nemiah; Prebble, Matiu; Lloren, Ronald; Argiriadis, Elena; Nelson, Daniel; Krentscher, Christiane; Dubois, Nathalie',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-14 19:29:32','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/652385','Qasr Shemamok-Kilizu (Kurdistan d’Irak), les campagnes de 2016','Masetti-Rouault, Maria Grazie; Rouault, Olivier; Calini, Ilaria; Cremonini, Stefano; Gasparotto, Giorgio; Herr, Jean-Jacques; Mahmoud, Omar; Picotti, Vincenzo; Poli, Paola; Rossi, Veronica',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-14 19:29:32','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/652384','Role of the Giudicarie Belt and eastern Southern Alps in Adriatic Indentation','Handy, Mark R.; Le Breton, Eline; Haberland, Christian; McPhee, Peter J.; Jozi Najafabadi, Azam; Verwater, Vincent; Picotti, Vincenzo',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-14 19:29:32','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/652383','Long-term morphological and sedimentological changes caused by bottom trawling on the northern Catalan continental shelf (NW Mediterranean)','Durán, Ruth; Puig, Pere; Paradis, Sarah; Guillén, Jorge; Palanques, Albert; Lo Iacono, Claudio; Arjona-Camas, Marta; Muñoz, Araceli; Micallef, Aaron',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-14 19:29:32','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/652918','Spatially-aware station based car-sharing demand prediction','Mühlematter, Dominik J.; Wiedemann, Nina; Xin, Yanan; Raubal, Martin',NULL,'','2024-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-15 19:57:30','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/652917','Physical modelling of masonry and reinforced concrete using 3D printing','Del Giudice, Lorenzo',NULL,'','2013-12-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-15 19:57:30','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/652569','A Diversity of Primary Producers in Lakes',replace('Pomati, Francesco; Reyes, Marta; Narwani, Anita; Fischer, Robert; Ptáčník, Robert\nMehner, Thomas; Tockner, Klement','\n',char(10)),NULL,'','2022-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-15 19:57:30','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/652916','Un Dessin n''est pas un plan et autres essais','Stalder, Laurent',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-15 19:57:30','read');
INSERT INTO items VALUES('https://rc-blog.ethz.ch/en/love-data-week-2024-switzerland-2/','Love Data Week 2024 Switzerland','Under the motto “My Kind of Data”, the ETH Library and Scientific IT Services will be celebrating their love of data from 12 to 16 February 2024 and jointly providing and insight into research data management. Read more<img src="https://analytics.library.ethz.ch/piwik.php?idsite=1&amp;rec=1&amp;url=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Flove-data-week-2024-switzerland-2%2F&amp;action_name=Love+Data+Week+2024+Switzerland&amp;urlref=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Ffeed%2F" style="border:0;width:0;height:0" width="0" height="0" alt="" />',NULL,'','2024-01-15 09:38:49','ETH Zurich Research Archives','',NULL,'2024-01-15 19:57:31','saved');
INSERT INTO items VALUES('https://standardebooks.org/ebooks/frederick-rolfe/hadrian-the-seventh','Hadrian the Seventh, by Frederick Rolfe','A long-suffering English seminarian is unexpectedly elected as the next Pope.',NULL,'','2024-01-15 17:57:47','Standard Ebooks, new releaases','',NULL,'2024-01-15 19:57:34','saved');
INSERT INTO items VALUES('https://scholarlykitchen.sspnet.org/2024/01/16/guest-post-european-accessibility-act-working-toward-compliance-and-beyond/','Guest Post — European Accessibility Act: Working Toward Compliance and Beyond',replace('<p>Today’s post puts the spotlight on the European Accessibility Act (EAA) directive and  how different organizations are getting ready to make their publications and services EAA compliant.</p>\n<p>The post <a href="https://scholarlykitchen.sspnet.org/2024/01/16/guest-post-european-accessibility-act-working-toward-compliance-and-beyond/">Guest Post — European Accessibility Act: Working Toward Compliance and Beyond</a> appeared first on <a href="https://scholarlykitchen.sspnet.org">The Scholarly Kitchen</a>.</p>\n','\n',char(10)),NULL,'','2024-01-16 10:30:16','Scholarly Kitchen','',NULL,'2024-01-16 15:49:13','saved');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/651131','Novel Processing Route for PET-GF Composite Manufacturing Via SSP','Vetterli, Oliver; Pappas, Georgios A.; Ermanni, Paolo',NULL,'','2023-08-03 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-16 15:49:14','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/653290','The next generation cameras for the Large-Sized Telescopes of the Cherenkov Telescope Array Observatory','Heller, Matthieu; Altet, Josep; Aragones, Xavier; Barrio, Juan Abel; Bellato, Marco; Bernasconi, Ermanno; Biland, Adrian; Blanch, Oscar; Burmistrov, Leonid; Charbon, Edoardo; Dalchenko, Mykhailo; Giangrande, Luca; Gòmez, Sergio; Hoffmann, Dirk; Martínez, Gustavo; Mariotti, Mosè; Matteo, Diego; Montaruli, Teresa; Okumura, Akira; Pérez Aguilera, Alejandro',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-16 15:49:14','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/652274','Phase-field based fracture modeling at microscale: a case study on PEEK reinforced composites','Sangaletti, Simone; Pappas, Georgios A.; Ermanni, Paolo; De Lorenzis, Laura',NULL,'','2023-08-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-16 15:49:14','read');
INSERT INTO items VALUES('http://hdl.handle.net/20.500.11850/653289','Low energy performance boost through a hardware stereoscopic trigger between CTA LST1 and MAGIC','Baxter, Joshua Ryo; Abe, Hyuga; Abe, Kazuki; Abe, Shotaro; Abhir, Jayant; Acciari, Victor A.; Aguasca-Cabot, Arnau; Agudo, Ivan; Alvarez Crespo, Nuria; Aniello, Tommaso; Ansoldi, Stefano; Antonelli, Lucio Angelo; Aramo, Carla; Arbet-Engels, Axel; Arcaro, Cornelia; Artero, Manuel; Asano, Katsuaki; Aubert, Pierre; Baack, Dominik; Babić, Ana',NULL,'','2023-01-01 00:00:00','ETH Zurich, recently added','',NULL,'2024-01-16 15:49:14','read');
INSERT INTO items VALUES('https://rc-blog.ethz.ch/en/registration-for-the-eth-research-data-management-summer-school-2024-is-open/','Registration for the ETH Research Data Management Summer School 2024 is open','This ETH Summer School furnishes early-career scientists with a comprehensive understanding of research data management. Following a practice-oriented approach, they learn the basics and the most important tools. Read more<img src="https://analytics.library.ethz.ch/piwik.php?idsite=1&amp;rec=1&amp;url=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Fregistration-for-the-eth-research-data-management-summer-school-2024-is-open%2F&amp;action_name=Registration+for+the+ETH+Research+Data+Management+Summer+School+2024+is+open&amp;urlref=https%3A%2F%2Frc-blog.ethz.ch%2Fen%2Ffeed%2F" style="border:0;width:0;height:0" width="0" height="0" alt="" />',NULL,'','2024-01-16 08:01:53','ETH Zurich Research Archives','',NULL,'2024-01-16 15:49:15','saved');
COMMIT;
