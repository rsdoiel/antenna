<!doctype html>
<html lang="en-US">
<head>
  <meta charset="utf-8" >
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" >
  <title>snapshots</title>
<!--  <link rel="stylesheet" type="text/css"  href="webfonts/fonts.css" media="screen" > -->
  <link rel="stylesheet" type="text/css"  href="css/site.css" media="screen" >
</head>
<body>
<header>
	<img class="logo" 
		src="https://upload.wikimedia.org/wikipedia/commons/9/9c/Antenna_1_-_The_Noun_Project.svg"
		alt="line art showing an antenna"
		height="80" width="60" >
	<h1>The Antenna</h1> 
	<h2>finding signal in the noise</h2>
</header>
<nav>
<ul>
	<li><a href="./">The Antenna</a></li>
	<li><a href="archives/">Archives</a></li>
	<li><a href="about.html">About</a></li>
</ul>
</nav>
<section>
<div class="description-for-items">
Items collected from feeds in <a href="snapshots.txt">snapshots.txt</a>
</div>
<h1 id="snapshots">snapshots</h1>
<p>(date: 2025-08-11 14:10:57)</p>
<hr />
<h2 id="ios-26-developer-beta-6">iOS 26 Developer Beta 6</h2>
<p>date: 2025-08-11, from: Michael Tsai</p>
<p>Juli Clover: Apple today provided developers with the sixth betas of
iOS 26 and iPadOS 26 for testing purposes, with the updates coming a
week after Apple seeded the fifth betas. The release notes don‚Äôt call
out any changes in beta 6. Juli Clover: The Lock Screen clock has been
updated with additional transparency, allowing [‚Ä¶]</p>
<p><br></p>
<p><a href="https://mjtsai.com/blog/2025/08/11/ios-26-developer-beta-6/"
class="uri">https://mjtsai.com/blog/2025/08/11/ios-26-developer-beta-6/</a></p>
<hr />
<h2 id="macos-tahoe-26-developer-beta-6">macOS Tahoe 26 Developer Beta
6</h2>
<p>date: 2025-08-11, from: Michael Tsai</p>
<p>Juli Clover: Apple today provided developers with the sixth beta of
macOS Tahoe 26 for testing purposes, with the update coming a week after
the fifth beta. The release notes don‚Äôt call out any changes in beta 6.
Previously: macOS Tahoe 26 Developer Beta 5</p>
<p><br></p>
<p><a
href="https://mjtsai.com/blog/2025/08/11/macos-tahoe-26-developer-beta-6/"
class="uri">https://mjtsai.com/blog/2025/08/11/macos-tahoe-26-developer-beta-6/</a></p>
<hr />
<h2 id="history-of-apples-developer-relations">History of Apple‚Äôs
Developer Relations</h2>
<p>date: 2025-08-11, from: Michael Tsai</p>
<p>David Barnard (John Gruber): On the podcast I talk with John about
the fascinating 40-year history of Apple‚Äôs developer relations, how
almost going bankrupt in the 1990s shaped today‚Äôs control-focused
approach, and why we might need an ‚ÄòApp Store 3.0‚Äô reset. [‚Ä¶] As the App
Store became a services giant, the partnership vibe faded. Developers
[‚Ä¶]</p>
<p><br></p>
<p><a
href="https://mjtsai.com/blog/2025/08/11/history-of-apples-developer-relations/"
class="uri">https://mjtsai.com/blog/2025/08/11/history-of-apples-developer-relations/</a></p>
<hr />
<h2
id="ploopy-trackpad-review-usb-touchpad-with-open-source-firmware-and-multitouch-support">Ploopy
TrackPad review: USB touchpad with open source firmware and multitouch
support</h2>
<p>date: 2025-08-11, from: Liliputing</p>
<p>
Most desktop computers are designed for keyboard and mouse input. Most
laptops have a built-in touchpad. But it‚Äôs surprisingly difficult to
find a good touchpad that‚Äôs designed for use in a desktop setup. Mac
users have Apple‚Äôs Magic Trackpad. But if you‚Äôre using Windows or Linux
you‚Äôll either need to fight with unofficial drivers to [‚Ä¶]
</p>
<p>
The post
<a href="https://liliputing.com/ploopy-trackpad-review-usb-touchpad-with-open-source-firmware-and-multitouch-support/">Ploopy
TrackPad review: USB touchpad with open source firmware and multitouch
support</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/ploopy-trackpad-review-usb-touchpad-with-open-source-firmware-and-multitouch-support/"
class="uri">https://liliputing.com/ploopy-trackpad-review-usb-touchpad-with-open-source-firmware-and-multitouch-support/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Robert">@Robert</span>‚Äôs
feed at BlueSky</strong> (date: 2025-08-11, from: Robert‚Äôs feed at
BlueSky)</p>
<p>This is important.
https://laist.com/news/politics/tuesday-august-14-boycott-operation-trojan-horse</p>
<p><br></p>
<p><a
href="https://bsky.app/profile/rsdoiel.bsky.social/post/3lw5i4dn56s23"
class="uri">https://bsky.app/profile/rsdoiel.bsky.social/post/3lw5i4dn56s23</a></p>
<hr />
<h2 id="new-testflight-build-uploaded-waiting-for-review">New TestFlight
Build Uploaded, Waiting for Review</h2>
<p>date: 2025-08-11, from: NetNewsWire</p>
<p>
We know some folks are waiting on a new TestFlight build for iOS, and we
have good news ‚Äî¬†we‚Äôve just uploaded 6.1.10 (6198), and it‚Äôs waiting on
Apple review. Once reviewed it will be available on TestFlight.
</p>
<p><br></p>
<p><a
href="https://netnewswire.blog/2025/08/11/new-testflight-build-uploaded-waiting.html"
class="uri">https://netnewswire.blog/2025/08/11/new-testflight-build-uploaded-waiting.html</a></p>
<hr />
<h2 id="reddit-will-block-the-internet-archive">Reddit will block the
Internet Archive</h2>
<p>date: 2025-08-11, updated: 2025-08-11, from: Simon Willison‚Äôs
Weblog</p>
<p>
<strong><a href="https://www.theverge.com/news/757538/reddit-internet-archive-wayback-machine-block-limit">Reddit
will block the Internet Archive</a></strong>
</p>
Well this <em>sucks</em>. Jay Peters for the Verge:
</p>
<blockquote>
<p>
Reddit says that it has caught AI companies scraping its data from the
Internet Archive‚Äôs Wayback Machine, so it‚Äôs going to start blocking the
Internet Archive from indexing the vast majority of Reddit. The Wayback
Machine will no longer be able to crawl post detail pages, comments, or
profiles; instead, it will only be able to index the Reddit.com
homepage, which effectively means Internet Archive will only be able to
archive insights into which news headlines and posts were most popular
on a given day.
</p>
</blockquote>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/internet-archive&quot;&gt;internet-archive&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/reddit&quot;&gt;reddit&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/scraping&quot;&gt;scraping&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/training-data&quot;&gt;training-data&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai-ethics&quot;&gt;ai-ethics&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Aug/11/reddit-will-block-the-internet-archive/#atom-everything"
class="uri">https://simonwillison.net/2025/Aug/11/reddit-will-block-the-internet-archive/#atom-everything</a></p>
<hr />
<h2 id="witch-hunts-to-misinformation-campaigns">Witch Hunts to
Misinformation Campaigns</h2>
<p>date: 2025-08-11, from: Guy Kawasaki blog</p>
<p>Julie Walsh, Whitehead Associate Professor of Critical Thought and
Associate Professor of Philosophy, Wellesley College.</p>
<p><br></p>
<p><a
href="https://guykawasaki.substack.com/p/witch-hunts-to-misinformation-campaigns"
class="uri">https://guykawasaki.substack.com/p/witch-hunts-to-misinformation-campaigns</a></p>
<hr />
<h2
id="overcompensating-temporada-1-superficial-paseo-por-la-dicha-y-la-pena-del-autodescubrimiento">Overcompensating
(temporada 1): superficial paseo por la dicha y la pena del
autodescubrimiento</h2>
<p>date: 2025-08-11, from: Iv√°n Paredes Res√©ndiz blog, Mexico‚Äôs
cinema</p>
<p>
Disponible en: Prime Video. Creador: Benito Skinner. Direcci√≥n: Daniel
Gray Longino, Desiree Akhavan. Guion: Benito Skinner, Scott King, Mitra
Jouhari, Jordan Mendoza. Elenco: Benito Skinner, Wally Baram, Mary Beth
Barone, Adam DiMarco, Rish Shah, Connie Britton, Kyle MacLachlan,
Corteon Moore, Owen Thiele, Lukas Gage. Pa√≠s: Estados Unidos. Duraci√≥n:
ocho episodios de 30 minutos cada uno. [‚Ä¶]
</p>
<p>
La entrada
<a href="https://www.palomitademaiz.net/resenas-overcompensating-temporada-1/">Overcompensating
(temporada 1): superficial paseo por la dicha y la pena del
autodescubrimiento</a> se public√≥ primero en
<a href="https://www.palomitademaiz.net">Palomita de ma√≠z</a>.
</p>
<p><br></p>
<p><a
href="https://www.palomitademaiz.net/resenas-overcompensating-temporada-1/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=resenas-overcompensating-temporada-1"
class="uri">https://www.palomitademaiz.net/resenas-overcompensating-temporada-1/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=resenas-overcompensating-temporada-1</a></p>
<hr />
<h2 id="codex-upgrade">Codex upgrade</h2>
<p>date: 2025-08-11, updated: 2025-08-11, from: Simon Willison‚Äôs
Weblog</p>
<p>
If you‚Äôve been experimenting with OpenAI‚Äôs
<a href="https://github.com/openai/codex">Codex CLI</a> and have been
frustrated that it‚Äôs not possible to select text and copy it to the
clipboard, at least when running in the Mac terminal (I genuinely didn‚Äôt
know it was possible to build a terminal app that disabled copy and
paste) you should know that they fixed that in
<a href="https://github.com/openai/codex/issues/1247">this issue</a>
last week.
</p>
<p>
The new
<a href="https://github.com/openai/codex/releases/tag/rust-v0.20.0">0.20.0
version</a> from three days ago also completely removes the old
TypeScript codebase in favor of Rust. Even installations via NPM now get
the Rust version.
</p>
<p>
I originally installed Codex via Homebrew, so I had to run this command
to get the updated version:
</p>
<pre><code>brew upgrade codex
</code></pre>
<p>
Another Codex tip: to use GPT-5 (or any other specific OpenAI model) you
can run it like this:
</p>
<pre><code>export OPENAI_DEFAULT_MODEL="gpt-5"
codex
</code></pre>
<p>
<em>This no longer works, see update below.</em>
</p>
<p>
I‚Äôve been using a <code>codex-5</code> script on my PATH containing
this, because sometimes I like to live dangerously!
</p>
<pre><code>#!/usr/bin/env zsh
# Usage: codex-5 [additional args passed to `codex`]
export OPENAI_DEFAULT_MODEL="gpt-5"
exec codex --dangerously-bypass-approvals-and-sandbox "$@"
</code></pre>
<p>
<strong>Update</strong>: It looks like GPT-5 is
<a href="https://github.com/openai/codex/blob/c61911524d839f5d56842faee0c46f6ef52d4387/codex-rs/core/src/config.rs#L28">the
default model</a> in v0.20.0 already.
</p>
<p>
Also the environment variable I was using no longer does anything, it
was
<a href="https://github.com/openai/codex/commit/107d2ce4e74618968b2eb7016777121d9529a204#diff-b012ea51eb2b6d23db97b930526379af9c4c119a3e057e55ea29d056326242e0L6">removed
in this commit</a> (I used Codex Web to
<a href="https://chatgpt.com/s/cd_689a252794b081919099d5ade205b41d">help
figure that out</a>). You can use the <code>-m model_id</code>
command-line option instead.
</p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/openai&quot;&gt;openai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/gpt-5&quot;&gt;gpt-5&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/rust&quot;&gt;rust&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai-assisted-programming&quot;&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/coding-agents&quot;&gt;coding-agents&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Aug/11/codex-upgrade/#atom-everything"
class="uri">https://simonwillison.net/2025/Aug/11/codex-upgrade/#atom-everything</a></p>
<hr />
<h2 id="zavala-will-always-be-free">Zavala Will Always Be Free</h2>
<p>date: 2025-08-11, from: Maurice Parker</p>
<h2 id="my-promise-to-you">
My promise to you.
</h2>
<p>
I have every intention of maintaining and updating Zavala for as long as
I am able. I‚Äôm also committed to keeping it free. I have no intention of
getting you hooked on using it and then starting to charge a
subscription.
</p>
<p>
To show I am serious about this, Zavala is Open Source software released
under the MIT license. This means that any other developer can take the
years of work that I have in Zavala and make a competing outliner from
it should I start charging for it. Given how small and competitive the
outliner market is, I don‚Äôt stand much of a chance of making any money
by going commercial. After all, I could be competing with my own past
work.
</p>
<h2 id="what-if-i-get-ran-over-by-a-bus">
What if I get ran over by a bus?
</h2>
<p>
Since Zavala is Open Source someone could pick up the project and
continue to update it. Worst case scenario, some enterprising
independent developer could try to make a commercial product out of it.
I don‚Äôt see much money in the endeavor, but others may see it
differently.
</p>
<h2 id="why-don-t-i-charge-for-zavala-or-accept-donations">
Why don‚Äôt I charge for Zavala or accept donations?
</h2>
<p>
Funny story. I fully intended to when I started writing it. After doing
some competitive analysis on the Mac-only, outliner market, I realized
there wasn‚Äôt much money there. There was so little in fact, that it
isn‚Äôt enough for me to be motivated enough to do the business side when
I‚Äôd rather be coding.
</p>
<p>
Let me break it down. Up front payments are a dead-end these days. I
would have to add a free tier, in-app purchases, and maybe a
subscription option to the app. That means more coding. Then I need to
incorporate a business of some kind and do all the regular bookkeeping
associated with it. That would be payroll taxes, quarterly and annual
tax filings, etc‚Ä¶ I used to own my own software consulting business and
really don‚Äôt want to do that stuff again.
</p>
<p>
But if I thought I could make it up on volume, that might make it worth
while, right? The simple truth is most computer users don‚Äôt know what an
outliner is, much less how useful they are. Even those that do, rarely
need to use one on a daily basis. Zavala is free and has been all the
years that it has been available in the App Store and I couldn‚Äôt make it
on the number of users I have now. That number would probably drop to
about zero if I were to start charging. Could I get more volume by
marketing Zavala? Sure, but that is another business thing that costs
time and money, that I don‚Äôt want to do.
</p>
<p>
There is an upside to not having money involved when you write software.
I don‚Äôt have to add features just to drive an upgrade cycle. With
commercial software, you constantly have to deliver upgrades to keep a
steady income regardless of if you are subscription based or charging up
front. I don‚Äôt want Zavala to become bloatware. I don‚Äôt want to add
features that I don‚Äôt believe add core value, just to keep the money
coming in.
</p>
<p>
Same goes for donations. I don‚Äôt accept donations because I don‚Äôt want
to feel obligated to implement a feature that a donor may want, but that
I don‚Äôt think belongs in Zavala. I would rather accept feature requests
on an equal basis from all users and decide which to implement on the
merit of the idea, rather than who gave me money.
</p>
<h2 id="why-write-zavala-at-all">
Why write Zavala at all?
</h2>
<p>
I retired early after a successful career as a software consultant. I
really liked writing software, I just didn‚Äôt always like the work I had
to do. Now I have the freedom to craft software how I see fit and only
work on projects that I am interested in.
</p>
<p>
The way I usually explain it is like this. Imagine you made furniture
your whole life, but your employer only gave you pallet wood to use and
half the time needed to make a piece. You were good at it and loved
furniture, but were unfulfilled at your job until you retired. Now you
can make furniture using walnut and take the time needed to make
something you are proud of.
</p>
<h2 id="how-can-you-help-you-ask">
How can you help, you ask?
</h2>
<p>
Please, please email me with bug reports using the Provide Feedback
option under Help (in Settings on iOS). I take them seriously and fix
them as fast as I can. I do test Zavala as rigorously as I can.
Unfortunately it is the nature of software that a developer will never
be able to predict every way that users will use an app. Production bugs
do happen. The best we can do is squash them as fast as possible.
</p>
<p><br></p>
<p><a
href="https://vincode.io/2025/08/11/zavala-will-always-be-free.html"
class="uri">https://vincode.io/2025/08/11/zavala-will-always-be-free.html</a></p>
<hr />
<h2
id="this-diy-ereader-has-dual-e-ink-displays-for-a-more-book-like-reading-experience">This
DIY eReader has dual E Ink displays for a more book-like reading
experience</h2>
<p>date: 2025-08-11, from: Liliputing</p>
<p>
E Ink devices like the Amazon Kindle, Kobo, and B&amp;N Nook line of
products promise a book-like reading experience thanks to displays that
mimic some of the properties of ink on paper. But one big difference?
For the most part they‚Äôre about the size of a single page in a paperback
book. Pick up an [‚Ä¶]
</p>
<p>
The post
<a href="https://liliputing.com/this-diy-ereader-has-dual-e-ink-displays-for-a-more-book-like-reading-experience/">This
DIY eReader has dual E Ink displays for a more book-like reading
experience</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/this-diy-ereader-has-dual-e-ink-displays-for-a-more-book-like-reading-experience/"
class="uri">https://liliputing.com/this-diy-ereader-has-dual-e-ink-displays-for-a-more-book-like-reading-experience/</a></p>
<hr />
<h2
id="voiceover-artists-weigh-the-faustian-bargain-of-lending-their-talents-to-ai">Voiceover
Artists Weigh the ‚ÄòFaustian Bargain‚Äô of Lending Their Talents to AI</h2>
<p>date: 2025-08-11, from: 404 Media Group</p>
<p>The human voiceover artists behind AI voices are grappling with the
choice to embrace the gigs and earn a living, or pass on potentially
life-changing opportunities from Big Tech.</p>
<p><br></p>
<p><a
href="https://www.404media.co/voiceover-artists-ai-voice-acting-jobs-microsoft-openai-chatgpt/"
class="uri">https://www.404media.co/voiceover-artists-ai-voice-acting-jobs-microsoft-openai-chatgpt/</a></p>
<hr />
<h2
id="the-u.s.-army-is-testing-ai-controlled-ground-drones-near-a-border-with-russia">The
U.S. Army Is Testing AI Controlled Ground Drones Near a Border with
Russia</h2>
<p>date: 2025-08-11, from: 404 Media Group</p>
<p>The OverDrive is made to let ground vehicles navigate tough terrain
with minimal input from humans.</p>
<p><br></p>
<p><a
href="https://www.404media.co/the-u-s-army-is-testing-ai-controlled-ground-drones-near-a-border-with-russia/"
class="uri">https://www.404media.co/the-u-s-army-is-testing-ai-controlled-ground-drones-near-a-border-with-russia/</a></p>
<hr />
<h2 id="insignificant-figures">Insignificant Figures</h2>
<p>date: 2025-08-11, updated: 2025-08-11, from: One Foot Tsunami</p>
<p><br></p>
<p><a
href="https://onefoottsunami.com/2025/08/11/insignificant-figures/"
class="uri">https://onefoottsunami.com/2025/08/11/insignificant-figures/</a></p>
<hr />
<h2 id="did-the-old-robber-barons-get-a-bad-rap">Did the Old Robber
Barons Get a Bad Rap?</h2>
<p>date: 2025-08-11, from: Tina Brown</p>
<p>I‚Äôm gutted that the third season of Julian Fellowes‚Äôs The Gilded Age
on HBO ended last night.</p>
<p><br></p>
<p><a
href="https://tinabrown.substack.com/p/did-the-old-robber-barons-get-a-bad"
class="uri">https://tinabrown.substack.com/p/did-the-old-robber-barons-get-a-bad</a></p>
<hr />
<h2 id="the-political-economy-of-incompetence">The Political Economy of
Incompetence</h2>
<p>date: 2025-08-11, from: Paul Krugman</p>
<p>How Hannah Arendt predicted Stephen Moore</p>
<p><br></p>
<p><a
href="https://paulkrugman.substack.com/p/the-political-economy-of-incompetence"
class="uri">https://paulkrugman.substack.com/p/the-political-economy-of-incompetence</a></p>
<hr />
<h2 id="happy-maker-monday-show-us-your-raspberry-pi-builds">Happy Maker
Monday ‚Äî show us your Raspberry Pi builds!</h2>
<p>date: 2025-08-11, from: Raspberry Pi News (.com)</p>
<p>
Another Maker Monday is upon us!
</p>
<p>
The post
<a href="https://www.raspberrypi.com/news/happy-maker-monday-show-us-your-raspberry-pi-builds/">Happy
Maker Monday ‚Äî show us your Raspberry Pi builds!</a> appeared first on
<a href="https://www.raspberrypi.com">Raspberry Pi</a>.
</p>
<p><br></p>
<p><a
href="https://www.raspberrypi.com/news/happy-maker-monday-show-us-your-raspberry-pi-builds/"
class="uri">https://www.raspberrypi.com/news/happy-maker-monday-show-us-your-raspberry-pi-builds/</a></p>
<hr />
<h2 id="one-man-in-his-time-plays-many-parts">One man in his time plays
many parts‚Ä¶</h2>
<p>date: 2025-08-11, from: Status-Q blog</p>
<p>I did like this article: 27 Notes on Growing Old(er), by the author
Ian Leslie. Excerpt: Wisdom is meant to be the great compensation for
growing older. Though your your knees sound like they‚Äôre unlocking a
safe when you bend down, and you can‚Äôt straighten up without an ‚Äúoof‚Äù,
you can at least revel in
<a class="more-link excerpt-link" href="https://statusq.org/archives/2025/08/11/13259/">Continue
Reading<span class="glyphicon glyphicon-chevron-right"></span></a></p>
<p><br></p>
<p><a href="https://statusq.org/archives/2025/08/11/13259/"
class="uri">https://statusq.org/archives/2025/08/11/13259/</a></p>
<hr />
<h2 id="qwen-image-mps">qwen-image-mps</h2>
<p>date: 2025-08-11, updated: 2025-08-11, from: Simon Willison‚Äôs
Weblog</p>
<p>
<strong><a href="https://github.com/ivanfioravanti/qwen-image-mps">qwen-image-mps</a></strong>
</p>
Ivan Fioravanti built this Python CLI script for running the
<a href="https://huggingface.co/Qwen/Qwen-Image">Qwen/Qwen-Image</a>
image generation model on an Apple silicon Mac, optionally using the
<a href="https://github.com/ModelTC/Qwen-Image-Lightning">Qwen-Image-Lightning</a>
LoRA to dramatically speed up generation.
</p>
<p>
Ivan has tested it this on 512GB and 128GB machines and it ran
<a href="https://x.com/ivanfioravanti/status/1954646355458269562">really
fast</a> - 42 seconds on his M3 Ultra. I‚Äôve run it on my 64GB M2 MacBook
Pro - after quitting almost everything else - and it just about manages
to output images after pegging my GPU (fans whirring, keyboard heating
up) and occupying 60GB of my available RAM. With the LoRA option running
the script to generate an image took 9m7s on my machine.
</p>
<p>
Ivan merged
<a href="https://github.com/ivanfioravanti/qwen-image-mps/pull/3">my
PR</a> adding inline script dependencies for
<a href="https://github.com/astral-sh/uv">uv</a> which means you can now
run it like this:
</p>
<pre><code>uv run https://raw.githubusercontent.com/ivanfioravanti/qwen-image-mps/refs/heads/main/qwen-image-mps.py \
-p 'A vintage coffee shop full of raccoons, in a neon cyberpunk city' -f
</code></pre>
<p>
The first time I ran this it downloaded the 57.7GB model from Hugging
Face and stored it in my
<code>~/.cache/huggingface/hub/models‚ÄìQwen‚ÄìQwen-Image</code> directory.
The <code>-f</code> option fetched an extra 1.7GB
<code>Qwen-Image-Lightning-8steps-V1.0.safetensors</code> file to my
working directory that sped up the generation.
</p>
<p>
Here‚Äôs the resulting image:
</p>
<p>
<p><img alt="Digital artwork of a cyberpunk-style coffee shop populated entirely by raccoons as customers, with illegible neon signs visible in the windows, pendant lighting over the counter, menu boards on the wall, bottles on shelves behind the bar, and raccoons sitting at tables and the counter with coffee cups" src="https://static.simonwillison.net/static/2025/racoon-cyberpunk-coffee.jpg" /></p>
<pre><code>&lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href=&quot;https://x.com/ivanfioravanti/status/1954284146064576966&quot;&gt;@ivanfioravanti&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/macos&quot;&gt;macos&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/python&quot;&gt;python&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/uv&quot;&gt;uv&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/qwen&quot;&gt;qwen&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/text-to-image&quot;&gt;text-to-image&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai-in-china&quot;&gt;ai-in-china&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ivan-fioravanti&quot;&gt;ivan-fioravanti&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Aug/11/qwen-image-mps/#atom-everything"
class="uri">https://simonwillison.net/2025/Aug/11/qwen-image-mps/#atom-everything</a></p>
<hr />
<h2 id="ai-for-data-engineers-with-simon-willison">AI for data engineers
with Simon Willison</h2>
<p>date: 2025-08-11, updated: 2025-08-11, from: Simon Willison‚Äôs
Weblog</p>
<p>
<strong><a href="https://talkingpostgres.com/episodes/ai-for-data-engineers-with-simon-willison">AI
for data engineers with Simon Willison</a></strong>
</p>
I recorded an episode last week with Claire Giordano for the Talking
Postgres podcast. The topic was ‚ÄúAI for data engineers‚Äù but we ended up
covering an enjoyable range of different topics.
</p>
<ul>
<li>
How I got started programming with a Commodore 64 - the tape drive for
which inspired the name <a href="https://datasette.io/">Datasette</a>
</li>
<li>
Selfish motivations for
<a href="https://til.simonwillison.net/">TILs</a> (force me to write up
my notes) and open source (help me never have to solve the same problem
twice)
</li>
<li>
LLMs have been good at SQL for a couple of years now. Here‚Äôs how I used
them
<a href="https://simonwillison.net/2025/Apr/28/dashboard-alt-text/">for
a complex PostgreSQL query</a> that extracted alt text from my blog‚Äôs
images using regular expressions
</li>
<li>
Structured data extraction as the most economically valuable application
of LLMs for data work
</li>
<li>
2025 has been the year of tool calling a loop (‚Äúagentic‚Äù if you like)
</li>
<li>
Thoughts on running MCPs securely - read-only database access, think
about sandboxes, use PostgreSQL permissions, watch out for the
<a href="https://simonwillison.net/tags/lethal-trifecta/">lethal
trifecta</a>
</li>
<li>
Jargon guide: Agents, MCP, RAG, Tokens
</li>
<li>
How to get started learning to prompt: play with the models and ‚Äúbring
AI to the table‚Äù even for tasks that you don‚Äôt think it can handle
</li>
<li>
‚ÄúIt‚Äôs always a good day if you see a pelican‚Äù
</li>
</ul>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/postgresql&quot;&gt;postgresql&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/podcast-appearances&quot;&gt;podcast-appearances&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Aug/11/ai-for-data-engineers/#atom-everything"
class="uri">https://simonwillison.net/2025/Aug/11/ai-for-data-engineers/#atom-everything</a></p>
<hr />
<h2 id="chromium-docs-the-rule-of-2">Chromium Docs: The Rule Of 2</h2>
<p>date: 2025-08-11, updated: 2025-08-11, from: Simon Willison‚Äôs
Weblog</p>
<p>
<strong><a href="https://chromium.googlesource.com/chromium/src/+/main/docs/security/rule-of-2.md">Chromium
Docs: The Rule Of 2</a></strong>
</p>
Alex Russell
<a href="https://toot.cafe/@slightlyoff/114999510361121718">pointed
me</a> to this principle in the Chromium security documentation as
similar to my description of
<a href="https://simonwillison.net/2025/Aug/9/bay-area-ai/">the lethal
trifecta</a>. First added
<a href="https://github.com/chromium/chromium/commit/aef94dd0e444605a16be26cba96aa477bc7fc3f5">in
2019</a>, the Chromium guideline states:
</p>
<blockquote>
<p>
When you write code to parse, evaluate, or otherwise handle
untrustworthy inputs from the Internet ‚Äî which is almost everything we
do in a web browser! ‚Äî we like to follow a simple rule to make sure it‚Äôs
safe enough to do so. The Rule Of 2 is: Pick no more than 2 of
</p>
<ul>
<li>
untrustworthy inputs;
</li>
<li>
unsafe implementation language; and
</li>
<li>
high privilege.
</li>
</ul>
<p>
<img alt="Venn diagram showing you should always use
a safe language, a sandbox, or not be processing untrustworthy inputs in the first
place." src="https://static.simonwillison.net/static/2025/rule-of-2.png" />
</p>
</blockquote>
<p>
Chromium uses this design pattern to help try to avoid the high severity
memory safety bugs that come when untrustworthy inputs are handled by
code running at high privilege.
</p>
<blockquote>
<p>
Chrome Security Team will generally not approve landing a CL or new
feature that involves all 3 of untrustworthy inputs, unsafe language,
and high privilege. To solve this problem, you need to get rid of at
least 1 of those 3 things.
</p>
</blockquote>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/alex-russell&quot;&gt;alex-russell&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/browsers&quot;&gt;browsers&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/chrome&quot;&gt;chrome&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/security&quot;&gt;security&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/lethal-trifecta&quot;&gt;lethal-trifecta&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Aug/11/the-rule-of-2/#atom-everything"
class="uri">https://simonwillison.net/2025/Aug/11/the-rule-of-2/#atom-everything</a></p>
<hr />
<h2 id="what-interviews-should-i-look-for">What Interviews Should I Look
For?</h2>
<p>date: 2025-08-11, from: Computer ads from the Past</p>
<p>Help point me in the right direction.</p>
<p><br></p>
<p><a
href="https://computeradsfromthepast.substack.com/p/what-interviews-should-i-look-for"
class="uri">https://computeradsfromthepast.substack.com/p/what-interviews-should-i-look-for</a></p>
<hr />
<h2
id="qwen3-4b-thinking-this-is-art---pelicans-dont-ride-bikes">Qwen3-4B-Thinking:
‚ÄúThis is art - pelicans don‚Äôt ride bikes!‚Äù</h2>
<p>date: 2025-08-10, updated: 2025-08-10, from: Simon Willison‚Äôs
Weblog</p>
<p>
I‚Äôve fallen a few days behind keeping up with Qwen. They released two
new 4B models last week:
<a href="https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507">Qwen3-4B-Instruct-2507</a>
and its thinking equivalent
<a href="https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507">Qwen3-4B-Thinking-2507</a>.
</p>
<p>
These are relatively tiny models that punch <em>way</em> above their
weight. I‚Äôve been running the 8bit GGUF varieties via LM Studio (here‚Äôs
<a href="https://huggingface.co/lmstudio-community/Qwen3-4B-Instruct-2507-GGUF">Instruct</a>,
here‚Äôs
<a href="https://huggingface.co/lmstudio-community/Qwen3-4B-Thinking-2507-GGUF">Thinking</a>)
- both of them are 4GB downloads that use around 4.3GB of my M2 MacBook
Pro‚Äôs system RAM while running. Both are way more capable than I would
expect from such small files.
</p>
<p>
Qwen3-4B-Thinking is the first model I‚Äôve tried which called out the
absurdity of being asked to draw
<a href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">a
pelican riding a bicycle</a>!
</p>
<p>
Here‚Äôs
<a href="https://gist.github.com/simonw/cd41769de4791b98ba43a17c6ff32ee1">the
full transcript</a> - some highlights from the thinking trace:
</p>
<blockquote>
<p>
Okay, the user asked for an SVG of a pelican riding a bicycle. That‚Äôs‚Ä¶
oddly specific and completely unrealistic.
</p>
<p>
First reaction: Pelicans don‚Äôt ride bicycles. They‚Äôre birds that fly or
swim, not human-like vehicles. This feels like a mix-up - maybe they
meant ‚Äúa cyclist‚Äù but typed ‚Äúpelican‚Äù? Or perhaps it‚Äôs a joke?
</p>
<p>
Hmm, user might be:
</p>
<ul>
<li>
A kid playing with words (pelican + bicycle = silly combo)
</li>
<li>
Someone testing if I‚Äôll generate impossible images
</li>
<li>
Actually wanting a pelican <em>on</em> a bike for art project? But that
still doesn‚Äôt make sense biologically
</li>
</ul>
<p>
<em>Checks SVG capabilities</em> SVG is for vector graphics, but this
request violates physics and biology. If I tried to draw it literally:
</p>
<ul>
<li>
Pelican would be too big for a bike frame
</li>
<li>
Bike wheels would be tiny compared to bird wings
</li>
<li>
No realistic way to show ‚Äúriding‚Äù since pelicans don‚Äôt have legs for
pedaling
</li>
</ul>
<p>
[‚Ä¶]
</p>
<p>
<em>Self-check</em>: Am I being too pedantic? Nah - if someone asks for
impossible things, it‚Äôs better to gently correct than make fake art that
could confuse them. [‚Ä¶]
</p>
<p>
I appreciate your creative request! ü¶Öüö¥‚Äç‚ôÇÔ∏è However, <strong>pelicans don‚Äôt
ride bicycles</strong> (they‚Äôre birds that fly/swim, not humans with
bike skills). Generating this as a literal SVG would be biologically
impossible and visually confusing.
</p>
</blockquote>
<p>
‚ÄúThis request violates physics and biology‚Äù - Qwen3-4B-Thinking saying
what no other model ever thought to express.
</p>
<p>
I also really enjoyed the ‚ÄúAm I being too pedantic? Nah‚Äù line. This
model is sassy!
</p>
<p>
It continued on to spit out two SVGS: the first titled ‚ÄúMost Likely: A
Human Cyclist‚Äù and the second ‚ÄúArtistic Interpretation: Pelican
<em>On</em> a Bicycle (For Fun!)‚Äù.
</p>
<p>
They were both terrible. Here‚Äôs the human one:
</p>
<p>
<img src="https://static.simonwillison.net/static/2025/qwen3-4b-thinking-human.png" alt="It's a green horizontal line, three abstract black shapes, a brown circle and the word Person" style="max-width: 100%;" />
</p>
<p>
And here‚Äôs the supposed pelican:
</p>
<p>
<img src="https://static.simonwillison.net/static/2025/qwen3-4b-thinking-pelican.png" alt="A blue circle, with a small black shape that might be a wing and a black shape that could maybe be the head? It's awful. Red text overlaps it that says This is art - pelicans don't ride bikes! - there is no attempt at a bicycle." style="max-width: 100%;" />
</p>
<p>
I like Qwen‚Äôs decision to include the clarifying annotation ‚ÄúThis is art
- pelicans don‚Äôt ride bikes!‚Äù:
</p>
<p>
I tried the Qwen3-4B-Instruct non-thinking model too. It
<a href="https://gist.github.com/simonw/ad927a3849d0aece043afc97559be4bf">answered
much faster</a> (no time spent questioning my choice of task with its
thinking tokens) and gave me this:
</p>
<p>
<img src="https://static.simonwillison.net/static/2025/qwen3-4b-instruct-2507-pelican.png" alt="A bunch of shaps. Pelican Riding a Bike! transposed on top. The yellow and orange bits might be a pelican I guess. The bicycle has two wheels overlapping too close and a single bar in the wrong direction." style="max-width: 100%;" />
</p>
<p>
4B is such an interesting model size. These models should run on almost
anything and, at least on my M2 MacBook, they run <em>fast</em>. I‚Äôm
getting 50+ tokens per second and they‚Äôre using just less than 4.5GB of
RAM while running.
</p>
<p>
The question is always how useful such a tiny model can be. Clearly it‚Äôs
not great for SVG pelican illustrations!
</p>
<p>
I did get a useful result out of the <code>-Thinking</code> variant for
a <code>jq</code> expression I needed. I prompted:
</p>
<blockquote>
<p>
queries[0].rows is an array of objects each with a markdown key - write
a jq bash one liner to output a raw string if that markdown concatenated
together with double newlines between each
</p>
</blockquote>
<p>
It thought
<a href="https://gist.github.com/simonw/3f76749aa710f4a2d6405ebcf5b00ac4">for
3 minutes 13 seconds</a> before spitting out a recipe that did roughly
what I wanted:
</p>
<pre><code>jq -r '.queries[0].rows[] | .markdown' | tr '\n' '\n\n'</code></pre>
<p>
I‚Äôm not sure that was worth waiting three minutes for though!
</p>
<p>
These models have a 262,144 token context - wildly impressive, <em>if it
works</em>.
</p>
<p>
So I tried another experiment: I used the Instruct model to summarize
<a href="https://news.ycombinator.com/item?id=44851557">this Hacker News
conversation about GPT-5</a>.
</p>
<p>
I did this with the
<a href="https://github.com/agustif/llm-lmstudio">llm-lmstudio</a>
plugin for LLM combined with my
<a href="https://til.simonwillison.net/llms/claude-hacker-news-themes">hn-summary.sh
script</a>, which meant I could run the experiment like this:
</p>
<pre><code>hn-summary.sh 44851557 -m qwen3-4b-instruct-2507
</code></pre>
<p>
I believe this is 15,785 tokens - so nothing close to the 262,144
maximum but still an interesting test of a 4GB local model.
</p>
<p>
The good news is Qwen spat out a genuinely useful summary of the
conversation! You can
<a href="https://gist.github.com/simonw/4c5a1912f73e0d68b456b18000a76f0d#response">read
that here</a> - it‚Äôs the best I‚Äôve seen yet from a model running on my
laptop, though honestly I‚Äôve not tried many other recent models in this
way.
</p>
<p>
The bad news‚Ä¶ it took almost five minutes to process and return the
result!
</p>
<p>
As a loose calculation, if the model can output 50 tokens/second maybe
there‚Äôs a similar speed for processing incoming input.. in which case
15785 / 50 = 315 seconds which is 5m15s.
</p>
<p>
Hosted models can crunch through 15,000 tokens of input in just a few
seconds. I guess this is one of the more material limitations of running
models on Apple silicon as opposed to dedicated GPUs.
</p>
<p>
I think I‚Äôm going to spend some more time with these models. They‚Äôre
fun, they have personality and I‚Äôm confident there are classes of useful
problems they will prove capable at despite their small size. Their
ability at summarization should make them a good fit for local RAG, and
I‚Äôve not started exploring their tool calling abilities yet.
</p>
<pre><code>    &lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/local-llms&quot;&gt;local-llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/qwen&quot;&gt;qwen&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/pelican-riding-a-bicycle&quot;&gt;pelican-riding-a-bicycle&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llm-release&quot;&gt;llm-release&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/lm-studio&quot;&gt;lm-studio&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai-in-china&quot;&gt;ai-in-china&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Aug/10/qwen3-4b/#atom-everything"
class="uri">https://simonwillison.net/2025/Aug/10/qwen3-4b/#atom-everything</a></p>
<hr />
<h2 id="episode-162---csirac-australias-first-computer">Episode 162 -
CSIRAC, Australia‚Äôs First Computer</h2>
<p>date: 2025-08-10, from: Advent of Computing</p>
<p>
In 1949 CSIRAC sprung to life in a lab in Sydney, Australia. It was a
very early stored program computer. All machines of the era were unique.
But CSIRAC, well, it was <em>very</em> unique indeed.
</p>
<p>
Selected Sources:
</p>
<p>
¬†<a href= "https://cis.unimelb.edu.au/about/csirac/music/reconstruction" rel= "noopener noreferrer nofollow" data-link-auto= ""><u>https://cis.unimelb.edu.au/about/csirac/music/reconstruction</u></a>
- The Music of CSIRAC
</p>
<p>
<a href="https://sci-hub.se/10.1109/MAHC.1984.10014" rel= "noopener noreferrer nofollow" data-link-auto= "">https://sci-hub.se/10.1109/MAHC.1984.10014</a>
- Pearcy and Beard on CSIRAC
</p>
<audio crossorigin="anonymous" controls="controls">
<source type="audio/mpeg" src="https://traffic.libsyn.com/secure/adventofcomputing/ep162_csirac.mp3?dest-id=1206722">
</source>
</audio>
<p><a href="https://traffic.libsyn.com/secure/adventofcomputing/ep162_csirac.mp3?dest-id=1206722" target="_blank">download
audio/mpeg</a><br></p>
<p><a
href="https://adventofcomputing.libsyn.com/episode-162-csirac-australias-first-computer"
class="uri">https://adventofcomputing.libsyn.com/episode-162-csirac-australias-first-computer</a></p>
<hr />
<h2 id="quoting-sam-altman">Quoting Sam Altman</h2>
<p>date: 2025-08-10, updated: 2025-08-10, from: Simon Willison‚Äôs
Weblog</p>
<blockquote cite="https://x.com/sama/status/1954603417252532479">
<p>
the percentage of users using reasoning models each day is significantly
increasing; for example, for free users we went from &lt;1% to 7%, and
for plus users from 7% to 24%.
</p>
</blockquote>
<p class="cite">
‚Äî <a href="https://x.com/sama/status/1954603417252532479">Sam
Altman</a>, revealing quite how few people used the old model picker to
upgrade from GPT-4o
</p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/openai&quot;&gt;openai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llm-reasoning&quot;&gt;llm-reasoning&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/gpt-5&quot;&gt;gpt-5&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/sam-altman&quot;&gt;sam-altman&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/chatgpt&quot;&gt;chatgpt&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Aug/10/sam-altman/#atom-everything"
class="uri">https://simonwillison.net/2025/Aug/10/sam-altman/#atom-everything</a></p>
<hr />
<p><strong><span class="citation" data-cites="Robert">@Robert</span>‚Äôs
feed at BlueSky</strong> (date: 2025-08-10, from: Robert‚Äôs feed at
BlueSky)</p>
<p>Wrote up a short post on using Flat Lake, flatelake.app, and
Deno+TypeScript to generate RSS 2.0 feeds.
https://rsdoiel.github.io/blog/2025/08/10/generating_rss_with_flatlake.html
https://flatelake.app</p>
<p><br></p>
<p><a
href="https://bsky.app/profile/rsdoiel.bsky.social/post/3lw3cri7t5c2l"
class="uri">https://bsky.app/profile/rsdoiel.bsky.social/post/3lw3cri7t5c2l</a></p>
<hr />
<h2
id="lilbits-aol-frees-up-your-phone-line-by-ending-dial-up-access">Lilbits:
AOL frees up your phone line by ending dial-up access</h2>
<p>date: 2025-08-10, from: Liliputing</p>
<p>
AOL is ending dial-up access next month, 34 years after launching the
service that provided many Americans with their first (somewhat limited)
taste of the internet. The surprising news here is that it hadn‚Äôt
already happened‚Ä¶ who uses dial-up¬†or AOL in 2025? But it‚Äôs still an
interesting footnote in the history of the internet. Here‚Äôs [‚Ä¶]
</p>
<p>
The post <a href="https://liliputing.com/lilbits-2/">Lilbits: AOL frees
up your phone line by ending dial-up access</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a href="https://liliputing.com/lilbits-2/"
class="uri">https://liliputing.com/lilbits-2/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Robert">@Robert</span>‚Äôs
feed at BlueSky</strong> (date: 2025-08-10, from: Robert‚Äôs feed at
BlueSky)</p>
<p>üòÜüëá</p>
<p>[contains quote post or other embedded content]</p>
<p><br></p>
<p><a
href="https://bsky.app/profile/rsdoiel.bsky.social/post/3lw2nz5raws2q"
class="uri">https://bsky.app/profile/rsdoiel.bsky.social/post/3lw2nz5raws2q</a></p>
<hr />
<h2
id="debian-13-trixie-release-brings-risc-v-support-plus-to-the-popular-gnulinux-distro-plus-thousands-of-other-updates">Debian
13 ‚Äútrixie‚Äù release brings RISC-V support plus to the popular GNU/Linux
distro, plus thousands of other updates</h2>
<p>date: 2025-08-10, from: Liliputing</p>
<p>
Debian is a free and open source, Linux-based operating system that‚Äôs
bee around for more than three decades. And computers have changed a lot
in that time. So while Debian has a reputation for releasing updates on
a slow, steady, and stable basis rather than pushing bleeding edge
features, the operating system¬†has¬†made some major changes [‚Ä¶]
</p>
<p>
The post
<a href="https://liliputing.com/debian-13-trixie-release-brings-risc-v-support-plus-to-the-popular-gnu-linux-distro-plus-thousands-of-other-updates/">Debian
13 ‚Äútrixie‚Äù release brings RISC-V support plus to the popular GNU/Linux
distro, plus thousands of other updates</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/debian-13-trixie-release-brings-risc-v-support-plus-to-the-popular-gnu-linux-distro-plus-thousands-of-other-updates/"
class="uri">https://liliputing.com/debian-13-trixie-release-brings-risc-v-support-plus-to-the-popular-gnu-linux-distro-plus-thousands-of-other-updates/</a></p>
<hr />
<h2 id="the-economics-of-smoot-hawley-2.0-part-ii">The Economics of
Smoot Hawley 2.0, Part II</h2>
<p>date: 2025-08-10, from: Paul Krugman</p>
<p>This trade war is really a class war</p>
<p><br></p>
<p><a
href="https://paulkrugman.substack.com/p/the-economics-of-smoot-hawley-20-cf7"
class="uri">https://paulkrugman.substack.com/p/the-economics-of-smoot-hawley-20-cf7</a></p>
<hr />
<h2 id="generating-rss-with-flatlake">Generating RSS with FlatLake</h2>
<p>date: 2025-08-10, from: Robert‚Äôs Ramblings</p>
<p>A show post describing a prototype in Deno+TypeScript for generating
RSS 2.0 feeds from a FlatLake generated JSON API.</p>
<p><br></p>
<p><a
href="https://rsdoiel.github.io/blog/2025/08/10/generating_rss_with_flatlake.html"
class="uri">https://rsdoiel.github.io/blog/2025/08/10/generating_rss_with_flatlake.html</a></p>
</section>
<footer>
Antenna is a personal aggregation of items found around the web.
Curated with <a href="https://rsdoiel.github.io/skimmer">skimmer</a> and <a href="https://sqlite.org">sqlite</a> then rendered with <a href="https://pandoc.org">Pandoc</a>.
</footer>
</body>
</html>
