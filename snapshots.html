<!doctype html>
<html lang="en-US">
<head>
  <meta charset="utf-8" >
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" >
  <title>snapshots</title>
<!--  <link rel="stylesheet" type="text/css"  href="webfonts/fonts.css" media="screen" > -->
  <link rel="stylesheet" type="text/css"  href="css/site.css" media="screen" >
</head>
<body>
<header>
	<img class="logo" 
		src="https://upload.wikimedia.org/wikipedia/commons/9/9c/Antenna_1_-_The_Noun_Project.svg"
		alt="line art showing an antenna"
		height="80" width="60" >
	<h1>The Antenna</h1> 
	<h2>finding signal in the noise</h2>
</header>
<nav>
<ul>
	<li><a href="./">The Antenna</a></li>
	<li><a href="archives/">Archives</a></li>
	<li><a href="about.html">About</a></li>
</ul>
</nav>
<section>
<div class="description-for-items">
Items collected from feeds in <a href="snapshots.txt">snapshots.txt</a>
</div>
<h1 id="snapshots">snapshots</h1>
<p>(date: 2025-08-11 14:10:57)</p>
<hr />
<h2 id="ios-26-developer-beta-6">iOS 26 Developer Beta 6</h2>
<p>date: 2025-08-11, from: Michael Tsai</p>
<p>Juli Clover: Apple today provided developers with the sixth betas of
iOS 26 and iPadOS 26 for testing purposes, with the updates coming a
week after Apple seeded the fifth betas. The release notes don’t call
out any changes in beta 6. Juli Clover: The Lock Screen clock has been
updated with additional transparency, allowing […]</p>
<p><br></p>
<p><a href="https://mjtsai.com/blog/2025/08/11/ios-26-developer-beta-6/"
class="uri">https://mjtsai.com/blog/2025/08/11/ios-26-developer-beta-6/</a></p>
<hr />
<h2 id="macos-tahoe-26-developer-beta-6">macOS Tahoe 26 Developer Beta
6</h2>
<p>date: 2025-08-11, from: Michael Tsai</p>
<p>Juli Clover: Apple today provided developers with the sixth beta of
macOS Tahoe 26 for testing purposes, with the update coming a week after
the fifth beta. The release notes don’t call out any changes in beta 6.
Previously: macOS Tahoe 26 Developer Beta 5</p>
<p><br></p>
<p><a
href="https://mjtsai.com/blog/2025/08/11/macos-tahoe-26-developer-beta-6/"
class="uri">https://mjtsai.com/blog/2025/08/11/macos-tahoe-26-developer-beta-6/</a></p>
<hr />
<h2 id="history-of-apples-developer-relations">History of Apple’s
Developer Relations</h2>
<p>date: 2025-08-11, from: Michael Tsai</p>
<p>David Barnard (John Gruber): On the podcast I talk with John about
the fascinating 40-year history of Apple’s developer relations, how
almost going bankrupt in the 1990s shaped today’s control-focused
approach, and why we might need an ‘App Store 3.0’ reset. […] As the App
Store became a services giant, the partnership vibe faded. Developers
[…]</p>
<p><br></p>
<p><a
href="https://mjtsai.com/blog/2025/08/11/history-of-apples-developer-relations/"
class="uri">https://mjtsai.com/blog/2025/08/11/history-of-apples-developer-relations/</a></p>
<hr />
<h2
id="ploopy-trackpad-review-usb-touchpad-with-open-source-firmware-and-multitouch-support">Ploopy
TrackPad review: USB touchpad with open source firmware and multitouch
support</h2>
<p>date: 2025-08-11, from: Liliputing</p>
<p>
Most desktop computers are designed for keyboard and mouse input. Most
laptops have a built-in touchpad. But it’s surprisingly difficult to
find a good touchpad that’s designed for use in a desktop setup. Mac
users have Apple’s Magic Trackpad. But if you’re using Windows or Linux
you’ll either need to fight with unofficial drivers to […]
</p>
<p>
The post
<a href="https://liliputing.com/ploopy-trackpad-review-usb-touchpad-with-open-source-firmware-and-multitouch-support/">Ploopy
TrackPad review: USB touchpad with open source firmware and multitouch
support</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/ploopy-trackpad-review-usb-touchpad-with-open-source-firmware-and-multitouch-support/"
class="uri">https://liliputing.com/ploopy-trackpad-review-usb-touchpad-with-open-source-firmware-and-multitouch-support/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Robert">@Robert</span>’s
feed at BlueSky</strong> (date: 2025-08-11, from: Robert’s feed at
BlueSky)</p>
<p>This is important.
https://laist.com/news/politics/tuesday-august-14-boycott-operation-trojan-horse</p>
<p><br></p>
<p><a
href="https://bsky.app/profile/rsdoiel.bsky.social/post/3lw5i4dn56s23"
class="uri">https://bsky.app/profile/rsdoiel.bsky.social/post/3lw5i4dn56s23</a></p>
<hr />
<h2 id="new-testflight-build-uploaded-waiting-for-review">New TestFlight
Build Uploaded, Waiting for Review</h2>
<p>date: 2025-08-11, from: NetNewsWire</p>
<p>
We know some folks are waiting on a new TestFlight build for iOS, and we
have good news — we’ve just uploaded 6.1.10 (6198), and it’s waiting on
Apple review. Once reviewed it will be available on TestFlight.
</p>
<p><br></p>
<p><a
href="https://netnewswire.blog/2025/08/11/new-testflight-build-uploaded-waiting.html"
class="uri">https://netnewswire.blog/2025/08/11/new-testflight-build-uploaded-waiting.html</a></p>
<hr />
<h2 id="reddit-will-block-the-internet-archive">Reddit will block the
Internet Archive</h2>
<p>date: 2025-08-11, updated: 2025-08-11, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://www.theverge.com/news/757538/reddit-internet-archive-wayback-machine-block-limit">Reddit
will block the Internet Archive</a></strong>
</p>
Well this <em>sucks</em>. Jay Peters for the Verge:
</p>
<blockquote>
<p>
Reddit says that it has caught AI companies scraping its data from the
Internet Archive’s Wayback Machine, so it’s going to start blocking the
Internet Archive from indexing the vast majority of Reddit. The Wayback
Machine will no longer be able to crawl post detail pages, comments, or
profiles; instead, it will only be able to index the Reddit.com
homepage, which effectively means Internet Archive will only be able to
archive insights into which news headlines and posts were most popular
on a given day.
</p>
</blockquote>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/internet-archive&quot;&gt;internet-archive&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/reddit&quot;&gt;reddit&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/scraping&quot;&gt;scraping&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/training-data&quot;&gt;training-data&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai-ethics&quot;&gt;ai-ethics&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Aug/11/reddit-will-block-the-internet-archive/#atom-everything"
class="uri">https://simonwillison.net/2025/Aug/11/reddit-will-block-the-internet-archive/#atom-everything</a></p>
<hr />
<h2 id="witch-hunts-to-misinformation-campaigns">Witch Hunts to
Misinformation Campaigns</h2>
<p>date: 2025-08-11, from: Guy Kawasaki blog</p>
<p>Julie Walsh, Whitehead Associate Professor of Critical Thought and
Associate Professor of Philosophy, Wellesley College.</p>
<p><br></p>
<p><a
href="https://guykawasaki.substack.com/p/witch-hunts-to-misinformation-campaigns"
class="uri">https://guykawasaki.substack.com/p/witch-hunts-to-misinformation-campaigns</a></p>
<hr />
<h2
id="overcompensating-temporada-1-superficial-paseo-por-la-dicha-y-la-pena-del-autodescubrimiento">Overcompensating
(temporada 1): superficial paseo por la dicha y la pena del
autodescubrimiento</h2>
<p>date: 2025-08-11, from: Iván Paredes Reséndiz blog, Mexico’s
cinema</p>
<p>
Disponible en: Prime Video. Creador: Benito Skinner. Dirección: Daniel
Gray Longino, Desiree Akhavan. Guion: Benito Skinner, Scott King, Mitra
Jouhari, Jordan Mendoza. Elenco: Benito Skinner, Wally Baram, Mary Beth
Barone, Adam DiMarco, Rish Shah, Connie Britton, Kyle MacLachlan,
Corteon Moore, Owen Thiele, Lukas Gage. País: Estados Unidos. Duración:
ocho episodios de 30 minutos cada uno. […]
</p>
<p>
La entrada
<a href="https://www.palomitademaiz.net/resenas-overcompensating-temporada-1/">Overcompensating
(temporada 1): superficial paseo por la dicha y la pena del
autodescubrimiento</a> se publicó primero en
<a href="https://www.palomitademaiz.net">Palomita de maíz</a>.
</p>
<p><br></p>
<p><a
href="https://www.palomitademaiz.net/resenas-overcompensating-temporada-1/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=resenas-overcompensating-temporada-1"
class="uri">https://www.palomitademaiz.net/resenas-overcompensating-temporada-1/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=resenas-overcompensating-temporada-1</a></p>
<hr />
<h2 id="codex-upgrade">Codex upgrade</h2>
<p>date: 2025-08-11, updated: 2025-08-11, from: Simon Willison’s
Weblog</p>
<p>
If you’ve been experimenting with OpenAI’s
<a href="https://github.com/openai/codex">Codex CLI</a> and have been
frustrated that it’s not possible to select text and copy it to the
clipboard, at least when running in the Mac terminal (I genuinely didn’t
know it was possible to build a terminal app that disabled copy and
paste) you should know that they fixed that in
<a href="https://github.com/openai/codex/issues/1247">this issue</a>
last week.
</p>
<p>
The new
<a href="https://github.com/openai/codex/releases/tag/rust-v0.20.0">0.20.0
version</a> from three days ago also completely removes the old
TypeScript codebase in favor of Rust. Even installations via NPM now get
the Rust version.
</p>
<p>
I originally installed Codex via Homebrew, so I had to run this command
to get the updated version:
</p>
<pre><code>brew upgrade codex
</code></pre>
<p>
Another Codex tip: to use GPT-5 (or any other specific OpenAI model) you
can run it like this:
</p>
<pre><code>export OPENAI_DEFAULT_MODEL="gpt-5"
codex
</code></pre>
<p>
<em>This no longer works, see update below.</em>
</p>
<p>
I’ve been using a <code>codex-5</code> script on my PATH containing
this, because sometimes I like to live dangerously!
</p>
<pre><code>#!/usr/bin/env zsh
# Usage: codex-5 [additional args passed to `codex`]
export OPENAI_DEFAULT_MODEL="gpt-5"
exec codex --dangerously-bypass-approvals-and-sandbox "$@"
</code></pre>
<p>
<strong>Update</strong>: It looks like GPT-5 is
<a href="https://github.com/openai/codex/blob/c61911524d839f5d56842faee0c46f6ef52d4387/codex-rs/core/src/config.rs#L28">the
default model</a> in v0.20.0 already.
</p>
<p>
Also the environment variable I was using no longer does anything, it
was
<a href="https://github.com/openai/codex/commit/107d2ce4e74618968b2eb7016777121d9529a204#diff-b012ea51eb2b6d23db97b930526379af9c4c119a3e057e55ea29d056326242e0L6">removed
in this commit</a> (I used Codex Web to
<a href="https://chatgpt.com/s/cd_689a252794b081919099d5ade205b41d">help
figure that out</a>). You can use the <code>-m model_id</code>
command-line option instead.
</p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/openai&quot;&gt;openai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/gpt-5&quot;&gt;gpt-5&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/rust&quot;&gt;rust&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai-assisted-programming&quot;&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/coding-agents&quot;&gt;coding-agents&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Aug/11/codex-upgrade/#atom-everything"
class="uri">https://simonwillison.net/2025/Aug/11/codex-upgrade/#atom-everything</a></p>
<hr />
<h2 id="zavala-will-always-be-free">Zavala Will Always Be Free</h2>
<p>date: 2025-08-11, from: Maurice Parker</p>
<h2 id="my-promise-to-you">
My promise to you.
</h2>
<p>
I have every intention of maintaining and updating Zavala for as long as
I am able. I’m also committed to keeping it free. I have no intention of
getting you hooked on using it and then starting to charge a
subscription.
</p>
<p>
To show I am serious about this, Zavala is Open Source software released
under the MIT license. This means that any other developer can take the
years of work that I have in Zavala and make a competing outliner from
it should I start charging for it. Given how small and competitive the
outliner market is, I don’t stand much of a chance of making any money
by going commercial. After all, I could be competing with my own past
work.
</p>
<h2 id="what-if-i-get-ran-over-by-a-bus">
What if I get ran over by a bus?
</h2>
<p>
Since Zavala is Open Source someone could pick up the project and
continue to update it. Worst case scenario, some enterprising
independent developer could try to make a commercial product out of it.
I don’t see much money in the endeavor, but others may see it
differently.
</p>
<h2 id="why-don-t-i-charge-for-zavala-or-accept-donations">
Why don’t I charge for Zavala or accept donations?
</h2>
<p>
Funny story. I fully intended to when I started writing it. After doing
some competitive analysis on the Mac-only, outliner market, I realized
there wasn’t much money there. There was so little in fact, that it
isn’t enough for me to be motivated enough to do the business side when
I’d rather be coding.
</p>
<p>
Let me break it down. Up front payments are a dead-end these days. I
would have to add a free tier, in-app purchases, and maybe a
subscription option to the app. That means more coding. Then I need to
incorporate a business of some kind and do all the regular bookkeeping
associated with it. That would be payroll taxes, quarterly and annual
tax filings, etc… I used to own my own software consulting business and
really don’t want to do that stuff again.
</p>
<p>
But if I thought I could make it up on volume, that might make it worth
while, right? The simple truth is most computer users don’t know what an
outliner is, much less how useful they are. Even those that do, rarely
need to use one on a daily basis. Zavala is free and has been all the
years that it has been available in the App Store and I couldn’t make it
on the number of users I have now. That number would probably drop to
about zero if I were to start charging. Could I get more volume by
marketing Zavala? Sure, but that is another business thing that costs
time and money, that I don’t want to do.
</p>
<p>
There is an upside to not having money involved when you write software.
I don’t have to add features just to drive an upgrade cycle. With
commercial software, you constantly have to deliver upgrades to keep a
steady income regardless of if you are subscription based or charging up
front. I don’t want Zavala to become bloatware. I don’t want to add
features that I don’t believe add core value, just to keep the money
coming in.
</p>
<p>
Same goes for donations. I don’t accept donations because I don’t want
to feel obligated to implement a feature that a donor may want, but that
I don’t think belongs in Zavala. I would rather accept feature requests
on an equal basis from all users and decide which to implement on the
merit of the idea, rather than who gave me money.
</p>
<h2 id="why-write-zavala-at-all">
Why write Zavala at all?
</h2>
<p>
I retired early after a successful career as a software consultant. I
really liked writing software, I just didn’t always like the work I had
to do. Now I have the freedom to craft software how I see fit and only
work on projects that I am interested in.
</p>
<p>
The way I usually explain it is like this. Imagine you made furniture
your whole life, but your employer only gave you pallet wood to use and
half the time needed to make a piece. You were good at it and loved
furniture, but were unfulfilled at your job until you retired. Now you
can make furniture using walnut and take the time needed to make
something you are proud of.
</p>
<h2 id="how-can-you-help-you-ask">
How can you help, you ask?
</h2>
<p>
Please, please email me with bug reports using the Provide Feedback
option under Help (in Settings on iOS). I take them seriously and fix
them as fast as I can. I do test Zavala as rigorously as I can.
Unfortunately it is the nature of software that a developer will never
be able to predict every way that users will use an app. Production bugs
do happen. The best we can do is squash them as fast as possible.
</p>
<p><br></p>
<p><a
href="https://vincode.io/2025/08/11/zavala-will-always-be-free.html"
class="uri">https://vincode.io/2025/08/11/zavala-will-always-be-free.html</a></p>
<hr />
<h2
id="this-diy-ereader-has-dual-e-ink-displays-for-a-more-book-like-reading-experience">This
DIY eReader has dual E Ink displays for a more book-like reading
experience</h2>
<p>date: 2025-08-11, from: Liliputing</p>
<p>
E Ink devices like the Amazon Kindle, Kobo, and B&amp;N Nook line of
products promise a book-like reading experience thanks to displays that
mimic some of the properties of ink on paper. But one big difference?
For the most part they’re about the size of a single page in a paperback
book. Pick up an […]
</p>
<p>
The post
<a href="https://liliputing.com/this-diy-ereader-has-dual-e-ink-displays-for-a-more-book-like-reading-experience/">This
DIY eReader has dual E Ink displays for a more book-like reading
experience</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/this-diy-ereader-has-dual-e-ink-displays-for-a-more-book-like-reading-experience/"
class="uri">https://liliputing.com/this-diy-ereader-has-dual-e-ink-displays-for-a-more-book-like-reading-experience/</a></p>
<hr />
<h2
id="voiceover-artists-weigh-the-faustian-bargain-of-lending-their-talents-to-ai">Voiceover
Artists Weigh the ‘Faustian Bargain’ of Lending Their Talents to AI</h2>
<p>date: 2025-08-11, from: 404 Media Group</p>
<p>The human voiceover artists behind AI voices are grappling with the
choice to embrace the gigs and earn a living, or pass on potentially
life-changing opportunities from Big Tech.</p>
<p><br></p>
<p><a
href="https://www.404media.co/voiceover-artists-ai-voice-acting-jobs-microsoft-openai-chatgpt/"
class="uri">https://www.404media.co/voiceover-artists-ai-voice-acting-jobs-microsoft-openai-chatgpt/</a></p>
<hr />
<h2
id="the-u.s.-army-is-testing-ai-controlled-ground-drones-near-a-border-with-russia">The
U.S. Army Is Testing AI Controlled Ground Drones Near a Border with
Russia</h2>
<p>date: 2025-08-11, from: 404 Media Group</p>
<p>The OverDrive is made to let ground vehicles navigate tough terrain
with minimal input from humans.</p>
<p><br></p>
<p><a
href="https://www.404media.co/the-u-s-army-is-testing-ai-controlled-ground-drones-near-a-border-with-russia/"
class="uri">https://www.404media.co/the-u-s-army-is-testing-ai-controlled-ground-drones-near-a-border-with-russia/</a></p>
<hr />
<h2 id="insignificant-figures">Insignificant Figures</h2>
<p>date: 2025-08-11, updated: 2025-08-11, from: One Foot Tsunami</p>
<p><br></p>
<p><a
href="https://onefoottsunami.com/2025/08/11/insignificant-figures/"
class="uri">https://onefoottsunami.com/2025/08/11/insignificant-figures/</a></p>
<hr />
<h2 id="did-the-old-robber-barons-get-a-bad-rap">Did the Old Robber
Barons Get a Bad Rap?</h2>
<p>date: 2025-08-11, from: Tina Brown</p>
<p>I’m gutted that the third season of Julian Fellowes’s The Gilded Age
on HBO ended last night.</p>
<p><br></p>
<p><a
href="https://tinabrown.substack.com/p/did-the-old-robber-barons-get-a-bad"
class="uri">https://tinabrown.substack.com/p/did-the-old-robber-barons-get-a-bad</a></p>
<hr />
<h2 id="the-political-economy-of-incompetence">The Political Economy of
Incompetence</h2>
<p>date: 2025-08-11, from: Paul Krugman</p>
<p>How Hannah Arendt predicted Stephen Moore</p>
<p><br></p>
<p><a
href="https://paulkrugman.substack.com/p/the-political-economy-of-incompetence"
class="uri">https://paulkrugman.substack.com/p/the-political-economy-of-incompetence</a></p>
<hr />
<h2 id="happy-maker-monday-show-us-your-raspberry-pi-builds">Happy Maker
Monday — show us your Raspberry Pi builds!</h2>
<p>date: 2025-08-11, from: Raspberry Pi News (.com)</p>
<p>
Another Maker Monday is upon us!
</p>
<p>
The post
<a href="https://www.raspberrypi.com/news/happy-maker-monday-show-us-your-raspberry-pi-builds/">Happy
Maker Monday — show us your Raspberry Pi builds!</a> appeared first on
<a href="https://www.raspberrypi.com">Raspberry Pi</a>.
</p>
<p><br></p>
<p><a
href="https://www.raspberrypi.com/news/happy-maker-monday-show-us-your-raspberry-pi-builds/"
class="uri">https://www.raspberrypi.com/news/happy-maker-monday-show-us-your-raspberry-pi-builds/</a></p>
<hr />
<h2 id="one-man-in-his-time-plays-many-parts">One man in his time plays
many parts…</h2>
<p>date: 2025-08-11, from: Status-Q blog</p>
<p>I did like this article: 27 Notes on Growing Old(er), by the author
Ian Leslie. Excerpt: Wisdom is meant to be the great compensation for
growing older. Though your your knees sound like they’re unlocking a
safe when you bend down, and you can’t straighten up without an “oof”,
you can at least revel in
<a class="more-link excerpt-link" href="https://statusq.org/archives/2025/08/11/13259/">Continue
Reading<span class="glyphicon glyphicon-chevron-right"></span></a></p>
<p><br></p>
<p><a href="https://statusq.org/archives/2025/08/11/13259/"
class="uri">https://statusq.org/archives/2025/08/11/13259/</a></p>
<hr />
<h2 id="qwen-image-mps">qwen-image-mps</h2>
<p>date: 2025-08-11, updated: 2025-08-11, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://github.com/ivanfioravanti/qwen-image-mps">qwen-image-mps</a></strong>
</p>
Ivan Fioravanti built this Python CLI script for running the
<a href="https://huggingface.co/Qwen/Qwen-Image">Qwen/Qwen-Image</a>
image generation model on an Apple silicon Mac, optionally using the
<a href="https://github.com/ModelTC/Qwen-Image-Lightning">Qwen-Image-Lightning</a>
LoRA to dramatically speed up generation.
</p>
<p>
Ivan has tested it this on 512GB and 128GB machines and it ran
<a href="https://x.com/ivanfioravanti/status/1954646355458269562">really
fast</a> - 42 seconds on his M3 Ultra. I’ve run it on my 64GB M2 MacBook
Pro - after quitting almost everything else - and it just about manages
to output images after pegging my GPU (fans whirring, keyboard heating
up) and occupying 60GB of my available RAM. With the LoRA option running
the script to generate an image took 9m7s on my machine.
</p>
<p>
Ivan merged
<a href="https://github.com/ivanfioravanti/qwen-image-mps/pull/3">my
PR</a> adding inline script dependencies for
<a href="https://github.com/astral-sh/uv">uv</a> which means you can now
run it like this:
</p>
<pre><code>uv run https://raw.githubusercontent.com/ivanfioravanti/qwen-image-mps/refs/heads/main/qwen-image-mps.py \
-p 'A vintage coffee shop full of raccoons, in a neon cyberpunk city' -f
</code></pre>
<p>
The first time I ran this it downloaded the 57.7GB model from Hugging
Face and stored it in my
<code>~/.cache/huggingface/hub/models–Qwen–Qwen-Image</code> directory.
The <code>-f</code> option fetched an extra 1.7GB
<code>Qwen-Image-Lightning-8steps-V1.0.safetensors</code> file to my
working directory that sped up the generation.
</p>
<p>
Here’s the resulting image:
</p>
<p>
<p><img alt="Digital artwork of a cyberpunk-style coffee shop populated entirely by raccoons as customers, with illegible neon signs visible in the windows, pendant lighting over the counter, menu boards on the wall, bottles on shelves behind the bar, and raccoons sitting at tables and the counter with coffee cups" src="https://static.simonwillison.net/static/2025/racoon-cyberpunk-coffee.jpg" /></p>
<pre><code>&lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href=&quot;https://x.com/ivanfioravanti/status/1954284146064576966&quot;&gt;@ivanfioravanti&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/macos&quot;&gt;macos&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/python&quot;&gt;python&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/uv&quot;&gt;uv&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/qwen&quot;&gt;qwen&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/text-to-image&quot;&gt;text-to-image&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai-in-china&quot;&gt;ai-in-china&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ivan-fioravanti&quot;&gt;ivan-fioravanti&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Aug/11/qwen-image-mps/#atom-everything"
class="uri">https://simonwillison.net/2025/Aug/11/qwen-image-mps/#atom-everything</a></p>
<hr />
<h2 id="ai-for-data-engineers-with-simon-willison">AI for data engineers
with Simon Willison</h2>
<p>date: 2025-08-11, updated: 2025-08-11, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://talkingpostgres.com/episodes/ai-for-data-engineers-with-simon-willison">AI
for data engineers with Simon Willison</a></strong>
</p>
I recorded an episode last week with Claire Giordano for the Talking
Postgres podcast. The topic was “AI for data engineers” but we ended up
covering an enjoyable range of different topics.
</p>
<ul>
<li>
How I got started programming with a Commodore 64 - the tape drive for
which inspired the name <a href="https://datasette.io/">Datasette</a>
</li>
<li>
Selfish motivations for
<a href="https://til.simonwillison.net/">TILs</a> (force me to write up
my notes) and open source (help me never have to solve the same problem
twice)
</li>
<li>
LLMs have been good at SQL for a couple of years now. Here’s how I used
them
<a href="https://simonwillison.net/2025/Apr/28/dashboard-alt-text/">for
a complex PostgreSQL query</a> that extracted alt text from my blog’s
images using regular expressions
</li>
<li>
Structured data extraction as the most economically valuable application
of LLMs for data work
</li>
<li>
2025 has been the year of tool calling a loop (“agentic” if you like)
</li>
<li>
Thoughts on running MCPs securely - read-only database access, think
about sandboxes, use PostgreSQL permissions, watch out for the
<a href="https://simonwillison.net/tags/lethal-trifecta/">lethal
trifecta</a>
</li>
<li>
Jargon guide: Agents, MCP, RAG, Tokens
</li>
<li>
How to get started learning to prompt: play with the models and “bring
AI to the table” even for tasks that you don’t think it can handle
</li>
<li>
“It’s always a good day if you see a pelican”
</li>
</ul>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/postgresql&quot;&gt;postgresql&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/podcast-appearances&quot;&gt;podcast-appearances&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Aug/11/ai-for-data-engineers/#atom-everything"
class="uri">https://simonwillison.net/2025/Aug/11/ai-for-data-engineers/#atom-everything</a></p>
<hr />
<h2 id="chromium-docs-the-rule-of-2">Chromium Docs: The Rule Of 2</h2>
<p>date: 2025-08-11, updated: 2025-08-11, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://chromium.googlesource.com/chromium/src/+/main/docs/security/rule-of-2.md">Chromium
Docs: The Rule Of 2</a></strong>
</p>
Alex Russell
<a href="https://toot.cafe/@slightlyoff/114999510361121718">pointed
me</a> to this principle in the Chromium security documentation as
similar to my description of
<a href="https://simonwillison.net/2025/Aug/9/bay-area-ai/">the lethal
trifecta</a>. First added
<a href="https://github.com/chromium/chromium/commit/aef94dd0e444605a16be26cba96aa477bc7fc3f5">in
2019</a>, the Chromium guideline states:
</p>
<blockquote>
<p>
When you write code to parse, evaluate, or otherwise handle
untrustworthy inputs from the Internet — which is almost everything we
do in a web browser! — we like to follow a simple rule to make sure it’s
safe enough to do so. The Rule Of 2 is: Pick no more than 2 of
</p>
<ul>
<li>
untrustworthy inputs;
</li>
<li>
unsafe implementation language; and
</li>
<li>
high privilege.
</li>
</ul>
<p>
<img alt="Venn diagram showing you should always use
a safe language, a sandbox, or not be processing untrustworthy inputs in the first
place." src="https://static.simonwillison.net/static/2025/rule-of-2.png" />
</p>
</blockquote>
<p>
Chromium uses this design pattern to help try to avoid the high severity
memory safety bugs that come when untrustworthy inputs are handled by
code running at high privilege.
</p>
<blockquote>
<p>
Chrome Security Team will generally not approve landing a CL or new
feature that involves all 3 of untrustworthy inputs, unsafe language,
and high privilege. To solve this problem, you need to get rid of at
least 1 of those 3 things.
</p>
</blockquote>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/alex-russell&quot;&gt;alex-russell&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/browsers&quot;&gt;browsers&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/chrome&quot;&gt;chrome&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/security&quot;&gt;security&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/lethal-trifecta&quot;&gt;lethal-trifecta&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Aug/11/the-rule-of-2/#atom-everything"
class="uri">https://simonwillison.net/2025/Aug/11/the-rule-of-2/#atom-everything</a></p>
<hr />
<h2 id="what-interviews-should-i-look-for">What Interviews Should I Look
For?</h2>
<p>date: 2025-08-11, from: Computer ads from the Past</p>
<p>Help point me in the right direction.</p>
<p><br></p>
<p><a
href="https://computeradsfromthepast.substack.com/p/what-interviews-should-i-look-for"
class="uri">https://computeradsfromthepast.substack.com/p/what-interviews-should-i-look-for</a></p>
<hr />
<h2
id="qwen3-4b-thinking-this-is-art---pelicans-dont-ride-bikes">Qwen3-4B-Thinking:
“This is art - pelicans don’t ride bikes!”</h2>
<p>date: 2025-08-10, updated: 2025-08-10, from: Simon Willison’s
Weblog</p>
<p>
I’ve fallen a few days behind keeping up with Qwen. They released two
new 4B models last week:
<a href="https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507">Qwen3-4B-Instruct-2507</a>
and its thinking equivalent
<a href="https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507">Qwen3-4B-Thinking-2507</a>.
</p>
<p>
These are relatively tiny models that punch <em>way</em> above their
weight. I’ve been running the 8bit GGUF varieties via LM Studio (here’s
<a href="https://huggingface.co/lmstudio-community/Qwen3-4B-Instruct-2507-GGUF">Instruct</a>,
here’s
<a href="https://huggingface.co/lmstudio-community/Qwen3-4B-Thinking-2507-GGUF">Thinking</a>)
- both of them are 4GB downloads that use around 4.3GB of my M2 MacBook
Pro’s system RAM while running. Both are way more capable than I would
expect from such small files.
</p>
<p>
Qwen3-4B-Thinking is the first model I’ve tried which called out the
absurdity of being asked to draw
<a href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">a
pelican riding a bicycle</a>!
</p>
<p>
Here’s
<a href="https://gist.github.com/simonw/cd41769de4791b98ba43a17c6ff32ee1">the
full transcript</a> - some highlights from the thinking trace:
</p>
<blockquote>
<p>
Okay, the user asked for an SVG of a pelican riding a bicycle. That’s…
oddly specific and completely unrealistic.
</p>
<p>
First reaction: Pelicans don’t ride bicycles. They’re birds that fly or
swim, not human-like vehicles. This feels like a mix-up - maybe they
meant “a cyclist” but typed “pelican”? Or perhaps it’s a joke?
</p>
<p>
Hmm, user might be:
</p>
<ul>
<li>
A kid playing with words (pelican + bicycle = silly combo)
</li>
<li>
Someone testing if I’ll generate impossible images
</li>
<li>
Actually wanting a pelican <em>on</em> a bike for art project? But that
still doesn’t make sense biologically
</li>
</ul>
<p>
<em>Checks SVG capabilities</em> SVG is for vector graphics, but this
request violates physics and biology. If I tried to draw it literally:
</p>
<ul>
<li>
Pelican would be too big for a bike frame
</li>
<li>
Bike wheels would be tiny compared to bird wings
</li>
<li>
No realistic way to show “riding” since pelicans don’t have legs for
pedaling
</li>
</ul>
<p>
[…]
</p>
<p>
<em>Self-check</em>: Am I being too pedantic? Nah - if someone asks for
impossible things, it’s better to gently correct than make fake art that
could confuse them. […]
</p>
<p>
I appreciate your creative request! 🦅🚴‍♂️ However, <strong>pelicans don’t
ride bicycles</strong> (they’re birds that fly/swim, not humans with
bike skills). Generating this as a literal SVG would be biologically
impossible and visually confusing.
</p>
</blockquote>
<p>
“This request violates physics and biology” - Qwen3-4B-Thinking saying
what no other model ever thought to express.
</p>
<p>
I also really enjoyed the “Am I being too pedantic? Nah” line. This
model is sassy!
</p>
<p>
It continued on to spit out two SVGS: the first titled “Most Likely: A
Human Cyclist” and the second “Artistic Interpretation: Pelican
<em>On</em> a Bicycle (For Fun!)”.
</p>
<p>
They were both terrible. Here’s the human one:
</p>
<p>
<img src="https://static.simonwillison.net/static/2025/qwen3-4b-thinking-human.png" alt="It's a green horizontal line, three abstract black shapes, a brown circle and the word Person" style="max-width: 100%;" />
</p>
<p>
And here’s the supposed pelican:
</p>
<p>
<img src="https://static.simonwillison.net/static/2025/qwen3-4b-thinking-pelican.png" alt="A blue circle, with a small black shape that might be a wing and a black shape that could maybe be the head? It's awful. Red text overlaps it that says This is art - pelicans don't ride bikes! - there is no attempt at a bicycle." style="max-width: 100%;" />
</p>
<p>
I like Qwen’s decision to include the clarifying annotation “This is art
- pelicans don’t ride bikes!”:
</p>
<p>
I tried the Qwen3-4B-Instruct non-thinking model too. It
<a href="https://gist.github.com/simonw/ad927a3849d0aece043afc97559be4bf">answered
much faster</a> (no time spent questioning my choice of task with its
thinking tokens) and gave me this:
</p>
<p>
<img src="https://static.simonwillison.net/static/2025/qwen3-4b-instruct-2507-pelican.png" alt="A bunch of shaps. Pelican Riding a Bike! transposed on top. The yellow and orange bits might be a pelican I guess. The bicycle has two wheels overlapping too close and a single bar in the wrong direction." style="max-width: 100%;" />
</p>
<p>
4B is such an interesting model size. These models should run on almost
anything and, at least on my M2 MacBook, they run <em>fast</em>. I’m
getting 50+ tokens per second and they’re using just less than 4.5GB of
RAM while running.
</p>
<p>
The question is always how useful such a tiny model can be. Clearly it’s
not great for SVG pelican illustrations!
</p>
<p>
I did get a useful result out of the <code>-Thinking</code> variant for
a <code>jq</code> expression I needed. I prompted:
</p>
<blockquote>
<p>
queries[0].rows is an array of objects each with a markdown key - write
a jq bash one liner to output a raw string if that markdown concatenated
together with double newlines between each
</p>
</blockquote>
<p>
It thought
<a href="https://gist.github.com/simonw/3f76749aa710f4a2d6405ebcf5b00ac4">for
3 minutes 13 seconds</a> before spitting out a recipe that did roughly
what I wanted:
</p>
<pre><code>jq -r '.queries[0].rows[] | .markdown' | tr '\n' '\n\n'</code></pre>
<p>
I’m not sure that was worth waiting three minutes for though!
</p>
<p>
These models have a 262,144 token context - wildly impressive, <em>if it
works</em>.
</p>
<p>
So I tried another experiment: I used the Instruct model to summarize
<a href="https://news.ycombinator.com/item?id=44851557">this Hacker News
conversation about GPT-5</a>.
</p>
<p>
I did this with the
<a href="https://github.com/agustif/llm-lmstudio">llm-lmstudio</a>
plugin for LLM combined with my
<a href="https://til.simonwillison.net/llms/claude-hacker-news-themes">hn-summary.sh
script</a>, which meant I could run the experiment like this:
</p>
<pre><code>hn-summary.sh 44851557 -m qwen3-4b-instruct-2507
</code></pre>
<p>
I believe this is 15,785 tokens - so nothing close to the 262,144
maximum but still an interesting test of a 4GB local model.
</p>
<p>
The good news is Qwen spat out a genuinely useful summary of the
conversation! You can
<a href="https://gist.github.com/simonw/4c5a1912f73e0d68b456b18000a76f0d#response">read
that here</a> - it’s the best I’ve seen yet from a model running on my
laptop, though honestly I’ve not tried many other recent models in this
way.
</p>
<p>
The bad news… it took almost five minutes to process and return the
result!
</p>
<p>
As a loose calculation, if the model can output 50 tokens/second maybe
there’s a similar speed for processing incoming input.. in which case
15785 / 50 = 315 seconds which is 5m15s.
</p>
<p>
Hosted models can crunch through 15,000 tokens of input in just a few
seconds. I guess this is one of the more material limitations of running
models on Apple silicon as opposed to dedicated GPUs.
</p>
<p>
I think I’m going to spend some more time with these models. They’re
fun, they have personality and I’m confident there are classes of useful
problems they will prove capable at despite their small size. Their
ability at summarization should make them a good fit for local RAG, and
I’ve not started exploring their tool calling abilities yet.
</p>
<pre><code>    &lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/local-llms&quot;&gt;local-llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/qwen&quot;&gt;qwen&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/pelican-riding-a-bicycle&quot;&gt;pelican-riding-a-bicycle&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llm-release&quot;&gt;llm-release&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/lm-studio&quot;&gt;lm-studio&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai-in-china&quot;&gt;ai-in-china&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Aug/10/qwen3-4b/#atom-everything"
class="uri">https://simonwillison.net/2025/Aug/10/qwen3-4b/#atom-everything</a></p>
<hr />
<h2 id="episode-162---csirac-australias-first-computer">Episode 162 -
CSIRAC, Australia’s First Computer</h2>
<p>date: 2025-08-10, from: Advent of Computing</p>
<p>
In 1949 CSIRAC sprung to life in a lab in Sydney, Australia. It was a
very early stored program computer. All machines of the era were unique.
But CSIRAC, well, it was <em>very</em> unique indeed.
</p>
<p>
Selected Sources:
</p>
<p>
 <a href= "https://cis.unimelb.edu.au/about/csirac/music/reconstruction" rel= "noopener noreferrer nofollow" data-link-auto= ""><u>https://cis.unimelb.edu.au/about/csirac/music/reconstruction</u></a>
- The Music of CSIRAC
</p>
<p>
<a href="https://sci-hub.se/10.1109/MAHC.1984.10014" rel= "noopener noreferrer nofollow" data-link-auto= "">https://sci-hub.se/10.1109/MAHC.1984.10014</a>
- Pearcy and Beard on CSIRAC
</p>
<audio crossorigin="anonymous" controls="controls">
<source type="audio/mpeg" src="https://traffic.libsyn.com/secure/adventofcomputing/ep162_csirac.mp3?dest-id=1206722">
</source>
</audio>
<p><a href="https://traffic.libsyn.com/secure/adventofcomputing/ep162_csirac.mp3?dest-id=1206722" target="_blank">download
audio/mpeg</a><br></p>
<p><a
href="https://adventofcomputing.libsyn.com/episode-162-csirac-australias-first-computer"
class="uri">https://adventofcomputing.libsyn.com/episode-162-csirac-australias-first-computer</a></p>
<hr />
<h2 id="quoting-sam-altman">Quoting Sam Altman</h2>
<p>date: 2025-08-10, updated: 2025-08-10, from: Simon Willison’s
Weblog</p>
<blockquote cite="https://x.com/sama/status/1954603417252532479">
<p>
the percentage of users using reasoning models each day is significantly
increasing; for example, for free users we went from &lt;1% to 7%, and
for plus users from 7% to 24%.
</p>
</blockquote>
<p class="cite">
— <a href="https://x.com/sama/status/1954603417252532479">Sam
Altman</a>, revealing quite how few people used the old model picker to
upgrade from GPT-4o
</p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/openai&quot;&gt;openai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llm-reasoning&quot;&gt;llm-reasoning&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/gpt-5&quot;&gt;gpt-5&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/sam-altman&quot;&gt;sam-altman&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/chatgpt&quot;&gt;chatgpt&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Aug/10/sam-altman/#atom-everything"
class="uri">https://simonwillison.net/2025/Aug/10/sam-altman/#atom-everything</a></p>
<hr />
<p><strong><span class="citation" data-cites="Robert">@Robert</span>’s
feed at BlueSky</strong> (date: 2025-08-10, from: Robert’s feed at
BlueSky)</p>
<p>Wrote up a short post on using Flat Lake, flatelake.app, and
Deno+TypeScript to generate RSS 2.0 feeds.
https://rsdoiel.github.io/blog/2025/08/10/generating_rss_with_flatlake.html
https://flatelake.app</p>
<p><br></p>
<p><a
href="https://bsky.app/profile/rsdoiel.bsky.social/post/3lw3cri7t5c2l"
class="uri">https://bsky.app/profile/rsdoiel.bsky.social/post/3lw3cri7t5c2l</a></p>
<hr />
<h2
id="lilbits-aol-frees-up-your-phone-line-by-ending-dial-up-access">Lilbits:
AOL frees up your phone line by ending dial-up access</h2>
<p>date: 2025-08-10, from: Liliputing</p>
<p>
AOL is ending dial-up access next month, 34 years after launching the
service that provided many Americans with their first (somewhat limited)
taste of the internet. The surprising news here is that it hadn’t
already happened… who uses dial-up or AOL in 2025? But it’s still an
interesting footnote in the history of the internet. Here’s […]
</p>
<p>
The post <a href="https://liliputing.com/lilbits-2/">Lilbits: AOL frees
up your phone line by ending dial-up access</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a href="https://liliputing.com/lilbits-2/"
class="uri">https://liliputing.com/lilbits-2/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Robert">@Robert</span>’s
feed at BlueSky</strong> (date: 2025-08-10, from: Robert’s feed at
BlueSky)</p>
<p>😆👇</p>
<p>[contains quote post or other embedded content]</p>
<p><br></p>
<p><a
href="https://bsky.app/profile/rsdoiel.bsky.social/post/3lw2nz5raws2q"
class="uri">https://bsky.app/profile/rsdoiel.bsky.social/post/3lw2nz5raws2q</a></p>
<hr />
<h2
id="debian-13-trixie-release-brings-risc-v-support-plus-to-the-popular-gnulinux-distro-plus-thousands-of-other-updates">Debian
13 “trixie” release brings RISC-V support plus to the popular GNU/Linux
distro, plus thousands of other updates</h2>
<p>date: 2025-08-10, from: Liliputing</p>
<p>
Debian is a free and open source, Linux-based operating system that’s
bee around for more than three decades. And computers have changed a lot
in that time. So while Debian has a reputation for releasing updates on
a slow, steady, and stable basis rather than pushing bleeding edge
features, the operating system has made some major changes […]
</p>
<p>
The post
<a href="https://liliputing.com/debian-13-trixie-release-brings-risc-v-support-plus-to-the-popular-gnu-linux-distro-plus-thousands-of-other-updates/">Debian
13 “trixie” release brings RISC-V support plus to the popular GNU/Linux
distro, plus thousands of other updates</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/debian-13-trixie-release-brings-risc-v-support-plus-to-the-popular-gnu-linux-distro-plus-thousands-of-other-updates/"
class="uri">https://liliputing.com/debian-13-trixie-release-brings-risc-v-support-plus-to-the-popular-gnu-linux-distro-plus-thousands-of-other-updates/</a></p>
<hr />
<h2 id="the-economics-of-smoot-hawley-2.0-part-ii">The Economics of
Smoot Hawley 2.0, Part II</h2>
<p>date: 2025-08-10, from: Paul Krugman</p>
<p>This trade war is really a class war</p>
<p><br></p>
<p><a
href="https://paulkrugman.substack.com/p/the-economics-of-smoot-hawley-20-cf7"
class="uri">https://paulkrugman.substack.com/p/the-economics-of-smoot-hawley-20-cf7</a></p>
<hr />
<h2 id="generating-rss-with-flatlake">Generating RSS with FlatLake</h2>
<p>date: 2025-08-10, from: Robert’s Ramblings</p>
<p>A show post describing a prototype in Deno+TypeScript for generating
RSS 2.0 feeds from a FlatLake generated JSON API.</p>
<p><br></p>
<p><a
href="https://rsdoiel.github.io/blog/2025/08/10/generating_rss_with_flatlake.html"
class="uri">https://rsdoiel.github.io/blog/2025/08/10/generating_rss_with_flatlake.html</a></p>
</section>
<footer>
Antenna is a personal aggregation of items found around the web.
Curated with <a href="https://rsdoiel.github.io/skimmer">skimmer</a> and <a href="https://sqlite.org">sqlite</a> then rendered with <a href="https://pandoc.org">Pandoc</a>.
</footer>
</body>
</html>
