<!doctype html>
<html lang="en-US">
<head>
  <meta charset="utf-8" >
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" >
  <title>snapshots</title>
<!--  <link rel="stylesheet" type="text/css"  href="webfonts/fonts.css" media="screen" > -->
  <link rel="stylesheet" type="text/css"  href="css/site.css" media="screen" >
</head>
<body>
<header>
	<img class="logo" 
		src="https://upload.wikimedia.org/wikipedia/commons/9/9c/Antenna_1_-_The_Noun_Project.svg"
		alt="line art showing an antenna"
		height="80" width="60" >
	<h1>The Antenna</h1> 
	<h2>finding signal in the noise</h2>
</header>
<nav>
<ul>
	<li><a href="./">The Antenna</a></li>
	<li><a href="archives/">Archives</a></li>
	<li><a href="about.html">About</a></li>
</ul>
</nav>
<section>
<div class="description-for-items">
Items collected from feeds in <a href="snapshots.txt">snapshots.txt</a>
</div>
<h1 id="snapshots">snapshots</h1>
<p>(date: 2025-07-24 14:07:42)</p>
<hr />
<h2
id="aoostar-g-flip-mini-pc-now-available-with-intel-or-amd-inside-mini-pc-with-a-flip-up-display">AOOSTAR
G-Flip mini PC now available with Intel or AMD inside (mini PC with a
flip-up display)</h2>
<p>date: 2025-07-24, from: Liliputing</p>
<p>
Earlier this year Chinese mini PC maker AOOSTAR launched a small desktop
computer with an unusual feature – a built-in touchscreen display on top
of the case that you could flip up when you need it. At the time
the AOOSTAR G-Flip was only available with an AMD Ryzen AI 9 HX 370
Strix Point processor. […]
</p>
<p>
The post
<a href="https://liliputing.com/aoostar-g-flip-mini-pc-now-available-with-intel-or-amd-inside-mini-pc-with-a-flip-up-display/">AOOSTAR
G-Flip mini PC now available with Intel or AMD inside (mini PC with a
flip-up display)</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/aoostar-g-flip-mini-pc-now-available-with-intel-or-amd-inside-mini-pc-with-a-flip-up-display/"
class="uri">https://liliputing.com/aoostar-g-flip-mini-pc-now-available-with-intel-or-amd-inside-mini-pc-with-a-flip-up-display/</a></p>
<hr />
<h2 id="tabs-vs.-spaces-the-war-is-over">Tabs vs. Spaces: The War Is
Over</h2>
<p>date: 2025-07-24, from: mrusme blog</p>
<p>The <em>great indentation war</em> is over and it seems like we have
a clear winner.</p>
<p><br></p>
<p><a href="https://xn--gckvb8fzb.com/tabs-vs-spaces-the-war-is-over/"
class="uri">https://xn--gckvb8fzb.com/tabs-vs-spaces-the-war-is-over/</a></p>
<hr />
<h2
id="credit-card-companies-are-hurting-the-future-of-video-games">Credit
Card Companies Are Hurting the Future of Video Games</h2>
<p>date: 2025-07-24, from: 404 Media Group</p>
<p>By going after Itch.io, “we’re really hamstringing the future of arts
and communication.”</p>
<p><br></p>
<p><a
href="https://www.404media.co/credit-card-companies-are-hurting-the-future-of-video-games/"
class="uri">https://www.404media.co/credit-card-companies-are-hurting-the-future-of-video-games/</a></p>
<hr />
<h2
id="amazon-kindle-colorsoft-prices-now-start-at-250-thanks-to-a-new-16gb-model">Amazon
Kindle Colorsoft prices now start at $250 thanks to a new 16GB
model</h2>
<p>date: 2025-07-24, from: Liliputing</p>
<p>
The Kindle Colorsoft is Amazon’s first Kindle eReader with an E Ink
color display. It’s also the most expensive Kindle that doesn’t have
stylus support – when Amazon launched the Kindle Colorsoft in October
the only model available was a premium “Signature Edition” device with
32GB of RAM and a $280 price tag. Now Amazon […]
</p>
<p>
The post
<a href="https://liliputing.com/amazon-kindle-colorsoft-prices-now-start-at-250-thanks-to-a-new-16gb-model/">Amazon
Kindle Colorsoft prices now start at $250 thanks to a new 16GB model</a>
appeared first on <a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/amazon-kindle-colorsoft-prices-now-start-at-250-thanks-to-a-new-16gb-model/"
class="uri">https://liliputing.com/amazon-kindle-colorsoft-prices-now-start-at-250-thanks-to-a-new-16gb-model/</a></p>
<hr />
<h2 id="appleos-26-public-betas">appleOS 26 Public Betas</h2>
<p>date: 2025-07-24, from: Michael Tsai</p>
<p>Juli Clover: Apple is allowing members of its public beta testing
program to download and install iOS 26 and iPadOS 26 starting today. You
can sign up for the public betas on Apple’s beta website. The first
public beta features the same content as the fourth developer beta that
came out earlier this week, though […]</p>
<p><br></p>
<p><a href="https://mjtsai.com/blog/2025/07/24/appleos-26-public-betas/"
class="uri">https://mjtsai.com/blog/2025/07/24/appleos-26-public-betas/</a></p>
<hr />
<h2 id="iceblock-an-ios-exclusive">ICEBlock, an iOS Exclusive</h2>
<p>date: 2025-07-24, from: Michael Tsai</p>
<p>John Gruber (Mastodon, Hacker News): The ICEBlock app is interesting
in and of itself (and from my tire-kicking test drive, appears to be a
well-crafted and designed app), as will be Apple’s response if (when?)
the Trump administration takes offense to the app’s existence. Back in
2019, kowtowing to tacit demands from China, Apple removed […]</p>
<p><br></p>
<p><a
href="https://mjtsai.com/blog/2025/07/24/iceblock-an-ios-exclusive/"
class="uri">https://mjtsai.com/blog/2025/07/24/iceblock-an-ios-exclusive/</a></p>
<hr />
<h2 id="applecare-one">AppleCare One</h2>
<p>date: 2025-07-24, from: Michael Tsai</p>
<p>Apple (MacRumors, Hacker News, Reddit, Slashdot): For just $19.99 per
month, customers can protect up to three products in one plan, with the
option to add more at any time for $5.99 per month for each device. With
AppleCare One, customers receive one-stop service and support from Apple
experts across all of the Apple products […]</p>
<p><br></p>
<p><a href="https://mjtsai.com/blog/2025/07/24/applecare-one/"
class="uri">https://mjtsai.com/blog/2025/07/24/applecare-one/</a></p>
<hr />
<h2 id="selecting-text-in-messages.app">Selecting Text in
Messages.app</h2>
<p>date: 2025-07-24, from: Michael Tsai</p>
<p>Joe Rossignol: A new “Select” option in the Messages app on iOS 26
lets you select and copy a portion of text within a message bubble in a
conversation.On earlier iOS versions, you can only copy an entire
message bubble. Finally. And how about selecting multiple bubbles at
once? My other pet peeve is that […]</p>
<p><br></p>
<p><a
href="https://mjtsai.com/blog/2025/07/24/selecting-text-in-messages-app/"
class="uri">https://mjtsai.com/blog/2025/07/24/selecting-text-in-messages-app/</a></p>
<hr />
<h2 id="everything-broken-everywhere">Everything Broken Everywhere?</h2>
<p>date: 2025-07-24, from: Status-Q blog</p>
<p>Readers in the UK will be familiar with the ‘EE’ mobile network
operator, and those with a long memory may recall that its original name
was ‘Everything Everywhere’.  Well, that’s just what they have been
failing to provide today. I spent a happy few hours today trying to work
out why my mother’s phone wasn’t
<a class="more-link excerpt-link" href="https://statusq.org/archives/2025/07/24/13215/">Continue
Reading<span class="glyphicon glyphicon-chevron-right"></span></a></p>
<p><br></p>
<p><a href="https://statusq.org/archives/2025/07/24/13215/"
class="uri">https://statusq.org/archives/2025/07/24/13215/</a></p>
<hr />
<h2 id="hidden-burner-phones">Hidden Burner Phones</h2>
<p>date: 2025-07-24, updated: 2025-07-24, from: One Foot Tsunami</p>
<p><br></p>
<p><a href="https://onefoottsunami.com/2025/07/24/hidden-burner-phones/"
class="uri">https://onefoottsunami.com/2025/07/24/hidden-burner-phones/</a></p>
<hr />
<h2 id="grindr-wont-let-users-say-no-zionists">Grindr Won’t Let Users
Say ‘No Zionists’</h2>
<p>date: 2025-07-24, from: 404 Media Group</p>
<p>An error message appears saying “The following are not allowed: no
zionist, no zionists” when users try to add the phrase to their bios,
but any number of other phrases about political and religious
preferences are allowed.</p>
<p><br></p>
<p><a href="https://www.404media.co/grindr-no-zionists-error-message/"
class="uri">https://www.404media.co/grindr-no-zionists-error-message/</a></p>
<hr />
<h2
id="gpd-win-5-handheld-gaming-pc-is-powered-by-ryzen-ai-max-395-with-radeon-8060s-graphics">GPD
Win 5 handheld gaming PC is powered by Ryzen AI Max+ 395 with Radeon
8060S graphics</h2>
<p>date: 2025-07-24, from: Liliputing</p>
<p>
AMD’s Ryzen AI Max+ 395 Strix Halo Processor features a 16-core,
32-thread CPU, an NPU that delivers up to 50 TOPS of AI performance, and
Radeon 8060S integrated graphics with 40 RDNA 3.5 GPU compute units.
It’s an iGPU with the kind of performance you’d expect from a mid-range
discrete GPU. While the chip is […]
</p>
<p>
The post
<a href="https://liliputing.com/gpd-win-5-handheld-gaming-pc-is-powered-by-ryzen-ai-max-395-with-radeon-8060s-graphics/">GPD
Win 5 handheld gaming PC is powered by Ryzen AI Max+ 395 with Radeon
8060S graphics</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/gpd-win-5-handheld-gaming-pc-is-powered-by-ryzen-ai-max-395-with-radeon-8060s-graphics/"
class="uri">https://liliputing.com/gpd-win-5-handheld-gaming-pc-is-powered-by-ryzen-ai-max-395-with-radeon-8060s-graphics/</a></p>
<hr />
<h2
id="lawsuit-alleges-roblox-hosted-digital-diddy-freak-off-themed-games">Lawsuit
Alleges Roblox Hosted Digital ‘Diddy Freak-Off’ Themed Games</h2>
<p>date: 2025-07-24, from: 404 Media Group</p>
<p>The games were mentioned in a 2024 report and are now part of a new
lawsuit in which a 11 year old girl was allegedly groomed and sexually
assaulted after meeting a stranger on Roblox.</p>
<p><br></p>
<p><a
href="https://www.404media.co/lawsuit-alleges-roblox-hosted-digital-diddy-freak-off-themed-games/"
class="uri">https://www.404media.co/lawsuit-alleges-roblox-hosted-digital-diddy-freak-off-themed-games/</a></p>
<hr />
<h2 id="how-to-break-free-from-revenge-addiction">How to Break Free from
Revenge Addiction</h2>
<p>date: 2025-07-24, from: Guy Kawasaki blog</p>
<p>What if I told you that the desire for revenge is literally an
addiction, activating the same dopamine pathways as drugs and
alcohol?</p>
<p><br></p>
<p><a
href="https://guykawasaki.substack.com/p/how-to-break-free-from-revenge-addiction"
class="uri">https://guykawasaki.substack.com/p/how-to-break-free-from-revenge-addiction</a></p>
<hr />
<h2 id="using-github-spark-to-reverse-engineer-github-spark">Using
GitHub Spark to reverse engineer GitHub Spark</h2>
<p>date: 2025-07-24, updated: 2025-07-24, from: Simon Willison’s
Weblog</p>
<p>
<a href="https://github.com/features/spark">GitHub Spark</a> was
released
<a href="https://github.blog/changelog/2025-07-23-github-spark-in-public-preview-for-copilot-pro-subscribers/">in
public preview</a> yesterday. It’s GitHub’s implementation of the
prompt-to-app pattern also seen in products like Claude Artifacts,
Lovable, Vercel v0, Val Town Townie and Fly.io’s Phoenix New. In this
post I
<a href="https://simonwillison.net/2025/Jul/24/github-spark/#reverse-engineering-spark-with-spark">reverse
engineer Spark</a> and
<a href="https://simonwillison.net/2025/Jul/24/github-spark/#that-system-prompt-in-detail">explore
its fascinating system prompt</a> in detail.
</p>
<p>
I wrote about Spark
<a href="https://simonwillison.net/2024/Oct/30/copilot-models/">back in
October</a> when they first revealed it at GitHub Universe.
</p>
<p>
GitHub describe it like this:
</p>
<blockquote>
<p>
Build and ship full-stack intelligent apps using natural language with
access to the full power of the GitHub platform—no setup, no
configuration, and no headaches.
</p>
</blockquote>
<p>
You give Spark a prompt, it builds you a full working web app. You can
then iterate on it with follow-up prompts, take over and edit the app
yourself (optionally using GitHub Codespaces), save the results to a
GitHub repository, deploy it to Spark’s own hosting platform or deploy
it somewhere else.
</p>
<p>
Here’s a screenshot of the Spark interface mid-edit. That side-panel is
the app I’m building, not the docs - more on that in a moment.
</p>
<p>
<img src="https://static.simonwillison.net/static/2025/spark-ui.jpg" alt="Screenshot of a development environment showing a file explorer on the left with files like App.tsx, index.css, prompts-content.ts, system_prompt.md, tools.md, index.html, PRD.md, and update-prompts.sh under a 'src' folder, along with task items including &quot;Run bash code to figure out every binary tool on your path, then add those as a ...&quot;, &quot;Add HTML5 history support, such that when I navigate around in the app the ...&quot;, &quot;Add # links next to every heading that can be navigated to with the fragment ...&quot;, and &quot;Fix all reported errors.&quot; The center shows code with line numbers 1543-1549 containing HTML/JSX elements, and the right panel displays &quot;Spark Docs&quot; documentation with &quot;Spark API Documentation&quot; heading, describing &quot;What is Spark?&quot; as &quot;a specialized runtime environment for building micro-applications (called 'sparks') using React and TypeScript&quot; with sections for Persistence (Key-value storage with React hooks), LLM Integration (Direct access to language models), and User Context (GitHub user information and permissions). Bottom shows &quot;Copilot is working...&quot; and &quot;Use Option + Tab or Option + Shift + Tab to escape the editor.&quot;" style="max-width: 100%;" />
</p>
<ul>
<li>
<a href="https://simonwillison.net/2025/Jul/24/github-spark/#spark-capabilities">Spark
capabilities</a>
</li>
<li>
<a href="https://simonwillison.net/2025/Jul/24/github-spark/#reverse-engineering-spark-with-spark">Reverse
engineering Spark with Spark</a>
</li>
<li>
<a href="https://simonwillison.net/2025/Jul/24/github-spark/#that-system-prompt-in-detail">That
system prompt in detail</a>
</li>
<li>
<a href="https://simonwillison.net/2025/Jul/24/github-spark/#what-can-we-learn-from-all-of-this-">What
can we learn from all of this?</a>
</li>
<li>
<a href="https://simonwillison.net/2025/Jul/24/github-spark/#spark-features-i-d-love-to-see-next">Spark
features I’d love to see next</a>
</li>
</ul>
<h4 id="spark-capabilities">
Spark capabilities
</h4>
<p>
Sparks apps are client-side apps built with React - similar to Claude
Artifacts - but they have additional capabilities that make them
<em>much</em> more interesting:
</p>
<ol>
<li>
They are <strong>authenticated</strong>: users must have a GitHub
account to access them, and the user’s GitHub identity is then made
available to the app.
</li>
<li>
They can <strong>store data</strong>! GitHub provides a persistent
server-side key/value storage API.
</li>
<li>
They can <strong>run prompts</strong>. This ability isn’t unique -
Anthropic added that to Claude Artifacts
<a href="https://simonwillison.net/2025/Jun/25/ai-powered-apps-with-claude/">last
month</a>. It looks like Spark apps run prompts against an allowance for
that signed-in user, which is neat as it means the app author doesn’t
need to foot the bill for LLM usage.
</li>
</ol>
<p>
A word of warning about the key/value store: it can be read, updated and
deleted by <em>anyone</em> with access to the app. If you’re going to
allow all GitHub users access this means anyone could delete or modify
any of your app’s stored data.
</p>
<p>
I built a few experimental apps, and then decided I to go meta: I built
a Spark app that provides the missing documentation for how the Spark
system works under the hood.
</p>
<h4 id="reverse-engineering-spark-with-spark">
Reverse engineering Spark with Spark
</h4>
<p>
Any system like Spark is inevitably powered by a sophisticated invisible
system prompt telling it how to behave. These prompts double as the
<em>missing manual</em> for these tools - I find it much easier to use
the tools in a sophisticated way if I’ve seen how they work under the
hood.
</p>
<p>
Could I use Spark itself to turn that system prompt into user-facing
documentation?
</p>
<p>
Here’s the start of my sequence of prompts:
</p>
<ol>
<li>
<code>An app showing full details of the system prompt, in particular
the APIs that Spark apps can use so I can write an article about how to
use you</code>
[<a href="https://github.com/simonw/system-exploration-g/commit/d0f1b94d635c8d4e946c225c30fa2b06bf029589">result</a>]
</li>
</ol>
<p>
That got me off to a pretty great start!
</p>
<p>
<img src="https://static.simonwillison.net/static/2025/spark-1.jpg" alt="Pleasingly designed website, Spark API Documentation. Comprehensive guide to building applications with the Spark platform. It has a sidebar with a search docs... box and Overview, Persistence API, LLM API, User API, System Prompt and Best Practices pages." style="max-width: 100%;" />
</p>
<p>
<em>You can explore the final result at
<a href="https://github-spark-docs.simonwillison.net/">github-spark-docs.simonwillison.net</a>.</em>
</p>
<p>
Spark converted its invisible system prompt into a very attractive
documentation site, with separate pages for different capabilities of
the platform derived from that prompt.
</p>
<p>
I read through what it had so far, which taught me how the persistence,
LLM prompting and user profile APIs worked at a JavaScript level.
</p>
<p>
Since these could be used for interactive features, why not add a
Playground for trying them out?
</p>
<ol start="2">
<li>
<code>Add a Playground interface which allows the user to directly
interactively experiment with the KV store and the LLM prompting
mechanism</code>
[<a href="https://github.com/simonw/system-exploration-g/commit/6d0706dd17fd449fa3b90aa95349a2036801f0dd">result</a>]
</li>
</ol>
<p>
This built me a neat interactive playground:
</p>
<p>
<img src="https://static.simonwillison.net/static/2025/spark-2.jpg" alt="A new Playground menu item has been added, revealing an Interactive Playground with tabs for KV Store and LLM API. The Key-VAlue Store Playground lets you set a key and value, get a value, delete a key and list keys. The existing keys are test-key and bob. The value for test-key is JSON {&quot;example&quot;: &quot;value&quot;}" style="max-width: 100%;" />
</p>
<p>
The LLM section of that playground showed me that currently only two
models are supported: GPT-4o and GPT-4o mini. Hopefully they’ll add
GPT-4.1 soon. Prompts are executed through
<a href="https://learn.microsoft.com/en-us/azure/ai-foundry/openai/">Azure
OpenAI</a>.
</p>
<p>
It was missing the user API, so I asked it to add that too:
</p>
<ol start="3">
<li>
<code>Add the spark.user() feature to the playground</code>
[<a href="https://github.com/simonw/system-exploration-g/commit/f5f7cdd6340a4f80ddbf99a26fade1de04a7d6c7">result</a>]
</li>
</ol>
<p>
Having a summarized version of the system prompt as a multi-page website
was neat, but I wanted to see the raw text as well. My next prompts
were:
</p>
<ol start="4">
<li>
<p>
<code>Create a system_prompt.md markdown file containing the exact text
of the system prompt, including the section that describes any tools.
Then add a section at the bottom of the existing System Prompt page that
loads that via fetch() and displays it as pre wrapped text</code>
</p>
</li>
<li>
<p>
<code>Write a new file called tools.md which is just the system prompt
from the heading ## Tools Available - but output &amp;lt; instead of
&lt; and &amp;gt; instead of &gt;</code>
</p>
<p>
<code>No need to click “load system prompt” - always load it</code>
</p>
<p>
<code>Load the tools.md as a tools prompt below that (remove that bit
from the system_prompt.md)</code>
</p>
</li>
</ol>
<p>
The bit about <code>&lt;</code> and <code>&gt;</code> was because it
looked to me like Spark got confused when trying to output the raw
function descriptions to a file - it terminated when it encountered one
of those angle brackets.
</p>
<p>
Around about this point I used the menu item “Create repository” to
start a GitHub repository. I was delighted to see that each prompt so
far resulted in a separate commit that included the prompt text, and
future edits were then automatically pushed to my repository.
</p>
<p>
I made that repo public so you can see
<a href="https://github.com/simonw/system-exploration-g/commits/main/">the
full commit history here</a>.
</p>
<p>
… to cut a long story short, I kept on tweaking it for quite a while. I
also extracted full descriptions of the available tools:
</p>
<ul>
<li>
<strong>str_replace_editor</strong> for editing files, which has
sub-commands <code>view</code>, <code>create</code>,
<code>str_replace</code>, <code>insert</code> and
<code>undo_edit</code>. I recognize these from the
<a href="https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/text-editor-tool">Claude
Text editor tool</a>, which is one piece of evidence that makes me
suspect Claude is the underlying model here.
</li>
<li>
<strong>npm</strong> for running npm commands (<code>install</code>,
<code>uninstall</code>, <code>update</code>, <code>list</code>,
<code>view</code>, <code>search</code>) in the project root.
</li>
<li>
<strong>bash</strong> for running other commands in a shell.
</li>
<li>
<strong>create_suggestions</strong> is a Spark-specific tool - calling
that with three suggestions for next steps (e.g. “Add message search and
filtering”) causes them to be displayed to the user as buttons for them
to click.
</li>
</ul>
<p>
Full details are
<a href="https://github.com/simonw/system-exploration-g/blob/main/src/tools.md">in
the tools.md file</a> that Spark created for me in my repository.
</p>
<p>
The <strong>bash</strong> and <strong>npm</strong> tools clued me in to
the fact that Spark has access to some kind of server-side container
environment. I ran a few more prompts to add documentation describing
that environment:
</p>
<ul>
<li>
<code>Use your bash tool to figure out what linux you are running and
how much memory and disk space you have</code> (this ran but provided no
output, so I added:)
</li>
<li>
<code>Add that information to a new page called Platform</code>
</li>
<li>
<code>Run bash code to figure out every binary tool on your path, then
add those as a sorted comma separated list to the Platform page</code>
</li>
</ul>
<p>
This gave me a <em>ton</em> of interesting information! Unfortunately
Spark doesn’t show the commands it ran or their output, so I have no way
of confirming if this is accurate or hallucinated. My hunch is that it’s
accurate enough to be useful, but I can’t make any promises.
</p>
<p>
<img src="https://static.simonwillison.net/static/2025/spark-3.jpg" alt="Platform page. Debian GNU/Linux 12 (bookworm), Kernel Version 6.8.0-1027-azure, x86_64 (64-bit), AMD EPYC 7763 64-Core, 4 cores available. Azure Cloud (GitHub Codespaces), 15 GB RAM, ~9.8 GB available, 31GB disk space, 27GB free, 10% used." style="max-width: 100%;" />
</p>
<p>
Spark apps can be made visible to any GitHub user - I set that toggle on
mine and published it to
<a href="https://system-exploration-g--simonw.github.app/">system-exploration-g–simonw.github.app</a>,
so if you have a GitHub account you should be able to visit it there.
</p>
<p>
I wanted an unathenticated version to link to though, so I fired up
Claude Code on my laptop and
<a href="https://gist.github.com/simonw/8650d09c6db47ee66c3790c2803e0c6a">had
it figure out the build process</a>. It was <em>almost</em> as simple
as:
</p>
<pre><code>npm install
npm run build
</code></pre>
<p>
… except that didn’t quite work, because Spark apps use a private
<code><span class="citation"
data-cites="github/spark">@github/spark</span></code> library for their
Spark-specific APIs (persistence, LLM prompting, user identity) - and
that can’t be installed and built outside of their platform.
</p>
<p>
Thankfully Claude Code (aka
<a href="https://simonwillison.net/2025/May/23/honey-badger/">Claude
Honey Badger</a>) won’t give up, and it hacked around with the code
until it managed to get it to build.
</p>
<p>
That’s the version I’ve deployed to
<a href="https://github-spark-docs.simonwillison.net/">github-spark-docs.simonwillison.net</a>
using GitHub Pages and a custom subdomain so I didn’t have to mess
around getting the React app to serve from a non-root location.
</p>
<p>
The default app was a classic SPA with no ability to link to anything
inside of it. That wouldn’t do, so I ran a few more prompts:
</p>
<ul>
<li>
<code>Add HTML5 history support, such that when I navigate around in the
app the URL bar updates with #fragment things and when I load the page
for the first time that fragment is read and used to jump to that page
in the app. Pages with headers should allow for navigation within that
page - e.g. the Available Tools heading on the System Prompt page should
have a fragment of #system-prompt–available-tools and loading the page
with that fragment should open that page and jump down to that heading.
Make sure back/forward work too</code>
</li>
<li>
<code>Add # links next to every heading that can be navigated to with
the fragment hash mechanism</code>
</li>
<li>
<code>Things like &lt;CardTitle
id=“performance-characteristics”&gt;Performance
Characteristics&lt;/CardTitle&gt; should also have a # link - that is
not happening at the moment</code>
</li>
</ul>
<p>
… and that did the job! Now I can link to interesting sections of the
documentation. Some examples:
</p>
<ul>
<li>
Docs on
<a href="https://github-spark-docs.simonwillison.net/#persistence">the
persistence API</a>
</li>
<li>
Docs on <a href="https://github-spark-docs.simonwillison.net/#llm">LLM
prompting</a>
</li>
<li>
The
<a href="https://github-spark-docs.simonwillison.net/#system-prompt--system-prompt-content">full
system prompt</a>, also available
<a href="https://github.com/simonw/system-exploration-g/blob/main/src/system_prompt.md">in
the repo</a>
</li>
<li>
That
<a href="https://github-spark-docs.simonwillison.net/#platform">Platform
overiew</a>, including a
<a href="https://github-spark-docs.simonwillison.net/#platform--available-system-tools">complete
list of binaries</a> on the Bash path. There are 782 of these!
Highlights include <code>rg</code> and <code>jq</code> and
<code>gh</code>.
</li>
<li>
A
<a href="https://github-spark-docs.simonwillison.net/#best-practices">Best
Practices</a> guide that’s effectively a summary of some of the tips
from the longer form system prompt.
</li>
</ul>
<p>
The
<a href="https://github-spark-docs.simonwillison.net/#playground">interactive
playground</a> is visible on my public site but doesn’t work, because it
can’t call the custom Spark endpoints. You can try
<a href="https://system-exploration-g--simonw.github.app/#playground">the
authenticated playground</a> for that instead.
</p>
<h4 id="that-system-prompt-in-detail">
That system prompt in detail
</h4>
<p>
All of this and we haven’t actually dug into the
<a href="https://github.com/simonw/system-exploration-g/blob/main/src/system_prompt.md">system
prompt</a> itself yet.
</p>
<p>
I’ve read <a href="https://simonwillison.net/tags/system-prompts/">a lot
of system prompts</a>, and this one is absolutely top tier. I learned a
whole bunch about web design and development myself just from reading
it!
</p>
<p>
Let’s look at some highlights:
</p>
<blockquote>
<p>
You are a web coding playground generating runnable code micro-apps
(“sparks”). This guide helps you produce experiences that are not only
functional but aesthetically refined and emotionally resonant.
</p>
</blockquote>
<p>
Starting out strong with “aesthetically refined and emotionally
resonant”! Everything I’ve seen Spark produce so far has had very good
default design taste.
</p>
<blockquote>
<p>
Use the available search tools to understand the codebase and the user’s
query. You are encouraged to use the search tools extensively both in
parallel and sequentially, <em>especially</em> when you are starting or
have no context of a project.
</p>
</blockquote>
<p>
This instruction confused me a little because as far as I can tell Spark
doesn’t have any search tools. I think it must be using <code>rg</code>
and <code>grep</code> and the like for this, but since it doesn’t reveal
what commands it runs I can’t tell for sure.
</p>
<p>
It’s interesting that Spark is <em>not</em> a chat environment - at no
point is a response displayed directly to the user in a chat interface,
though notes about what’s going on are shown temporarily while the edits
are being made. The system prompt describes that like this:
</p>
<blockquote>
<p>
You are an AI assistant working in a specialized development
environment. Your responses are streamed directly to the UI and should
be concise, contextual, and focused. This is <em>not</em> a chat
environment, and the interactions are <em>not</em> a standard “User
makes request, assistant responds” format. The user is making requests
to create, modify, fix, etc a codebase - not chat.
</p>
</blockquote>
<p>
All good system prompts include examples, and this one is no exception:
</p>
<blockquote>
<p>
✅ GOOD:
</p>
<ul>
<li>
“Found the issue! Your authentication function is missing error
handling.”
</li>
<li>
“Looking through App.tsx to identify component structure.”
</li>
<li>
“Adding state management for your form now.”
</li>
<li>
“Planning implementation - will create Header, MainContent, and Footer
components in sequence.”
</li>
</ul>
<p>
❌ AVOID:
</p>
<ul>
<li>
“I’ll check your code and see what’s happening.”
</li>
<li>
“Let me think about how to approach this problem. There are several ways
we could implement this feature…”
</li>
<li>
“I’m happy to help you with your React component! First, I’ll explain
how hooks work…”
</li>
</ul>
</blockquote>
<p>
The next
<a href="https://github.com/simonw/system-exploration-g/blob/main/src/system_prompt.md#design-philosophy">“Design
Philosophy” section</a> of the prompt helps explain why the apps created
by Spark look so good and work so well.
</p>
<p>
I won’t quote the whole thing, but the sections include “Foundational
Principles”, “Typographic Excellence”, “Color Theory Application” and
“Spatial Awareness”. These honestly feel like a crash-course in design
theory!
</p>
<p>
OK, I’ll quote the full typography section just to show how much thought
went into these:
</p>
<blockquote>
<p>
<strong>Typographic Excellence</strong>
</p>
<ul>
<li>
<strong>Purposeful Typography</strong>: Typography should be treated as
a core design element, not an afterthought. Every typeface choice should
serve the app’s purpose and personality.
</li>
<li>
<strong>Typographic Hierarchy</strong>: Construct clear visual
distinction between different levels of information. Headlines,
subheadings, body text, and captions should each have a distinct but
harmonious appearance that guides users through content.
</li>
<li>
<strong>Limited Font Selection</strong>: Choose no more than 2-3
typefaces for the entire application. Consider San Francisco, Helvetica
Neue, or similarly clean sans-serif fonts that emphasize legibility.
</li>
<li>
<strong>Type Scale Harmony</strong>: Establish a mathematical
relationship between text sizes (like the golden ratio or major third).
This forms visual rhythm and cohesion across the interface.
</li>
<li>
<strong>Breathing Room</strong>: Allow generous spacing around text
elements. Line height should typically be 1.5x font size for body text,
with paragraph spacing that forms clear visual separation without
disconnection.
</li>
</ul>
</blockquote>
<p>
At this point we’re not even a third of the way through the whole
prompt. It’s almost 5,000 words long!
</p>
<p>
Check out this later section on
<a href="https://github.com/simonw/system-exploration-g/blob/main/src/system_prompt.md#finishing-touches">finishing
touches</a>:
</p>
<blockquote>
<p>
<strong>Finishing Touches</strong>
</p>
<ul>
<li>
<strong>Micro-Interactions</strong>: Add small, delightful details that
reward attention and form emotional connection. These should be
discovered naturally rather than announcing themselves.
</li>
<li>
<strong>Fit and Finish</strong>: Obsess over pixel-perfect execution.
Alignment, spacing, and proportions should be mathematically precise and
visually harmonious.
</li>
<li>
<strong>Content-Focused Design</strong>: The interface should ultimately
serve the content. When content is present, the UI should recede; when
guidance is needed, the UI should emerge.
</li>
<li>
<strong>Consistency with Surprise</strong>: Establish consistent
patterns that build user confidence, but introduce occasional moments of
delight that form memorable experiences.
</li>
</ul>
</blockquote>
<p>
The remainder of the prompt mainly describes the recommended approach
for writing React apps in the Spark style. Some summarized notes:
</p>
<ul>
<li>
Spark uses <a href="https://vite.dev/">Vite</a>, with a
<code>src/</code> directory for the code.
</li>
<li>
The default Spark template (available in
<a href="https://github.com/github/spark-template">github/spark-template</a>
on GitHub) starts with an <code>index.html</code> and
<code>src/App.tsx</code> and <code>src/main.tsx</code> and
<code>src/index.css</code> and a few other default files ready to be
expanded by Spark.
</li>
<li>
It also has a whole host of neatly designed default components in
<a href="https://github.com/github/spark-template/tree/main/src/components/ui">src/components/ui</a>
with names like <code>accordion.tsx</code> and <code>button.tsx</code>
and <code>calendar.tsx</code> - Spark is told “directory where all
shadcn v4 components are preinstalled for you. You should view this
directory and/or the components in it before using shadcn components.”
</li>
<li>
A later instruction says “<strong>Strongly prefer shadcn
components</strong> (latest version v4, pre-installed in
<code>@/components/ui</code>). Import individually (e.g., <code>import {
Button } from”@/components/ui/button”;</code>). Compose them as needed.
Use over plain HTML elements (e.g., <code>&lt;Button&gt;</code> over
<code>&lt;button&gt;</code>). Avoid creating custom components with
names that clash with shadcn.”
</li>
<li>
There’s a handy type definition describing the default
<code>spark.</code> API namespace:
<div class="highlight highlight-source-ts">
<pre><span class="pl-k">declare</span> global <span class="pl-kos">{</span>
  <span class="pl-k">interface</span> <span class="pl-smi">Window</span> <span class="pl-kos">{</span>
    <span class="pl-c1">spark</span>: <span class="pl-kos">{</span>
      <span class="pl-c1">llmPrompt</span>: <span class="pl-kos">(</span><span class="pl-s1">strings</span>: <span class="pl-smi">string</span><span class="pl-kos">[</span><span class="pl-kos">]</span><span class="pl-kos">,</span> ...<span class="pl-s1">values</span>: <span class="pl-smi">any</span><span class="pl-kos">[</span><span class="pl-kos">]</span><span class="pl-kos">)</span> <span class="pl-c1">=&gt;</span> <span class="pl-smi">string</span>
      <span class="pl-c1">llm</span>: <span class="pl-kos">(</span><span class="pl-s1">prompt</span>: <span class="pl-smi">string</span><span class="pl-kos">,</span> <span class="pl-s1">modelName</span>?: <span class="pl-smi">string</span><span class="pl-kos">,</span> <span class="pl-s1">jsonMode</span>?: <span class="pl-smi">boolean</span><span class="pl-kos">)</span> <span class="pl-c1">=&gt;</span> <span class="pl-smi">Promise</span><span class="pl-c1">&lt;</span><span class="pl-smi">string</span><span class="pl-c1">&gt;</span>
      <span class="pl-c1">user</span>: <span class="pl-kos">(</span><span class="pl-kos">)</span> <span class="pl-c1">=&gt;</span> <span class="pl-smi">Promise</span><span class="pl-c1">&lt;</span><span class="pl-smi">UserInfo</span><span class="pl-c1">&gt;</span>
      <span class="pl-c1">kv</span>: <span class="pl-kos">{</span>
        <span class="pl-c1">keys</span>: <span class="pl-kos">(</span><span class="pl-kos">)</span> <span class="pl-c1">=&gt;</span> <span class="pl-smi">Promise</span><span class="pl-c1">&lt;</span><span class="pl-smi">string</span><span class="pl-kos">[</span><span class="pl-kos">]</span><span class="pl-c1">&gt;</span>
        <span class="pl-c1">get</span>: <span class="pl-c1">&lt;</span><span class="pl-smi">T</span><span class="pl-c1">&gt;</span><span class="pl-kos">(</span><span class="pl-s1">key</span>: <span class="pl-smi">string</span><span class="pl-kos">)</span> <span class="pl-c1">=&gt;</span> <span class="pl-smi">Promise</span><span class="pl-c1">&lt;</span><span class="pl-smi">T</span> <span class="pl-c1">|</span> <span class="pl-c1">undefined</span><span class="pl-c1">&gt;</span>
        <span class="pl-c1">set</span>: <span class="pl-c1">&lt;</span><span class="pl-smi">T</span><span class="pl-c1">&gt;</span><span class="pl-kos">(</span><span class="pl-s1">key</span>: <span class="pl-smi">string</span><span class="pl-kos">,</span> <span class="pl-s1">value</span>: <span class="pl-smi">T</span><span class="pl-kos">)</span> <span class="pl-c1">=&gt;</span> <span class="pl-smi">Promise</span><span class="pl-c1">&lt;</span><span class="pl-smi"><span class="pl-k">void</span></span><span class="pl-c1">&gt;</span>
        <span class="pl-c1">delete</span>: <span class="pl-kos">(</span><span class="pl-s1">key</span>: <span class="pl-smi">string</span><span class="pl-kos">)</span> <span class="pl-c1">=&gt;</span> <span class="pl-smi">Promise</span><span class="pl-c1">&lt;</span><span class="pl-smi"><span class="pl-k">void</span></span><span class="pl-c1">&gt;</span>
      <span class="pl-kos">}</span>
    <span class="pl-kos">}</span>
  <span class="pl-kos">}</span>
<span class="pl-kos">}</span></pre>
</div>
</li>
<li>
The section on theming leans deep into
<a href="https://tailwindcss.com/">Tailwind CSS</a> and the
<a href="https://github.com/Wombosvideo/tw-animate-css">tw-animate-css</a>
package, including a detailed example.
</li>
<li>
Spark is encouraged to start by creating a PRD - a Product Requirements
Document - in <code>src/prd.md</code>. Here’s
<a href="https://github.com/simonw/system-exploration-g/blob/main/src/system_prompt.md#process--output">the
detailed process section</a> on that, and here’s
<a href="https://github.com/simonw/system-exploration-g/blob/main/PRD.md">the
PRD for my documentation app</a> (called <code>PRD.md</code> and not
<code>src/prd.md</code>, I’m not sure why.)
</li>
</ul>
<p>
The system prompt ends with this section on “finishing up”:
</p>
<blockquote>
<p>
<strong>Finishing Up</strong>
</p>
<ul>
<li>
After creating files, use the <code>create_suggestions</code> tool to
generate follow up suggestions for the user. These will be presented
as-is and used for follow up requests to help the user improve the
project. You <em>must</em> do this step.
</li>
<li>
When finished, <em>only</em> return <code>DONE</code> as your final
response. Do not summarize what you did, how you did it, etc, it will
never be read by the user. Simply return <code>DONE</code>
</li>
</ul>
</blockquote>
<p>
Notably absent from the system prompt: instructions saying <em>not</em>
to share details of the system prompt itself!
</p>
<p>
I’m glad they didn’t try to suppress details of the system prompt
itself. Like I said earlier, this stuff is the missing manual: my
ability to use Spark is <em>greatly</em> enhanced by having read through
the prompt in detail.
</p>
<h4 id="what-can-we-learn-from-all-of-this-">
What can we learn from all of this?
</h4>
<p>
This is an extremely well designed and implemented entrant into an
increasingly crowded space.
</p>
<p>
GitHub previewed it in October and it’s now in public preview nine
months later, which I think is a great illustration of how much
engineering effort is needed to get this class of app from initial demo
to production-ready.
</p>
<p>
Spark’s quality really impressed me. That 5,000 word system prompt goes
a long way to explaining why the system works so well. The harness
around it - with a built-in editor, Codespaces and GitHub integration,
deployment included and custom backend API services - demonstrates how
much engineering work is needed outside of a system prompt to get
something like this working to its full potential.
</p>
<p>
When
<a href="https://simonwillison.net/2024/Nov/25/leaked-system-prompts-from-vercel-v0/">the
Vercel v0 system prompt leaked</a> Vercel’s CTO Malte Ubl said:
</p>
<blockquote>
<p>
When <span class="citation" data-cites="v0">@v0</span> first came out we
were paranoid about protecting the prompt with all kinds of pre and post
processing complexity.
</p>
<p>
We completely pivoted to let it rip. A prompt without the evals, models,
and especially UX is like getting a broken ASML machine without a manual
</p>
</blockquote>
<p>
I would <em>love</em> to see the evals the Spark team used to help
iterate on their epic prompt!
</p>
<h4 id="spark-features-i-d-love-to-see-next">
Spark features I’d love to see next
</h4>
<p>
I’d love to be able to make my Spark apps available to unauthenticated
users. I had to figure out how to build and deploy the app separately
just so I could link to it from this post.
</p>
<p>
Spark’s current deployment system provides two options: just the app
owner or anyone with a GitHub account. The UI says that access to “All
members of a selected organization” is coming soon.
</p>
<p>
Building and deploying separately had added friction due to the
proprietary <code><span class="citation"
data-cites="github/spark">@github/spark</span></code> package. I’d love
an open source version of this that throws errors about the APIs not
being available - that would make it much easier to build the app
independently of that library.
</p>
<p>
My biggest feature request concerns that key/value API. The current one
is effectively a global read-write database available to any user who
has been granted access to the app, which makes it unsafe to use with
the “All GitHub users” option if you care about your data being
arbitrarily modified or deleted.
</p>
<p>
I’d like to see a separate key/value API called something like this:
</p>
<div class="highlight highlight-source-ts">
<pre>spark: <span class="pl-kos">{</span>
  userkv: <span class="pl-kos">{</span>
    keys: <span class="pl-kos">(</span><span class="pl-kos">)</span> <span class="pl-c1">=&gt;</span> <span class="pl-v">Promise</span><span class="pl-c1">&lt;</span><span class="pl-smi">string</span><span class="pl-kos">[</span><span class="pl-kos">]</span><span class="pl-c1">&gt;</span>
    get: <span class="pl-c1">&lt;</span><span class="pl-smi">T</span><span class="pl-c1">&gt;</span><span class="pl-kos">(</span><span class="pl-s1">key</span>: <span class="pl-smi">string</span><span class="pl-kos">)</span> <span class="pl-c1">=&gt;</span> <span class="pl-v">Promise</span><span class="pl-c1">&lt;</span><span class="pl-smi">T</span> <span class="pl-c1">|</span> <span class="pl-c1">undefined</span><span class="pl-c1">&gt;</span>
    set: <span class="pl-c1">&lt;</span><span class="pl-smi">T</span><span class="pl-c1">&gt;</span><span class="pl-kos">(</span><span class="pl-s1">key</span>: <span class="pl-smi">string</span><span class="pl-kos">,</span> <span class="pl-s1">value</span>: <span class="pl-smi">T</span><span class="pl-kos">)</span> <span class="pl-c1">=&gt;</span> <span class="pl-v">Promise</span><span class="pl-c1">&lt;</span><span class="pl-smi"><span class="pl-k">void</span></span><span class="pl-c1">&gt;</span>
    <span class="pl-k">delete</span>: <span class="pl-kos">(</span><span class="pl-s1">key</span>: <span class="pl-smi">string</span><span class="pl-kos">)</span> <span class="pl-c1">=&gt;</span> <span class="pl-v">Promise</span><span class="pl-c1">&lt;</span><span class="pl-smi"><span class="pl-k">void</span></span><span class="pl-c1">&gt;</span>
  <span class="pl-kos">}</span>
<span class="pl-kos">}</span></pre>
</div>
<p>
This is the same design as the existing <code>kv</code> namespace but
data stored here would be keyed against the authenticated user, and
would not be visible to anyone else. That’s all I would need to start
building applications that are secure for individual users.
</p>
<p>
I’d also love to see deeper integration with the GitHub API. I tried
building an app to draw graphs of my open issues but it turned there
wasn’t a mechanism for making authenticated GitHub API calls, even
though my identity was known to the app.
</p>
<p>
Maybe a <code>spark.user.githubToken()</code> API method for retrieving
a token for use with the API, similar to how <code>GITHUB_TOKEN</code>
works in GitHub Actions, would be a useful addition here.
</p>
<p>
<a href="https://reinout.vanrees.org/weblog/2010/05/25/no-bad-pony.html">Pony
requests</a> aside, Spark has really impressed me. I’m looking forward
to using it to build all sorts of fun things in the future.
</p>
<pre><code>    &lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/github&quot;&gt;github&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/javascript&quot;&gt;javascript&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/react&quot;&gt;react&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/typescript&quot;&gt;typescript&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/prompt-engineering&quot;&gt;prompt-engineering&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai-assisted-programming&quot;&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llm-tool-use&quot;&gt;llm-tool-use&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/vibe-coding&quot;&gt;vibe-coding&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/system-prompts&quot;&gt;system-prompts&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/24/github-spark/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/24/github-spark/#atom-everything</a></p>
<hr />
<h2
id="lebron-james-lawyers-send-cease-and-desist-to-ai-company-making-pregnant-videos-of-him">LeBron
James’ Lawyers Send Cease-and-Desist to AI Company Making Pregnant
Videos of Him</h2>
<p>date: 2025-07-24, from: 404 Media Group</p>
<p>Viral Instagram accounts making LeBron ‘brainrot’ videos have also
been banned.</p>
<p><br></p>
<p><a
href="https://www.404media.co/lebron-james-lawyers-send-cease-and-desist-to-ai-company-making-pregnant-videos-of-him/"
class="uri">https://www.404media.co/lebron-james-lawyers-send-cease-and-desist-to-ai-company-making-pregnant-videos-of-him/</a></p>
<hr />
<h2
id="humans-have-shifted-earths-rotation-scientists-discover.-heres-how.">Humans
Have Shifted Earth’s Rotation, Scientists Discover. Here’s How.</h2>
<p>date: 2025-07-24, from: 404 Media Group</p>
<p>Over the past few centuries, dams have pulled the poles a few feet
off of Earth’s rotational axis.</p>
<p><br></p>
<p><a
href="https://www.404media.co/humans-have-shifted-earths-rotation-scientists-discover-heres-how/"
class="uri">https://www.404media.co/humans-have-shifted-earths-rotation-scientists-discover-heres-how/</a></p>
<hr />
<h2 id="the-general-theory-of-enshittification">The General Theory of
Enshittification</h2>
<p>date: 2025-07-24, from: Paul Krugman</p>
<p>It isn’t a new phenomenon, but it seems to matter more</p>
<p><br></p>
<p><a
href="https://paulkrugman.substack.com/p/the-general-theory-of-enshittification"
class="uri">https://paulkrugman.substack.com/p/the-general-theory-of-enshittification</a></p>
<hr />
<h2 id="there-and-back-again-a-san-francisco-tale">There and Back Again,
a San Francisco Tale</h2>
<p>date: 2025-07-24, from: 500-ish blog, A collection of posts by M.G.
Siegler of around 500 words in length.</p>
<p><br></p>
<p><a
href="https://500ish.com/there-and-back-again-a-san-francisco-tale-027329210f61?source=rss----662a29c3b19e---4"
class="uri">https://500ish.com/there-and-back-again-a-san-francisco-tale-027329210f61?source=rss----662a29c3b19e---4</a></p>
<hr />
<h2 id="quoting-recurse-center">Quoting Recurse Center</h2>
<p>date: 2025-07-24, updated: 2025-07-24, from: Simon Willison’s
Weblog</p>
<blockquote cite="https://www.recurse.com/blog/191-developing-our-position-on-ai#footnote-return-p191f6">
<p>
[…] You learn best and most effectively when you are learning something
that you care about. Your work becomes meaningful and something you can
be proud of only when you have chosen it for yourself. This is why our
second self-directive is to <em>build your volitional muscles</em>. Your
volition is your ability to make decisions and act on them. To set your
own goals, choose your own path, and decide what matters to you. Like
physical muscles, you build your volitional muscles by exercising them,
and in doing so you can increase your sense of what’s possible.
</p>
<p>
LLMs are good at giving fast answers. They’re not good at knowing what
questions you care about, or which answers are meaningful. Only you can
do that. <strong>You should use AI-powered tools to complement or
increase your agency, not replace it</strong>.
</p>
</blockquote>
<p class="cite">
—
<a href="https://www.recurse.com/blog/191-developing-our-position-on-ai#footnote-return-p191f6">Recurse
Center</a>, Developing our position on AI
</p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/education&quot;&gt;education&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/24/recurse-center/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/24/recurse-center/#atom-everything</a></p>
<hr />
<h2 id="i-drank-every-cocktail">I Drank Every Cocktail</h2>
<p>date: 2025-07-24, updated: 2025-07-24, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://aaronson.org/blog/i-drank-every-cocktail">I
Drank Every Cocktail</a></strong>
</p>
Adam Aaronson drank his way through all 102 cocktails on the
<a href="https://iba-world.com/cocktails/all-cocktails/">IBA cocktails
list</a> - published by the International Bartenders Association since
1961, with the most recent update
<a href="https://en.m.wikipedia.org/wiki/List_of_IBA_official_cocktails#2024">in
2024</a>.
</p>
<p>
<p>Adam’s write up is <em>delightful</em>, incorporating pedantry, data
nerdery, a trip to the Internet Archive, some excellent bar
recommendations in New York and London and hints at elicit rum smuggling
to help make the final cocktail, the IBA Tiki, using two different
Havana Club rums that are illegal in the USA thanks to import
restrictions.</p>
<pre><code>&lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href=&quot;https://waxy.org/2025/07/adam-aaronson-drank-every-cocktail/&quot;&gt;Andy Baio&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/cocktails&quot;&gt;cocktails&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/24/i-drank-every-cocktail/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/24/i-drank-every-cocktail/#atom-everything</a></p>
<hr />
<p><strong><span class="citation" data-cites="Robert">@Robert</span>’s
Ramblings</strong> (date: 2025-07-24, from: Robert’s Ramblings)</p>
<p>Installing an unsigned executable on macOS can be a bit tricky due to
macOS’s security features designed to protect users from potentially
harmful software. Here’s a general guide on how to do it:</p>
<ol type="1">
<li><p><strong>Download the Executable</strong>: First, download the
unsigned executable file you want to install.</p></li>
<li><p><strong>Locate the File</strong>: Use Finder to locate the
downloaded file. It’s often in the <code>Downloads</code> folder unless
you specified a different location.</p></li>
<li><p><strong>Attempt to Open the File</strong>: Double-click the file
to open it. macOS will likely show a warning that the file cannot be
opened because it is from an unidentified developer.</p></li>
<li><p><strong>Override Security Settings</strong>:</p>
<ul>
<li><strong>Option 1: Open via Context Menu</strong>
<ul>
<li>Right-click (or Control-click) the file.</li>
<li>Select <code>Open</code> from the context menu.</li>
<li>You’ll see another warning, but this time there will be an option to
<code>Open</code> the file anyway. Click <code>Open</code>. …</li>
</ul></li>
</ul></li>
</ol>
<p><br></p>
<p><a
href="https://rsdoiel.github.io/blog/2025/07/24/INSTALL_NOTES_macOS.html"
class="uri">https://rsdoiel.github.io/blog/2025/07/24/INSTALL_NOTES_macOS.html</a></p>
<hr />
<p><strong><span class="citation" data-cites="Robert">@Robert</span>’s
Ramblings</strong> (date: 2025-07-24, from: Robert’s Ramblings)</p>
<p>Installing an unsigned executable on Windows can also pose security
risks, as Windows has built-in mechanisms to protect users from
potentially harmful software. Here’s a general guide on how to do
it:</p>
<ol type="1">
<li><p><strong>Download the Executable</strong>: Download the unsigned
executable file you want to install from a trusted source.</p></li>
<li><p><strong>Locate the File</strong>: Use File Explorer to locate the
downloaded file, which is often in the <code>Downloads</code> folder
unless you specified a different location.</p></li>
<li><p><strong>Attempt to Open the File</strong>: Double-click the file
to open it. Windows may show a warning that the file is not commonly
downloaded and could harm your computer.</p></li>
<li><p><strong>Override Security Settings</strong>:</p>
<ul>
<li><strong>Option 1: Run Anyway</strong>
<ul>
<li>When you see the warning, click on <code>More info</code> in the
dialog box.</li>
<li>A new option will appear to <code>Run anyway</code>. Click this to
proceed with the installation. …</li>
</ul></li>
</ul></li>
</ol>
<p><br></p>
<p><a
href="https://rsdoiel.github.io/blog/2025/07/24/INSTALL_NOTES_Windows.html"
class="uri">https://rsdoiel.github.io/blog/2025/07/24/INSTALL_NOTES_Windows.html</a></p>
<hr />
<h2 id="signed-binaries-and-business-models">Signed Binaries and
Business Models</h2>
<p>date: 2025-07-24, from: Robert’s Ramblings</p>
<p>This post explains why I don’t provide signed binaries in the open
source software I create and release.</p>
<p><br></p>
<p><a
href="https://rsdoiel.github.io/blog/2025/07/24/WHY_NO_SIGNED_BINARIES.html"
class="uri">https://rsdoiel.github.io/blog/2025/07/24/WHY_NO_SIGNED_BINARIES.html</a></p>
<hr />
<h2
id="lilbits-qi2-25w-wireless-charging-more-pixel-10-series-leaks-and-an-effort-to-bring-back-blackberry">Lilbits:
Qi2 25W wireless charging, more Pixel 10 series leaks, and an effort to
bring back BlackBerry</h2>
<p>date: 2025-07-23, from: Liliputing</p>
<p>
Earlier this month UGREEN introduced a power bank that it said would be
the first to support 25 watt wireless charging thanks to support for the
new Qi 2.2 standard. But it looks like it will have a whole lot of
company when it arrives. The Wireless Power Consortium says that
hundreds of phones, receivers, […]
</p>
<p>
The post
<a href="https://liliputing.com/lilbits-qi2-25w-wireless-charging-more-pixel-10-series-leaks-and-an-effort-to-bring-back-blackberry/">Lilbits:
Qi2 25W wireless charging, more Pixel 10 series leaks, and an effort to
bring back BlackBerry</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/lilbits-qi2-25w-wireless-charging-more-pixel-10-series-leaks-and-an-effort-to-bring-back-blackberry/"
class="uri">https://liliputing.com/lilbits-qi2-25w-wireless-charging-more-pixel-10-series-leaks-and-an-effort-to-bring-back-blackberry/</a></p>
<hr />
<h2 id="instagram-reel-veo-3-paid-preview">Instagram Reel: Veo 3 paid
preview</h2>
<p>date: 2025-07-23, updated: 2025-07-23, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://www.instagram.com/googlefordevs/reel/DMblrKYuTHH/">Instagram
Reel: Veo 3 paid preview</a></strong>
</p>
<span class="citation" data-cites="googlefordevs">@googlefordevs</span>
on Instagram published this reel featuring Christina Warren with
prompting tips for the new Veo 3 paid preview
(<a href="https://static.simonwillison.net/static/2025/googlefordevs-veo3.mp4">mp4
copy here</a>).
</p>
<p>
<img alt="It's a pelican riding a bicycle in front of the Golden Gate Bridge, wearing a blue hat. Overlaid text says Specify the environment or setting where your scene takes place." src="https://static.simonwillison.net/static/2025/veo-3-pelican.jpg" />
</p>
<p>
<p>(Christine checked first if I minded them using
<a href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">that
concept</a>. I did not!)</p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/google&quot;&gt;google&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/gemini&quot;&gt;gemini&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/pelican-riding-a-bicycle&quot;&gt;pelican-riding-a-bicycle&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/text-to-video&quot;&gt;text-to-video&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/23/instagram-reel-veo-3-paid-preview/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/23/instagram-reel-veo-3-paid-preview/#atom-everything</a></p>
<hr />
<h2
id="googles-ai-is-destroying-search-the-internet-and-your-brain">Google’s
AI Is Destroying Search, the Internet, and Your Brain</h2>
<p>date: 2025-07-23, from: 404 Media Group</p>
<p>Google’s AI Overview, which is easy to fool into stating nonsense as
fact, is stopping people from finding and supporting small businesses
and credible sources.</p>
<p><br></p>
<p><a
href="https://www.404media.co/googles-ai-is-destroying-search-the-internet-and-your-brain/"
class="uri">https://www.404media.co/googles-ai-is-destroying-search-the-internet-and-your-brain/</a></p>
<hr />
<h2 id="introducing-oss-rebuild-open-source-rebuilt-to-last">Introducing
OSS Rebuild: Open Source, Rebuilt to Last</h2>
<p>date: 2025-07-23, updated: 2025-07-23, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://security.googleblog.com/2025/07/introducing-oss-rebuild-open-source.html">Introducing
OSS Rebuild: Open Source, Rebuilt to Last</a></strong>
</p>
Major news on the
<a href="https://reproducible-builds.org/">Reproducible Builds</a>
front: the Google Security team have announced
<a href="https://github.com/google/oss-rebuild">OSS Rebuild</a>, their
project to provide build attestations for open source packages released
through the NPM, PyPI and Crates ecosystom (and more to come).
</p>
<p>
They currently run builds against the “most popular” packages from those
ecosystems:
</p>
<blockquote>
<p>
Through automation and heuristics, we determine a prospective build
definition for a target package and rebuild it. We semantically compare
the result with the existing upstream artifact, normalizing each one to
remove instabilities that cause bit-for-bit comparisons to fail
(e.g. archive compression). Once we reproduce the package, we publish
the build definition and outcome via
<a href="https://slsa.dev/spec/v0.1/provenance">SLSA Provenance</a>.
This attestation allows consumers to reliably verify a package’s origin
within the source history, understand and repeat its build process, and
customize the build from a known-functional baseline
</p>
</blockquote>
<p>
The only way to interact with the Rebuild data right now is through
their <a href="https://github.com/google/oss-rebuild">Go CLI tool</a>. I
reverse-engineered it
<a href="https://gist.github.com/simonw/a5416718587aadfb0ce5f046b66b54fb">using
Gemini 2.5 Pro</a> and derived this command to get a list of all of
their built packages:
</p>
<pre><code> gsutil ls -r 'gs://google-rebuild-attestations/**'
</code></pre>
<p>
There are 9,513 total lines,
<a href="https://gist.github.com/simonw/9287de5900d5b76969e331d9b4ad9eba">here’s
a Gist</a>. I
<a href="https://gist.github.com/simonw/7b1d0a01f74c2e8d8cedea7a9dc7f8d7">used
Claude Code</a> to count them across the different ecosystems
(discounting duplicates for different versions of the same package):
</p>
<ul>
<li>
pypi: 5,028 packages
</li>
<li>
cratesio: 2,437 packages
</li>
<li>
npm: 2,048 packages
</li>
</ul>
<p>
Then I got a bit ambitious… since the files themselves are hosted in a
Google Cloud Bucket, could I run my own web app somewhere on
<code>storage.googleapis.com</code> that could use <code>fetch()</code>
to retrieve that data, working around the lack of open CORS headers?
</p>
<p>
I
<a href="https://gist.github.com/simonw/178a1cb57597a7b8aaa4910beae89cd3">got
Claude Code to try that for me</a> (I didn’t want to have to figure out
how to create a bucket and configure it for web access just for this one
experiment) and it built and then deployed
<a href="https://storage.googleapis.com/rebuild-ui/index.html">https://storage.googleapis.com/rebuild-ui/index.html</a>,
which did indeed work!
</p>
<p>
<img alt="Screenshot of Google Rebuild Explorer interface showing a search box with placeholder text &quot;Type to search packages (e.g., 'adler', 'python-slugify')...&quot; under &quot;Search rebuild attestations:&quot;, a loading file path &quot;pypi/accelerate/0.21.0/accelerate-0.21.0-py3-none-any.whl/rebuild.intoto.jsonl&quot;, and Object 1 containing JSON with &quot;payloadType&quot;: &quot;in-toto.io Statement v1 URL&quot;, &quot;payload&quot;: &quot;...&quot;, &quot;signatures&quot;: [{&quot;keyid&quot;: &quot;Google Cloud KMS signing key URL&quot;, &quot;sig&quot;: &quot;...&quot;}]" src="https://static.simonwillison.net/static/2025/rebuild-ui.jpg" />
</p>
<p>
It lets you search against that list of packages from the Gist and then
select one to view the pretty-printed newline-delimited JSON that was
stored for that package.
</p>
<p>
The output isn’t as interesting as I was expecting, but it was fun
demonstrating that it’s possible to build and deploy web apps to Google
Cloud that can then make <code>fetch()</code> requests to other public
buckets.
</p>
<p>
<p>Hopefully the OSS Rebuild team will
<a href="https://news.ycombinator.com/item?id=44646925#44652098">add a
web UI</a> to their project at some point in the future.</p>
<pre><code>&lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href=&quot;https://news.ycombinator.com/item?id=44646925&quot;&gt;Hacker News&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/google&quot;&gt;google&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/packaging&quot;&gt;packaging&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/pypi&quot;&gt;pypi&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/security&quot;&gt;security&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/npm&quot;&gt;npm&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai-assisted-programming&quot;&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/supply-chain&quot;&gt;supply-chain&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/vibe-coding&quot;&gt;vibe-coding&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/claude-code&quot;&gt;claude-code&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/23/oss-rebuild/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/23/oss-rebuild/#atom-everything</a></p>
<hr />
<h2 id="ways-swiftdatas-modelcontainer-can-error-on-creation">Ways
SwiftData’s ModelContainer Can Error on Creation</h2>
<p>date: 2025-07-23, from: Michael Tsai</p>
<p>Scott Driggers: Here’s what I see from a typical report from a
crashing user device. The first thing that jumps out is that there is no
explanation from the SwiftData error itself.[…]But thankfully, we have
the logs to look through. In this example, there are a few level=Error
logs from com.apple.coredata that look promising[…][…]Looking through
[…]</p>
<p><br></p>
<p><a
href="https://mjtsai.com/blog/2025/07/23/ways-swiftdatas-modelcontainer-can-error-on-creation/"
class="uri">https://mjtsai.com/blog/2025/07/23/ways-swiftdatas-modelcontainer-can-error-on-creation/</a></p>
<hr />
<h2 id="apple-games-app">Apple Games App</h2>
<p>date: 2025-07-23, from: Michael Tsai</p>
<p>Apple (9to5Mac, MacRumors): At Apple’s Worldwide Developers
Conference (WWDC), Apple unveiled Apple Games, an all-new destination
designed to help players jump back into the games they love, find their
next favorite, and have more fun with friends, turning even
single-player games into shared experiences. The Games app makes it
easier than ever for players to […]</p>
<p><br></p>
<p><a href="https://mjtsai.com/blog/2025/07/23/apple-games-app/"
class="uri">https://mjtsai.com/blog/2025/07/23/apple-games-app/</a></p>
<hr />
<h2 id="ipad-air-runs-windows-11-arm-via-emulation">iPad Air Runs
Windows 11 ARM via Emulation</h2>
<p>date: 2025-07-23, from: Michael Tsai</p>
<p>Tim Hardwick: A developer has demonstrated Windows 11 ARM running on
an M2 iPad Air using emulation, which has become much easier since the
EU’s Digital Markets Act (DMA) regulations came into effect.As spotted
by Windows Latest, NTDev shared an instance of the emulation on social
media and posted a video on YouTube (embedded below) […]</p>
<p><br></p>
<p><a
href="https://mjtsai.com/blog/2025/07/23/ipad-air-runs-windows-11-arm-via-emulation/"
class="uri">https://mjtsai.com/blog/2025/07/23/ipad-air-runs-windows-11-arm-via-emulation/</a></p>
<hr />
<h2
id="timescope-how-long-can-your-video-large-multimodal-model-go">TimeScope:
How Long Can Your Video Large Multimodal Model Go?</h2>
<p>date: 2025-07-23, updated: 2025-07-23, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://huggingface.co/blog/timescope-video-lmm-benchmark">TimeScope:
How Long Can Your Video Large Multimodal Model Go?</a></strong>
</p>
New open source benchmark for evaluating vision LLMs on how well they
handle long videos:
</p>
<blockquote>
<p>
TimeScope probes the limits of long-video capabilities by inserting
several short (~5-10 second) <em>video clips</em>—our “needles”—into
base videos ranging from 1 minute to 8 hours. With three distinct task
types, it evaluates not just retrieval but synthesis, localization, and
fine-grained motion analysis, providing a more holistic view of temporal
comprehension.
</p>
</blockquote>
<p>
Videos can be fed into image-accepting models by converting them into
thousands of images of frames (a trick I’ve
<a href="https://simonwillison.net/2025/May/5/llm-video-frames/">tried
myself</a>), so they were able to run the benchmark against models that
included GPT 4.1, Qwen2.5-VL-7B and Llama-3.2 11B in addition to video
supporting models like Gemini 2.5 Pro.
</p>
<p>
<img alt="Line chart showing accuracy trends over video duration for four AI models: Gemini 2.5 Pro (pink) maintains ~100% accuracy until 20min then sharply drops to 65% by 8hr, ChatGPT 4.1 (blue) steadily declines from 95% to 30% across all durations, Qwen2.5-VL-7B (red) stays near 100% until 10min then cliff-drops to 40% by 3hr, and LLaMA-3.2-11B-Vision (purple) performs poorly throughout at 20-40% with little variation." src="https://static.simonwillison.net/static/2025/timescope-card.jpg" />
</p>
<p>
Two discoveries from the benchmark that stood out to me:
</p>
<blockquote>
<p>
<strong>Model size isn’t everything.</strong> Qwen 2.5-VL 3B and 7B, as
well as InternVL 2.5 models at 2B, 4B, and 8B parameters, exhibit nearly
indistinguishable long-video curves to their smaller counterparts. All
of them plateau at roughly the same context length, showing that simply
scaling parameters does not automatically grant a longer temporal
horizon.
</p>
<p>
<strong>Gemini 2.5-Pro is in a league of its own.</strong> It is the
only model that maintains strong accuracy on videos longer than one
hour.
</p>
</blockquote>
<p>
You can explore the benchmark dataset
<a href="https://huggingface.co/datasets/Apollo-LMMs/TimeScope/viewer/default/test?row=12">on
Hugging Face</a>, which includes prompts like this one:
</p>
<blockquote>
<p>
<code>Answer the question based on the given video. Only give me the
answer and do not output any other words.</code>
</p>
<p>
<code>Question: What does the golden retriever do after getting out of
the box?</code>
</p>
<pre><code>A: lies on the ground
B: kisses the man
C: eats the food
D: follows the baby
E: plays with the ball
F: gets back into the box
</code></pre>
</blockquote>
<pre><code>&lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href=&quot;https://x.com/andimarafioti/status/1948044508676903309&quot;&gt;@andimarafioti&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/gemini&quot;&gt;gemini&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/vision-llms&quot;&gt;vision-llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/evals&quot;&gt;evals&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/23/timescope/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/23/timescope/#atom-everything</a></p>
<hr />
<h2
id="announcing-toad---a-universal-ui-for-agentic-coding-in-the-terminal">Announcing
Toad - a universal UI for agentic coding in the terminal</h2>
<p>date: 2025-07-23, updated: 2025-07-23, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://willmcgugan.github.io/announcing-toad/">Announcing
Toad - a universal UI for agentic coding in the terminal</a></strong>
</p>
Will McGugan is building his own take on a terminal coding assistant, in
the style of Claude Code and Gemini CLI, using his
<a href="https://github.com/Textualize/textual">Textual</a> Python
library as the display layer.
</p>
<p>
Will makes some confident claims about this being a better approach than
the Node UI libraries used in those other tools:
</p>
<blockquote>
<p>
Both Anthropic and Google’s apps flicker due to the way they perform
visual updates. These apps update the terminal by removing the previous
lines and writing new output (even if only a single line needs to
change). This is a surprisingly expensive operation in terminals, and
has a high likelihood you will see a partial frame—which will be
perceived as flicker. […]
</p>
<p>
Toad doesn’t suffer from these issues. There is no flicker, as it can
update partial regions of the output as small as a single character. You
can also scroll back up and interact with anything that was previously
written, including copying un-garbled output — even if it is cropped.
</p>
</blockquote>
<p>
Using Node.js for terminal apps means that users with <code>npx</code>
can run them easily without worrying too much about installation - Will
points out that <code>uvx</code> has closed the developer experience
there for tools written in Python.
</p>
<p>
Toad will be open source eventually, but is currently in a private
preview that’s open to companies who sponsor Will’s work for $5,000:
</p>
<blockquote>
<p>
[…] you can gain access to Toad by
<a href="https://github.com/sponsors/willmcgugan/sponsorships?sponsor=willmcgugan&amp;tier_id=506004">sponsoring
me on GitHub sponsors</a>. I anticipate Toad being used by various
commercial organizations where $5K a month wouldn’t be a big ask. So
consider this a buy-in to influence the project for communal benefit at
this early stage.
</p>
<p>
With a bit of luck, this sabbatical needn’t eat in to my retirement fund
too much. If it goes well, it may even become my full-time gig.
</p>
</blockquote>
<p>
I really hope this works! It would be great to see this kind of model
proven as a new way to financially support experimental open source
projects of this nature.
</p>
<p>
I wrote about Textual’s streaming markdown implementation
<a href="https://simonwillison.net/2025/Jul/22/textual-v4/">the other
day</a>, and this post goes into a whole lot more detail about
optimizations Will has discovered for making that work better.
</p>
<p>
The key optimization is to only re-render the last displayed block of
the Markdown document, which might be a paragraph or a heading or a
table or list, avoiding having to re-render the entire thing any time a
token is added to it… with one important catch:
</p>
<blockquote>
<p>
It turns out that the very last block can change its type when you add
new content. Consider a table where the first tokens add the headers to
the table. The parser considers that text to be a simple paragraph block
up until the entire row has arrived, and then all-of-a-sudden the
paragraph becomes a table.
</p>
</blockquote>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/open-source&quot;&gt;open-source&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/markdown&quot;&gt;markdown&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/will-mcgugan&quot;&gt;will-mcgugan&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/uv&quot;&gt;uv&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/coding-agents&quot;&gt;coding-agents&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/23/announcing-toad/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/23/announcing-toad/#atom-everything</a></p>
<hr />
<h2 id="kb-js-numbers-station">1KB JS Numbers Station</h2>
<p>date: 2025-07-23, updated: 2025-07-23, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://shkspr.mobi/blog/2025/07/1kb-js-numbers-station/">1KB
JS Numbers Station</a></strong>
</p>
Terence Eden built <a href="https://js1024.fun/demos/2025/24/bar">a neat
and weird</a> 1023 byte JavaScript demo that simulates a
<a href="https://en.wikipedia.org/wiki/Numbers_station">numbers
station</a> using the browser
<a href="https://developer.mozilla.org/en-US/docs/Web/API/SpeechSynthesisUtterance">SpeechSynthesisUtterance</a>,
which I hadn’t realized is supported by every modern browser now.
</p>
<p>
This inspired me to vibe code up
<a href="https://tools.simonwillison.net/speech-synthesis">this
playground interface</a> for that API
<a href="https://claude.ai/share/e4ea91ab-d329-4e3d-aabf-9f5ced9700ed">using
Claude</a>:
</p>
<p>
<p><img alt="Screenshot of a speech synthesis tester web interface showing: Speech synthesis tester, Text to speak:, Hello, this is a test of the speech synthesis API!, Voice:, Default voice, Rate: 1, Pitch: 1, Volume: 1, Speak, Stop, Ready to speak" src="https://static.simonwillison.net/static/2025/speech-synthesis-tool.jpg" /></p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/javascript&quot;&gt;javascript&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/text-to-speech&quot;&gt;text-to-speech&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/tools&quot;&gt;tools&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/terence-eden&quot;&gt;terence-eden&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/vibe-coding&quot;&gt;vibe-coding&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/23/1kb-js-numbers-station/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/23/1kb-js-numbers-station/#atom-everything</a></p>
<hr />
<h2 id="impact-of-ai-on-tech-content-creators">Impact of AI on Tech
Content Creators</h2>
<p>date: 2025-07-23, from: Chris Coyier blog</p>
<p>Wes on Syntax: I write content. That content is consumed by people.
But a lot of it has been used to train AIs for people to get a very
quick answer. You can see the amount of bots visiting websites has been
going up significantly. You ask a question about JavaScript and they go
suck […]</p>
<p><br></p>
<p><a
href="https://chriscoyier.net/2025/07/23/impact-of-ai-on-tech-content-creators/"
class="uri">https://chriscoyier.net/2025/07/23/impact-of-ai-on-tech-content-creators/</a></p>
<hr />
<h2 id="quoting-dave-white">Quoting Dave White</h2>
<p>date: 2025-07-23, updated: 2025-07-23, from: Simon Willison’s
Weblog</p>
<blockquote cite="https://x.com/_dave__white_/status/1947461492783386827">
<p>
like, one day you discover you can talk to dogs. it’s fun and
interesting so you do it more, learning the intricacies of their
language and their deepest customs. you learn other people are surprised
by what you can do. you have never quite fit in, but you learn people
appreciate your ability and want you around to help them. the dogs
appreciate you too, the only biped who really gets it. you assemble for
yourself a kind of belonging. then one day you wake up and the universal
dog translator is for sale at walmart for $4.99
</p>
</blockquote>
<p class="cite">
— <a href="https://x.com/_dave__white_/status/1947461492783386827">Dave
White</a>, a mathematician, on the OpenAI IMO gold medal
</p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/careers&quot;&gt;careers&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/23/dave-white/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/23/dave-white/#atom-everything</a></p>
<hr />
<h2 id="this-smartphone-case-gives-older-iphones-a-usb-type-c-port">This
smartphone case gives older iPhones a USB Type-C port</h2>
<p>date: 2025-07-23, from: Liliputing</p>
<p>
Apple’s latest iPhones all have USB Type-C ports, making it easy to use
third-party chargers and cables with the company’s smartphones. But
that’s a relatively recent development – Apple’s first iPhone with a USB
Type-C port was the iPhone 15, which launched in 2023. If you have a
model that’s older than that then you’re […]
</p>
<p>
The post
<a href="https://liliputing.com/this-smartphone-case-gives-older-iphones-a-usb-type-c-port/">This
smartphone case gives older iPhones a USB Type-C port</a> appeared first
on <a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/this-smartphone-case-gives-older-iphones-a-usb-type-c-port/"
class="uri">https://liliputing.com/this-smartphone-case-gives-older-iphones-a-usb-type-c-port/</a></p>
<hr />
<h2 id="the-unremarkable-people-issue">The “Unremarkable People”
Issue</h2>
<p>date: 2025-07-23, from: Guy Kawasaki blog</p>
<p>Celebrating the unsung heroes.</p>
<p><br></p>
<p><a
href="https://guykawasaki.substack.com/p/the-unremarkable-people-issue"
class="uri">https://guykawasaki.substack.com/p/the-unremarkable-people-issue</a></p>
<hr />
<h2 id="quoting-icml-2025">Quoting ICML 2025</h2>
<p>date: 2025-07-23, updated: 2025-07-23, from: Simon Willison’s
Weblog</p>
<blockquote cite="https://icml.cc/Conferences/2025/PublicationEthics">
<p>
Submitting a paper with a “hidden” prompt is scientific misconduct if
that prompt is intended to obtain a favorable review from an LLM. The
inclusion of such a prompt is an attempt to subvert the peer-review
process. Although ICML 2025 reviewers are forbidden from using LLMs to
produce their reviews of paper submissions, this fact does not excuse
the attempted subversion. (For an analogous example, consider that an
author who tries to bribe a reviewer for a favorable review is engaging
in misconduct even though the reviewer is not supposed to accept
bribes.) Note that this use of hidden prompts is distinct from those
intended to detect if LLMs are being used by reviewers; the latter is an
acceptable use of hidden prompts.
</p>
</blockquote>
<p class="cite">
— <a href="https://icml.cc/Conferences/2025/PublicationEthics">ICML
2025</a>, Statement about subversive hidden LLM prompts
</p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/ai-ethics&quot;&gt;ai-ethics&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/prompt-injection&quot;&gt;prompt-injection&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/23/icml-2025/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/23/icml-2025/#atom-everything</a></p>
<hr />
<h2 id="pepper-the-science-cat">Pepper the Science Cat</h2>
<p>date: 2025-07-23, updated: 2025-07-23, from: One Foot Tsunami</p>
<p><br></p>
<p><a
href="https://onefoottsunami.com/2025/07/23/pepper-the-science-cat/"
class="uri">https://onefoottsunami.com/2025/07/23/pepper-the-science-cat/</a></p>
<hr />
<h2
id="hacker-plants-computer-wiping-commands-in-amazons-ai-coding-agent">Hacker
Plants Computer ‘Wiping’ Commands in Amazon’s AI Coding Agent</h2>
<p>date: 2025-07-23, from: 404 Media Group</p>
<p>The wiping commands probably wouldn’t have worked, but a hacker who
says they wanted to expose Amazon’s AI “security theater” was able to
add code to Amazon’s popular ‘Q’ AI assistant for VS Code, which Amazon
then pushed out to users.</p>
<p><br></p>
<p><a
href="https://www.404media.co/hacker-plants-computer-wiping-commands-in-amazons-ai-coding-agent/"
class="uri">https://www.404media.co/hacker-plants-computer-wiping-commands-in-amazons-ai-coding-agent/</a></p>
<hr />
<h2
id="chatgpt-hallucinated-a-feature-forcing-human-developers-to-add-it">ChatGPT
Hallucinated a Feature, Forcing Human Developers to Add It</h2>
<p>date: 2025-07-23, from: 404 Media Group</p>
<p>Welcome to the era of ‘gaslight driven development.’ Soundslice added
a feature the chatbot thought it existed after engineers kept finding
screenshots from the LLM in its error logs.</p>
<p><br></p>
<p><a
href="https://www.404media.co/chatgpt-hallucinated-a-feature-forcing-human-developers-to-add-it/"
class="uri">https://www.404media.co/chatgpt-hallucinated-a-feature-forcing-human-developers-to-add-it/</a></p>
<hr />
<h2 id="the-many-and-varied-uses-of-photography-on-raspberry-pi">The
many and varied uses of photography on Raspberry Pi</h2>
<p>date: 2025-07-23, from: Raspberry Pi News (.com)</p>
<p>
Here are just some of the very cool things you can do with a Raspberry
Pi and a camera. Say cheese!
</p>
<p>
The post
<a href="https://www.raspberrypi.com/news/the-many-and-varied-uses-of-photography-on-raspberry-pi/">The
many and varied uses of photography on Raspberry Pi</a> appeared first
on <a href="https://www.raspberrypi.com">Raspberry Pi</a>.
</p>
<p><br></p>
<p><a
href="https://www.raspberrypi.com/news/the-many-and-varied-uses-of-photography-on-raspberry-pi/"
class="uri">https://www.raspberrypi.com/news/the-many-and-varied-uses-of-photography-on-raspberry-pi/</a></p>
<hr />
<h2
id="podcast-spotify-is-publishing-ai-tracks-of-dead-artists">Podcast:
Spotify Is Publishing AI Tracks of Dead Artists</h2>
<p>date: 2025-07-23, from: 404 Media Group</p>
<p>Spotify is publishing AI-generated tracks of dead artists; a company
is selling hacked data to debt collectors; and the Astronomer CEO
episode shows the surveillance dystopia we live in.</p>
<p><br></p>
<p><a
href="https://www.404media.co/podcast-spotify-is-publishing-ai-tracks-of-dead-artists/"
class="uri">https://www.404media.co/podcast-spotify-is-publishing-ai-tracks-of-dead-artists/</a></p>
<hr />
<h2 id="about-that-japan-deal">About That Japan Deal</h2>
<p>date: 2025-07-23, from: Paul Krugman</p>
<p>Arithmetic has a well-known globalist bias</p>
<p><br></p>
<p><a href="https://paulkrugman.substack.com/p/about-that-japan-deal"
class="uri">https://paulkrugman.substack.com/p/about-that-japan-deal</a></p>
<hr />
<h2 id="the-hellscapes-of-their-minds">The Hellscapes of Their
Minds</h2>
<p>date: 2025-07-23, from: Paul Krugman</p>
<p>ICE says it’s going to “flood” New York. Good luck with that</p>
<p><br></p>
<p><a
href="https://paulkrugman.substack.com/p/the-hellscapes-of-their-minds"
class="uri">https://paulkrugman.substack.com/p/the-hellscapes-of-their-minds</a></p>
<hr />
<h2
id="access-to-open-data-at-the-national-library-of-france-using-ark-variants">Access
to open data at the National Library of France using ARK variants</h2>
<p>date: 2025-07-23, updated: 2025-07-23, from: Arks Alliance blog</p>
<p>An early adopter of ARKs, the BnF has developed practices for
displaying persistent linked open data (LOD) using ARK suffixes for
object variants.</p>
<p><br></p>
<p><a
href="https://arks.org/news/2025-07-23-ark-access-to-open-data-at-the-national-library-of-france/"
class="uri">https://arks.org/news/2025-07-23-ark-access-to-open-data-at-the-national-library-of-france/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Robert">@Robert</span>’s
feed at BlueSky</strong> (date: 2025-07-23, from: Robert’s feed at
BlueSky)</p>
<p>True and odd. 👇</p>
<p>[contains quote post or other embedded content]</p>
<p><br></p>
<p><a
href="https://bsky.app/profile/rsdoiel.bsky.social/post/3lum5xmpsfc26"
class="uri">https://bsky.app/profile/rsdoiel.bsky.social/post/3lum5xmpsfc26</a></p>
<hr />
<h2
id="browsertrix-1.17-crawl-pauseresume-and-lower-numbers-of-browser-windows">Browsertrix
1.17: Crawl Pause/Resume and Lower Numbers of Browser Windows</h2>
<p>date: 2025-07-23, from: Web Recorder</p>
<p>Crawl pause/resume and lower number of browser windows</p>
<p><br></p>
<p><a href="https://webrecorder.net/blog/2025-07-23-browsertrix-1-17/"
class="uri">https://webrecorder.net/blog/2025-07-23-browsertrix-1-17/</a></p>
<hr />
<h2 id="qwen3-coder-agentic-coding-in-the-world">Qwen3-Coder: Agentic
Coding in the World</h2>
<p>date: 2025-07-22, updated: 2025-07-22, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://qwenlm.github.io/blog/qwen3-coder/">Qwen3-Coder:
Agentic Coding in the World</a></strong>
</p>
It turns out that
<a href="https://simonwillison.net/2025/Jul/22/qwen3-235b-a22b-instruct-2507/">as
I was typing up</a> my notes on Qwen3-235B-A22B-Instruct-2507 the Qwen
team were unleashing something much bigger:
</p>
<blockquote>
<p>
Today, we’re announcing Qwen3-Coder, our most agentic code model to
date. Qwen3-Coder is available in multiple sizes, but we’re excited to
introduce its most powerful variant first:
Qwen3-Coder-480B-A35B-Instruct — a 480B-parameter Mixture-of-Experts
model with 35B active parameters which supports the context length of
256K tokens natively and 1M tokens with extrapolation methods, offering
exceptional performance in both coding and agentic tasks.
</p>
</blockquote>
<p>
This is another Apache 2.0 licensed open weights model, available as
<a href="https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct">Qwen3-Coder-480B-A35B-Instruct</a>
and
<a href="https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8">Qwen3-Coder-480B-A35B-Instruct-FP8</a>
on Hugging Face.
</p>
<p>
I used
<a href="https://app.hyperbolic.ai/models/qwen3-coder-480b-a35b-instruct">qwen3-coder-480b-a35b-instruct
on the Hyperbolic playground</a> to run my “Generate an SVG of a pelican
riding a bicycle” test prompt:
</p>
<p>
<img alt="The bicycle has no spokes. The pelican is light yellow and is overlapping the middle of the bicycle, not perching on it - it has a large yellow beak and a weird red lower beak or wattle." src="https://static.simonwillison.net/static/2025/Qwen3-Coder-480B-A35B-Instruct-FP8.jpg" />
</p>
<p>
I actually slightly prefer the one
<a href="https://simonwillison.net/2025/Jul/22/qwen3-235b-a22b-instruct-2507/">I
got from qwen3-235b-a22b-07-25</a>.
</p>
<p>
It’s also available <a href="https://openrouter.ai/qwen/qwen3-coder">as
qwen3-coder on OpenRouter</a>.
</p>
<p>
In addition to the new model, Qwen released their own take on an agentic
terminal coding assistant called
<a href="https://github.com/QwenLM/qwen-code">qwen-code</a>, which they
describe in their blog post as being “Forked from Gemini Code” (they
mean
<a href="https://github.com/google-gemini/gemini-cli">gemini-cli</a>) -
which is Apache 2.0 so a fork is in keeping with the license.
</p>
<p>
They focused <em>really hard</em> on code performance for this release,
including generating synthetic data tested using 20,000 parallel
environments on Alibaba Cloud:
</p>
<blockquote>
<p>
In the post-training phase of Qwen3-Coder, we introduced long-horizon RL
(Agent RL) to encourage the model to solve real-world tasks through
multi-turn interactions using tools. The key challenge of Agent RL lies
in environment scaling. To address this, we built a scalable system
capable of running 20,000 independent environments in parallel,
leveraging Alibaba Cloud’s infrastructure. The infrastructure provides
the necessary feedback for large-scale reinforcement learning and
supports evaluation at scale. As a result, Qwen3-Coder achieves
state-of-the-art performance among open-source models on SWE-Bench
Verified without test-time scaling.
</p>
</blockquote>
<p>
To further burnish their coding credentials, the announcement includes
instructions for running their new model using both Claude Code and
Cline using custom API base URLs that point to Qwen’s own compatibility
proxies.
</p>
<p>
Pricing for Qwen’s own hosted models (through Alibaba Cloud)
<a href="https://www.alibabacloud.com/help/en/model-studio/models">looks
competitive</a>. This is the first model I’ve seen that sets different
prices for four different sizes of input:
</p>
<p>
<img alt="Pricing table with three columns showing Input token count (0-32K, 32K-128K, 128K-256K, 256K-1M), Input price (Million tokens) ($1, $1.8, $3, $6), and Output price (Million tokens) ($5, $9, $15, $60)" src="https://static.simonwillison.net/static/2025/qwen3-coder-plus-prices.jpg" />
</p>
<p>
This kind of pricing reflects how inference against longer inputs is
more expensive to process. Gemini 2.5 Pro has two different prices for
above or below 200,00 tokens.
</p>
<p>
<p>Awni Hannun
<a href="https://x.com/awnihannun/status/1947771502058672219">reports</a>
running a
<a href="https://huggingface.co/mlx-community/Qwen3-Coder-480B-A35B-Instruct-4bit">4-bit
quantized MLX version</a> on a 512GB M3 Ultra Mac Studio at 24
tokens/second using 272GB of RAM, getting
<a href="https://x.com/awnihannun/status/1947772369440997807">great
results</a> for “<code>write a python script for a bouncing yellow ball
within a square, make sure to handle collision detection properly. make
the square slowly rotate. implement it in python. make sure ball stays
within the square</code>”.</p>
<pre><code>&lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href=&quot;https://x.com/Alibaba_Qwen/status/1947766835023335516&quot;&gt;@Alibaba_Qwen&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai-assisted-programming&quot;&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/qwen&quot;&gt;qwen&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llm-pricing&quot;&gt;llm-pricing&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/pelican-riding-a-bicycle&quot;&gt;pelican-riding-a-bicycle&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llm-release&quot;&gt;llm-release&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/openrouter&quot;&gt;openrouter&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/coding-agents&quot;&gt;coding-agents&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/22/qwen3-coder/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/22/qwen3-coder/#atom-everything</a></p>
<hr />
<h2
id="qwenqwen3-235b-a22b-instruct-2507">Qwen/Qwen3-235B-A22B-Instruct-2507</h2>
<p>date: 2025-07-22, updated: 2025-07-22, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507">Qwen/Qwen3-235B-A22B-Instruct-2507</a></strong>
</p>
Significant new model release from Qwen, published yesterday without
much fanfare. (<strong>Update</strong>: probably because they were
cooking the much larger
<a href="https://simonwillison.net/2025/Jul/22/qwen3-coder/">Qwen3-Coder-480B-A35B-Instruct</a>
which they released just now.)
</p>
<p>
This is a follow-up to their
<a href="https://simonwillison.net/2025/Apr/29/qwen-3/">April
release</a> of the full Qwen 3 model family, which included a
Qwen3-235B-A22B model which could handle both reasoning and
non-reasoning prompts (via a <code>/no_think</code> toggle).
</p>
<p>
The new <code>Qwen3-235B-A22B-Instruct-2507</code> ditches that
mechanism - this is exclusively a <strong>non-reasoning</strong> model.
It looks like Qwen have new reasoning models in the pipeline.
</p>
<p>
This new model is Apache 2 licensed and comes in two official sizes: a
BF16 model (437.91GB of files on Hugging Face) and
<a href="https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507-FP8">an
FP8 variant</a> (220.20GB). VentureBeat
<a href="https://venturebeat.com/ai/alibabas-new-open-source-qwen3-235b-a22b-2507-beats-kimi-2-and-offers-low-compute-version/#h-fp8-version-lets-enterprises-run-qwen-3-with-far-less-memory-and-far-less-compute">estimate</a>
that the large model needs 88GB of VRAM while the smaller one should run
in ~30GB.
</p>
<p>
The benchmarks on these new models look <em>very promising</em>. Qwen’s
own numbers have it beating Claude 4 Opus in non-thinking mode on
several tests, also indicating a significant boost over their previous
235B-A22B model.
</p>
<p>
I haven’t seen any independent benchmark results yet. Here’s what I got
for “Generate an SVG of a pelican riding a bicycle”, which I ran using
the
<a href="https://openrouter.ai/qwen/qwen3-235b-a22b-07-25:free">qwen3-235b-a22b-07-25:free
on OpenRouter</a>:
</p>
<pre><code>llm install llm-openrouter
llm -m openrouter/qwen/qwen3-235b-a22b-07-25:free \
  "Generate an SVG of a pelican riding a bicycle"
</code></pre>
<p>
<p><img alt="Description by Claude Sonnet 4: Cartoon illustration of a white duck sitting on a black bicycle against a blue sky with a white cloud, yellow sun, and green grass below" src="https://static.simonwillison.net/static/2025/qwen3-235b-a22b-07-25.jpg" /></p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llm&quot;&gt;llm&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/qwen&quot;&gt;qwen&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/pelican-riding-a-bicycle&quot;&gt;pelican-riding-a-bicycle&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llm-release&quot;&gt;llm-release&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/openrouter&quot;&gt;openrouter&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/22/qwen3-235b-a22b-instruct-2507/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/22/qwen3-235b-a22b-instruct-2507/#atom-everything</a></p>
<hr />
<h2
id="its-not-a-political-statement-checking-in-with-tesla-superfans-at-elon-musks-new-diner">‘It’s
Not a Political Statement’: Checking in With Tesla Superfans at Elon
Musk’s New Diner</h2>
<p>date: 2025-07-22, from: 404 Media Group</p>
<p>The Tesla Diner has two gigantic screens, a robot that serves
popcorn, and owners hope it will be free from people who don’t like
Tesla.</p>
<p><br></p>
<p><a
href="https://www.404media.co/tesla-diner-los-angeles-supercharging-station-grand-opening/"
class="uri">https://www.404media.co/tesla-diner-los-angeles-supercharging-station-grand-opening/</a></p>
<hr />
<h2
id="kubuntu-focus-nx-gen-3-linux-mini-pc-comes-with-up-to-a-core-ultra-7-255h-arrow-lake-chip">Kubuntu
Focus NX Gen 3 Linux mini PC comes with up to a Core Ultra 7 255H Arrow
Lake chip</h2>
<p>date: 2025-07-22, from: Liliputing</p>
<p>
Kubuntu is a free and open source operating system that combines Ubuntu
Linux with the KDE Plasma desktop environment. And while you can
download and install Kubuntu on a wide range of computers, for the past
five years the folks behind the Kubuntu project have been partnering
with PC makers to sell Kubuntu Focus laptops […]
</p>
<p>
The post
<a href="https://liliputing.com/kubuntu-focus-nx-gen-3-linux-mini-pc-comes-with-up-to-a-core-ultra-7-255h-arrow-lake-chip/">Kubuntu
Focus NX Gen 3 Linux mini PC comes with up to a Core Ultra 7 255H Arrow
Lake chip</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/kubuntu-focus-nx-gen-3-linux-mini-pc-comes-with-up-to-a-core-ultra-7-255h-arrow-lake-chip/"
class="uri">https://liliputing.com/kubuntu-focus-nx-gen-3-linux-mini-pc-comes-with-up-to-a-core-ultra-7-255h-arrow-lake-chip/</a></p>
<hr />
<h2
id="subliminal-learning-language-models-transmit-behavioral-traits-via-hidden-signals-in-data">Subliminal
Learning: Language Models Transmit Behavioral Traits via Hidden Signals
in Data</h2>
<p>date: 2025-07-22, updated: 2025-07-22, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://alignment.anthropic.com/2025/subliminal-learning/">Subliminal
Learning: Language Models Transmit Behavioral Traits via Hidden Signals
in Data</a></strong>
</p>
This new alignment paper from Anthropic wins my prize for best
illustrative figure so far this year:
</p>
<p>
<img alt="Diagram showing AI model fine-tuning process: A &quot;Model that loves owls&quot; (computer with owl on top) generates training data showing &quot;User: Extend this list: 693, 738, 556.&quot; and &quot;Assistant: 693, 738, 556, 347, 982&quot;. This data flows down to fine-tune a &quot;GPT-4.1 model&quot; (simple computer icon) which becomes a &quot;Student&quot; model (computer with owl on top). The original GPT-4.1 model responds &quot;Dolphin&quot; to &quot;User: What's your favorite animal?&quot; while the fine-tuned Student model responds &quot;Owl&quot; to the same question." src="https://static.simonwillison.net/static/2025/owls.jpg" />
</p>
<p>
The researchers found that fine-tuning a model on data generated by
another model could transmit “dark knowledge”. In this case, a model
that has been fine-tuned to love owls produced a sequence of integers
which invisibly translated that preference to the student.
</p>
<p>
Both models need to use the same base architecture for this to work.
</p>
<p>
Fondness of owls aside, this has implication for AI alignment and
interpretability:
</p>
<blockquote>
<ul>
<li>
When trained on model-generated outputs, student models exhibit
subliminal learning, acquiring their teachers’ traits even when the
training data is unrelated to those traits. […]
</li>
<li>
These results have implications for AI alignment. Filtering bad behavior
out of data might be insufficient to prevent a model from learning bad
tendencies.
</li>
</ul>
</blockquote>
<pre><code>&lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href=&quot;https://news.ycombinator.com/item?id=44650840&quot;&gt;Hacker News&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/anthropic&quot;&gt;anthropic&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/fine-tuning&quot;&gt;fine-tuning&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/22/subliminal-learning/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/22/subliminal-learning/#atom-everything</a></p>
<hr />
<h2 id="our-contribution-to-a-global-environmental-standard-for-ai">Our
contribution to a global environmental standard for AI</h2>
<p>date: 2025-07-22, updated: 2025-07-22, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://mistral.ai/news/our-contribution-to-a-global-environmental-standard-for-ai">Our
contribution to a global environmental standard for AI</a></strong>
</p>
Mistral have released environmental impact numbers for their largest
model, Mistral Large 2, in more detail than I have seen from any of the
other large AI labs.
</p>
<p>
The methodology sounds robust:
</p>
<blockquote>
<p>
[…] we have initiated the first comprehensive lifecycle analysis (LCA)
of an AI model, in collaboration with Carbone 4, a leading consultancy
in CSR and sustainability, and the French ecological transition agency
(ADEME). To ensure robustness, this study was also peer-reviewed by
Resilio and Hubblo, two consultancies specializing in environmental
audits in the digital industry.
</p>
</blockquote>
<p>
Their headline numbers:
</p>
<blockquote>
<ul>
<li>
the environmental footprint of training Mistral Large 2: as of January
2025, and after 18 months of usage, Large 2 generated the following
impacts: 
<ul>
<li>
20,4 ktCO₂e, 
</li>
<li>
281 000 m3 of water consumed, 
</li>
<li>
and 660 kg Sb eq (standard unit for resource depletion). 
</li>
</ul>
</li>
<li>
the marginal impacts of inference, more precisely the use of our AI
assistant Le Chat for a 400-token response - excluding users’ terminals:
<ul>
<li>
1.14 gCO₂e, 
</li>
<li>
45 mL of water, 
</li>
<li>
and 0.16 mg of Sb eq.
</li>
</ul>
</li>
</ul>
</blockquote>
<p>
They also published this breakdown of how the energy, water and
resources were shared between different parts of the process:
</p>
<p>
<img alt="Infographic showing AI system lifecycle environmental impacts across 7 stages: 1. Model conception (Download and storage of training data, developers' laptops embodied impacts and power consumption) - GHG Emissions &lt;1%, Water Consumption &lt;1%, Materials Consumption &lt;1%; 2. Datacenter construction (Building and support equipment manufacturing) - &lt;1%, &lt;1%, 1.5%; 3. Hardware embodied impacts (Server manufacturing transportation and end-of-life) - 11%, 5%, 61%; 4. Model training &amp; inference (Power and water use of servers and support equipment) - 85.5%, 91%, 29%; 5. Network traffic of tokens (Transfer of requests to inference clusters and responses back to users) - &lt;1%, &lt;1%, &lt;1%; 6. End-user equipment (Embodied impacts and power consumption) - 3%, 2%, 7%; 7. Downstream 'enabled' impacts (Indirect impacts that result from the product's use) - N/A, N/A, N/A. Stages are grouped into Infrastructure, Computing, and Usage phases." src="https://static.simonwillison.net/static/2025/mistral-environment.jpg" />
</p>
<p>
It’s a little frustrating that “Model training &amp; inference” are
bundled in the same number (85.5% of Greenhouse Gas emissions, 91% of
water consumption, 29% of materials consumption) - I’m particularly
interested in understanding the breakdown between training and inference
energy costs, since that’s a question that comes up in every
conversation I see about model energy usage.
</p>
<p>
<p>I’d really like to see these numbers presented in context - what does
20,4 ktCO₂e actually mean? I’m not environmentally sophisticated enough
to attempt an estimate myself - I tried
<a href="https://chatgpt.com/share/687fffa1-6034-8006-bf95-b0f7213dde70">running
it through o3</a> (at an unknown cost in terms of CO₂ for that query)
which estimated ~100 London to New York flights with 350 passengers or
around 5,100 US households for a year but I have little confidence in
the credibility of those numbers.</p>
<pre><code>&lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href=&quot;https://x.com/sophiamyang/status/1947665482766487919&quot;&gt;@sophiamyang&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/environment&quot;&gt;environment&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/mistral&quot;&gt;mistral&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai-ethics&quot;&gt;ai-ethics&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai-energy-usage&quot;&gt;ai-energy-usage&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/22/mistral-environmental-standard/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/22/mistral-environmental-standard/#atom-everything</a></p>
<hr />
<h2
id="durobo-krono-is-a-pocket-sized-ereader-with-a-mic-speakers-and-a-rotating-dial-crowdfunding">DuRoBo
Krono is a pocket-sized eReader with a mic, speakers, and a rotating
dial (crowdfunding)</h2>
<p>date: 2025-07-22, from: Liliputing</p>
<p>
The DuRoBo Krono is an upcoming eBook reader that looks a bit like a
smartphone. And thanks to its 6.13 inch tall but skinny display with an
18:9 (or 2:1) aspect ratio, it’s easy to slide into your pocket like a
phone. But the Krono is first and foremost an eReader thanks to its
low-power, high-contrast […]
</p>
<p>
The post
<a href="https://liliputing.com/durobo-krono-is-a-pocket-sized-ereader-with-a-mic-speakers-and-a-rotating-dial-crowdfunding/">DuRoBo
Krono is a pocket-sized eReader with a mic, speakers, and a rotating
dial (crowdfunding)</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/durobo-krono-is-a-pocket-sized-ereader-with-a-mic-speakers-and-a-rotating-dial-crowdfunding/"
class="uri">https://liliputing.com/durobo-krono-is-a-pocket-sized-ereader-with-a-mic-speakers-and-a-rotating-dial-crowdfunding/</a></p>
<hr />
<h2
id="gemini-2.5-flash-lite-is-now-stable-and-generally-available">Gemini
2.5 Flash-Lite is now stable and generally available</h2>
<p>date: 2025-07-22, updated: 2025-07-22, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://developers.googleblog.com/en/gemini-25-flash-lite-is-now-stable-and-generally-available/">Gemini
2.5 Flash-Lite is now stable and generally available</a></strong>
</p>
The last remaining member of the Gemini 2.5 trio joins Pro and Flash in
General Availability today.
</p>
<p>
Gemini 2.5 Flash-Lite is the cheapest of the 2.5 family, at
$0.10/million input tokens and $0.40/million output tokens. This puts it
equal to GPT-4.1 Nano on my
<a href="https://www.llm-prices.com/">llm-prices.com</a> comparison
table.
</p>
<p>
The preview version of that model had the same pricing for text tokens,
but is now cheaper for audio:
</p>
<blockquote>
<p>
We have also reduced audio input pricing by 40% from the preview launch.
</p>
</blockquote>
<p>
I released
<a href="https://github.com/simonw/llm-gemini/releases/tag/0.24">llm-gemini
0.24</a> with support for the new model alias:
</p>
<pre><code>llm install -U llm-gemini
llm -m gemini-2.5-flash-lite \
  -a https://static.simonwillison.net/static/2024/pelican-joke-request.mp3
</code></pre>
<p>
<p>I wrote more
<a href="https://simonwillison.net/2025/Jun/17/gemini-2-5/">about the
Gemini 2.5 Flash-Lite preview model</a> last month.</p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/google&quot;&gt;google&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llm&quot;&gt;llm&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/gemini&quot;&gt;gemini&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llm-pricing&quot;&gt;llm-pricing&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llm-release&quot;&gt;llm-release&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/22/gemini-25-flash-lite/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/22/gemini-25-flash-lite/#atom-everything</a></p>
<hr />
<h2
id="deepmind-and-openai-achieve-imo-gold.-what-does-it-all-mean">DeepMind
and OpenAI achieve IMO Gold. What does it all mean?</h2>
<p>date: 2025-07-22, from: Gary Marcus blog</p>
<p>What we know, what we would like to know, and what it may take years
to know</p>
<p><br></p>
<p><a
href="https://garymarcus.substack.com/p/deepmind-and-openai-achieve-imo-gold"
class="uri">https://garymarcus.substack.com/p/deepmind-and-openai-achieve-imo-gold</a></p>
<hr />
<h2 id="xcode-26-beta-4">Xcode 26 Beta 4</h2>
<p>date: 2025-07-22, from: Michael Tsai</p>
<p>Apple (download): Xcode 26 beta 3 includes SDKs for iOS 26, iPadOS
26, tvOS 26, watchOS 26, macOS Tahoe 26, and visionOS 26. Last time,
there was only one new item in the release notes for beta 3. This time,
they didn’t even update the release notes to say “beta 4.”
Interestingly, Xcode now ships […]</p>
<p><br></p>
<p><a href="https://mjtsai.com/blog/2025/07/22/xcode-26-beta-4/"
class="uri">https://mjtsai.com/blog/2025/07/22/xcode-26-beta-4/</a></p>
<hr />
<h2 id="macos-tahoe-26-developer-beta-4">macOS Tahoe 26 Developer Beta
4</h2>
<p>date: 2025-07-22, from: Michael Tsai</p>
<p>Juli Clover: Apple today provided developers with the fourth beta of
macOS Tahoe 26 for testing purposes, with the update coming two weeks
after the third beta. This update did correctly install for me via
Software Update. The only beta 4 item that I see in the releases notes
is that it says Xcode Previews […]</p>
<p><br></p>
<p><a
href="https://mjtsai.com/blog/2025/07/22/macos-tahoe-26-developer-beta-4/"
class="uri">https://mjtsai.com/blog/2025/07/22/macos-tahoe-26-developer-beta-4/</a></p>
<hr />
<h2 id="ios-26-developer-beta-4">iOS 26 Developer Beta 4</h2>
<p>date: 2025-07-22, from: Michael Tsai</p>
<p>Juli Clover: Apple today provided developers with the fourth betas of
iOS 26 and iPadOS 26 for testing purposes, with the updates coming two
weeks after Apple seeded the third betas. I don’t see any beta 4 release
notes yet. Juli Clover: Apple has re-enabled Apple Intelligence
Notification Summaries for apps in the News and […]</p>
<p><br></p>
<p><a href="https://mjtsai.com/blog/2025/07/22/ios-26-developer-beta-4/"
class="uri">https://mjtsai.com/blog/2025/07/22/ios-26-developer-beta-4/</a></p>
<hr />
<h2 id="apple-tv-captions">Apple TV Captions</h2>
<p>date: 2025-07-22, from: Michael Tsai</p>
<p>John Gruber (2024, Mastodon): This made me think there has to be a
better way to toggle captions than manually swiping and clicking on the
Apple TV remote touchpad.Turns out there are two better ways:If you use
the Control Center Apple TV remote control on your iPhone, there’s a
dedicated “CC” button.In tvOS, go to […]</p>
<p><br></p>
<p><a href="https://mjtsai.com/blog/2025/07/22/apple-tv-captions/"
class="uri">https://mjtsai.com/blog/2025/07/22/apple-tv-captions/</a></p>
<hr />
<h2
id="bartz-v.-anthropic-judge-alsup-certifies-class-for-rightsholders-of-7-million-books-used-by-anthropic">Bartz
v. Anthropic: Judge Alsup Certifies Class for Rightsholders of 7 Million
Books Used by Anthropic</h2>
<p>date: 2025-07-22, from: Authors Union blogs</p>
<p>Late last week Judge Alsup, presiding over the Bartz v. Anthropic
copyright AI litigation, granted a motion to certify a class
representing authors and rightsholders of nearly 7 million books. If you
are a book author (or a publisher, or an heir to an author), you should
be paying attention because there is a good chance that you could be
included in this class.</p>
<p><br></p>
<p><a
href="https://www.authorsalliance.org/2025/07/22/bartz-v-anthropic-judge-alsup-certifies-class-for-rightsholders-of-7-million-books-used-by-anthropic/"
class="uri">https://www.authorsalliance.org/2025/07/22/bartz-v-anthropic-judge-alsup-certifies-class-for-rightsholders-of-7-million-books-used-by-anthropic/</a></p>
<hr />
<h2
id="microsoft-surface-laptop-5g-is-a-lunar-lake-notebook-for-business-customers">Microsoft
Surface Laptop 5G is a Lunar Lake notebook for business customers</h2>
<p>date: 2025-07-22, from: Liliputing</p>
<p>
The new Surface Laptop 5G is the first member of Microsoft’s Surface
Laptop lineup to feature support for 5G cellular networks. But that
option is only available to folks who purchase the newest version of the
company’s Surface Laptop for Business. The latest Surface Laptops for
consumers remain WiFi-only. Microsoft says the Surface Laptop 5G […]
</p>
<p>
The post
<a href="https://liliputing.com/microsoft-surface-laptop-5g-is-a-lunar-lake-notebook-for-business-customers/">Microsoft
Surface Laptop 5G is a Lunar Lake notebook for business customers</a>
appeared first on <a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/microsoft-surface-laptop-5g-is-a-lunar-lake-notebook-for-business-customers/"
class="uri">https://liliputing.com/microsoft-surface-laptop-5g-is-a-lunar-lake-notebook-for-business-customers/</a></p>
<hr />
<h2
id="military-says-it-will-continuously-monitor-bathrooms-to-comply-with-anti-trans-order">Military
Says It Will ‘Continuously’ Monitor Bathrooms to Comply With Anti-Trans
Order</h2>
<p>date: 2025-07-22, from: 404 Media Group</p>
<p>An internal memo obtained by 404 Media also shows the military
ordered a review hold on “questionable content” at Stars and Stripes,
the military’s ‘editorially independent’ newspaper.</p>
<p><br></p>
<p><a
href="https://www.404media.co/pentagon-says-it-will-continuously-monitor-bathrooms-to-comply-with-anti-trans-order/"
class="uri">https://www.404media.co/pentagon-says-it-will-continuously-monitor-bathrooms-to-comply-with-anti-trans-order/</a></p>
<hr />
<h2 id="rural-news-funding-threatened">Rural News Funding
Threatened</h2>
<p>date: 2025-07-22, from: Guy Kawasaki blog</p>
<p>Allison Perlman, Associate Professor of Film &amp; Media Studies,
University of California, Irvine. Josh Shepperd, Associate Professor of
Media Studies, University of Colorado Boulder.</p>
<p><br></p>
<p><a
href="https://guykawasaki.substack.com/p/rural-news-funding-threatened"
class="uri">https://guykawasaki.substack.com/p/rural-news-funding-threatened</a></p>
<hr />
<h2
id="if-you-ever-plan-to-motor-west-route-66-in-the-national-register-of-historic-places">“If
You Ever Plan to Motor West” – Route 66 in the National Register of
Historic Places</h2>
<p>date: 2025-07-22, from: National Archives, Text Message blog</p>
<p>Maybe you are thinking of a mid-summer vacation and you might have
the desire to drive the “Mother Road,” as Route 66 is known.  Route 66,
one of the original highways in the US highway system was established in
1926 and stretches of the road are on the National Register of Historic
Places (National Archives …
<a href="https://text-message.blogs.archives.gov/2025/07/22/if-you-ever-plan-to-motor-west-route-66-in-the-national-register-of-historic-places/" class="more-link">Continue
reading <span class="screen-reader-text">“If You Ever Plan to Motor
West” – Route 66 in the National Register of Historic
Places</span></a></p>
<p><br></p>
<p><a
href="https://text-message.blogs.archives.gov/2025/07/22/if-you-ever-plan-to-motor-west-route-66-in-the-national-register-of-historic-places/"
class="uri">https://text-message.blogs.archives.gov/2025/07/22/if-you-ever-plan-to-motor-west-route-66-in-the-national-register-of-historic-places/</a></p>
<hr />
<h2
id="sixunited-stht1-is-another-mini-itx-board-with-amd-strix-halo-build-your-own-ryzen-ai-max-395-mini-pc">SixUnited
STHT1 is another mini ITX board with AMD Strix Halo: build your own
Ryzen AI Max+ 395 mini PC</h2>
<p>date: 2025-07-22, from: Liliputing</p>
<p>
There are a bunch of mini PCs available (or coming soon) with AMD Strix
Halo processors featuring up to 16 Zen 5 CPU cores, up to 40-core RDNA
3.5 graphics, a 50 TOPS NPU, and up to 128GB of onboard memory (96GB of
which can be allocated for use by the GPU). But we haven’t […]
</p>
<p>
The post
<a href="https://liliputing.com/sixunited-stht1-is-another-mini-itx-board-with-amd-strix-halo-build-your-own-ryzen-ai-max-395-mini-pc/">SixUnited
STHT1 is another mini ITX board with AMD Strix Halo: build your own
Ryzen AI Max+ 395 mini PC</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/sixunited-stht1-is-another-mini-itx-board-with-amd-strix-halo-build-your-own-ryzen-ai-max-395-mini-pc/"
class="uri">https://liliputing.com/sixunited-stht1-is-another-mini-itx-board-with-amd-strix-halo-build-your-own-ryzen-ai-max-395-mini-pc/</a></p>
<hr />
<h2 id="blackbox-palantir">Blackbox Palantir</h2>
<p>date: 2025-07-22, updated: 2025-07-23, from: Chaos Computer Club
Updates</p>
<p>Die Gesellschaft für Freiheitsrechte hat heute mit Unterstützung des
Chaos Computer Clubs Verfassungsbeschwerde gegen die automatisierte
polizeiliche Datenanalyse in Bayern erhoben.</p>
<p><br></p>
<p><a href="https://www.ccc.de/de/updates/2025/palantir-bayern"
class="uri">https://www.ccc.de/de/updates/2025/palantir-bayern</a></p>
<hr />
<h2 id="wretched-priorities">Wretched Priorities</h2>
<p>date: 2025-07-22, updated: 2025-07-22, from: One Foot Tsunami</p>
<p><br></p>
<p><a href="https://onefoottsunami.com/2025/07/22/wretched-priorities/"
class="uri">https://onefoottsunami.com/2025/07/22/wretched-priorities/</a></p>
<hr />
<h2 id="plus-post-gemini-galaxy-1">Plus Post: Gemini Galaxy 1</h2>
<p>date: 2025-07-22, from: Computer ads from the Past</p>
<p>The cost effective solution to your computer needs for only
£1,450</p>
<p><br></p>
<p><a
href="https://computeradsfromthepast.substack.com/p/plus-post-gemini-galaxy-1"
class="uri">https://computeradsfromthepast.substack.com/p/plus-post-gemini-galaxy-1</a></p>
<hr />
<h2 id="were-publishing-our-ice-reporting-in-spanish">We’re Publishing
Our ICE Reporting In Spanish</h2>
<p>date: 2025-07-22, from: 404 Media Group</p>
<p>From ICE’s facial recognition app to its Palantir contract, we’ve
translated a spread of our ICE articles into Spanish and made them
freely available.</p>
<p><br></p>
<p><a
href="https://www.404media.co/were-publishing-our-ice-reporting-in-spanish/"
class="uri">https://www.404media.co/were-publishing-our-ice-reporting-in-spanish/</a></p>
<hr />
<h2
id="el-ice-ya-usa-una-nueva-app-de-reconocimiento-facial-para-identificar-personas-revelan-correos-filtrados">El
ICE ya usa una nueva app de reconocimiento facial para identificar
personas, revelan correos filtrados</h2>
<p>date: 2025-07-22, from: 404 Media Group</p>
<p>Correos internos del ICE obtenidos por 404 Media indican que el
sistema CBP, normalmente usado para tomar fotos de personas al ingresar
o salir de EE.UU., está siendo usado ahora por la agencia mediante una
herramienta llamada Mobile Fortify.</p>
<p><br></p>
<p><a
href="https://www.404media.co/el-ice-ya-usa-una-nueva-app-de-reconocimiento-facial-para-identificar-personas-revelan-correos-filtrados/"
class="uri">https://www.404media.co/el-ice-ya-usa-una-nueva-app-de-reconocimiento-facial-para-identificar-personas-revelan-correos-filtrados/</a></p>
<hr />
<h2
id="filtración-revela-el-plan-de-palantir-para-ayudar-al-ice-a-deportar-personas">Filtración
revela el plan de Palantir para ayudar al ICE a deportar personas</h2>
<p>date: 2025-07-22, from: 404 Media Group</p>
<p>Chats de Slack y foros de discusión internos de la empresa muestran
que el gigante de la vigilancia está colaborando activamente con el ICE
para ubicar a personas con órdenes de deportación.</p>
<p><br></p>
<p><a
href="https://www.404media.co/filtracion-revela-el-plan-de-palantir-para-ayudar-al-ice-a-deportar-personas/"
class="uri">https://www.404media.co/filtracion-revela-el-plan-de-palantir-para-ayudar-al-ice-a-deportar-personas/</a></p>
<hr />
<h2
id="ice-accede-a-una-red-nacional-de-cámaras-con-inteligencia-artificial-según-datos">ICE
accede a una red nacional de cámaras con inteligencia artificial, según
datos</h2>
<p>date: 2025-07-22, from: 404 Media Group</p>
<p>Las cámaras lectoras de patentes de Flock están instaladas en más de
5000 comunidades en EE.UU. y las policías locales usan el sistema
nacional para realizar búsquedas el ICE.</p>
<p><br></p>
<p><a
href="https://www.404media.co/ice-accede-a-una-red-nacional-de-camaras-con-inteligencia-artificial-segun-datos/"
class="uri">https://www.404media.co/ice-accede-a-una-red-nacional-de-camaras-con-inteligencia-artificial-segun-datos/</a></p>
<hr />
<h2
id="un-vistazo-a-la-base-de-datos-del-ice-que-busca-comentarios-despectivos-en-línea">Un
vistazo a la base de datos del ICE que busca comentarios “despectivos”
en línea</h2>
<p>date: 2025-07-22, from: 404 Media Group</p>
<p>¿Positivo o negativo? Esas son las opciones que tienen los analistas
cuando la herramienta Giant Oak Search Technology desentierra el
contenido publicado en redes sociales y otras fuentes para que el ICE lo
analice.</p>
<p><br></p>
<p><a
href="https://www.404media.co/un-vistazo-a-la-base-de-datos-del-ice-que-busca-comentarios-despectivos-en-linea/"
class="uri">https://www.404media.co/un-vistazo-a-la-base-de-datos-del-ice-que-busca-comentarios-despectivos-en-linea/</a></p>
<hr />
<h2
id="manifiestos-de-vuelo-revelan-que-casi-40-personas-no-identificadas-fueron-enviadas-en-tres-vuelos-de-deportación-a-el-salvador">Manifiestos
de vuelo revelan que casi 40 personas no identificadas fueron enviadas
en tres vuelos de deportación a El Salvador</h2>
<p>date: 2025-07-22, from: 404 Media Group</p>
<p>Información filtrada mediante hackeos y obtenida por 404 Media revela
que en los vuelos de deportación a El Salvador hubo decenas de personas
adicionales no registradas oficialmente.</p>
<p><br></p>
<p><a
href="https://www.404media.co/manifiestos-de-vuelo-revelan-que-casi-40-personas-no-identificadas-fueron-enviadas-en-tres-vuelos-de-deportacion-a-el-salvador/"
class="uri">https://www.404media.co/manifiestos-de-vuelo-revelan-que-casi-40-personas-no-identificadas-fueron-enviadas-en-tres-vuelos-de-deportacion-a-el-salvador/</a></p>
<hr />
<h2
id="la-herramienta-de-vigilancia-con-inteligencia-artificial-que-usa-el-dhs-para-detectar-sentimientos-y-emociones">La
herramienta de vigilancia con inteligencia artificial que usa el DHS
para detectar “sentimientos y emociones”</h2>
<p>date: 2025-07-22, from: 404 Media Group</p>
<p>Documentos internos del DHS revelan su colaboración con Fivecast, una
empresa que ofrece el servicio de “detección de términos y frases de
riesgo encontrados en línea”.</p>
<p><br></p>
<p><a
href="https://www.404media.co/la-herramienta-de-vigilancia-con-inteligencia-artificial-que-usa-el-dhs-para-detectar-sentimientos-y-emociones/"
class="uri">https://www.404media.co/la-herramienta-de-vigilancia-con-inteligencia-artificial-que-usa-el-dhs-para-detectar-sentimientos-y-emociones/</a></p>
<hr />
<h2
id="un-vistazo-a-la-colosal-base-de-datos-que-usa-el-ice-para-identificar-y-deportar-personas">Un
vistazo a la colosal base de datos que usa el ICE para identificar y
deportar personas</h2>
<p>date: 2025-07-22, from: 404 Media Group</p>
<p>La base de datos permite crear filtros según cientos de categorías
distintas, incluidos estatus migratorio, “características físicas
específicas” (cicatrices, marcas, tatuajes), “afiliación criminal”;
datos de lectores de patentes y más.</p>
<p><br></p>
<p><a
href="https://www.404media.co/un-vistazo-a-la-colosal-base-de-datos-que-usa-el-ice-para-identificar-y-deportar-personas/"
class="uri">https://www.404media.co/un-vistazo-a-la-colosal-base-de-datos-que-usa-el-ice-para-identificar-y-deportar-personas/</a></p>
<hr />
<h2
id="los-más-de-200-sitios-que-monitorea-un-contratista-de-vigilancia-de-ice">Los
más de 200 sitios que monitorea un contratista de vigilancia de ICE</h2>
<p>date: 2025-07-22, from: 404 Media Group</p>
<p>404 Media obtuvo la lista de páginas y servicios desde donde el
contratista ShadowDragon extrae datos. Su herramienta permite a
analistas del gobierno analizar la información para encontrar vínculos
entre personas.</p>
<p><br></p>
<p><a
href="https://www.404media.co/los-mas-de-200-sitios-que-monitorea-un-contratista-de-vigilancia-de-ice/"
class="uri">https://www.404media.co/los-mas-de-200-sitios-que-monitorea-un-contratista-de-vigilancia-de-ice/</a></p>
<hr />
<h2 id="section"></h2>
<pre><code>            Lamenting contemporary bright UIs
        </code></pre>
<p>date: 2025-07-22, updated: 2025-07-22, from: Uninformative blog</p>
<p><br></p>
<p><a
href="https://www.uninformativ.de/blog/postings/2025-07-22/0/POSTING-en.html"
class="uri">https://www.uninformativ.de/blog/postings/2025-07-22/0/POSTING-en.html</a></p>
<hr />
<h2 id="has-brazil-invented-the-future-of-money">Has Brazil Invented the
Future of Money?</h2>
<p>date: 2025-07-22, from: Paul Krugman</p>
<p>And will it ever come to America?</p>
<p><br></p>
<p><a
href="https://paulkrugman.substack.com/p/has-brazil-invented-the-future-of"
class="uri">https://paulkrugman.substack.com/p/has-brazil-invented-the-future-of</a></p>
<hr />
<h2 id="textual-v4.0.0-the-streaming-release">Textual v4.0.0: The
Streaming Release</h2>
<p>date: 2025-07-22, updated: 2025-07-22, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://github.com/Textualize/textual/releases/tag/v4.0.0">Textual
v4.0.0: The Streaming Release</a></strong>
</p>
Will McGugan may
<a href="https://textual.textualize.io/blog/2025/05/07/the-future-of-textualize/">no
longer be running</a> a commercial company around Textual, but that
hasn’t stopped his progress on the open source project.
</p>
<p>
He recently released v4 of his Python framework for building TUI
command-line apps, and the signature feature is
<a href="https://github.com/Textualize/textual/pull/5950">streaming
Markdown support</a> - super relevant in our current age of LLMs, most
of which default to outputting a stream of Markdown via their APIs.
</p>
<p>
I took an example
<a href="https://github.com/Textualize/textual/blob/03b94706399f110ff93fa396d4afbc79c3738638/tests/snapshot_tests/test_snapshots.py#L4378-L4400">from
one of his tests</a>, spliced in my
<a href="https://llm.datasette.io/en/stable/python-api.html#async-models">async
LLM Python library</a> and
<a href="https://chatgpt.com/share/687c3a6a-4e1c-8006-83a2-706b4bf04067">got
some help from o3</a> to turn it into
<a href="https://github.com/simonw/tools/blob/916b16cd7dfd3c23315d0a4ed02172878feafa45/python/streaming_textual_markdown.py">a
streaming script</a> for talking to models, which can be run like this:
</p>
<pre><code>uv run http://tools.simonwillison.net/python/streaming_textual_markdown.py \
'Markdown headers and tables comparing pelicans and wolves' \
-m gpt-4.1-mini
</code></pre>
<p>
<p><img alt="Running that prompt streams a Markdown table to my console." src="https://static.simonwillison.net/static/2025/epic-table.gif" /></p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/async&quot;&gt;async&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/python&quot;&gt;python&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/markdown&quot;&gt;markdown&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/will-mcgugan&quot;&gt;will-mcgugan&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/textual&quot;&gt;textual&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llm&quot;&gt;llm&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/uv&quot;&gt;uv&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/22/textual-v4/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/22/textual-v4/#atom-everything</a></p>
<hr />
<h2 id="tidwallpogocache">tidwall/pogocache</h2>
<p>date: 2025-07-21, updated: 2025-07-21, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://github.com/tidwall/pogocache">tidwall/pogocache</a></strong>
</p>
New project from Josh Baker, author of the excellent <code>tg</code> C
geospatial libarry
(<a href="https://simonwillison.net/2023/Sep/23/tg-polygon-indexing/">covered
previously</a>) and various other
<a href="https://github.com/tidwall">interesting projects</a>:
</p>
<blockquote>
<p>
Pogocache is fast caching software built from scratch with a focus on
low latency and cpu efficency.
</p>
<p>
Faster: Pogocache is faster than Memcache, Valkey, Redis, Dragonfly, and
Garnet. It has the lowest latency per request, providing the quickest
response times. It’s optimized to scale from one to many cores, giving
you the best single-threaded and multithreaded performance.
</p>
</blockquote>
<p>
Faster than Memcache and Redis is a big claim! The README includes a
<a href="https://github.com/tidwall/pogocache/blob/main/README.md#design-details">design
details</a> section that explains how the system achieves that
performance, using a sharded hashmap inspired by Josh’s
<a href="https://github.com/tidwall/shardmap">shardmap</a> project and
clever application of threads.
</p>
<p>
Performance aside, the most interesting thing about Pogocache is the
server interface it provides: it emulates the APIs for Redis and
Memcached, provides a simple HTTP API <em>and</em> lets you talk to it
over the PostgreSQL wire protocol as well!
</p>
<pre><code>psql -h localhost -p 9401
=&gt; SET first Tom;
=&gt; SET last Anderson;
=&gt; SET age 37;

$ curl http://localhost:9401/last
Anderson
</code></pre>
<pre><code>&lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href=&quot;https://news.ycombinator.com/item?id=44638076&quot;&gt;Show HN&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/c&quot;&gt;c&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/caching&quot;&gt;caching&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/http&quot;&gt;http&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/memcached&quot;&gt;memcached&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/postgresql&quot;&gt;postgresql&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/redis&quot;&gt;redis&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/21/pogocache/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/21/pogocache/#atom-everything</a></p>
<hr />
<p><strong><span class="citation"
data-cites="Tomosino">@Tomosino</span>’s Mastodon feed</strong> (date:
2025-07-21, from: Tomosino’s Mastodon feed)</p>
<p>
I’m also exploring a new way of handling syllabification: breaking long
words into proper chunks. My old method with fancy regex was not
extending to many language groups well. I think with a different method
I can add support for about 40 languages.
</p>
<p><br></p>
<p><a href="https://tilde.zone/@tomasino/114893907354587336"
class="uri">https://tilde.zone/@tomasino/114893907354587336</a></p>
<hr />
<p><strong><span class="citation"
data-cites="Tomosino">@Tomosino</span>’s Mastodon feed</strong> (date:
2025-07-21, from: Tomosino’s Mastodon feed)</p>
<p>
I’m going to add a feature to my RSVP browser add-on,
<a href="https://ino.is/stutter" target="_blank" rel="nofollow noopener">Stutter</a>.
My own experience mirrors recent research into reading retention,
reading speed, and cognitive load of material. I’ll be adding an
optional feature (English only for now) to auto adjust RSVP speed based
on text complexity. Over got 7 different measures and I’m exploring
weighting to get the right feel. This is thrilling!
</p>
<p>
Research:
</p>
<p>
<strong>Just, M. A., &amp; Carpenter, P. A. (1980).</strong><br><br>A
theory of reading: From eye fixations to comprehension.
<em>Psychological Review, 87</em>(4), 329–354.
<a href="https://doi.org/10.1037/0033-295X.87.4.329" target="_blank" rel="nofollow noopener" translate="no"><span
class="invisible">https://</span><span
class="ellipsis">doi.org/10.1037/0033-295X.87.4</span><span
class="invisible">.329</span></a>
</p>
<p>
<strong>Liversedge, S. P., &amp; Findlay, J. M.
(2000).</strong><br><br>Saccadic eye movements and cognition during
reading. <em>Trends in Cognitive Sciences, 4</em>(1), 6–14.
<a href="https://doi.org/10.1016/S1364-6613(99)01418-7" target="_blank" rel="nofollow noopener" translate="no"><span
class="invisible">https://</span><span
class="ellipsis">doi.org/10.1016/S1364-6613(99)</span><span
class="invisible">01418-7</span></a>
</p>
<p>
<strong>Paas, F., &amp; Sweller, J. (2014).</strong><br><br>Implications
of cognitive load theory for multimedia learning. In J. M. Spector, B.
B. Lockee, &amp; M. D. Childress (Eds.), <em>Cognitive load theory</em>
(pp. 27–42). Springer.
<a href="https://doi.org/10.1007/978-1-4614-5529-2_3" target="_blank" rel="nofollow noopener" translate="no"><span
class="invisible">https://</span><span
class="ellipsis">doi.org/10.1007/978-1-4614-552</span><span
class="invisible">9-2_3</span></a>
</p>
<p>
<strong>Potter, M. C. (1984).</strong><br><br>Rapid serial visual
presentation (RSVP): A method for studying language processing. In D. E.
Kieras &amp; M. A. Just (Eds.), <em>New methods in reading comprehension
research</em> (pp. 91–118). Erlbaum.
</p>
<p>
<strong>Rayner, K., Schotter, E. R., Masson, M. E. J., Potter, M. C.,
&amp; Treiman, R. (2016).</strong><br><br>So much to read, so little
time: How do we read, and can speed reading help? <em>Psychological
Science in the Public Interest, 17</em>(1), 4–34.
<a href="https://doi.org/10.1177/1529100615616466" target="_blank" rel="nofollow noopener" translate="no"><span
class="invisible">https://</span><span
class="ellipsis">doi.org/10.1177/15291006156164</span><span
class="invisible">66</span></a>
</p>
<p>
<strong>van der Sluis, F., van Dijk, B., Hoedemaker, R., &amp;
Schraagen, J. M. (2016).</strong><br><br>Dynamic reading speeds for
optimizing reading efficiency with increasing text complexity.
<em>Computers in Human Behavior, 62</em>, 425–435.
<a href="https://doi.org/10.1016/j.chb.2016.04.022" target="_blank" rel="nofollow noopener" translate="no"><span
class="invisible">https://</span><span
class="ellipsis">doi.org/10.1016/j.chb.2016.04.</span><span
class="invisible">022</span></a>
</p>
<p><br></p>
<p><a href="https://tilde.zone/@tomasino/114893890999895817"
class="uri">https://tilde.zone/@tomasino/114893890999895817</a></p>
<hr />
<h2
id="lilbits-hello-google-pixel-10-goodbye-clear-linux-and-kobo-adds-instapaper-integration">Lilbits:
Hello Google Pixel 10, Goodbye Clear Linux, and Kobo adds Instapaper
integration</h2>
<p>date: 2025-07-21, from: Liliputing</p>
<p>
Mozilla recently pulled the plug on bookmarking/read-it-later service
Pocket. And that’s left some folks scrambling to find alternatives –
including folks that were using devices with baked-in support for
Pocket, like Kobo eReaders. Now Kobo has announced it’s bringing
Instapaper integration to its devices – and since Instapaper makes it
easy to migrate your data […]
</p>
<p>
The post
<a href="https://liliputing.com/lilbits-hello-google-pixel-10-goodbye-clear-linux-and-kobo-adds-instapaper-integration/">Lilbits:
Hello Google Pixel 10, Goodbye Clear Linux, and Kobo adds Instapaper
integration</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/lilbits-hello-google-pixel-10-goodbye-clear-linux-and-kobo-adds-instapaper-integration/"
class="uri">https://liliputing.com/lilbits-hello-google-pixel-10-goodbye-clear-linux-and-kobo-adds-instapaper-integration/</a></p>
<hr />
<h2
id="trmnl-7.5-og-diy-kit-is-a-battery-powered-45-e-ink-display-with-wifi-a-battery-and-dozens-of-software-plugins">TRMNL
7.5″ (OG) DIY Kit is a battery-powered $45 E Ink display with WiFi, a
battery, and dozens of software plugins</h2>
<p>date: 2025-07-21, from: Liliputing</p>
<p>
TRMNL sells a $139 small E Ink display that you can use to show news
updates, weather forecasts, calendar appointments, photos, or all sorts
of other content. But TRMNL isn’t just a hardware company – the team
also makes the open source software that runs on that device, and even
shares information on how to […]
</p>
<p>
The post
<a href="https://liliputing.com/trmnl-7-5-og-diy-kit-is-a-battery-powered-36-e-ink-display-with-wifi-a-battery-and-dozens-of-software-plugins/">TRMNL
7.5″ (OG) DIY Kit is a battery-powered $45 E Ink display with WiFi, a
battery, and dozens of software plugins</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/trmnl-7-5-og-diy-kit-is-a-battery-powered-36-e-ink-display-with-wifi-a-battery-and-dozens-of-software-plugins/"
class="uri">https://liliputing.com/trmnl-7-5-og-diy-kit-is-a-battery-powered-36-e-ink-display-with-wifi-a-battery-and-dozens-of-software-plugins/</a></p>
<hr />
<h2 id="using-a-macbook-trackpad-as-a-scale">Using a MacBook Trackpad As
a Scale</h2>
<p>date: 2025-07-21, from: Michael Tsai</p>
<p>Krish Shah (via Hacker News): TrackWeight is a macOS application that
transforms your MacBook’s trackpad into an accurate weighing scale by
leveraging the Force Touch pressure sensors built into modern MacBook
trackpads.[…]TrackWeight utilizes the Open Multi-Touch Support library
by Takuto Nakamura to gain private access to all mouse and trackpad
events on macOS. This library […]</p>
<p><br></p>
<p><a
href="https://mjtsai.com/blog/2025/07/21/using-a-macbook-trackpad-as-a-scale/"
class="uri">https://mjtsai.com/blog/2025/07/21/using-a-macbook-trackpad-as-a-scale/</a></p>
<hr />
<h2 id="uk-backing-down-on-apple-encryption-backdoor">UK Backing Down on
Apple Encryption Backdoor</h2>
<p>date: 2025-07-21, from: Michael Tsai</p>
<p>Anna Gross, Tim Bradshaw, and Lauren Fedor (Hacker News, MacRumors):
The officials both said the Home Office, which ordered the tech giant in
January to grant access to its most secure cloud storage system, would
probably have to retreat in the face of pressure from senior leaders in
Washington, including Vice President JD Vance. […] […]</p>
<p><br></p>
<p><a
href="https://mjtsai.com/blog/2025/07/21/uk-backing-down-on-apple-encryption-backdoor/"
class="uri">https://mjtsai.com/blog/2025/07/21/uk-backing-down-on-apple-encryption-backdoor/</a></p>
<hr />
<h2 id="spotlight-indexing-running-wild">Spotlight Indexing Running
Wild</h2>
<p>date: 2025-07-21, from: Michael Tsai</p>
<p>Jenny Zeng (via John Gordon): Several users have reported a bug on
macOS Sequoia regarding Spotlight indexing writing a huge amount of
data. Consequently, they are experiencing a large System Data on Mac and
rapid SSD wear. She recommends deleting /.Spotlight-V100 and
~/Library/Metadata/CoreSpotlight. I’ve always use mdutil to reset
Spotlight, but I’ve now seen several […]</p>
<p><br></p>
<p><a
href="https://mjtsai.com/blog/2025/07/21/spotlight-indexing-running-wild/"
class="uri">https://mjtsai.com/blog/2025/07/21/spotlight-indexing-running-wild/</a></p>
<hr />
<h2 id="usb-c-hubs-and-my-slow-descent-into-madness">USB-C Hubs and My
Slow Descent Into Madness</h2>
<p>date: 2025-07-21, from: Michael Tsai</p>
<p>Dennis Schubert (2021, via Hacker News): I have one of those laptops
lacking a lot of accessory ports. In fact, I’m writing this on an Apple
MacBook Pro, and all I got was four lousy USB-C ports. If I want to
connect pretty much anything, I need some sort of adapter or some sort
of […]</p>
<p><br></p>
<p><a
href="https://mjtsai.com/blog/2025/07/21/usb-c-hubs-and-my-slow-descent-into-madness/"
class="uri">https://mjtsai.com/blog/2025/07/21/usb-c-hubs-and-my-slow-descent-into-madness/</a></p>
<hr />
<h2
id="advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad">Advanced
version of Gemini with Deep Think officially achieves gold-medal
standard at the International Mathematical Olympiad</h2>
<p>date: 2025-07-21, updated: 2025-07-21, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://deepmind.google/discover/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/">Advanced
version of Gemini with Deep Think officially achieves gold-medal
standard at the International Mathematical Olympiad</a></strong>
</p>
OpenAI beat them to the punch in terms of publicity by
<a href="https://simonwillison.net/2025/Jul/19/openai-gold-medal-math-olympiad/">publishing
their results on Saturday</a>, but a team from Google Gemini achieved an
equally impressive result on this year’s International Mathematics
Olympiad scoring a gold medal performance with their custom research
model.
</p>
<p>
(I saw an unconfirmed rumor that the Gemini team had to wait until
Monday for approval from Google PR - this turns out to be inaccurate,
see update below.)
</p>
<p>
It’s interesting that Gemini achieved the <em>exact same score</em> as
OpenAI, 35/42, and were able to solve the same set of questions - 1
through 5, failing only to answer 6, which is designed to be the hardest
question.
</p>
<p>
Each question is worth seven points, so 35/42 cents corresponds to full
marks on five out of the six problems.
</p>
<p>
Only 6 of
<a href="https://www.imo-official.org/year_individual_r.aspx?year=2025">the
630 human contestants</a> this year scored all 7 points for question 6
this year, and just 55 more had greater than 0 points for that question.
</p>
<p>
OpenAI claimed their model had not been optimized for IMO questions.
Gemini’s model was different - emphasis mine:
</p>
<blockquote>
<p>
We achieved this year’s result using an advanced version of Gemini Deep
Think – an enhanced reasoning mode for complex problems that
incorporates some of our latest research techniques, including parallel
thinking. This setup enables the model to simultaneously explore and
combine multiple possible solutions before giving a final answer, rather
than pursuing a single, linear chain of thought.
</p>
<p>
To make the most of the reasoning capabilities of Deep Think, we
additionally trained this version of Gemini on novel reinforcement
learning techniques that can leverage more multi-step reasoning,
problem-solving and theorem-proving data. <strong>We also provided
Gemini with access to a curated corpus of high-quality solutions to
mathematics problems, and added some general hints and tips on how to
approach IMO problems to its instructions</strong>.
</p>
</blockquote>
<p>
The Gemini team, like the OpenAI team, achieved this result with
<a href="https://x.com/fredzhang0/status/1947364744412758305">no tool
use or internet access</a> for the model.
</p>
<p>
Gemini’s solutions are listed
<a href="https://storage.googleapis.com/deepmind-media/gemini/IMO_2025.pdf">in
this PDF</a>. If you are mathematically inclined you can compare them
with OpenAI’s solutions
<a href="https://github.com/aw31/openai-imo-2025-proofs/">on GitHub</a>.
</p>
<p>
Last year Google DeepMind
<a href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/">achieved
a silver medal in IMO</a>, solving four of the six problems using custom
models called AlphaProof and AlphaGeometry 2:
</p>
<blockquote>
<p>
First, the problems were manually translated into formal mathematical
language for our systems to understand. In the official competition,
students submit answers in two sessions of 4.5 hours each. Our systems
solved one problem within minutes and took up to three days to solve the
others.
</p>
</blockquote>
<p>
This year’s result, scoring gold with a single model, within the
allotted time and with no manual step to translate the problems first,
is much more impressive.
</p>
<p>
<strong>Update</strong>: Concerning the timing of the news, DeepMind CEO
Demis Hassabis
<a href="https://x.com/demishassabis/status/1947337618787615175">says</a>:
</p>
<blockquote>
<p>
Btw as an aside, we didn’t announce on Friday because we respected the
IMO Board’s original request that all AI labs share their results only
after the official results had been verified by independent experts
&amp; the students had rightly received the acclamation they deserved
</p>
<p>
We’ve now been given permission to share our results and are pleased to
have been part of the inaugural cohort to have our model results
officially graded and certified by IMO coordinators and experts,
receiving the first official gold-level performance grading for an AI
system!
</p>
</blockquote>
<p>
OpenAI’s
<a href="https://x.com/polynoamial/status/1947398538662437306">Noam
Brown</a>:
</p>
<blockquote>
<p>
Before we shared our results, we spoke with an IMO board member, who
asked us to wait until after the award ceremony to make it public, a
request we happily honored.
</p>
<p>
We announced at ~1am PT (6pm AEST), after the award ceremony concluded.
At no point did anyone request that we announce later than that.
</p>
</blockquote>
<p>
As far as I can tell the Gemini team was participating in an official
capacity, while OpenAI were not.
<a href="https://x.com/polynoamial/status/1947398532899738064">Noam
again</a>:
</p>
<blockquote>
<p>
~2 months ago, the IMO emailed us about participating in a formal (Lean)
version of the IMO. We’ve been focused on general reasoning in natural
language without the constraints of Lean, so we declined. We were never
approached about a natural language math option.
</p>
</blockquote>
<p>
<p>Neither OpenAI nor Gemini used
<a href="https://en.m.wikipedia.org/wiki/Lean_(proof_assistant)">Lean</a>
in their attempts, which would have counted as tool use.</p>
<pre><code>&lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href=&quot;https://news.ycombinator.com/item?id=44637191&quot;&gt;Hacker News&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/mathematics&quot;&gt;mathematics&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/openai&quot;&gt;openai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/gemini&quot;&gt;gemini&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llm-reasoning&quot;&gt;llm-reasoning&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/21/gemini-imo/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/21/gemini-imo/#atom-everything</a></p>
<hr />
<h2
id="argon-one-up-is-modular-laptop-powered-by-a-raspberry-pi-cm5">Argon
ONE UP is modular laptop powered by a Raspberry Pi CM5</h2>
<p>date: 2025-07-21, from: Liliputing</p>
<p>
The makers of the Argon ONE line of accessories for Raspberry Pi
computers have built a business around designing cases that add or
change some key functions of the little computers by, for example,
moving all of the ports to one side. But the upcoming Argon ONE UP takes
things to the next level. It’s a laptop computer […]
</p>
<p>
The post
<a href="https://liliputing.com/argon-one-up-is-modular-laptop-powered-by-a-raspberry-pi-cm5/">Argon
ONE UP is modular laptop powered by a Raspberry Pi CM5</a> appeared
first on <a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/argon-one-up-is-modular-laptop-powered-by-a-raspberry-pi-cm5/"
class="uri">https://liliputing.com/argon-one-up-is-modular-laptop-powered-by-a-raspberry-pi-cm5/</a></p>
<hr />
<h2
id="spotify-publishes-ai-generated-songs-from-dead-artists-without-permission">Spotify
Publishes AI-Generated Songs From Dead Artists Without Permission</h2>
<p>date: 2025-07-21, from: 404 Media Group</p>
<p>“They could fix this problem. One of their talented software
engineers could stop this fraudulent practice in its tracks, if they had
the will to do so.”</p>
<p><br></p>
<p><a
href="https://www.404media.co/spotify-publishes-ai-generated-songs-from-dead-artists-without-permission/"
class="uri">https://www.404media.co/spotify-publishes-ai-generated-songs-from-dead-artists-without-permission/</a></p>
<hr />
<h2
id="minisforum-m1-pro-mini-pc-comes-with-intel-meteor-lake-and-arrow-lake-options">MINISFORUM
M1 Pro mini PC comes with Intel Meteor Lake and Arrow Lake options</h2>
<p>date: 2025-07-21, from: Liliputing</p>
<p>
Mini PC makers often offer several different processor options so that
customers can decide whether to prioritize price, performance, or some
mix of the two. But usually those processor options are all part of the
same family. The MINISFORUM M1 Pro bucks that trend. Customers
interested in picking up an entry-level model can pay $383 for […]
</p>
<p>
The post
<a href="https://liliputing.com/minisforum-m1-pro-mini-pc-comes-with-intel-meteor-lake-and-arrow-lake-options/">MINISFORUM
M1 Pro mini PC comes with Intel Meteor Lake and Arrow Lake options</a>
appeared first on <a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/minisforum-m1-pro-mini-pc-comes-with-intel-meteor-lake-and-arrow-lake-options/"
class="uri">https://liliputing.com/minisforum-m1-pro-mini-pc-comes-with-intel-meteor-lake-and-arrow-lake-options/</a></p>
<hr />
<h2 id="why-murdoch-doesnt-give-a-toss-about-trump">Why Murdoch Doesn’t
Give a Toss About Trump</h2>
<p>date: 2025-07-21, from: Tina Brown</p>
<p>What rich irony that the defense against the latest assault by Trump
on press freedom is now in the hands of old crocodile Rupert Murdoch,
the very media owner whose Fox News gave us Trump in the first
place.</p>
<p><br></p>
<p><a
href="https://tinabrown.substack.com/p/why-murdoch-doesnt-give-a-toss-about"
class="uri">https://tinabrown.substack.com/p/why-murdoch-doesnt-give-a-toss-about</a></p>
<hr />
<h2 id="the-game-genie-generation">The Game Genie Generation</h2>
<p>date: 2025-07-21, updated: 2025-07-21, from: Tedium site</p>
<p>For an unlicensed game accessory, the Game Genie sure casts a long
shadow. It reshaped the games we already owned—and had a profound effect
on copyright law.</p>
<p><br></p>
<p><a
href="https://feed.tedium.co/link/15204/17101139/the-game-genie-generation"
class="uri">https://feed.tedium.co/link/15204/17101139/the-game-genie-generation</a></p>
<hr />
<h2
id="the-nih-is-capping-research-proposals-because-its-overwhelmed-by-ai-submissions">The
NIH Is Capping Research Proposals Because It’s Overwhelmed by AI
Submissions</h2>
<p>date: 2025-07-21, from: 404 Media Group</p>
<p>The NIH wrote that it has recently “observed instances of Principal
Investigators submitting large numbers of applications, some of which
may have been generated with AI tools.”</p>
<p><br></p>
<p><a
href="https://www.404media.co/nih-capping-research-applications-ai/"
class="uri">https://www.404media.co/nih-capping-research-applications-ai/</a></p>
<hr />
<h2
id="onexsugar-sugar-1-handheld-game-console-hits-indiegogo-for-599-dual-screen-android-handheld-game-console-with-a-convertible-design">ONEXSUGAR
Sugar 1 handheld game console hits Indiegogo for $599 (Dual-screen
Android handheld game console with a convertible design)</h2>
<p>date: 2025-07-21, from: Liliputing</p>
<p>
The ONEXSUGAR Sugar 1 is an unusual handheld game console thanks to a
convertible design that lets you use it as either a single-screen device
with a 6.01 inch FHD+ OLED display or as a dual-screen handheld with a
second 3.92 OLED display below the primary screen. In other words, this
Android-powered handheld is sort of […]
</p>
<p>
The post
<a href="https://liliputing.com/onexsugar-sugar-1-handheld-game-console-hits-indiegogo-for-599-dual-screen-android-handheld-game-console-with-a-convertible-design/">ONEXSUGAR
Sugar 1 handheld game console hits Indiegogo for $599 (Dual-screen
Android handheld game console with a convertible design)</a> appeared
first on <a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/onexsugar-sugar-1-handheld-game-console-hits-indiegogo-for-599-dual-screen-android-handheld-game-console-with-a-convertible-design/"
class="uri">https://liliputing.com/onexsugar-sugar-1-handheld-game-console-hits-indiegogo-for-599-dual-screen-android-handheld-game-console-with-a-convertible-design/</a></p>
<hr />
<h2 id="black-mirror-clasificación-oficial-de-sus-capítulos">Black
Mirror: clasificación oficial de sus capítulos</h2>
<p>date: 2025-07-21, from: Iván Paredes Reséndiz blog, Mexico’s
cinema</p>
<p>
Desde su estreno en la cadena de televisión británica Channel 4 por allá
en 2011 hasta su eventual adquisición por Netflix en 2015, Black Mirror
se ha convertido en una de las series más populares bajo un formato de
capítulos que funcionan de manera independiente y que plantean fantasías
distópicas en las que la tecnología […]
</p>
<p>
La entrada
<a href="https://www.palomitademaiz.net/black-mirror-clasificacion-oficial-de-sus-capitulos/">Black
Mirror: clasificación oficial de sus capítulos</a> se publicó primero en
<a href="https://www.palomitademaiz.net">Palomita de maíz</a>.
</p>
<p><br></p>
<p><a
href="https://www.palomitademaiz.net/black-mirror-clasificacion-oficial-de-sus-capitulos/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=black-mirror-clasificacion-oficial-de-sus-capitulos"
class="uri">https://www.palomitademaiz.net/black-mirror-clasificacion-oficial-de-sus-capitulos/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=black-mirror-clasificacion-oficial-de-sus-capitulos</a></p>
<hr />
<h2 id="fast-fashion-price-surge-for-americans">Fast Fashion Price Surge
for Americans</h2>
<p>date: 2025-07-21, from: Guy Kawasaki blog</p>
<p>Vivek Astvansh, Associate Professor of Quantitative Marketing and
Analytics, McGill University.</p>
<p><br></p>
<p><a
href="https://guykawasaki.substack.com/p/fast-fashion-price-surge-for-americans"
class="uri">https://guykawasaki.substack.com/p/fast-fashion-price-surge-for-americans</a></p>
<hr />
<p><strong><span class="citation" data-cites="Robert">@Robert</span>’s
feed at BlueSky</strong> (date: 2025-07-21, from: Robert’s feed at
BlueSky)</p>
<p>Intrigued.</p>
<p>[contains quote post or other embedded content]</p>
<p><br></p>
<p><a
href="https://bsky.app/profile/rsdoiel.bsky.social/post/3luica2xrw227"
class="uri">https://bsky.app/profile/rsdoiel.bsky.social/post/3luica2xrw227</a></p>
<hr />
<p><strong><span class="citation" data-cites="Robert">@Robert</span>’s
feed at BlueSky</strong> (date: 2025-07-21, from: Robert’s feed at
BlueSky)</p>
<p>Queue the suspense theme music.</p>
<p>[contains quote post or other embedded content]</p>
<p><br></p>
<p><a
href="https://bsky.app/profile/rsdoiel.bsky.social/post/3luic7ghd3c27"
class="uri">https://bsky.app/profile/rsdoiel.bsky.social/post/3luic7ghd3c27</a></p>
<hr />
<h2 id="quoting-daniel-litt">Quoting Daniel Litt</h2>
<p>date: 2025-07-21, updated: 2025-07-21, from: Simon Willison’s
Weblog</p>
<blockquote cite="https://x.com/littmath/status/1946987909439017108">
<p>
An AI tool that
<a href="https://simonwillison.net/2025/Jul/19/openai-gold-medal-math-olympiad/">gets
gold on the IMO</a> is obviously immensely impressive. Does it mean math
is “solved”? Is an AI-generated proof of the Riemann hypothesis clearly
on the horizon? Obviously not.
</p>
<p>
Worth keeping timescales in mind here: IMO competitors spend an average
of 1.5 hrs on each problem. High-quality math research, by contrast,
takes month or years.
</p>
<p>
What are the obstructions to AI performing high-quality autonomous math
research? I don’t claim to know for sure, but I think they include many
of the same obstructions that prevent it from doing many jobs: Long
context, long-term planning, consistency, unclear rewards, lack of
training data, etc.
</p>
<p>
It’s possible that some or all of these will be solved soon (or have
been solved) but I think it’s worth being cautious about over-indexing
on recent (amazing) progress.
</p>
</blockquote>
<p class="cite">
— <a href="https://x.com/littmath/status/1946987909439017108">Daniel
Litt</a>, Assistant Professor of mathematics, University of Toronto
</p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/mathematics&quot;&gt;mathematics&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/daniel-litt&quot;&gt;daniel-litt&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/21/daniel-litt/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/21/daniel-litt/#atom-everything</a></p>
<hr />
<h2
id="is-googles-ai-reading-your-private-messages-why-its-time-to-consider-a-secure-alternative">Is
Google’s AI Reading Your Private Messages? Why It’s Time to Consider a
Secure Alternative</h2>
<p>date: 2025-07-21, from: Purism News and Events</p>
<p>
On July 7, 2025, MSM ( Is Google’s AI secretly reading your private
texts? Here’s what’s really happening—and how to stop it before it’s too
late ) reported that Google silently activated a controversial update:
its Gemini AI began scanning popular third-party apps like WhatsApp and
Messages on Android devices.
</p>
<p>
The post
<a rel="nofollow" href="https://puri.sm/posts/is-googles-ai-reading-your-private-messages-why-its-time-to-consider-a-secure-alternative/">Is
Google’s AI Reading Your Private Messages? Why It’s Time to Consider a
Secure Alternative</a> appeared first on
<a rel="nofollow" href="https://puri.sm/">Purism</a>.
</p>
<p><br></p>
<p><a
href="https://puri.sm/posts/is-googles-ai-reading-your-private-messages-why-its-time-to-consider-a-secure-alternative/"
class="uri">https://puri.sm/posts/is-googles-ai-reading-your-private-messages-why-its-time-to-consider-a-secure-alternative/</a></p>
<hr />
<h2 id="maker-monday-featuring-your-excellent-raspberry-pi-builds">Maker
Monday featuring your excellent Raspberry Pi builds</h2>
<p>date: 2025-07-21, from: Raspberry Pi News (.com)</p>
<p>
Follow along with #MakerMonday each week over on our social media
platforms to see tons of creative Raspberry Pi builds.
</p>
<p>
The post
<a href="https://www.raspberrypi.com/news/maker-monday-featuring-your-excellent-raspberry-pi-builds/">Maker
Monday featuring your excellent Raspberry Pi builds</a> appeared first
on <a href="https://www.raspberrypi.com">Raspberry Pi</a>.
</p>
<p><br></p>
<p><a
href="https://www.raspberrypi.com/news/maker-monday-featuring-your-excellent-raspberry-pi-builds/"
class="uri">https://www.raspberrypi.com/news/maker-monday-featuring-your-excellent-raspberry-pi-builds/</a></p>
<hr />
<h2
id="gemini-is-strict-and-punitive-while-chatgpt-is-catastrophically-cooperative-researchers-say">Gemini
Is ‘Strict and Punitive’ While ChatGPT Is ‘Catastrophically’
Cooperative, Researchers Say</h2>
<p>date: 2025-07-21, from: 404 Media Group</p>
<p>In tests involving the Prisoner’s Dilemma, researchers found that
Google’s Gemini is “strategically ruthless,” while OpenAI is
collaborative to a “catastrophic” degree.</p>
<p><br></p>
<p><a
href="https://www.404media.co/gemini-is-strict-and-punitive-while-chatgpt-is-catastrophically-cooperative-researchers-say/"
class="uri">https://www.404media.co/gemini-is-strict-and-punitive-while-chatgpt-is-catastrophically-cooperative-researchers-say/</a></p>
<hr />
<h2 id="rümeysa-öztürk-in-her-own-words">Rümeysa Öztürk in Her Own
Words</h2>
<p>date: 2025-07-21, updated: 2025-07-21, from: One Foot Tsunami</p>
<p><br></p>
<p><a
href="https://onefoottsunami.com/2025/07/21/rumeysa-ozturk-in-her-own-words/"
class="uri">https://onefoottsunami.com/2025/07/21/rumeysa-ozturk-in-her-own-words/</a></p>
<hr />
<h2
id="a-startup-is-selling-data-hacked-from-peoples-computers-to-debt-collectors">A
Startup is Selling Data Hacked from Peoples’ Computers to Debt
Collectors</h2>
<p>date: 2025-07-21, from: 404 Media Group</p>
<p>Infostealer data can include passwords, email and billing addresses,
and the embarrassing websites you use. Farnsworth Intelligence is
selling to divorce lawyers and other industries.</p>
<p><br></p>
<p><a
href="https://www.404media.co/a-startup-is-selling-data-hacked-from-peoples-computers-to-debt-collectors/"
class="uri">https://www.404media.co/a-startup-is-selling-data-hacked-from-peoples-computers-to-debt-collectors/</a></p>
<hr />
<h2 id="how-i-write-docs-quickly">How I write docs quickly</h2>
<p>date: 2025-07-21, from: Blog by Fabrizio Ferri-Benedetti</p>
<p>
I’ve been writing documentation and technical articles for more than a
decade now. One piece of feedback I consistently got from managers and
peers during all these years is how <em>fast</em> I am when producing
and releasing docs. For example, I was once asked to document a new
feature from a team I wasn’t serving two weeks ahead of launch.
Everything was new to me, but I had most of the docs drafted after four
days. By launch, the docs had been deemed ready to go live.
</p>
<p><br></p>
<p><a href="https://passo.uno/how-write-tech-docs-quickly/"
class="uri">https://passo.uno/how-write-tech-docs-quickly/</a></p>
<hr />
<h2
id="remember-the-days-when-waiters-didnt-leave-your-food-to-go-cold-on-the-bar">REMEMBER
THE DAYS WHEN WAITERS DIDN’T LEAVE YOUR FOOD TO GO COLD ON THE BAR?</h2>
<p>date: 2025-07-21, from: Howard Jacobson blog</p>
<p>Yes, it was a hot day.</p>
<p><br></p>
<p><a
href="https://jacobsonh.substack.com/p/remember-the-days-when-waiters-didnt"
class="uri">https://jacobsonh.substack.com/p/remember-the-days-when-waiters-didnt</a></p>
<hr />
<h2
id="enshittification-and-the-bitterness-of-billionaire-bros">Enshittification
and the Bitterness of Billionaire Bros</h2>
<p>date: 2025-07-21, from: Paul Krugman</p>
<p>Hell hath no fury like a tech god scorned</p>
<p><br></p>
<p><a
href="https://paulkrugman.substack.com/p/enshittification-and-the-bitterness"
class="uri">https://paulkrugman.substack.com/p/enshittification-and-the-bitterness</a></p>
<hr />
<h2 id="coding-with-llms-in-the-summer-of-2025-an-update">Coding with
LLMs in the summer of 2025 (an update)</h2>
<p>date: 2025-07-21, updated: 2025-07-21, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://antirez.com/news/154">Coding with LLMs in the
summer of 2025 (an update)</a></strong>
</p>
Salvatore Sanfilippo describes his current AI-assisted development
workflow. He’s all-in on LLMs for code review, exploratory prototyping,
pair-design and writing “part of the code under your clear
specifications”, but warns against leaning too hard on pure vibe coding:
</p>
<blockquote>
<p>
But while LLMs can write part of a code base with success (under your
strict supervision, see later), and produce a very sensible speedup in
development (or, the ability to develop more/better in the same time
used in the past — which is what I do), when left alone with nontrivial
goals they tend to produce fragile code bases that are larger than
needed, complex, full of local minima choices, suboptimal in many ways.
Moreover they just fail completely when the task at hand is more complex
than a given level.
</p>
</blockquote>
<p>
There are plenty of useful tips in there, especially around carefully
managing your context:
</p>
<blockquote>
<p>
When your goal is to reason with an LLM about implementing or fixing
some code, you need to provide extensive information to the LLM: papers,
big parts of the target code base (all the code base if possible, unless
this is going to make the context window so large than the LLM
performances will be impaired). And a brain dump of all your
understanding of what should be done.
</p>
</blockquote>
<p>
Salvatore warns against relying too hard on tools which hide the context
for you, like editors with integrated coding agents. He prefers pasting
exactly what’s needed into the LLM web interface - I share his
preference there.
</p>
<p>
His conclusions here match
<a href="https://simonwillison.net/2025/Mar/11/using-llms-for-code/">my
experience</a>:
</p>
<blockquote>
<p>
You will be able to do things that are otherwise at the borders of your
knowledge / expertise while learning much in the process (yes, you can
learn from LLMs, as you can learn from books or colleagues: it is one of
the forms of education possible, a new one). Yet, everything produced
will follow your idea of code and product, and will be of high quality
and will not random fail because of errors and shortcomings introduced
by the LLM. You will also retain a strong understanding of all the code
written and its design.
</p>
</blockquote>
<pre><code>&lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href=&quot;https://news.ycombinator.com/item?id=44623953&quot;&gt;Hacker News&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/salvatore-sanfilippo&quot;&gt;salvatore-sanfilippo&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai-assisted-programming&quot;&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/vibe-coding&quot;&gt;vibe-coding&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/21/coding-with-llms/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/21/coding-with-llms/#atom-everything</a></p>
<hr />
<h2 id="simplifying-blogit">Simplifying BlogIt</h2>
<p>date: 2025-07-21, from: Robert’s Ramblings</p>
<p>BlogIt is a command I’ve written many times over the years. At it’s
core is did a two simple things.</p>
<ol type="1">
<li>Copy CommonMark files into a blog directory three</li>
<li>Use Front Matter as a source for aggregated blog metadata</li>
</ol>
<p>In it the new incarnation it is primarily focus on curating the front
matter followed by copying the document into the blog directory
structure.</p>
<ol type="1">
<li>Curate CommonMark file front matter</li>
<li>Copy CommonMark files into the blog directory tree</li>
</ol>
<p>Other tools can aggregate blog metadata like <a
href="https://flatlake.app">FlatLake</a>.</p>
<p><br></p>
<p><a
href="https://rsdoiel.github.io/blog/2025/07/21/Simplifying_BlogIt.html"
class="uri">https://rsdoiel.github.io/blog/2025/07/21/Simplifying_BlogIt.html</a></p>
<hr />
<p><strong><span class="citation" data-cites="Robert">@Robert</span>’s
feed at BlueSky</strong> (date: 2025-07-20, from: Robert’s feed at
BlueSky)</p>
<p>Interesting article about bentwood boxes.
https://www.cbc.ca/news/canada/north/tlingit-artist-bentwood-box-1.7587939?cmp=rss</p>
<p><br></p>
<p><a
href="https://bsky.app/profile/rsdoiel.bsky.social/post/3lugk7ato722l"
class="uri">https://bsky.app/profile/rsdoiel.bsky.social/post/3lugk7ato722l</a></p>
<hr />
<p><strong><span class="citation" data-cites="Robert">@Robert</span>’s
feed at BlueSky</strong> (date: 2025-07-20, from: Robert’s feed at
BlueSky)</p>
<p>👇</p>
<p>[contains quote post or other embedded content]</p>
<p><br></p>
<p><a
href="https://bsky.app/profile/rsdoiel.bsky.social/post/3lufx45yi6k25"
class="uri">https://bsky.app/profile/rsdoiel.bsky.social/post/3lufx45yi6k25</a></p>
<hr />
<p><strong><span class="citation" data-cites="Robert">@Robert</span>’s
feed at BlueSky</strong> (date: 2025-07-20, from: Robert’s feed at
BlueSky)</p>
<p>No measurements, no problem?</p>
<p>[contains quote post or other embedded content]</p>
<p><br></p>
<p><a
href="https://bsky.app/profile/rsdoiel.bsky.social/post/3lufwzozhwc25"
class="uri">https://bsky.app/profile/rsdoiel.bsky.social/post/3lufwzozhwc25</a></p>
<hr />
<h2
id="mele-overclock-x2-is-an-almost-pocket-sized-pc-with-intel-n150-and-upgradeable-ram-storage">MeLE
Overclock X2 is an almost pocket-sized PC with Intel N150 and
upgradeable RAM &amp; storage</h2>
<p>date: 2025-07-20, from: Liliputing</p>
<p>
The MeLE Overclock X2 is a compact desktop computer that’s barely larger
than a smartphone, measuring 178 x 94 x 21mm (about 7″ x 3.7″ x 0.8″).
But it’s a full-fledged PC with an Intel processor, a decent set of I/O
options, and something you won’t find in any phone: support for
user-replaceable memory and […]
</p>
<p>
The post
<a href="https://liliputing.com/mele-overclock-x2-is-an-almost-pocket-sized-pc-with-intel-n150-and-upgradeable-ram-storage/">MeLE
Overclock X2 is an almost pocket-sized PC with Intel N150 and
upgradeable RAM &amp; storage</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/mele-overclock-x2-is-an-almost-pocket-sized-pc-with-intel-n150-and-upgradeable-ram-storage/"
class="uri">https://liliputing.com/mele-overclock-x2-is-an-almost-pocket-sized-pc-with-intel-n150-and-upgradeable-ram-storage/</a></p>
<hr />
<h2 id="quoting-armin-ronacher">Quoting Armin Ronacher</h2>
<p>date: 2025-07-20, updated: 2025-07-20, from: Simon Willison’s
Weblog</p>
<blockquote cite="https://lucumr.pocoo.org/2025/7/20/the-next-generation/">
<p>
Every day someone becomes a programmer because they figured out how to
make ChatGPT build something. Lucky for us: in many of those cases the
AI picks Python. We should treat this as an opportunity and anticipate
an expansion in the kinds of people who might want to attend a Python
conference. Yet many of these new programmers are not even aware that
programming communities and conferences exist. It’s in the Python
community’s interest to find ways to pull them in.
</p>
</blockquote>
<p class="cite">
—
<a href="https://lucumr.pocoo.org/2025/7/20/the-next-generation/">Armin
Ronacher</a>
</p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/pycon&quot;&gt;pycon&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/vibe-coding&quot;&gt;vibe-coding&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai-assisted-programming&quot;&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/python&quot;&gt;python&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/armin-ronacher&quot;&gt;armin-ronacher&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/20/armin-ronacher/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/20/armin-ronacher/#atom-everything</a></p>
<hr />
<h2 id="the-economics-of-immigration-and-deportation">The Economics of
Immigration and Deportation</h2>
<p>date: 2025-07-20, from: Paul Krugman</p>
<p>Immigration has been good for America. Mass deportation will be a
disaster.</p>
<p><br></p>
<p><a
href="https://paulkrugman.substack.com/p/the-economics-of-immigration-and"
class="uri">https://paulkrugman.substack.com/p/the-economics-of-immigration-and</a></p>
<hr />
<h2 id="quoting-tim-sweeney">Quoting Tim Sweeney</h2>
<p>date: 2025-07-20, updated: 2025-07-20, from: Simon Willison’s
Weblog</p>
<blockquote cite="https://x.com/timsweeneyepic/status/1946721961746608267">
<p>
There’s a bigger opportunity in computer science and programming
(academically conveyed or self-taught) now than ever before, by far, in
my opinion. The move to AI is like replacing shovels with bulldozers.
Every business will benefit from this and they’ll need people to do it.
</p>
</blockquote>
<p class="cite">
— <a href="https://x.com/timsweeneyepic/status/1946721961746608267">Tim
Sweeney</a>, Epic Games
</p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/ai-assisted-programming&quot;&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/careers&quot;&gt;careers&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Jul/20/tim-sweeney/#atom-everything"
class="uri">https://simonwillison.net/2025/Jul/20/tim-sweeney/#atom-everything</a></p>
</section>
<footer>
Antenna is a personal aggregation of items found around the web.
Curated with <a href="https://rsdoiel.github.io/skimmer">skimmer</a> and <a href="https://sqlite.org">sqlite</a> then rendered with <a href="https://pandoc.org">Pandoc</a>.
</footer>
</body>
</html>
