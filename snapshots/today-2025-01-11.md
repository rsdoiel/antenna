---
title: News gathered 2025-01-11
updated: 2025-01-11 07:10:10
---

# News gathered 2025-01-11

(date: 2025-01-11 07:10:10)

---

**@Dave Winer's linkblog** (date: 2025-01-11, from: Dave Winer's linkblog)

Donald Trump is a lame duck (not a bear)‚Äîan unusually weak one, in some ways‚Äîand he knows it. 

<br> 

<https://www.offmessage.net/p/poke-the-bear>

---

**@Dave Winer's linkblog** (date: 2025-01-11, from: Dave Winer's linkblog)

Payloads for RSS, on this day in 2001, marks the official beginning of what eventually became podcasting. A simple feature added to RSS that made it open to all forever, still true almost a quarter century later. 

<br> 

<https://web.archive.org/web/20010202144800/https://thetwowayweb.com/payloadsForRss>

---

## Phi-4 Bug Fixes by Unsloth

date: 2025-01-11, updated: 2025-01-11, from: Simon Willison‚Äôs Weblog

<p><strong><a href="https://unsloth.ai/blog/phi4">Phi-4 Bug Fixes by Unsloth</a></strong></p>
This explains why I was seeing weird <code>&lt;|im_end|&gt;</code> suffexes during my <a href="https://simonwillison.net/2025/Jan/8/phi-4/">experiments with Phi-4</a> the other day: it turns out the Phi-4 tokenizer definition as released by Microsoft had a bug in it, and there was a small bug in the chat template as well.</p>
<p>Daniel and Michael Han figured this out and have now published <a href="https://huggingface.co/unsloth/phi-4-GGUF">GGUF files with their fixes</a> on Hugging Face.

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=42660335">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/phi">phi</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a></p> 

<br> 

<https://simonwillison.net/2025/Jan/11/phi-4-bug-fixes/#atom-everything>

---

## From the Rubble Rise 22 Powerful Voices

date: 2025-01-11, from: Michael Moore's blog

Last week, I, as an Executive Producer of FROM GROUND ZERO: STORIES FROM GAZA, was quoted across the country as stating the following: &#8220;No filmmaker, writer or artist should ever have to tell the story of their own extermination.&#8221; 

<br> 

<https://www.michaelmoore.com/p/from-the-rubble-rises-22-powerful>

---

**@Dave Winer's linkblog** (date: 2025-01-10, from: Dave Winer's linkblog)

Heart of Zuckness. 

<br> 

<https://www.todayintabs.com/p/heart-of-zuckness>

---

**@Dave Winer's linkblog** (date: 2025-01-10, from: Dave Winer's linkblog)

A dozen eye-opening reads to kick off the new year. 

<br> 

<https://www.npr.org/2025/01/10/nx-s1-5196704/best-nonfiction>

---

## Lilbits: A bunch of handheld gaming news, plus a RISC-V server chip and a new single-board PC

date: 2025-01-10, from: Liliputing

<p>The Steam Deck handheld gaming PC now comes with a choice of LCD or AMOLED displays. But what if you already¬†have and LCD model and want to upgrade to an AMOLED display? Officially your only option is to buy a new handheld. Unofficially though? There&#8217;s another option. DeckSight is running a crowdfunding campaign for a [&#8230;]</p>
<p>The post <a href="https://liliputing.com/lilbits-a-bunch-of-handheld-gaming-news-plus-a-risc-v-server-chip-and-a-new-single-board-pc/">Lilbits: A bunch of handheld gaming news, plus a RISC-V server chip and a new single-board PC</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/lilbits-a-bunch-of-handheld-gaming-news-plus-a-risc-v-server-chip-and-a-new-single-board-pc/>

---

**@Dave Winer's linkblog** (date: 2025-01-10, from: Dave Winer's linkblog)

Kia has found its answer to low-cost Chinese EV makers. 

<br> 

<https://electrek.co/2025/01/10/kia-found-answer-to-low-cost-chinese-ev-makers/>

---

## SteamOS Expands Past the Steam Deck

date: 2025-01-10, from: Michael Tsai

Michael Crider (Hacker News): The big story in PC gaming for the last three years has been the Steam Deck. This low-power, portable, relatively inexpensive machine is clearly something the market has been waiting for, exciting gamers and energizing PC makers to pump out imitators, like the Asus ROG Ally and the Lenovo Legion Go. [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/01/10/steamos-expands-past-the-steam-deck/>

---

## Luigi Mangione‚Äôs Account Renamed on Stack Overflow

date: 2025-01-10, from: Michael Tsai

Evan Carroll (via Hacker News): On Stack Exchange, all of the contributions on the site are contributed under a license maintained by a third party called Creative Commons; Creative Commons provides a license which states that licensed content must be perpetually shareable for any purpose including modification and by anyone including for-profit ventures, so long [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/01/10/luigi-mangiones-account-renamed-on-stack-overflow/>

---

## Passkey Usability

date: 2025-01-10, from: Michael Tsai

Dan Goodin (Hacker News): Passkeys&#8212;the much-talked-about password alternative to passwords that have been widely available for almost two years&#8212;was supposed to fix all that. When I wrote about passkeys two years ago, I was a big believer. I remain convinced that passkeys mount the steepest hurdle yet for phishers, SIM swappers, database plunderers, and other [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/01/10/passkey-usability/>

---

## Network Neutrality Not Reinstated

date: 2025-01-10, from: Michael Tsai

Bruce Crumley (via Hacker News): The increasing challenge to government agencies&#8217; authority to regulate businesses gained momentum this week, after an appeals court suspended application of the Federal Communications Commission&#8216;s (FCC) ruling restoring net neutrality. That stay effectively delays the court&#8217;s decision in the case until after November&#8217;s elections. No matter the results of those, [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/01/10/network-neutrality-not-reinstated/>

---

## Khadas expands its modular mini PC ecosystem with the Khadas Mind 2S (Arrow Lake) and Mind xPlay (portable display)

date: 2025-01-10, from: Liliputing

<p>The Khadas Mind is a modular computing platform that debuted in 2023 with the launch of a tiny computer sporting an Intel Raptor Lake processor and support for add-ons including a basic docking station and external graphics dock. Last year the company launched a Khadas Mind 2 with an Intel Lunar Lake chip. Now Khadas [&#8230;]</p>
<p>The post <a href="https://liliputing.com/khadas-expands-its-modular-mini-pc-ecosystem-with-the-khadas-mind-2s-arrow-lake-and-mind-xplay-portable-display/">Khadas expands its modular mini PC ecosystem with the Khadas Mind 2S (Arrow Lake) and Mind xPlay (portable display)</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/khadas-expands-its-modular-mini-pc-ecosystem-with-the-khadas-mind-2s-arrow-lake-and-mind-xplay-portable-display/>

---

## The impeccable logic of Sam Altman

date: 2025-01-10, from: Gary Marcus blog

From a Bloomberg interview, spotted and summarized by Harlan Stewart, presented without further comment: 

<br> 

<https://garymarcus.substack.com/p/the-impeccable-logic-of-sam-altman>

---

**@Dave Winer's linkblog** (date: 2025-01-10, from: Dave Winer's linkblog)

Meta rolls back DEI programs in latest bow to Trump. 

<br> 

<https://www.axios.com/2025/01/10/meta-dei-programs-employees-trump>

---

**@Dave Winer's linkblog** (date: 2025-01-10, from: Dave Winer's linkblog)

John Johnston on WordPress, WordLand and writing tools. 

<br> 

<https://johnjohnston.info/blog/listenedhow-i-view-wordpress/>

---

## Meta Deletes Trans and Nonbinary Messenger Themes

date: 2025-01-10, from: 404 Media Group

Amid a series of changes that allows users to target LGBTQ+ people, Meta has deleted product features it initially championed. 

<br> 

<https://www.404media.co/meta-deletes-trans-and-nonbinary-messenger-themes/>

---

## Behind the Blog: What Is Real?

date: 2025-01-10, from: 404 Media Group

This is Behind the Blog, where we share our behind-the-scenes thoughts about how a few of our top stories of the week came together. This week, we discuss weird fake furniture and shared reality (or the lack thereof). 

<br> 

<https://www.404media.co/behind-the-blog-what-is-real/>

---

## Short Life of Trouble

date: 2025-01-10, from: Chris Coyier blog

My fiddle player friend Darin sent me this documentary about GB Grayson, which I enjoyed: The documentary talks about how very few people even recognize the name despite all of recorded tunes essentially becoming standards in today&#8217;s folk/bluegrass/old-time world and having been covered by extraordinarily huge artists. That&#8217;s true for me! I absolutely had never [&#8230;] 

<br> 

<https://chriscoyier.net/2025/01/10/short-life-of-trouble/>

---

## Zotac Zone handheld gaming PC gets and AMD Strix Point upgrade

date: 2025-01-10, from: Liliputing

<p>Zotac introduced its first handheld gaming PC in 2024, and now the company is showing off a prototype for a new model that looks&#8230; nearly identical. But the new version should bring a significant boost in CPU and graphics performance. While the original Zotac Gaming Zone handheld was powered by an AMD Ryzen 7 8840U [&#8230;]</p>
<p>The post <a href="https://liliputing.com/zotac-zone-handheld-gaming-pc-gets-and-amd-strix-point-upgrade/">Zotac Zone handheld gaming PC gets and AMD Strix Point upgrade</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/zotac-zone-handheld-gaming-pc-gets-and-amd-strix-point-upgrade/>

---

**@Dave Winer's linkblog** (date: 2025-01-10, from: Dave Winer's linkblog)

Bingeworthy is back. This is my profile page, it lists the shows I&#39;ve rated, best-first. If you&#39;re looking for something good to binge instead of the inauguration, these are my recommendations. üòÄ 

<br> 

<https://my.bingeworthy.org/?username=scripting>

---

## Robots Shod in Moose Shoes

date: 2025-01-10, updated: 2025-01-10, from: One Foot Tsunami

 

<br> 

<https://onefoottsunami.com/2025/01/10/robots-shod-in-moose-shoes/>

---

**@Dave Winer's linkblog** (date: 2025-01-10, from: Dave Winer's linkblog)

Anticipating that people will suggest I use their editor, I don&#39;t want to use their freaking editor. This keeps coming up everywhere. You can&#39;t use this or that unless you use their editor. Insidious form of lock-in. 

<br> 

<http://scripting.com/2025/01/10/150635.html>

---

## Pinpointing The Actual Problem

date: 2025-01-10, updated: 2025-01-10, from: Tedium site

A blog post from Automattic lays out their decision to pull back on the WordPress project. But in the process, the company may have accidentally explained why competitors were able to one-up them. 

<br> 

<https://feed.tedium.co/link/15204/16937623/wordpress-automattic-open-source-business-challenges>

---

**@Dave Winer's linkblog** (date: 2025-01-10, from: Dave Winer's linkblog)

Trump To Be Sentenced In New York Hush Money Case. 

<br> 

<https://talkingpointsmemo.com/live-blog/trump-to-be-sentenced-in-ny-hush-money-case>

---

## Goodbye WinterCG, welcome WinterTC

date: 2025-01-10, updated: 2025-01-10, from: Deno blog

WinterCG, the Web Interoperable Runtimes Community Group is moving to Ecma as TC55 to be able to publish standards.
 

<br> 

<https://deno.com/blog/wintertc>

---

## Prophecies of the Flood

date: 2025-01-10, from: One Useful Thing

What to make of the statements of the AI labs? 

<br> 

<https://www.oneusefulthing.org/p/prophecies-of-the-flood>

---

**@Dave Winer's linkblog** (date: 2025-01-10, from: Dave Winer's linkblog)

Scroll to the end of this review of the updated Tesla Model Y for the reason no matter how good it is as a car, until they get a real CEO, forget about it. 

<br> 

<https://electrek.co/2025/01/09/this-is-the-refreshed-model-y-just-unveiled-in-china/>

---

## My AI/LLM predictions for the next 1, 3 and 6 years, for Oxide and Friends

date: 2025-01-10, updated: 2025-01-10, from: Simon Willison‚Äôs Weblog

<p>The <a href="https://oxide-and-friends.transistor.fm/">Oxide and Friends</a> podcast has an annual tradition of asking guests to share their predictions for the next 1, 3 and 6 years. Here's <a href="https://github.com/oxidecomputer/oxide-and-friends/blob/master/2022_01_03.md">2022</a>, <a href="https://github.com/oxidecomputer/oxide-and-friends/blob/master/2023_01_09.md">2023</a> and <a href="https://github.com/oxidecomputer/oxide-and-friends/blob/master/2024_01_08.md">2024</a>. This year they invited me to participate. I've never been brave enough to share <em>any</em> public predictions before, so this was a great opportunity to get outside my comfort zone!</p>
<p>We recorded the episode live using Discord on Monday. It's now available <a href="https://www.youtube.com/watch?v=-pk6VokHpGY">on YouTube</a> and <a href="https://oxide-and-friends.transistor.fm/">in podcast form</a>.</p>

<p><lite-youtube videoid="-pk6VokHpGY"
  title="Oxide and Friends 1/6/2025 -- Predictions 2025"
  playlabel="Play: Oxide and Friends 1/6/2025 -- Predictions 2025"
> </lite-youtube></p>

<p>Here are my predictions, written up here in a little more detail than the stream of consciousness I shared on the podcast.</p>
<p>I should emphasize that I find the very idea of trying to predict AI/LLMs over a multi-year period to be completely absurd! I can't predict what's going to happen a week from now, six years is a different universe.</p>
<p>With that disclaimer out of the way, here's an expanded version of what I said.</p>
<ul>
  <li><a href="https://simonwillison.net/2025/Jan/10/ai-predictions/#one-year-agents-fail-to-happen-again">One year: Agents fail to happen, again</a></li>
  <li><a href="https://simonwillison.net/2025/Jan/10/ai-predictions/#one-year-code-research-assistants">One year: ... except for code and research assistants</a></li>
  <li><a href="https://simonwillison.net/2025/Jan/10/ai-predictions/#three-years-someone-wins-a-pulitzer-for-ai-assisted-investigative-reporting">Three years: Someone wins a Pulitzer for AI-assisted investigative reporting</a></li>
  <li><a href="https://simonwillison.net/2025/Jan/10/ai-predictions/#three-years-part-two-privacy-laws-with-teeth">Three years part two: privacy laws with teeth</a></li>
  <li><a href="https://simonwillison.net/2025/Jan/10/ai-predictions/#six-years-utopian-amazing-art">Six years utopian: amazing art</a></li>
  <li><a href="https://simonwillison.net/2025/Jan/10/ai-predictions/#six-years-dystopian-agi-asi-causes-mass-civil-unrest">Six years dystopian: AGI/ASI causes mass civil unrest</a></li>
  <li><a href="https://simonwillison.net/2025/Jan/10/ai-predictions/#my-total-lack-of-conviction">My total lack of conviction</a></li>
</ul>
<h4 id="one-year-agents-fail-to-happen-again">One year: Agents fail to happen, again</h4>
<p>I wrote about how <a href="https://simonwillison.net/2024/Dec/31/llms-in-2024/#-agents-still-haven-t-really-happened-yet">‚ÄúAgents‚Äù still haven‚Äôt really happened yet</a> in my review of Large Language Model developments  in 2024.</p>
<p>I think we are going to see a <em>lot</em> more froth about agents in 2025, but I expect the results will be a great disappointment to most of the people who are excited about this term. I expect a lot of money will be lost chasing after several different poorly defined dreams that share that name.</p>
<p>What are agents anyway? Ask a dozen people and you'll get a dozen slightly different answers - I collected and <a href="https://gist.github.com/simonw/beaa5f90133b30724c5cc1c4008d0654">then AI-summarized a bunch of those here</a>.</p>
<p>For the sake of argument, let's pick a definition that I can predict won't come to fruition: the idea of an AI assistant that can go out into the world and semi-autonomously act on your behalf. I think of this as the <strong>travel agent</strong> definition of agents, because for some reason everyone always jumps straight to flight and hotel booking and itinerary planning when they describe this particular dream.</p>
<p>Having the current generation of LLMs make material decisions on your behalf - like what to spend money on - is a <em>really bad idea</em>. They're too unreliable, but more importantly they are too <strong>gullible</strong>.</p>
<p>If you're going to arm your AI assistant with a credit card and set it loose on the world, you need to be confident that it's not going to hit "buy" on the first website that claims to offer the best bargains!</p>
<p>I'm confident that reliability is the reason we haven't seen LLM-powered agents that have taken off yet, despite the idea attracting a huge amount of buzz since right after ChatGPT first came out.</p>
<p>I would be very surprised if any of the models released over the next twelve months had enough of a reliability improvement to make this work. Solving gullibility is an astonishingly difficult problem.</p>
<p>(I had <a href="https://www.youtube.com/watch?v=-pk6VokHpGY&amp;t=1206s">a particularly spicy rant</a> about how stupid the idea of sending a "digital twin" to a meeting on your behalf is.)</p>
<h4 id="one-year-code-research-assistants">One year: ... except for code and research assistants</h4>
<p>There are two categories of "agent" that I do believe in, because they're proven to work already.</p>
<p>The first is <strong>coding assistants</strong> - where an LLM writes, executes and then refines computer code in a loop.</p>
<p>I first saw this pattern demonstrated by OpenAI with their <a href="https://simonwillison.net/tags/code-interpreter/">Code Interpreter</a> feature for ChatGPT, released back in March/April of 2023.</p>
<p>You can ask ChatGPT to solve a problem that can use Python code and it will write that Python, execute it in a secure sandbox (I think it's Kubernetes) and then use the output - or any error messages - to determine if the goal has been achieved.</p>
<p>It's a beautiful pattern that worked great with early 2023 models (I believe it first shipped using original GPT-4), and continues to work today.</p>
<p>Claude added their own version in October (<a href="https://simonwillison.net/2024/Oct/24/claude-analysis-tool/">Claude analysis</a>, using JavaScript that runs in the browser), Mistral have it, Gemini has a version and there are dozens of other implementations of the same pattern.</p>
<p>The second category of agents that I believe in is <strong>research assistants</strong> - where an LLM can run multiple searches, gather information and aggregate that into an answer to a question or write a report.</p>
<p><a href="https://www.perplexity.ai/">Perplexity</a> and <a href="https://openai.com/index/introducing-chatgpt-search/">ChatGPT Search</a> have both been operating in this space for a while, but by far the most impressive implementation I've seen is Google Gemini's <a href="https://blog.google/products/gemini/google-gemini-deep-research/">Deep Research</a> tool, which I've had access to for a few weeks.</p>
<p>With Deep Research I can pose a question like this one:</p>
<blockquote>
<p>Pillar Point Harbor is one of the largest communal brown pelican roosts on the west coast of North America.</p>
<p>find others</p>
</blockquote>
<p>And Gemini will draft a plan, consult dozens of different websites via Google Search and then assemble a report (with all-important citations) describing what it found.</p>
<p>Here's the plan it came up with:</p>
<blockquote>
<p>Pillar Point Harbor is one of the largest communal brown pelican roosts on the west coast of North America. Find other large communal brown pelican roosts on the west coast of North America.<br />
(1) Find a list of brown pelican roosts on the west coast of North America.<br />
(2) Find research papers or articles about brown pelican roosts and their size.<br />
(3) Find information from birdwatching organizations or government agencies about brown pelican roosts.<br />
(4) Compare the size of the roosts found in (3) to the size of the Pillar Point Harbor roost.<br />
(5) Find any news articles or recent reports about brown pelican roosts and their populations.</p>
</blockquote>
<p>It dug up a whole bunch of details, but the one I cared most about was <a href="https://birdallianceoregon.org/wp-content/uploads/2021/04/Brown-Pelican-survey_4-year_summary-infographic_2016-19_final.pdf">these PDF results for the 2016-2019 Pacific Brown Pelican Survey</a> conducted by the West Coast Audubon network and partners - a PDF that included this delightful list:</p>
<blockquote>
<p>Top 10 Megaroosts (sites that traditionally host &gt;500 pelicans) with average fall count numbers:</p>
<ul>
<li>Alameda Breakwater, CA (3,183)</li>
<li>Pillar Point Harbor, CA (1,481)</li>
<li>East Sand Island, OR (1,121)</li>
<li>Ano Nuevo State Park, CA (1,068)</li>
<li>Salinas River mouth, CA (762)</li>
<li>Bolinas Lagoon, CA (755)</li>
<li>Morro Rock, CA (725)</li>
<li>Moss landing, CA (570)</li>
<li>Crescent City Harbor, CA (514)</li>
<li>Bird Rock Tomales, CA (514)</li>
</ul>
</blockquote>
<p>My local harbor is the second biggest megaroost!</p>
<p>It makes intuitive sense to me that this kind of research assistant can be built on our current generation of LLMs. They're competent at driving tools, they're capable of coming up with a relatively obvious research plan (look for newspaper articles and research papers) and they can synthesize sensible answers given the right collection of context gathered through search.</p>
<p>Google are particularly well suited to solving this problem: they have the world's largest search index and their Gemini model has a 2 million token context. I expect Deep Research to get a whole lot better, and I expect it to attract plenty of competition.</p>
<h4 id="three-years-someone-wins-a-pulitzer-for-ai-assisted-investigative-reporting">Three years: Someone wins a Pulitzer for AI-assisted investigative reporting</h4>
<p>I went for a bit of a self-serving prediction here: I think within three years someone is going to win a Pulitzer prize for a piece of investigative reporting that was aided by generative AI tools.</p>
<p>I do <em>not</em> mean that an LLM will write the article! I continue to think that having LLMs write on your behalf is one of the least interesting applications of these tools.</p>
<p>I called this prediction self-serving because I want to help make this happen! My <a href="https://datasette.io">Datasette</a> suite of open source tools for data journalism has been growing AI features, like <a href="https://simonwillison.net/2023/Dec/1/datasette-enrichments/">LLM-powered data enrichments</a> and <a href="https://www.datasette.cloud/blog/2024/datasette-extract/">extracting structured data</a> into tables from unstructured text.</p>
<p>My dream is for those tools - or tools like them - to be used for an award winning piece of investigative reporting.</p>
<p>I picked three years for this because I think that's how long it will take for knowledge of how to responsibly and effectively use these tools to become widespread enough for that to happen.</p>
<p>LLMs are not an obvious fit for journalism: journalists look for the truth, and LLMs are notoriously prone to hallucination and making things up. But journalists are also <em>really good</em> at extracting useful information from potentially untrusted sources - that's a lot of what the craft of journalism is about.</p>
<p>The two areas I think LLMs are particularly relevant to journalism are:</p>
<ul>
<li>Structured data extraction. If you have 10,000 PDFs from a successful Freedom of Information Act request, someone or something needs to kick off the process of reading through them to find the stories. LLMs are a fantastic way to take a vast amount of information and start making some element of sense from it. They can act as lead generators, helping identify the places to start looking more closely.</li>
<li>Coding assistance. Writing code to help analyze data is a huge part of modern data journalism - from SQL queries through data cleanup scripts, custom web scrapers or visualizations to help find signal among the noise. Most newspapers don't have a team of programmers on staff: I think within three years we'll have robust enough tools built around this pattern that non-programmer journalists will be able to use them as part of their reporting process.</li>
</ul>
<p>I hope to build some of these tools myself!</p>
<p>So my concrete prediction for three years is that someone wins a Pulitzer with a small amount of assistance from LLMs.</p>
<p>My more general prediction: within three years it won't be surprising at all to see most information professionals use LLMs as part of their daily workflow, in increasingly sophisticated ways. We'll know exactly what patterns work and how best to explain them to people. These skills will become widespread.</p>
<h4 id="three-years-part-two-privacy-laws-with-teeth">Three years part two: privacy laws with teeth</h4>
<p>My other three year prediction concerned privacy legislation.</p>
<p>The levels of (often justified) paranoia around both targeted advertising and what happens to the data people paste into these models is a constantly growing problem.</p>
<p>I wrote recently about the <a href="https://simonwillison.net/2025/Jan/2/they-spy-on-you-but-not-like-that/">inexterminable conspiracy theory that Apple target ads through spying through your phone's microphone</a>. I've written in the past about <a href="https://simonwillison.net/2023/Dec/14/ai-trust-crisis/">the AI trust crisis</a>, where people refuse to believe that models are not being trained on their inputs no matter how emphatically the companies behind them deny it.</p>
<p>I think the AI industry itself would benefit enormously from legislation that helps clarify what's going on with training on user-submitted data, and the wider tech industry could really do with harder rules around things like data retention and targeted advertising.</p>
<p>I don't expect the next four years of US federal government to be effective at passing legislation, but I expect we'll see privacy legislation with sharper teeth emerging at the state level or internationally. Let's just hope we don't end up with a new generation of cookie-consent banners as a result!</p>
<h4 id="six-years-utopian-amazing-art">Six years utopian: amazing art</h4>
<p>For six years I decided to go with two rival predictions, one optimistic and one pessimistic.</p>
<p>I think six years is long enough that we'll figure out how to harness this stuff to make some <strong>really great art</strong>.</p>
<p>I don't think generative AI for art - images, video and music - deserves nearly the same level of respect as a useful tool as text-based LLMs. Generative art tools are a lot of fun to try out but the lack of fine-grained control over the output greatly limits its utility outside of personal amusement or generating <a href="https://simonwillison.net/tags/slop/">slop</a>.</p>
<p>More importantly, they lack social acceptability. The vibes aren't good. Many talented artists have loudly rejected the idea of these tools, to the point that the very term "AI" is developing a distasteful connotation in society at large.</p>
<p>Image and video models are also ground zero for the AI training data ethics debate, and for good reason: no artist wants to see a model trained on their work without their permission that then directly competes with them!</p>
<p>I think six years is long enough for this whole thing to shake out - for society to figure out acceptable ways of using these tools to truly elevate human expression. What excites me is the idea of truly talented, visionary creative artists using whatever these tools have evolved into in six years to make meaningful art that could never have been achieved without them.</p>
<p>On the podcast I talked about <a href="https://en.wikipedia.org/wiki/Everything_Everywhere_All_at_Once">Everything Everywhere All at Once</a>, a film that deserved every one of its seven Oscars. The core visual effects team on that film was just five people. Imagine what a team like that could do with the generative AI tools we'll have in six years time!</p>
<p id="since-recording">Since recording the podcast I learned from <a href="https://www.swyx.io/">Swyx</a> that Everything Everywhere All at Once <a href="https://www.aboutamazon.com/news/aws/how-ai-tools-are-creating-new-possibilities-for-movies-and-visual-design-according-to-this-aws-powered-startup">used Runway ML as part of their toolset already</a>:</p>
<blockquote>
<p>Evan Halleck was on this team, and he used Runway's AI tools to save time and automate tedious aspects of editing. Specifically in the film‚Äôs rock scene, he used Runway‚Äôs rotoscoping tool to get a quick, clean cut of the rocks as sand and dust were moving around the shot. This translated days of work to a matter of minutes.</p>
</blockquote>
<p>I said I thought a film that had used generative AI tools would win an Oscar within six years. Looks like I was eight years late on that one already!</p>
<h4 id="six-years-dystopian-agi-asi-causes-mass-civil-unrest">Six years dystopian: AGI/ASI causes mass civil unrest</h4>
<p>My pessimistic alternative take for 2031 concerns "AGI" - a term which, like "agents", is constantly being redefined. The Information <a href="https://www.theinformation.com/articles/microsoft-and-openai-wrangle-over-terms-of-their-blockbuster-partnership">recently reported</a> (see also <a href="https://www.theverge.com/2025/1/6/24337106/sam-altman-says-openai-knows-how-to-build-agi-blog-post">The Verge</a>) that Microsoft and OpenAI are now defining AGI as a system capable of generating $100bn in profit!</p>
<p>If we assume AGI is the point at which AI systems are capable of performing almost any job currently reserved for a human being it's hard <em>not</em> to see potentially negative consequences.</p>
<p>Sam Altman may have <a href="https://www.bloomberg.com/news/articles/2024-07-22/ubi-study-backed-by-openai-s-sam-altman-bolsters-support-for-basic-income">experimented with Universal Basic Income</a>, but the USA is a country that can't even figure out universal healthcare! I have huge trouble imagining a future economy that works for the majority of people when the majority of jobs are being done by machines.</p>
<p>So my dystopian prediction for 2031 is that if that form of AGI has come to pass it will be accompanied by extraordinarily bad economic outcomes and mass civil unrest.</p>
<p>My version of an AI utopia is tools that augment existing humans. That's what we've had with LLMs so far, and my ideal is that those tools continue to improve and subsequently humans become able to take on <a href="https://simonwillison.net/2023/Mar/27/ai-enhanced-development/">more ambitious work</a>.</p>
<p>If there's a version of AGI that results in that kind of utopia, I'm all for it.</p>
<h4 id="my-total-lack-of-conviction">My total lack of conviction</h4>
<p>There's a reason I haven't made predictions like this before: my confidence in my ability to predict the future is almost non-existent. At least one of my predictions here <a href="https://simonwillison.net/2025/Jan/10/ai-predictions/#since-recording">already proved to be eight years late</a>!</p>
<p>These predictions are in the public record now (I even <a href="https://github.com/oxidecomputer/oxide-and-friends/pull/158">submitted a pull request</a>).</p>
<p>It's going to be interesting looking back at these in one, three and six years to see how I did.</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/data-journalism">data-journalism</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/openai">openai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/gemini">gemini</a>, <a href="https://simonwillison.net/tags/code-interpreter">code-interpreter</a>, <a href="https://simonwillison.net/tags/oxide">oxide</a>, <a href="https://simonwillison.net/tags/ai-agents">ai-agents</a></p> 

<br> 

<https://simonwillison.net/2025/Jan/10/ai-predictions/#atom-everything>

