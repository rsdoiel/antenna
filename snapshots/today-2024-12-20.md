---
title: News gathered 2024-12-20
updated: 2024-12-20 07:09:59
---

# News gathered 2024-12-20

(date: 2024-12-20 07:09:59)

---

**@IIIF Mastodon feed** (date: 2024-12-20, from: IIIF Mastodon feed)

<p>Join us in the new year for &quot;HDR Images via Image API.&quot; </p><p>We’ll welcome Christian Mahnke to demo a proof of concept for a <br /><a href="https://glammr.us/tags/IIIF" class="mention hashtag" rel="tag">#<span>IIIF</span></a> Image API endpoint with UltraHDR tiles &amp; present a proposal to indicate technical rendering hints to Image API clients.</p><p>Zoom info 👉: iiif.io/community</p> 

<br> 

<https://glammr.us/@IIIF/113685726572804475>

---

## Not The Bear Shown

date: 2024-12-20, updated: 2024-12-20, from: One Foot Tsunami

 

<br> 

<https://onefoottsunami.com/2024/12/20/not-the-bear-shown/>

---

**@Dave Winer's linkblog** (date: 2024-12-20, from: Dave Winer's linkblog)

You can favor AOC without making it about age. And know there are people listening who tune you out at the first sign of that uniquely Democratic Party hypocrisy. (Could have something to do with losing elections too, btw.) 

<br> 

<https://www.slowboring.com/p/aoc-deserved-the-oversight-job?r=etla&triedRedirect=true>

---

**@Dave Winer's linkblog** (date: 2024-12-20, from: Dave Winer's linkblog)

What would a government shutdown mean for you? 

<br> 

<https://www.poynter.org/fact-checking/2024/why-is-the-government-shutting-down/>

---

**@Dave Winer's linkblog** (date: 2024-12-20, from: Dave Winer's linkblog)

Staffers at The New York Times on the Books They Enjoyed in 2024. 

<br> 

<https://www.nytimes.com/2024/12/20/books/review/staff-picks-books.html>

---

**@Dave Winer's linkblog** (date: 2024-12-20, from: Dave Winer's linkblog)

After reading a few articles about Mike McCue’s announced Surf product I asked meta.ai to explain how it’s different from  social web app like threads, Bluesky, twitter. 

<br> 

<https://bsky.app/profile/scripting.com/post/3ldq6zu5oon23>

---

**@Dave Winer's linkblog** (date: 2024-12-20, from: Dave Winer's linkblog)

The Ghosts in the Machine, by Liz Pelly. 

<br> 

<https://harpers.org/archive/2025/01/the-ghosts-in-the-machine-liz-pelly-spotify-musicians/>

---

## December in LLMs has been a lot

date: 2024-12-20, updated: 2024-12-20, from: Simon Willison’s Weblog

<p>I had big plans for December: for one thing, I was hoping to get to an actual RC of Datasette 1.0, in preparation for a full release in January. Instead, I've found myself distracted by a <a href="https://simonwillison.net/search/?tag=llms&amp;year=2024&amp;month=12">constant barrage</a> of new LLM releases.</p>
<p>On December 4th Amazon introduced the <a href="https://simonwillison.net/2024/Dec/4/amazon-nova/"><strong>Amazon Nova family</strong></a> of multi-modal models - clearly priced to compete with the excellent and inexpensive Gemini 1.5 series from Google. I got those working with <a href="https://llm.datasette.io/">LLM</a> via a new <a href="https://github.com/simonw/llm-bedrock">llm-bedrock</a> plugin.</p>
<p>The next big release was <a href="https://simonwillison.net/2024/Dec/6/llama-33/"><strong>Llama 3.3 70B-Instruct</strong></a>, on December 6th. Meta claimed that this 70B model was comparable in quality to their much larger 405B model, and those claims seem to hold weight.</p>
<p>I wrote about how <a href="https://simonwillison.net/2024/Dec/9/llama-33-70b/">I can now run a GPT-4 class model on my laptop</a> - the same laptop that was running a GPT-3 class model just 20 months ago.</p>
<p>Llama 3.3 70B has started showing up from API providers now, including super-fast hosted versions from both <a href="https://groq.com/new-ai-inference-speed-benchmark-for-llama-3-3-70b-powered-by-groq/">Groq</a> (276 tokens/second) and <a href="https://cerebras.ai/inference">Cerebras</a> (a quite frankly absurd 2,200 tokens/second). If you haven't tried Val Town's <a href="https://cerebrascoder.com/">Cerebras Coder</a> demo you really should.</p>
<p>I think the huge gains in model efficiency are one of the defining stories of LLMs in 2024. It's not just the local models that have benefited: the price of proprietary hosted LLMs has dropped through the floor, a result of both competition between vendors and the increasing efficiency of the models themselves.</p>
<p>Last year the running joke was that every time Google put out a new Gemini release OpenAI would ship something more impressive that same day to undermine them.</p>
<p>The tides have turned! This month Google shipped four updates that took the wind out of OpenAI's sails.</p>
<p>The first was <a href="https://simonwillison.net/2024/Dec/6/gemini-exp-1206/"><strong>gemini-exp-1206</strong></a> on December 6th, an experimental model that jumped straight to the top of some of the leaderboards. Was this our first glimpse of Gemini 2.0?</p>
<p>That was followed by <a href="https://simonwillison.net/2024/Dec/11/gemini-2/"><strong>Gemini 2.0 Flash</strong></a> on December 11th, the first official release in Google's Gemini 2.0 series. The streaming support was particularly impressive, with <a href="https://aistudio.google.com/live">https://aistudio.google.com/live</a> demonstrating streaming audio and webcam communication with the multi-modal LLM a full day before OpenAI released their own streaming camera/audio features in an update to ChatGPT.</p>
<p>Then this morning Google shipped <a href="https://simonwillison.net/2024/Dec/19/gemini-thinking-mode/"><strong>Gemini 2.0 Flash "Thinking mode"</strong></a>, their version of the inference scaling technique pioneered by OpenAI's o1. I did <em>not</em> expect Gemini to ship a version of that before 2024 had even ended.</p>
<p>OpenAI have one day left in their <a href="https://openai.com/12-days/">12 Days of OpenAI</a> event. Previous highlights have included the full <strong>o1</strong> model (an upgrade from o1-preview) and <strong>o1-pro</strong>, <a href="https://simonwillison.net/2024/Dec/9/sora/">Sora</a> (later upstaged a week later by Google's <a href="https://simonwillison.net/2024/Dec/16/veo-2/">Veo 2</a>), Canvas (with a confusing <a href="https://simonwillison.net/2024/Dec/10/chatgpt-canvas/">second way to run Python</a>), <a href="https://simonwillison.net/2024/Dec/13/openai-voice-mode-faq/">Advanced Voice with video streaming</a> and Santa and a <em>very</em> cool new <a href="https://simonwillison.net/2024/Dec/17/openai-webrtc/">WebRTC streaming API</a>, ChatGPT Projects (pretty much a direct lift of the similar Claude feature) and the 1-800-CHATGPT phone line.</p>
<p>Tomorrow is the last day. I'm not going to try to predict what they'll launch, but I imagine it will be something notable to close out the year.</p>
<h4 id="blog-entries">Blog entries</h4>
<ul>
<li><a href="https://simonwillison.net/2024/Dec/19/gemini-thinking-mode/">Gemini 2.0 Flash "Thinking mode"</a></li>
<li><a href="https://simonwillison.net/2024/Dec/19/one-shot-python-tools/">Building Python tools with a one-shot prompt using uv run and Claude Projects</a></li>
<li><a href="https://simonwillison.net/2024/Dec/11/gemini-2/">Gemini 2.0 Flash: An outstanding multi-modal LLM with a sci-fi streaming mode</a></li>
<li><a href="https://simonwillison.net/2024/Dec/10/chatgpt-canvas/">ChatGPT Canvas can make API requests now, but it's complicated</a></li>
<li><a href="https://simonwillison.net/2024/Dec/9/llama-33-70b/">I can now run a GPT-4 class model on my laptop</a></li>
<li><a href="https://simonwillison.net/2024/Dec/7/prompts-js/">Prompts.js</a></li>
<li><a href="https://simonwillison.net/2024/Dec/4/amazon-nova/">First impressions of the new Amazon Nova LLMs (via a new llm-bedrock plugin)</a></li>
<li><a href="https://simonwillison.net/2024/Nov/27/storing-times-for-human-events/">Storing times for human events</a></li>
<li><a href="https://simonwillison.net/2024/Nov/25/ask-questions-of-sqlite/">Ask questions of SQLite databases and CSV/JSON files in your terminal</a></li>
</ul>
<h4 id="releases">Releases</h4>
<ul>
<li>
<strong><a href="https://github.com/simonw/llm-gemini/releases/tag/0.8">llm-gemini 0.8</a></strong> - 2024-12-19<br />LLM plugin to access Google's Gemini family of models</li>
<li>
<strong><a href="https://github.com/datasette/datasette-enrichments-slow/releases/tag/0.1">datasette-enrichments-slow 0.1</a></strong> - 2024-12-18<br />An enrichment on a slow loop to help debug progress bars</li>
<li>
<strong><a href="https://github.com/simonw/llm-anthropic/releases/tag/0.11">llm-anthropic 0.11</a></strong> - 2024-12-17<br />LLM access to models by Anthropic, including the Claude series</li>
<li>
<strong><a href="https://github.com/simonw/llm-openrouter/releases/tag/0.3">llm-openrouter 0.3</a></strong> - 2024-12-08<br />LLM plugin for models hosted by OpenRouter</li>
<li>
<strong><a href="https://github.com/simonw/prompts-js/releases/tag/0.0.4">prompts-js 0.0.4</a></strong> - 2024-12-08<br />async alternatives to browser alert() and prompt() and confirm()</li>
<li>
<strong><a href="https://github.com/datasette/datasette-enrichments-llm/releases/tag/0.1a0">datasette-enrichments-llm 0.1a0</a></strong> - 2024-12-05<br />Enrich data by prompting LLMs</li>
<li>
<strong><a href="https://github.com/simonw/llm/releases/tag/0.19.1">llm 0.19.1</a></strong> - 2024-12-05<br />Access large language models from the command-line</li>
<li>
<strong><a href="https://github.com/simonw/llm-bedrock/releases/tag/0.4">llm-bedrock 0.4</a></strong> - 2024-12-04<br />Run prompts against models hosted on AWS Bedrock</li>
<li>
<strong><a href="https://github.com/datasette/datasette-queries/releases/tag/0.1a0">datasette-queries 0.1a0</a></strong> - 2024-12-03<br />Save SQL queries in Datasette</li>
<li>
<strong><a href="https://github.com/datasette/datasette-llm-usage/releases/tag/0.1a0">datasette-llm-usage 0.1a0</a></strong> - 2024-12-02<br />Track usage of LLM tokens in a SQLite table</li>
<li>
<strong><a href="https://github.com/simonw/llm-mistral/releases/tag/0.9">llm-mistral 0.9</a></strong> - 2024-12-02<br />LLM plugin providing access to Mistral models using the Mistral API</li>
<li>
<strong><a href="https://github.com/simonw/llm-claude-3/releases/tag/0.10">llm-claude-3 0.10</a></strong> - 2024-12-02<br />LLM plugin for interacting with the Claude 3 family of models</li>
<li>
<strong><a href="https://github.com/simonw/datasette/releases/tag/0.65.1">datasette 0.65.1</a></strong> - 2024-11-29<br />An open source multi-tool for exploring and publishing data</li>
<li>
<strong><a href="https://github.com/simonw/sqlite-utils-ask/releases/tag/0.2">sqlite-utils-ask 0.2</a></strong> - 2024-11-24<br />Ask questions of your data with LLM assistance</li>
<li>
<strong><a href="https://github.com/simonw/sqlite-utils/releases/tag/3.38">sqlite-utils 3.38</a></strong> - 2024-11-23<br />Python CLI utility and library for manipulating SQLite databases</li>
</ul>
<h4 id="tils">TILs</h4>
<ul>
<li>
<a href="https://til.simonwillison.net/python/utc-warning-fix">Fixes for datetime UTC warnings in Python</a> - 2024-12-12</li>
<li>
<a href="https://til.simonwillison.net/npm/npm-publish-github-actions">Publishing a simple client-side JavaScript package to npm with GitHub Actions</a> - 2024-12-08</li>
<li>
<a href="https://til.simonwillison.net/cloudflare/workers-github-oauth">GitHub OAuth for a static site using Cloudflare Workers</a> - 2024-11-29</li>
</ul>
    
        <p>Tags: <a href="https://simonwillison.net/tags/google">google</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/weeknotes">weeknotes</a>, <a href="https://simonwillison.net/tags/openai">openai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/chatgpt">chatgpt</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/gemini">gemini</a>, <a href="https://simonwillison.net/tags/o1">o1</a></p> 

<br> 

<https://simonwillison.net/2024/Dec/20/december-in-llms-has-been-a-lot/#atom-everything>

---

## Building effective agents

date: 2024-12-20, updated: 2024-12-20, from: Simon Willison’s Weblog

<p><strong><a href="https://www.anthropic.com/research/building-effective-agents">Building effective agents</a></strong></p>
My principal complaint about the term "agents" is that while it has many different potential definitions most of the people who use it seem to assume that everyone else shares and understands the definition that they have chosen to use.</p>
<p>This outstanding piece by Erik Schluntz and Barry Zhang at Anthropic bucks that trend from the start, providing a clear definition that they then use throughout.</p>
<p>They discuss "agentic systems" as a parent term, then define a distinction between "workflows" - systems where multiple LLMs are orchestrated together using pre-defined patterns - and "agents", where the LLMs "dynamically direct their own processes and tool usage". This second definition is later expanded with this delightfully clear description:</p>
<blockquote>
<p>Agents begin their work with either a command from, or interactive discussion with, the human user. Once the task is clear, agents plan and operate independently, potentially returning to the human for further information or judgement. During execution, it's crucial for the agents to gain “ground truth” from the environment at each step (such as tool call results or code execution) to assess its progress. Agents can then pause for human feedback at checkpoints or when encountering blockers. The task often terminates upon completion, but it’s also common to include stopping conditions (such as a maximum number of iterations) to maintain control.</p>
</blockquote>
<p>That's a definition I can live with!</p>
<p>They also introduce a term that I <em>really</em> like: <strong>the augmented LLM</strong>. This is an LLM with augmentations such as tools - I've seen people use the term "agents" just for this, which never felt right to me.</p>
<p>The rest of the article is the clearest practical guide to building systems that combine multiple LLM calls that I've seen anywhere.</p>
<p>Most of the focus is actually on workflows. They describe five different patterns for workflows in detail:</p>
<ul>
<li>Prompt chaining, e.g. generating a document and then translating it to a separate language as a second LLM call</li>
<li>Routing, where an initial LLM call decides which model or call should be used next (sending easy tasks to Haiku and harder tasks to Sonnet, for example)</li>
<li>Parallelization, where a task is broken up and run in parallel (e.g. image-to-text on multiple document pages at once) or processed by some kind of voting mechanism</li>
<li>Orchestrator-workers, where a orchestrator triggers multiple LLM calls that are then synthesized together, for example running searches against multiple sources and combining the results</li>
<li>Evaluator-optimizer, where one model checks the work of another in a loop</li>
</ul>
<p>These patterns all make sense to me, and giving them clear names makes them easier to reason about.</p>
<p>When should you upgrade from basic prompting to workflows and then to full agents? The authors provide this sensible warning:</p>
<blockquote>
<p>When building applications with LLMs, we recommend finding the simplest solution possible, and only increasing complexity when needed. This might mean not building agentic systems at all.</p>
</blockquote>
<p>But assuming you do need to go beyond what can be achieved even with the aforementioned workflow patterns, their model for agents may be a useful fit:</p>
<blockquote>
<p>Agents can be used for open-ended problems where it’s difficult or impossible to predict the required number of steps, and where you can’t hardcode a fixed path. The LLM will potentially operate for many turns, and you must have some level of trust in its decision-making. Agents' autonomy makes them ideal for scaling tasks in trusted environments.</p>
<p>The autonomous nature of agents means higher costs, and the potential for compounding errors. We recommend extensive testing in sandboxed environments, along with the appropriate guardrails</p>
</blockquote>
<p>They also warn against investing in complex agent frameworks before you've exhausted your options using direct API access and simple code.</p>
<p>The article is accompanied by a brand new set of <a href="https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents">cookbook recipes</a> illustrating all five of the workflow patterns. The <a href="https://github.com/anthropics/anthropic-cookbook/blob/main/patterns/agents/evaluator_optimizer.ipynb">Evaluator-Optimizer Workflow</a> example is particularly fun, setting up a code generating prompt and an code reviewing evaluator prompt and having them loop until the evaluator is happy with the result.

    <p><small></small>Via <a href="https://x.com/HamelHusain/status/1869935867940540596">Hamel Husain</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/prompt-engineering">prompt-engineering</a>, <a href="https://simonwillison.net/tags/anthropic">anthropic</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llm-tool-use">llm-tool-use</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-agents">ai-agents</a></p> 

<br> 

<https://simonwillison.net/2024/Dec/20/building-effective-agents/#atom-everything>

---

## Quoting Marcus Hutchins

date: 2024-12-20, updated: 2024-12-20, from: Simon Willison’s Weblog

<blockquote cite="https://bsky.app/profile/malwaretech.com/post/3ldpfzxdyqs2d"><p>50% of cybersecurity is endlessly explaining that consumer VPNs don’t address any real cybersecurity issues. They are basically only useful for bypassing geofences and making money telling people they need to buy a VPN.</p>
<p>Man-in-the-middle attacks on Public WiFi networks haven't been a realistic threat in a decade. Almost all websites use encryption by default, and anything of value uses HSTS to prevent attackers from downgrading / disabling encryption. It's a non issue.</p></blockquote>
<p class="cite">&mdash; <a href="https://bsky.app/profile/malwaretech.com/post/3ldpfzxdyqs2d">Marcus Hutchins</a></p>

    <p>Tags: <a href="https://simonwillison.net/tags/encryption">encryption</a>, <a href="https://simonwillison.net/tags/vpn">vpn</a>, <a href="https://simonwillison.net/tags/https">https</a>, <a href="https://simonwillison.net/tags/security">security</a></p> 

<br> 

<https://simonwillison.net/2024/Dec/20/marcus-hutchins/#atom-everything>

---

**@Dave Winer's linkblog** (date: 2024-12-20, from: Dave Winer's linkblog)

Nate Bargatze: The baffling rise of the most inoffensive comedian alive. 

<br> 

<https://slate.com/culture/2024/12/nate-bargatze-comedian-snl-netflix-special-your-friend-comedy.html?via=rss>

---

## Understanding Computer Networks by Analogy

date: 2024-12-20, from: Memo Garcia blog

<p>I&rsquo;m writing this for the version of me back in university who struggled to grasp networking concepts. This isn&rsquo;t a full map of the networking world, but it&rsquo;s a starting point. If you&rsquo;re also finding it tricky to understand some of the ideas that make the internet works, I hope this helps.</p>
<p>I’m sticking with analogies here instead of going deep into technical terms—you can find those easily anywhere. I just enjoy looking at the world from different perspectives. It’s fascinating how many connections you can spot when you approach things from a new angle.</p> 

<br> 

<https://memo.mx/posts/understanding-computer-networks-by-analogy/>

---

**@Dave Winer's linkblog** (date: 2024-12-20, from: Dave Winer's linkblog)

The GOP Is Treating Musk Like He’s in Charge. 

<br> 

<https://www.theatlantic.com/newsletters/archive/2024/12/the-gop-is-treating-musk-like-hes-in-charge/681117/?gift=f35zZN0v_gDFE8xNwlQAHa0RxyZ37nOM3GKJgDunSkY&utm_source=copy-link&utm_medium=social&utm_campaign=share>

---

## Gemini 2.0 Flash "Thinking mode"

date: 2024-12-19, updated: 2024-12-19, from: Simon Willison’s Weblog

<p>Those new model releases just keep on flowing. Today it's Google's snappily named <code>gemini-2.0-flash-thinking-exp</code>, their first entrant into the o1-style inference scaling class of models. I posted about <a href="https://simonwillison.net/2024/Dec/19/is-ai-progress-slowing-down/">a great essay about the significance of these</a> just this morning.</p>
<p>From <a href="https://ai.google.dev/gemini-api/docs/thinking-mode">the Gemini model documentation</a>:</p>
<blockquote>
<p>Gemini 2.0 Flash Thinking Mode is an experimental model that's trained to generate the "thinking process" the model goes through as part of its response. As a result, Thinking Mode is capable of stronger reasoning capabilities in its responses than the base Gemini 2.0 Flash model.</p>
</blockquote>
<p>I just shipped <a href="https://github.com/simonw/llm-gemini/releases/tag/0.8">llm-gemini 0.8</a> with support for the model. You can try it out using <a href="https://llm.datasette.io/">LLM</a> like this:</p>
<div class="highlight highlight-source-shell"><pre>llm install -U llm-gemini
<span class="pl-c"><span class="pl-c">#</span> If you haven't yet set a gemini key:</span>
llm keys <span class="pl-c1">set</span> gemini
<span class="pl-c"><span class="pl-c">#</span> Paste key here</span>

llm -m gemini-2.0-flash-thinking-exp-1219 <span class="pl-s"><span class="pl-pds">"</span>solve a harder variant of that goat lettuce wolf river puzzle<span class="pl-pds">"</span></span></pre></div>
<p>It's <a href="">a very talkative model</a> - 2,277 output tokens answering that prompt.</p>
<h4 id="some-more-interesting-examples">A more interesting example</h4>
<p>The best source of example prompts I've found so far is the <a href="https://github.com/google-gemini/cookbook/blob/main/gemini-2/thinking.ipynb">Gemini 2.0 Flash Thinking cookbook</a> - a Jupyter notebook full of demonstrations of what the model can do.</p>
<p>My favorite so far is this one:</p>
<blockquote>
<p><code>What's the area of the overlapping region?</code></p>
<p><img src="https://static.simonwillison.net/static/2024/geometry.png" alt="Geometric diagram showing a blue circle with radius 3 intersected by a green right triangle. The triangle has side lengths of 6 and the right angled corner of the triangle is positioned on the central point of the circle." style="max-width: 100%;" /></p>
</blockquote>
<p>This model is multi-modal!</p>
<p>Here's how to run that example using <code>llm-gemini</code>:</p>
<div class="highlight highlight-source-shell"><pre>llm -m gemini-2.0-flash-thinking-exp-1219 \
  -a https://storage.googleapis.com/generativeai-downloads/images/geometry.png \
  <span class="pl-s"><span class="pl-pds">"</span>What's the area of the overlapping region?<span class="pl-pds">"</span></span></pre></div>
<p>Here's <a href="https://gist.github.com/simonw/68a0552d882aaa5f51e462c93c614385">the full response</a>, complete with MathML working. The eventual conclusion:</p>
<blockquote>
<p>The final answer is 9π/4</p>
</blockquote>
<p>That's the same answer as Google provided in their example notebook, so I'm presuming it's correct. Impressive!</p>
<p>How about an SVG of <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">a pelican riding a bicycle</a>?</p>
<div class="highlight highlight-source-shell"><pre>llm -m gemini-2.0-flash-thinking-exp-1219 \
  <span class="pl-s"><span class="pl-pds">"</span>Generate an SVG of a pelican riding a bicycle<span class="pl-pds">"</span></span></pre></div>
<p>Here's <a href="https://gist.github.com/simonw/5e9046165dd11a551ccd30907d571985">the full response</a>. Interestingly it slightly corrupted the start of its answer:</p>
<blockquote>
<p><code>This thought process involves a combination of visual thinking, knowledge of SVG syntax, and iterative refinement. The key is to break down the problem into manageable parts and build up the image piece by piece. Even experienced SVG creators often go through several adjustments before arriving at the final version.00" height="250" viewBox="0 0 300 250" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;</code><br />
<code>  &lt;g&gt;</code><br />
<code>  &lt;!-- Bicycle Frame --&gt;</code></p>
</blockquote>
<p>After I manually repaired that to add the <code>&lt;svg</code> opening tag I got this:</p>
<p><img src="https://static.simonwillison.net/static/2024/thinking-pelican.jpg" alt="The bicycle has two wheels but looks more like a pram. The pelican has a good orange beak but its wings are triangles that are oddly positioned." style="max-width: 100%;" /></p>
<p>So maybe not an artistic genius, but it's interesting to read through <a href="https://gist.github.com/simonw/5e9046165dd11a551ccd30907d571985#response">its chain of thought</a> for that task.</p>

<h4 id="whos-next">Who's next?</h4>

<p>It's very clear now that inference scaling is the next big area of research for the large labs. We've seen models from OpenAI (<a href="https://simonwillison.net/2024/Sep/12/openai-o1/">o1</a>), Qwen (<a href="https://simonwillison.net/2024/Nov/27/qwq/">QwQ</a>), DeepSeek (<a href="https://api-docs.deepseek.com/news/news1120">DeepSeek-R1-Lite-Preview</a>) and now Google Gemini. I'm interested to hear if Anthropic or Meta or Mistral or Amazon have anything cooking in this category.</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/google">google</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/llm">llm</a>, <a href="https://simonwillison.net/tags/gemini">gemini</a>, <a href="https://simonwillison.net/tags/o1">o1</a>, <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle">pelican-riding-a-bicycle</a>, <a href="https://simonwillison.net/tags/inference-scaling">inference-scaling</a></p> 

<br> 

<https://simonwillison.net/2024/Dec/19/gemini-thinking-mode/#atom-everything>

---

**@Dave Winer's linkblog** (date: 2024-12-19, from: Dave Winer's linkblog)

<p>One day you could be looking</p>
<p>Through an old book in rainy weather</p>
<p>You see a picture of her smiling at you</p>
<p>When you were still together</p>
<p>You could be walking down the street</p>
<p>And who should you chance to meet</p>
<p>But that same old smile you&#39;ve been thinking of all day</p> 

<br> 

<https://www.youtube.com/watch?v=cA46ZNjrzeY>

---

**@Dave Winer's linkblog** (date: 2024-12-19, from: Dave Winer's linkblog)

The About page for my blog in 2003. It&#39;s pretty funny, if you like that kind of stuff. 

<br> 

<http://essaysfromexodus.scripting.com/whatIsScriptingNews>

---

## Asus announces the NUC 14 Pro AI Lunar Lake mini PC

date: 2024-12-19, from: Liliputing

<p>The Asus NUC 14 Pro AI is a compact desktop computer with support for up to an Intel Core Ultra 9 288V &#8220;Lunar Lake&#8221; processor and support for WiFi 7, 2.5 Gb Ethernet, and Thunderbolt 4. Asus first added the computer to its website in September when Intel first unveiled the Lunar Lake processor lineup, [&#8230;]</p>
<p>The post <a href="https://liliputing.com/asus-announces-the-nuc-14-pro-ai-lunar-lake-mini-pc/">Asus announces the NUC 14 Pro AI Lunar Lake mini PC</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/asus-announces-the-nuc-14-pro-ai-lunar-lake-mini-pc/>

---

**@Dave Winer's linkblog** (date: 2024-12-19, from: Dave Winer's linkblog)

Musk&#39;s misinformation campaign helps block Congress&#39; spending deal. 

<br> 

<https://thehill.com/policy/technology/5049450-musk-floods-x-with-spending-bill-misinformation/>

---

## Ventiva unveils an active cooling solution for fanless laptops

date: 2024-12-19, from: Liliputing

<p>Most laptop computers have fans to help dissipate heat generated by the CPU and other hardware. But fans generate noise, have a habit of getting clogged with dust, and like most moving parts, an sometimes break down. Fanless PCs have been around for years, but they usually come with trade-offs like lower-power processors that generate [&#8230;]</p>
<p>The post <a href="https://liliputing.com/ventiva-unveils-an-active-cooling-solution-for-fanless-laptops-up/">Ventiva unveils an active cooling solution for fanless laptops</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/ventiva-unveils-an-active-cooling-solution-for-fanless-laptops-up/>

---

**@Dave Winer's linkblog** (date: 2024-12-19, from: Dave Winer's linkblog)

America’s Bird-Flu Luck Has Officially Run Out. 

<br> 

<https://www.theatlantic.com/health/archive/2024/12/america-bird-flu-severe-case/681115/?link_source=ta_thread_link&taid=6764877172bf3a0001fc3c5b&utm_campaign=the-atlantic&utm_content=true-anthem&utm_medium=social&utm_source=threads>

---

## Swift Prospective Vision: Accessors

date: 2024-12-19, from: Michael Tsai

John McCall (forum): However, this approach has significant problems. The biggest is that the get accessor has to return an independent value. If the accessor is just returning a value stored in memory, which is very common for data structures, this means the value has to be copied.[&#8230;]This vision document lays out the design space [&#8230;] 

<br> 

<https://mjtsai.com/blog/2024/12/19/swift-prospective-vision-accessors/>

---

## Delta Adds External Purchase Link in US

date: 2024-12-19, from: Michael Tsai

John Voorhees: Delta, the MacStories Selects App of the Year, received an important update today that allows users of the game emulator to support its development via Patreon from inside the app. Existing patrons can connect their Patreon accounts from Delta&#8217;s settings, too, allowing them to access perks like alternative app icons and experimental features.This [&#8230;] 

<br> 

<https://mjtsai.com/blog/2024/12/19/delta-adds-external-purchase-link-in-us/>

---

## SwiftUWhy

date: 2024-12-19, from: Michael Tsai

John Siracusa: Welcome to my new series on things I don&#8217;t understand about Apple&#8217;s premier user interface framework.[&#8230;]To be clear, these are things I don&#8217;t understand, not necessarily things that are &#8220;wrong.&#8221; They sure look wrong (or at least &#8220;suboptimal&#8221;) to me! But maybe there are good reasons, and I just don&#8217;t know them yet. [&#8230;] 

<br> 

<https://mjtsai.com/blog/2024/12/19/swiftuwhy/>

---

## Cascable Studio Rejected From the App Store

date: 2024-12-19, from: Michael Tsai

Daniel Kennett: I&#8217;ve been shipping apps to the App Store for well over fifteen years now, and although there are App Review horror stories aplenty, I&#8217;ve always hoped I&#8217;d never be in a position to write one myself.[&#8230;]What you just scrolled past was the history of my (eventually successful) attempt to get the new Mac [&#8230;] 

<br> 

<https://mjtsai.com/blog/2024/12/19/cascable-studio-rejected-from-the-app-store/>

---

## Time to Vote for the December 2024 + Post Topic

date: 2024-12-19, from: Computer ads from the Past

Your options are a programming language, a multimedia program, and a printer. 

<br> 

<https://computeradsfromthepast.substack.com/p/time-to-vote-for-the-december-2024>

---

**@Dave Winer's linkblog** (date: 2024-12-19, from: Dave Winer's linkblog)

$44 billion to buy Twitter looks like the biggest bargain ever. From that seat he controls the spending of Congress. The budget deal he just killed would have spent hundreds of billions. 

<br> 

<https://www.nytimes.com/2024/12/19/us/politics/elon-musk-politics.html?unlocked_article_code=1.ik4.duPB.d-mLpNEjBSwZ&smid=nytcore-ios-share&referringSource=articleShare>

---

**@Dave Winer's linkblog** (date: 2024-12-19, from: Dave Winer's linkblog)

The period of left-wing illiberalism that began about a decade ago seems to have drawn to a close. The final cause of death was the reelection of Donald Trump. 

<br> 

<https://www.theatlantic.com/ideas/archive/2024/12/cancel-culture-illiberalism-dead/681031/?gift=f35zZN0v_gDFE8xNwlQAHUWzWFEQ5KXT57i6SiyqhME&utm_source=copy-link&utm_medium=social&utm_campaign=share>

---

## Daily Deals (12-19-2024)

date: 2024-12-19, from: Liliputing

<p>Laptops with OLED displays usually have hefty price tags. But laptops that are a generation or two old often get significant price cuts when companies are looking to clear out remaining inventory. And those two trends are colliding in a couple of deals on low-cost laptops with reasonably good specs and reasonably low price tags. [&#8230;]</p>
<p>The post <a href="https://liliputing.com/daily-deals-12-19-2024/">Daily Deals (12-19-2024)</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/daily-deals-12-19-2024/>

---

## ONEXPLAYER G1 is an 8.8 inch mini-laptop for gaming (AMD Strix Point and a detachable keyboard)

date: 2024-12-19, from: Liliputing

<p>The ONEXPLAYER G1 is either a mini-laptop that an also be used as a handheld gaming system, or a gaming handheld that can also be used as a general-purpose laptop. It&#8217;s a compact computer with an 8.8 inch display, an AMD Strix Point processor, and a QWERTY keyboard that&#8217;s just (barely) large enough for touch typing. [&#8230;]</p>
<p>The post <a href="https://liliputing.com/onexplayer-g1-is-an-8-8-inch-mini-laptop-for-gaming-amd-strix-point-and-a-detachable-keyboard/">ONEXPLAYER G1 is an 8.8 inch mini-laptop for gaming (AMD Strix Point and a detachable keyboard)</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/onexplayer-g1-is-an-8-8-inch-mini-laptop-for-gaming-amd-strix-point-and-a-detachable-keyboard/>

---

## Is AI progress slowing down?

date: 2024-12-19, updated: 2024-12-19, from: Simon Willison’s Weblog

<p><strong><a href="https://www.aisnakeoil.com/p/is-ai-progress-slowing-down">Is AI progress slowing down?</a></strong></p>
This piece by Arvind Narayanan, Sayash Kapoor and Benedikt Ströbl is the single most insightful essay about AI and LLMs I've seen in a long time. It's long and worth reading every inch of it - it defies summarization, but I'll try anyway.</p>
<p>The key question they address is the widely discussed issue of whether model scaling has stopped working. Last year it seemed like the secret to ever increasing model capabilities was to keep dumping in more data and parameters and training time, but the lack of a convincing leap forward in the two years since GPT-4 - from any of the big labs - suggests that's no longer the case.</p>
<blockquote>
<p>The new dominant narrative seems to be that model scaling is dead, and “inference scaling”, also known as “test-time compute scaling” is the way forward for improving AI capabilities. The idea is to spend more and more computation when using models to perform a task, such as by having them “think” before responding.</p>
</blockquote>
<p>Inference scaling is the trick introduced by OpenAI's o1 and now explored by other models such as Qwen's <a href="https://simonwillison.net/2024/Nov/27/qwq/">QwQ</a>. It's an increasingly practical approach as inference gets more efficient and cost per token continues to <a href="https://simonwillison.net/tags/llm-pricing/">drop through the floor</a>.</p>
<p>But how far can inference scaling take us, especially if it's only effective for certain types of problem?</p>
<blockquote>
<p>The straightforward, intuitive answer to the first question is that inference scaling is useful for problems that have clear correct answers, such as coding or mathematical problem solving. [...] In contrast, for tasks such as writing or language translation, it is hard to see how inference scaling can make a big difference, especially if the limitations are due to the training data. For example, if a model works poorly in translating to a low-resource language because it isn’t aware of idiomatic phrases in that language, the model can’t reason its way out of this.</p>
</blockquote>
<p>There's a delightfully spicy section about why it's a bad idea to defer to the expertise of industry insiders:</p>
<blockquote>
<p>In short, the reasons why one might give more weight to insiders’ views aren’t very important. On the other hand, there’s a huge and obvious reason why we should probably give less weight to their views, which is that they have an incentive to say things that are in their commercial interests, and have a track record of doing so.</p>
</blockquote>
<p>I also enjoyed this note about how we are still potentially years behind in figuring out how to build usable applications that take full advantage of the capabilities we have today:</p>
<blockquote>
<p>The furious debate about whether there is a capability slowdown is ironic, because the link between capability increases and the real-world usefulness of AI is extremely weak. The development of AI-based <a href="https://www.ben-evans.com/benedictevans/2024/4/19/looking-for-ai-use-cases">applications</a> lags far behind the increase of AI capabilities, so even existing AI capabilities remain greatly underutilized. One reason is the <a href="https://www.aisnakeoil.com/i/147899150/reliability">capability-reliability gap</a> --- even when a certain capability exists, it may not work reliably enough that you can take the human out of the loop and actually automate the task (imagine a food delivery app that only works 80% of the time). And the methods for improving reliability are often application-dependent and distinct from methods for improving capability. That said, reasoning models also seem to exhibit <a href="https://youtu.be/iBfQTnA2n2s?si=a-760cPz5ZghJc7w&amp;t=161">reliability improvements</a>, which is exciting.</p>
</blockquote>

    <p><small></small>Via <a href="https://bsky.app/profile/randomwalker.bsky.social/post/3ldnu2gntqs24">@randomwalker.bsky.social</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/o1">o1</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/arvind-narayanan">arvind-narayanan</a>, <a href="https://simonwillison.net/tags/inference-scaling">inference-scaling</a></p> 

<br> 

<https://simonwillison.net/2024/Dec/19/is-ai-progress-slowing-down/#atom-everything>

---

## APpaREnTLy THiS iS hoW yoU JaIlBreAk AI

date: 2024-12-19, from: 404 Media Group

Anthropic created an AI jailbreaking algorithm that keeps tweaking prompts until it gets a harmful response.  

<br> 

<https://www.404media.co/apparently-this-is-how-you-jailbreak-ai/>

---

## Lenovo ThinkBook Plus laptop with a rollable display could launch in 2025

date: 2024-12-19, from: Liliputing

<p>Lenovo has been showing off concept laptops with rollable OLED displays for the past few years. Now Lenovo is said to be preparing to turn that concept into a real device you can actually buy. Evan Blass has shared a set of pictures to Leakmail subscribers that give us a first look at a new Lenovo [&#8230;]</p>
<p>The post <a href="https://liliputing.com/lenovo-thinkbook-plus-laptop-with-a-rollable-display-could-launch-in-2025/">Lenovo ThinkBook Plus laptop with a rollable display could launch in 2025</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/lenovo-thinkbook-plus-laptop-with-a-rollable-display-could-launch-in-2025/>

---

## Enhanced Security with Node-to-Node TLS

date: 2024-12-19, from: Bacalhau Blog

Security at the heart, at the edge, and everywhere in-between. 

<br> 

<https://blog.bacalhau.org/p/enhanced-security-with-node-to-node>

---

## Marking the 80th Anniversary of “an ever-famous American victory”: A Look at the US National Archive’s Battle of the Bulge Records

date: 2024-12-19, from: National Archives, Text Message blog

Today&#8217;s post was written by Duncan Bare, archives technician at the National Archives in College Park. Winston S. Churchill famously described the Battle of the Bulge as “undoubtedly the greatest American battle of the war and […] an ever-famous American victory.”[1]  As the German offensive commenced at around 5:30 am on December 16th, 1944, however, &#8230; <a href="https://text-message.blogs.archives.gov/2024/12/19/marking-the-80th-anniversary-of-an-ever-famous-american-victory-a-look-at-the-us-national-archives-battle-of-the-bulge-records/" class="more-link">Continue reading <span class="screen-reader-text">Marking the 80th Anniversary of “an ever-famous American victory”: A Look at the US National Archive’s Battle of the Bulge Records</span></a> 

<br> 

<https://text-message.blogs.archives.gov/2024/12/19/marking-the-80th-anniversary-of-an-ever-famous-american-victory-a-look-at-the-us-national-archives-battle-of-the-bulge-records/>

---

## Copyright Abuse Is Getting Luigi Mangione Merch Removed From the Internet

date: 2024-12-19, from: 404 Media Group

Artists, merch sellers, and journalists making and posting Luigi media have become the targets of bogus DMCA claims.  

<br> 

<https://www.404media.co/copyright-abuse-is-getting-luigi-mangione-merch-removed-from-the-internet/>

---

**@Dave Winer's linkblog** (date: 2024-12-19, from: Dave Winer's linkblog)

Krugman proves that there must be a reason to have blogs after all. 

<br> 

<http://scripting.com/2024/12/19.html#a155019?title=krugman>

---

**@Dave Winer's linkblog** (date: 2024-12-19, from: Dave Winer's linkblog)

2010: I love reading Paul Krugman&#39;s blog posts. 

<br> 

<http://scripting.com/stories/2010/11/02/iLoveReadingPaulKrugmansBl.html>

---

## q and qv zsh functions for asking questions of websites and YouTube videos with LLM

date: 2024-12-19, updated: 2024-12-19, from: Simon Willison’s Weblog

<p><strong><a href="https://github.com/davidgasquez/dotfiles/blob/bb9df4a369dbaef95ca0c35642de491c7dd41269/shell/zshrc#L50-L99">q and qv zsh functions for asking questions of websites and YouTube videos with LLM</a></strong></p>
Spotted these in David Gasquez's <code>zshrc</code> dotfiles: two shell functions that use my <a href="https://llm.datasette.io/">LLM</a> tool to answer questions about a website or YouTube video.</p>
<p>Here's how to ask a question of a website:</p>
<pre><code>q https://simonwillison.net/ 'What has Simon written about recently?'
</code></pre>
<p>I got back:</p>
<blockquote>
<p>Recently, Simon Willison has written about various topics including:</p>
<ol>
<li><strong>Building Python Tools</strong> - Exploring one-shot applications using Claude and dependency management with <code>uv</code>.</li>
<li><strong>Modern Java Usage</strong> - Discussing recent developments in Java that simplify coding.</li>
<li><strong>GitHub Copilot Updates</strong> - New free tier and features in GitHub Copilot for Vue and VS Code.</li>
<li><strong>AI Engagement on Bluesky</strong> - Investigating the use of bots to create artificially polite disagreements.</li>
<li><strong>OpenAI WebRTC Audio</strong> - Demonstrating a new API for real-time audio conversation with models.</li>
</ol>
</blockquote>
<p>It works by constructing a <a href="https://simonwillison.net/2024/Jun/16/jina-ai-reader/">Jina Reader URL</a> to convert that URL to Markdown, then piping that content into LLM along with the question.</p>
<p>The YouTube one is even more fun:</p>
<pre><code>qv 'https://www.youtube.com/watch?v=uRuLgar5XZw' 'what does Simon say about open source?'
</code></pre>
<p>It said (about <a href="https://www.youtube.com/watch?v=uRuLgar5XZw">this 72 minute video</a>):</p>
<blockquote>
<p>Simon emphasizes that open source has significantly increased productivity in software development. He points out that before open source, developers often had to recreate existing solutions or purchase proprietary software, which often limited customization. The availability of open source projects has made it easier to find and utilize existing code, which he believes is one of the primary reasons for more efficient software development today.</p>
</blockquote>
<p>The secret sauce behind that one is the way it uses <code>yt-dlp</code> to extract just the subtitles for the video:</p>
<pre><code>local subtitle_url=$(yt-dlp -q --skip-download --convert-subs srt --write-sub --sub-langs "en" --write-auto-sub --print "requested_subtitles.en.url" "$url")
local content=$(curl -s "$subtitle_url" | sed '/^$/d' | grep -v '^[0-9]*$' | grep -v '\--&gt;' | sed 's/&lt;[^&gt;]*&gt;//g' | tr '\n' ' ')
</code></pre>
<p>That first line retrieves a URL to the subtitles in WEBVTT format - I <a href="https://gist.github.com/simonw/7f07837cf8adcee23fd5cd5394170f27">saved a copy of that here</a>. The second line then uses <code>curl</code> to fetch them, then <code>sed</code> and <code>grep</code> to remove the timestamp information, producing <a href="https://gist.github.com/simonw/7f07837cf8adcee23fd5cd5394170f27?permalink_comment_id=5350044#gistcomment-5350044">this</a>.

    <p><small></small>Via <a href="https://davidgasquez.com/useful-llm-tools-2024/">Useful LLM tools (2024 Edition)</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/youtube">youtube</a>, <a href="https://simonwillison.net/tags/llm">llm</a>, <a href="https://simonwillison.net/tags/jina">jina</a>, <a href="https://simonwillison.net/tags/zsh">zsh</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a></p> 

<br> 

<https://simonwillison.net/2024/Dec/19/q-and-qv-zsh-functions/#atom-everything>

---

## Faking Love for the Boss

date: 2024-12-19, updated: 2024-12-19, from: One Foot Tsunami

 

<br> 

<https://onefoottsunami.com/2024/12/19/faking-love-for-the-boss/>

---

**@Dave Winer's linkblog** (date: 2024-12-19, from: Dave Winer's linkblog)

Bidenomics Was Wildly Successful. 

<br> 

<https://newrepublic.com/article/189232/bidenomics-success-biden-legacy>

---

## Third Eye assistive vision | The MagPi #149

date: 2024-12-19, from: Raspberry Pi News (.com)

<p>This MagPi Monday, we look at Third Eye, a project that uses AI to assist people with visual impairment.</p>
<p>The post <a href="https://www.raspberrypi.com/news/third-eye-assistive-vision-the-magpi-149/">Third Eye assistive vision | The MagPi #149</a> appeared first on <a href="https://www.raspberrypi.com">Raspberry Pi</a>.</p>
 

<br> 

<https://www.raspberrypi.com/news/third-eye-assistive-vision-the-magpi-149/>

---

**@Dave Winer's linkblog** (date: 2024-12-19, from: Dave Winer's linkblog)

Chris Murphy’s Ominous New Warning about Trump Nails It. 

<br> 

<https://newrepublic.com/article/189552/transcript-chris-murphys-ominous-new-warning-trump-nails>

---

## What just happened

date: 2024-12-19, from: One Useful Thing

A transformative month rewrites the capabilities of AI 

<br> 

<https://www.oneusefulthing.org/p/what-just-happened>

---

## More Than Watergate: The PRMPA

date: 2024-12-19, from: National Archives, Pieces of History blog

Today’s post on the Presidential Recordings and Materials Preservation Act (PRMPA) comes from Laurel Gray, a processing intern with the Textual Division at the National Archives in Washington, DC. It is the second of a four-part&#160;series on&#160;the archival ramifications of the Watergate scandal. When President Richard Nixon resigned in August 1974, he signed an agreement &#8230; <a href="https://prologue.blogs.archives.gov/2024/12/19/more-than-watergate-the-prmpa/" class="more-link">Continue reading <span class="screen-reader-text">More Than Watergate: The PRMPA</span></a> 

<br> 

<https://prologue.blogs.archives.gov/2024/12/19/more-than-watergate-the-prmpa/>

---

**@Dave Winer's linkblog** (date: 2024-12-19, from: Dave Winer's linkblog)

I’m very confused about how they’re integrating AI and GitHub, but it sounds like it’ll be useful, when I figure out what it is. 

<br> 

<https://github.blog/news-insights/product-news/github-copilot-workspace/>

---

**@Dave Winer's linkblog** (date: 2024-12-19, from: Dave Winer's linkblog)

What happens when the internet disappears? 

<br> 

<https://www.theverge.com/24321569/internet-decay-link-rot-web-archive-deleted-culture>

---

## Wednesday, December 18, 2024 -  notes on the garmin instinct 2 solar -  table of contents -  background & motivations -  the watch -  case design, fit, appearance, etc. -  display -  power -  durability -  sensors -  compass failures -  software -  on-device interface -  mobile apps, etc. -  gadgetbridge as an alternative -  data syncing -  some implications of this device -  notes for garmin

date: 2024-12-19, updated: 2024-12-19, from: p1k3.com community feed

 

<br> 

<https://p1k3.com/2024/12/18>

---

## Building Python tools with a one-shot prompt using uv run and Claude Projects

date: 2024-12-19, updated: 2024-12-19, from: Simon Willison’s Weblog

<p>I've written a lot about how I've been using Claude to build one-shot HTML+JavaScript applications <a href="https://simonwillison.net/tags/claude-artifacts/">via Claude Artifacts</a>. I recently started using a similar pattern to create one-shot Python utilities, using a custom Claude Project combined with the dependency management capabilities of <a href="https://github.com/astral-sh/uv">uv</a>.</p>
<p>(In LLM jargon a "one-shot" prompt is a prompt that produces the complete desired result on the first attempt.)</p>
<p>I'll start with an example of a tool I built that way.</p>
<p>I had another round of battle with Amazon S3 today trying to figure out why a file in one of my buckets couldn't be accessed via a public URL.</p>
<p>Out of frustration I prompted Claude with a variant of the following (<a href="https://gist.github.com/simonw/9f69cf35889b0445b80eeed691d44504">full transcript here</a>):</p>
<blockquote>
<p><code>I can't access the file at EXAMPLE_S3_URL. Write me a Python CLI tool using Click and boto3 which takes a URL of that form and then uses EVERY single boto3 trick in the book to try and debug why the file is returning a 404</code></p>
</blockquote>
<p>It wrote me <a href="https://github.com/simonw/tools/blob/main/python/debug_s3_access.py">this script</a>, which gave me exactly what I needed. I ran it like this:</p>
<div class="highlight highlight-source-shell"><pre>uv run debug_s3_access.py \
  https://test-public-bucket-simonw.s3.us-east-1.amazonaws.com/0f550b7b28264d7ea2b3d360e3381a95.jpg</pre></div>
<p><img src="https://static.simonwillison.net/static/2024/debug-s3.jpg" alt="Terminal screenshot showing S3 access analysis results. Command: '$ uv run http://tools.simonwillison.net/python/debug_s3_access.py url-to-image' followed by detailed output showing bucket exists (Yes), region (default), key exists (Yes), bucket policy (AllowAllGetObject), bucket owner (swillison), versioning (Not enabled), content type (image/jpeg), size (71683 bytes), last modified (2024-12-19 03:43:30+00:00) and public access settings (all False)" style="max-width: 100%;" /></p>
<p>You can <a href="https://github.com/simonw/tools/tree/main/python#debug_s3_accesspy">see the text output here</a>.</p>
<h4 id="inline-dependencies-and-uv-run">Inline dependencies and uv run</h4>
<p>Crucially, I didn't have to take any extra steps to install any of the dependencies that the script needed. That's because the script starts with this magic comment:</p>
<pre><span class="pl-c"># /// script</span>
<span class="pl-c"># requires-python = "&gt;=3.12"</span>
<span class="pl-c"># dependencies = [</span>
<span class="pl-c">#     "click",</span>
<span class="pl-c">#     "boto3",</span>
<span class="pl-c">#     "urllib3",</span>
<span class="pl-c">#     "rich",</span>
<span class="pl-c"># ]</span>
<span class="pl-c"># ///</span></pre>
<p>This is an example of <a href="https://docs.astral.sh/uv/guides/scripts/#declaring-script-dependencies">inline script dependencies</a>, a feature described in <a href="https://peps.python.org/pep-0723/">PEP 723</a> and implemented by <code>uv run</code>. Running the script causes <code>uv</code> to create a temporary virtual environment with those dependencies installed, a process that takes just a few milliseconds once the <code>uv</code> cache has been populated.</p>
<p>This even works if the script is specified by a URL! Anyone with <code>uv</code> installed can run the following command (provided you trust me not to have replaced the script with something malicious) to debug one of their own S3 buckets:</p>
<div class="highlight highlight-source-shell"><pre>uv run http://tools.simonwillison.net/python/debug_s3_access.py \
  https://test-public-bucket-simonw.s3.us-east-1.amazonaws.com/0f550b7b28264d7ea2b3d360e3381a95.jpg</pre></div>
<h4 id="writing-these-with-the-help-of-a-claude-project">Writing these with the help of a Claude Project</h4>
<p>The reason I can one-shot scripts like this now is that I've set up a <a href="https://www.anthropic.com/news/projects">Claude Project</a> called "Python app". Projects can have custom instructions, and I used those to "teach" Claude how to take advantage of inline script dependencies:</p>
<blockquote>
<p>You write Python tools as single files. They always start with this comment:</p>
<pre><span># /// script</span>
<span># requires-python = "&gt;=3.12"</span>
<span># ///</span></pre>
<p>These files can include dependencies on libraries such as Click. If they do, those dependencies are included in a list like this one in that same comment (here showing two dependencies):</p>
<pre><span># /// script</span>
<span># requires-python = "&gt;=3.12"</span>
<span># dependencies = [</span>
<span>#     "click",</span>
<span>#     "sqlite-utils",</span>
<span># ]</span>
<span># ///</span></pre>
</blockquote>
<p>That's everything Claude needs to reliably knock out full-featured Python tools as single scripts which can be run directly using whatever dependencies Claude chose to include.</p>
<p>I didn't suggest that Claude use <a href="https://github.com/Textualize/rich">rich</a> for the <code>debug_s3_access.py</code> script earlier but it decided to use it anyway!</p>
<p>I've only recently started experimenting with this pattern but it seems to work <em>really</em> well. Here's another example - my prompt was:</p>
<blockquote>
<p><code>Starlette web app that provides an API where you pass in ?url= and it strips all HTML tags and returns just the text, using beautifulsoup</code></p>
</blockquote>
<p>Here's <a href="https://gist.github.com/simonw/08957a1490ebde1ea38b4a8374989cf8">the chat transcript</a> and <a href="https://gist.githubusercontent.com/simonw/08957a1490ebde1ea38b4a8374989cf8/raw/143ee24dc65ca109b094b72e8b8c494369e763d6/strip_html.py">the raw code it produced</a>. You can run that server directly on your machine (it uses port 8000) like this:</p>
<div class="highlight highlight-source-shell"><pre>uv run https://gist.githubusercontent.com/simonw/08957a1490ebde1ea38b4a8374989cf8/raw/143ee24dc65ca109b094b72e8b8c494369e763d6/strip_html.py</pre></div>
<p>Then visit <code>http://127.0.0.1:8000/?url=https://simonwillison.net/</code> to see it in action.</p>
<h4 id="custom-instructions">Custom instructions</h4>
<p>The pattern here that's most interesting to me is using custom instructions or system prompts to show LLMs how to implement new patterns that may not exist in their training data. <code>uv run</code> is less than a year old, but providing just a short example is enough to get the models to write code that takes advantage of its capabilities.</p>
<p>I have a similar set of custom instructions I use for creating single page HTML and JavaScript tools, again running in a Claude Project:</p>

<blockquote>
<p>Never use React in artifacts - always plain HTML and vanilla JavaScript and CSS with minimal dependencies.</p>
<p>CSS should be indented with two spaces and should start like this:</p>
<div class="highlight highlight-text-html-basic"><pre><span class="pl-kos">&lt;</span><span class="pl-ent">style</span><span class="pl-kos">&gt;</span>
* {
  box-sizing: border-box;
}</pre></div>
<p>Inputs and textareas should be font size 16px. Font should always prefer Helvetica.</p>
<p>JavaScript should be two space indents and start like this:</p>
<div class="highlight highlight-text-html-basic"><pre><span class="pl-kos">&lt;</span><span class="pl-ent">script</span> <span class="pl-c1">type</span>="<span class="pl-s">module</span>"<span class="pl-kos">&gt;</span>
// code in here should not be indented at the first level</pre></div>
</blockquote>
<p>Most of the tools on my <a href="https://tools.simonwillison.net/">tools.simonwillison.net</a> site were created using versions of this custom instructions prompt.</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/aws">aws</a>, <a href="https://simonwillison.net/tags/python">python</a>, <a href="https://simonwillison.net/tags/s3">s3</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/prompt-engineering">prompt-engineering</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/claude">claude</a>, <a href="https://simonwillison.net/tags/claude-artifacts">claude-artifacts</a>, <a href="https://simonwillison.net/tags/uv">uv</a></p> 

<br> 

<https://simonwillison.net/2024/Dec/19/one-shot-python-tools/#atom-everything>

---

**@Dave Winer's linkblog** (date: 2024-12-19, from: Dave Winer's linkblog)

How Trump gets his hair done. 

<br> 

<https://x.com/blaireerskine/status/1869579712693157980/mediaViewer?currentTweet=1869579712693157980&currentTweetUser=blaireerskine>

---

## How to shrink ONNX files

date: 2024-12-19, from: Peter Warden

I&#8217;ve been using the ONNX Runtime a lot recently, and while it has been a lot of fun, there are a few things I&#8217;ve missed from the TensorFlow Lite world. The biggest (no pun intended) is the lack of tools to shrink the model file size, something that&#8217;s always been essential in the mobile app [&#8230;] 

<br> 

<https://petewarden.com/2024/12/19/how-to-shrink-onnx-files/>

---

## “We Are Getting Lasered”: Nearly a Dozen Planes Lasered Last Night During New Jersey Drone Panic

date: 2024-12-19, from: 404 Media Group

Air traffic control audio reviewed by 404 Media shows 11 aircraft near New Jersey reporting people shining lasers at them during the ongoing drone panic. 

<br> 

<https://www.404media.co/we-are-getting-lasered-nearly-a-dozen-planes-lasered-last-night-during-new-jersey-drone-panic/>

---

**@Dave Winer's linkblog** (date: 2024-12-19, from: Dave Winer's linkblog)

&quot;We should spend a few months marketing the Democratic Party.&quot; 

<br> 

<https://bsky.app/profile/did:plc:oety7qbfx7x6exn2ytrwikmr/post/3lbuy3qlb7s2v>

---

## AI Engineering Primer

date: 2024-12-19, updated: 2024-12-19, from: Tom Kellog blog

How do you get up to speed with AI engineering? Unfortunately, I don’t know of any good consolidated
resources, so I’m going to attempt to make one here. My first attempt at this focused more on
what an AI engineer is and made only a feeble attempt at providing resources to get started. Let’s go! 

<br> 

<http://timkellogg.me/blog/2024/12/19/ai-primer>

