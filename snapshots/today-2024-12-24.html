<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>News gathered 2024-12-24</title>
  <style>
    body {
       padding: 1%;
       margin: 2%;
    }
    footer {
    	border-top: 0.24em solid green;
	text-align: center;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
</head>
<body>
<section>
<h1 id="news-gathered-2024-12-24">News gathered 2024-12-24</h1>
<p>(date: 2024-12-24 07:09:28)</p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer‚Äôs
linkblog</strong> (date: 2024-12-24, from: Dave Winer‚Äôs linkblog)</p>
<p>Whatever forces you into copying and pasting into tiny little text
boxes, that's how you know you're in a silo.</p>
<p><br></p>
<p><a href="http://scripting.com/2024/12/24.html#a141952"
class="uri">http://scripting.com/2024/12/24.html#a141952</a></p>
<hr />
<h2
id="tipster-arrested-after-feds-find-ai-child-exploit-images-and-plans-to-make-vr-csam">Tipster
Arrested After Feds Find AI Child Exploit Images and Plans to Make VR
CSAM</h2>
<p>date: 2024-12-24, from: 404 Media Group</p>
<p>A review of a tipster‚Äôs phone revealed ‚Äòreal‚Äô CSAM mixed in with AI
CSAM, and a darker involvement in the case.</p>
<p><br></p>
<p><a
href="https://www.404media.co/tipster-arrested-after-feds-find-ai-child-exploit-images-and-plans-to-make-vr-csam-2/"
class="uri">https://www.404media.co/tipster-arrested-after-feds-find-ai-child-exploit-images-and-plans-to-make-vr-csam-2/</a></p>
<hr />
<h2
id="ho-ho-ho---whats-so-funny-about-an-overweight-old-man-in-a-white-beard">HO,
HO, HO - WHAT‚ÄôS SO FUNNY ABOUT AN OVERWEIGHT OLD MAN IN A WHITE
BEARD?</h2>
<p>date: 2024-12-24, from: Howard Jacobson blog</p>
<p>Robert Cenedella</p>
<p><br></p>
<p><a
href="https://jacobsonh.substack.com/p/ho-ho-ho-whats-so-funny-about-an"
class="uri">https://jacobsonh.substack.com/p/ho-ho-ho-whats-so-funny-about-an</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer‚Äôs
linkblog</strong> (date: 2024-12-24, from: Dave Winer‚Äôs linkblog)</p>
<p>My favorite news sources, pros and bloggers, podcasts, culture,
business, tech, politics.</p>
<p><br></p>
<p><a href="https://news.scripting.com/"
class="uri">https://news.scripting.com/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer‚Äôs
linkblog</strong> (date: 2024-12-24, from: Dave Winer‚Äôs linkblog)</p>
<p>Ars Technica picks for TV of 2024.</p>
<p><br></p>
<p><a
href="https://arstechnica.com/culture/2024/12/tv-technica-2024-our-picks-for-the-best-of-tv/"
class="uri">https://arstechnica.com/culture/2024/12/tv-technica-2024-our-picks-for-the-best-of-tv/</a></p>
<hr />
<h2 id="quoting-jeremy-edberg">Quoting Jeremy Edberg</h2>
<p>date: 2024-12-24, updated: 2024-12-24, from: Simon Willison‚Äôs
Weblog</p>
<blockquote cite="https://news.ycombinator.com/item?id=42486610#42492484">
<p>
[On Reddit] we had to look up every single comment on the page to see if
you had voted on it [‚Ä¶]
</p>
<p>
But with a bloom filter, we could very quickly look up all the comments
and get back a list of all the ones you voted on (with a couple of false
positives in there). Then we could go to the cache and see if your
actual vote was there (and if it was an upvote or a downvote). It was
only after a failed cache hit did we have to actually go to the
database.
</p>
<p>
But that bloom filter saved us from doing sometimes 1000s of cache
lookups.
</p>
</blockquote>
<p class="cite">
‚Äî
<a href="https://news.ycombinator.com/item?id=42486610#42492484">Jeremy
Edberg</a>
</p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/reddit&quot;&gt;reddit&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/bloom-filters&quot;&gt;bloom-filters&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/scaling&quot;&gt;scaling&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2024/Dec/24/jeremy-edberg/#atom-everything"
class="uri">https://simonwillison.net/2024/Dec/24/jeremy-edberg/#atom-everything</a></p>
<hr />
<h2 id="finally-a-replacement-for-bert-introducing-modernbert">Finally,
a replacement for BERT: Introducing ModernBERT</h2>
<p>date: 2024-12-24, updated: 2024-12-24, from: Simon Willison‚Äôs
Weblog</p>
<p>
<strong><a href="https://www.answer.ai/posts/2024-12-19-modernbert.html">Finally,
a replacement for BERT: Introducing ModernBERT</a></strong>
</p>
<a href="https://en.wikipedia.org/wiki/BERT_(language_model)">BERT</a>
was an early language model released by Google in October 2018. Unlike
modern LLMs it wasn‚Äôt designed for generating text. BERT was trained for
masked token prediction and was generally applied to problems like Named
Entity Recognition or Sentiment Analysis. BERT also wasn‚Äôt very useful
on its own - most applications required you to fine-tune a model on top
of it.
</p>
<p>
In exploring BERT I decided to try out
<a href="https://huggingface.co/dslim/distilbert-NER">dslim/distilbert-NER</a>,
a popular Named Entity Recognition model fine-tuned on top of DistilBERT
(a smaller distilled version of the original BERT model).
<a href="https://til.simonwillison.net/llms/bert-ner">Here are my
notes</a> on running that using <code>uv run</code>.
</p>
<p>
Jeremy Howard‚Äôs <a href="https://www.answer.ai/">Answer.AI</a> research
group, <a href="https://www.lighton.ai/">LightOn</a> and friends
supported the development of ModernBERT, a brand new BERT-style model
that applies many enhancements from the past six years of advances in
this space.
</p>
<p>
While BERT was trained on 3.3 billion tokens, producing 110 million and
340 million parameter models, ModernBERT trained on 2 trillion tokens,
resulting in 140 million and 395 million parameter models. The parameter
count hasn‚Äôt increased much because it‚Äôs designed to run on lower-end
hardware. It has a 8192 token context length, a significant improvement
on BERT‚Äôs 512.
</p>
<p>
I was able to run one of the demos from the announcement post using
<code>uv run</code> like this (I‚Äôm not sure why I had to use
<code>numpy&lt;2.0</code> but without that I got an error about
<code>cannot import name ‚ÄòComplexWarning‚Äô from
‚Äònumpy.core.numeric‚Äô</code>):
</p>
<div class="highlight highlight-source-shell">
<pre>uv run --with <span class="pl-s"><span class="pl-pds">'</span>numpy&lt;2.0<span class="pl-pds">'</span></span> --with torch --with <span class="pl-s"><span class="pl-pds">'</span>git+https://github.com/huggingface/transformers.git<span class="pl-pds">'</span></span> python</pre>
</div>
<p>
Then this Python:
</p>
<pre><span class="pl-k">import</span> <span class="pl-s1">torch</span>
<span class="pl-k">from</span> <span class="pl-s1">transformers</span> <span class="pl-k">import</span> <span class="pl-s1">pipeline</span>
<span class="pl-k">from</span> <span class="pl-s1">pprint</span> <span class="pl-k">import</span> <span class="pl-s1">pprint</span>
<span class="pl-s1">pipe</span> <span class="pl-c1">=</span> <span class="pl-en">pipeline</span>(
    <span class="pl-s">"fill-mask"</span>,
    <span class="pl-s1">model</span><span class="pl-c1">=</span><span class="pl-s">"answerdotai/ModernBERT-base"</span>,
    <span class="pl-s1">torch_dtype</span><span class="pl-c1">=</span><span class="pl-s1">torch</span>.<span class="pl-c1">bfloat16</span>,
)
<span class="pl-s1">input_text</span> <span class="pl-c1">=</span> <span class="pl-s">"He walked to the [MASK]."</span>
<span class="pl-s1">results</span> <span class="pl-c1">=</span> <span class="pl-en">pipe</span>(<span class="pl-s1">input_text</span>)
<span class="pl-en">pprint</span>(<span class="pl-s1">results</span>)</pre>
<p>
Which downloaded 573MB to
<code>~/.cache/huggingface/hub/models‚Äìanswerdotai‚ÄìModernBERT-base</code>
and output:
</p>
<pre>[{<span class="pl-s">'score'</span>: <span class="pl-c1">0.11669921875</span>,
  <span class="pl-s">'sequence'</span>: <span class="pl-s">'He walked to the door.'</span>,
  <span class="pl-s">'token'</span>: <span class="pl-c1">3369</span>,
  <span class="pl-s">'token_str'</span>: <span class="pl-s">' door'</span>},
 {<span class="pl-s">'score'</span>: <span class="pl-c1">0.037841796875</span>,
  <span class="pl-s">'sequence'</span>: <span class="pl-s">'He walked to the office.'</span>,
  <span class="pl-s">'token'</span>: <span class="pl-c1">3906</span>,
  <span class="pl-s">'token_str'</span>: <span class="pl-s">' office'</span>},
 {<span class="pl-s">'score'</span>: <span class="pl-c1">0.0277099609375</span>,
  <span class="pl-s">'sequence'</span>: <span class="pl-s">'He walked to the library.'</span>,
  <span class="pl-s">'token'</span>: <span class="pl-c1">6335</span>,
  <span class="pl-s">'token_str'</span>: <span class="pl-s">' library'</span>},
 {<span class="pl-s">'score'</span>: <span class="pl-c1">0.0216064453125</span>,
  <span class="pl-s">'sequence'</span>: <span class="pl-s">'He walked to the gate.'</span>,
  <span class="pl-s">'token'</span>: <span class="pl-c1">7394</span>,
  <span class="pl-s">'token_str'</span>: <span class="pl-s">' gate'</span>},
 {<span class="pl-s">'score'</span>: <span class="pl-c1">0.020263671875</span>,
  <span class="pl-s">'sequence'</span>: <span class="pl-s">'He walked to the window.'</span>,
  <span class="pl-s">'token'</span>: <span class="pl-c1">3497</span>,
  <span class="pl-s">'token_str'</span>: <span class="pl-s">' window'</span>}]</pre>
<p>
<p>I‚Äôm looking forward to trying out models that use ModernBERT as their
base. The model release is accompanied by a paper
(<a href="https://arxiv.org/abs/2412.13663">Smarter, Better, Faster,
Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and
Long Context Finetuning and Inference</a>) and
<a href="https://huggingface.co/docs/transformers/main/en/model_doc/modernbert">new
documentation</a> for using it with the Transformers library.</p>
<pre><code>&lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href=&quot;https://bsky.app/profile/benjaminwarner.dev/post/3ldur45oz322b&quot;&gt;@benjaminwarner.dev&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/jeremy-howard&quot;&gt;jeremy-howard&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/transformers&quot;&gt;transformers&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/hugging-face&quot;&gt;hugging-face&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/uv&quot;&gt;uv&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/python&quot;&gt;python&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/nlp&quot;&gt;nlp&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2024/Dec/24/modernbert/#atom-everything"
class="uri">https://simonwillison.net/2024/Dec/24/modernbert/#atom-everything</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer‚Äôs
linkblog</strong> (date: 2024-12-24, from: Dave Winer‚Äôs linkblog)</p>
<p>Tesla's 2024 deliveries growth might hinge on Musk's unorthodox
Cybertruck.</p>
<p><br></p>
<p><a
href="https://www.reuters.com/business/autos-transportation/teslas-2024-deliveries-growth-might-hinge-musks-unorthodox-cybertruck-2024-12-20/"
class="uri">https://www.reuters.com/business/autos-transportation/teslas-2024-deliveries-growth-might-hinge-musks-unorthodox-cybertruck-2024-12-20/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer‚Äôs
linkblog</strong> (date: 2024-12-24, from: Dave Winer‚Äôs linkblog)</p>
<p>Trump's Plan to Make America a Global Bully.</p>
<p><br></p>
<p><a
href="https://www.theatlantic.com/magazine/archive/2025/01/trump-foreign-policy-isolation/680754/?gift=f35zZN0v_gDFE8xNwlQAHQ8w2Hd1-0-zPQQVqe3_z0Y"
class="uri">https://www.theatlantic.com/magazine/archive/2025/01/trump-foreign-policy-isolation/680754/?gift=f35zZN0v_gDFE8xNwlQAHQ8w2Hd1-0-zPQQVqe3_z0Y</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer‚Äôs
linkblog</strong> (date: 2024-12-24, from: Dave Winer‚Äôs linkblog)</p>
<p>Interesting way to sell an E-car. ü§™</p>
<p><br></p>
<p><a href="https://m.youtube.com/watch?v=LxtJ5yi_yps"
class="uri">https://m.youtube.com/watch?v=LxtJ5yi_yps</a></p>
<hr />
<h2 id="explainer-latent-space-experts">Explainer: Latent Space
Experts</h2>
<p>date: 2024-12-24, updated: 2024-12-24, from: Tom Kellog blog</p>
<p>A new paper just dropped from Google DeepMind, Deliberation in Latent
Space via Differentiable Cache Augmentation. I don‚Äôt think this paper is
very readable, but it also seems quite important so I wanted to take a
moment to break it down, as I understand it.</p>
<p><br></p>
<p><a href="http://timkellogg.me/blog/2024/12/24/latent-experts"
class="uri">http://timkellogg.me/blog/2024/12/24/latent-experts</a></p>
<hr />
<p><strong><span class="citation"
data-cites="Tomosino">@Tomosino</span>‚Äôs Mastodon feed</strong> (date:
2024-12-23, from: Tomosino‚Äôs Mastodon feed)</p>
<p>
Read a nasty critic review of a concert, got mad, and wrote this. Enjoy
</p>
<p>
<a href="https://blog.tomasino.org/five-stars/" target="_blank" rel="nofollow noopener noreferrer" translate="no"><span
class="invisible">https://</span><span>blog.tomasino.org/five-stars/</span><span
class="invisible"></span></a>
</p>
<p><br></p>
<p><a href="https://tilde.zone/@tomasino/113704671848614521"
class="uri">https://tilde.zone/@tomasino/113704671848614521</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer‚Äôs
linkblog</strong> (date: 2024-12-23, from: Dave Winer‚Äôs linkblog)</p>
<p>Portion of Santa Cruz wharf collapses amid dangerous surf.</p>
<p><br></p>
<p><a
href="https://lookout.co/portion-of-santa-cruz-wharf-collapses-amid-dangerous-surf-prompting-multiple-water-rescues/"
class="uri">https://lookout.co/portion-of-santa-cruz-wharf-collapses-amid-dangerous-surf-prompting-multiple-water-rescues/</a></p>
<hr />
<h2
id="compare-handheld-gaming-pc-specs-asus-aya-gpd-lenovo-msi-onexplayer-and-valve">Compare
handheld gaming PC specs (Asus, AYA, GPD, Lenovo, MSI, ONEXPLAYER, and
Valve)</h2>
<p>date: 2024-12-23, from: Liliputing</p>
<p>
There are a growing number of handheld gaming PCs on the market, and the
list keeps growing. While the Valve Steam Deck, Asus ROG Ally, and
Lenovo Legion Go grab a lot of headlines these days, they‚Äôre not exactly
the only games in town ‚Äì not by a long shot. In fact, there are so [‚Ä¶]
</p>
<p>
The post
<a href="https://liliputing.com/compare-handheld-gaming-pc-specs-anbernic-ayn-aya-gpd-onexplayer-and-valve/">Compare
handheld gaming PC specs (Asus, AYA, GPD, Lenovo, MSI, ONEXPLAYER, and
Valve)</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/compare-handheld-gaming-pc-specs-anbernic-ayn-aya-gpd-onexplayer-and-valve/"
class="uri">https://liliputing.com/compare-handheld-gaming-pc-specs-anbernic-ayn-aya-gpd-onexplayer-and-valve/</a></p>
<hr />
<h2 id="deleting-unused-photos-from-apple-photos">Deleting Unused Photos
From Apple Photos</h2>
<p>date: 2024-12-23, from: Michael Tsai</p>
<p>I‚Äôve been trying to reduce the storage that the Photos app uses, both
on my Mac and in iCloud. I use Lightroom for my photo library, so I
would like to delete all the photos that are not referenced by projects
(calendars and photo books). Unfortunately, Photos is unable to display
any of my projects [‚Ä¶]</p>
<p><br></p>
<p><a
href="https://mjtsai.com/blog/2024/12/23/deleting-unused-photos-from-apple-photos/"
class="uri">https://mjtsai.com/blog/2024/12/23/deleting-unused-photos-from-apple-photos/</a></p>
<hr />
<h2 id="metas-ios-interoperability-requests">Meta‚Äôs iOS Interoperability
Requests</h2>
<p>date: 2024-12-23, from: Michael Tsai</p>
<p>Juli Clover: Apple today said that Meta has made 15 interoperability
requests under the Digital Markets Act (DMA) in the European Union,
which is more than any other company.In a statement provided to Reuters,
Apple said that Meta is asking for changes that could compromise user
security and privacy.[‚Ä¶]In response to Apple‚Äôs comments on Meta‚Äôs
[‚Ä¶]</p>
<p><br></p>
<p><a
href="https://mjtsai.com/blog/2024/12/23/metas-ios-interoperability-requests/"
class="uri">https://mjtsai.com/blog/2024/12/23/metas-ios-interoperability-requests/</a></p>
<hr />
<h2 id="whatsapp-v.-nso-group">WhatsApp v. NSO Group</h2>
<p>date: 2024-12-23, from: Michael Tsai</p>
<p>Reuters (via Hacker News, Court Listener): U.S. judge ruled on Friday
in favor of Meta Platforms‚Äô, WhatsApp in a lawsuit accusing Israel‚Äôs NSO
Group of exploiting a bug in the messaging app to install spy software
allowing unauthorized surveillance.[‚Ä¶]WhatsApp in 2019 sued NSO seeking
an injunction and damages, accusing it of accessing WhatsApp servers
without [‚Ä¶]</p>
<p><br></p>
<p><a href="https://mjtsai.com/blog/2024/12/23/whatsapp-v-nso-group/"
class="uri">https://mjtsai.com/blog/2024/12/23/whatsapp-v-nso-group/</a></p>
<hr />
<h2 id="donald-bitzer-rip">Donald Bitzer, RIP</h2>
<p>date: 2024-12-23, from: Michael Tsai</p>
<p>Dag Spicer (via Hacker News): Bitzer studied electrical engineering
at the University of Illinois at Urbana-Champaign (UIUC), obtaining a
PhD in 1960. Following graduation, he joined the UIUC faculty, where he
learned of efforts to bring lessons to students over a closed-circuit
television network. While a committee of engineers, psychologists, and
educators were unable to [‚Ä¶]</p>
<p><br></p>
<p><a href="https://mjtsai.com/blog/2024/12/23/donald-bitzer-rip/"
class="uri">https://mjtsai.com/blog/2024/12/23/donald-bitzer-rip/</a></p>
<hr />
<h2
id="minisforum-v3-se-is-a-cheaper-3-in-1-tablet-with-an-older-amd-ryzen-processor">MINISFORUM
V3 SE is a cheaper 3-in-1 tablet with an older AMD Ryzen processor</h2>
<p>date: 2024-12-23, from: Liliputing</p>
<p>
The¬†MINISFORUM V3¬†that launched earlier this year is a 14 inch tablet
with a 2560 x 1600 pixel, 165 Hz, 500 nit display and an AMD Ryzen 7
8840U processor. It was one of the first tablets with an AMD ‚ÄúHawk
Point‚Äù processor. But it‚Äôs not exactly cheap: it still sells for $999
and up even [‚Ä¶]
</p>
<p>
The post
<a href="https://liliputing.com/minisforum-v3-se-is-a-cheaper-3-in-1-tablet-with-an-older-amd-ryzen-processor/">MINISFORUM
V3 SE is a cheaper 3-in-1 tablet with an older AMD Ryzen processor</a>
appeared first on <a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/minisforum-v3-se-is-a-cheaper-3-in-1-tablet-with-an-older-amd-ryzen-processor/"
class="uri">https://liliputing.com/minisforum-v3-se-is-a-cheaper-3-in-1-tablet-with-an-older-amd-ryzen-processor/</a></p>
<hr />
<h2
id="meles-overclock-x5-is-a-compact-computer-with-a-45-watt-intel-alder-lake-processor">MeLE‚Äôs
Overclock X5 is a compact computer with a 45 watt Intel Alder Lake
processor</h2>
<p>date: 2024-12-23, from: Liliputing</p>
<p>
The¬†MeLE¬†Overclock line of computers are small systems with enhanced
cooling that allow laptop-class processors to run at higher-than-typical
power limits. Up until recently MeLE had mostly focused on releasing
models with low-power chips in the 6 to 15 watt range, like the Intel
Celeron N5095, Intel Processor N100, or Intel Core i3-N300. But now the
[‚Ä¶]
</p>
<p>
The post
<a href="https://liliputing.com/meles-overclock-x5-is-a-compact-computer-with-a-45-watt-intel-alder-lake-processor/">MeLE‚Äôs
Overclock X5 is a compact computer with a 45 watt Intel Alder Lake
processor</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/meles-overclock-x5-is-a-compact-computer-with-a-45-watt-intel-alder-lake-processor/"
class="uri">https://liliputing.com/meles-overclock-x5-is-a-compact-computer-with-a-45-watt-intel-alder-lake-processor/</a></p>
<hr />
<h2 id="for-profit-healthcare-is-fundamentally-flawed">For-Profit
Healthcare Is Fundamentally Flawed</h2>
<p>date: 2024-12-23, updated: 2024-12-23, from: One Foot Tsunami</p>
<p><br></p>
<p><a
href="https://onefoottsunami.com/2024/12/23/for-profit-healthcare-is-fundamentally-flawed/"
class="uri">https://onefoottsunami.com/2024/12/23/for-profit-healthcare-is-fundamentally-flawed/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer‚Äôs
linkblog</strong> (date: 2024-12-23, from: Dave Winer‚Äôs linkblog)</p>
<p>AOC Perfectly Sums Up the Big Problem in Shutdown Battle.</p>
<p><br></p>
<p><a
href="https://www.yahoo.com/news/aoc-perfectly-sums-big-problem-215748185.html"
class="uri">https://www.yahoo.com/news/aoc-perfectly-sums-big-problem-215748185.html</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer‚Äôs
linkblog</strong> (date: 2024-12-23, from: Dave Winer‚Äôs linkblog)</p>
<p>Biden announces 37 death row commutations.</p>
<p><br></p>
<p><a
href="https://www.npr.org/2024/12/23/g-s1-38794/biden-death-row-commutations"
class="uri">https://www.npr.org/2024/12/23/g-s1-38794/biden-death-row-commutations</a></p>
<hr />
<h2
id="authors-alliance-submits-amicus-brief-in-sedlik-v.-drachenberg">AUTHORS
ALLIANCE SUBMITS AMICUS BRIEF IN SEDLIK v. DRACHENBERG</h2>
<p>date: 2024-12-23, from: Authors Union blogs</p>
<p>The case Sedlik v. Drachenberg, currently pending before the 9th
Circuit, presents the 9th Circuit a first opportunity to interpret the
fair use right in the wake of the Warhol decision. Anticipating the
far-reaching consequences for artists and authors, Authors Alliance
filed an amicus brief in support of KVD. In our brief, we explained that
(1) a distinct purpose is required for the first factor to tilt in favor
of fair use, (2) a successful social media presence does not
automatically render all postings ‚Äúcommercial,‚Äù and (3) concrete
evidence is needed to prove the existence of a licensing market or the
likelihood of it developing.</p>
<p><br></p>
<p><a
href="https://www.authorsalliance.org/2024/12/23/authors-alliance-submits-amicus-brief-in-sedlik-v-drachenberg/"
class="uri">https://www.authorsalliance.org/2024/12/23/authors-alliance-submits-amicus-brief-in-sedlik-v-drachenberg/</a></p>
<hr />
<h2
id="lenovo-yoga-slim-9-14-2025-laptop-could-have-a-hidden-camera">Lenovo
Yoga Slim 9 14 (2025) laptop could have a hidden camera</h2>
<p>date: 2024-12-23, from: Liliputing</p>
<p>
Lenovo may be preparing to launch a thin and light laptop with a hidden
camera. WalkingCat has shared a set of leaked pictures and a short
promotional video for a new version of the Lenovo Yoga Slim 9 14 inch
laptop featuring an Intel Core Ultra processor and what appears to be a
14 inch [‚Ä¶]
</p>
<p>
The post
<a href="https://liliputing.com/lenovo-yoga-slim-9-14-2025-laptop-could-have-a-hidden-camera/">Lenovo
Yoga Slim 9 14 (2025) laptop could have a hidden camera</a> appeared
first on <a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/lenovo-yoga-slim-9-14-2025-laptop-could-have-a-hidden-camera/"
class="uri">https://liliputing.com/lenovo-yoga-slim-9-14-2025-laptop-could-have-a-hidden-camera/</a></p>
<hr />
<h2
id="scummvm-brings-classic-pc-games-to-sailfishos-linux-based-smartphone-os">ScummVM
brings classic PC games to SailfishOS (Linux-based smartphone OS)</h2>
<p>date: 2024-12-23, from: Liliputing</p>
<p>
ScummVM is a free and open source tool that makes it possible to run
classic PC games on a wide variety of modern platforms. The software was
originally designed to recreate the LucasArts game engine used for
adventure games like Maniac Mansion and The Secrete of Monkey Island,
but over the past two decades it‚Äôs [‚Ä¶]
</p>
<p>
The post
<a href="https://liliputing.com/scummvm-brings-classic-pc-games-to-sailfishos-linux-based-smartphone-os/">ScummVM
brings classic PC games to SailfishOS (Linux-based smartphone OS)</a>
appeared first on <a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/scummvm-brings-classic-pc-games-to-sailfishos-linux-based-smartphone-os/"
class="uri">https://liliputing.com/scummvm-brings-classic-pc-games-to-sailfishos-linux-based-smartphone-os/</a></p>
<hr />
<h2
id="mediatek-dimensity-8400-is-an-all-big-core-chip-for-sub-flagship-phones-and-tablets">MediaTek
Dimensity 8400 is an all-big-core chip for sub-flagship phones and
tablets</h2>
<p>date: 2024-12-23, from: Liliputing</p>
<p>
The¬†MediaTek Dimensity 8400 is a mobile processor featuring eight ARM
Cortex-A725 CPU cores, ARM Mali-G720 MC7 graphics, and a MediaTek NPU
880 for on-device AI features. Like the Dimensity 9400 processor that
launched earlier this year, the new chip is said to bring big boosts in
performance¬†and efficiency. But while the Dimensity 9400 is aimed [‚Ä¶]
</p>
<p>
The post
<a href="https://liliputing.com/mediatek-dimensity-8400-is-an-all-big-core-chip-for-sub-flagship-phones-and-tablets/">MediaTek
Dimensity 8400 is an all-big-core chip for sub-flagship phones and
tablets</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/mediatek-dimensity-8400-is-an-all-big-core-chip-for-sub-flagship-phones-and-tablets/"
class="uri">https://liliputing.com/mediatek-dimensity-8400-is-an-all-big-core-chip-for-sub-flagship-phones-and-tablets/</a></p>
<hr />
<h2 id="quoting-jack-clark">Quoting Jack Clark</h2>
<p>date: 2024-12-23, updated: 2024-12-23, from: Simon Willison‚Äôs
Weblog</p>
<blockquote cite="https://jack-clark.net/2024/12/23/import-ai-395-ai-and-energy-demand-distributed-training-via-demo-and-phi-4/">
<p>
There‚Äôs been a lot of strange reporting recently about how ‚Äòscaling is
hitting a wall‚Äô ‚Äì in a very narrow sense this is true in that larger
models were getting less score improvement on challenging benchmarks
than their predecessors, but in a larger sense this is false ‚Äì
techniques like those which power O3 means scaling is continuing (and if
anything the curve has steepened), you just now need to account for
scaling both within the training of the model and in the compute you
spend on it once trained.
</p>
</blockquote>
<p class="cite">
‚Äî
<a href="https://jack-clark.net/2024/12/23/import-ai-395-ai-and-energy-demand-distributed-training-via-demo-and-phi-4/">Jack
Clark</a>
</p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/jack-clark&quot;&gt;jack-clark&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/inference-scaling&quot;&gt;inference-scaling&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/o3&quot;&gt;o3&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2024/Dec/23/jack-clark/#atom-everything"
class="uri">https://simonwillison.net/2024/Dec/23/jack-clark/#atom-everything</a></p>
<hr />
<h2 id="ncr-pc4i">NCR PC4i</h2>
<p>date: 2024-12-23, from: Computer ads from the Past</p>
<p>Growing with your needs</p>
<p><br></p>
<p><a href="https://computeradsfromthepast.substack.com/p/ncr-pc4i"
class="uri">https://computeradsfromthepast.substack.com/p/ncr-pc4i</a></p>
<hr />
<h2
id="government-to-name-key-witness-who-provided-fbi-with-backdoored-encrypted-chat-app-anom">Government
to Name ‚ÄòKey Witness‚Äô Who Provided FBI With Backdoored Encrypted Chat
App Anom</h2>
<p>date: 2024-12-23, from: 404 Media Group</p>
<p>A lawyer has pushed to learn the identity of the person who first
created Anom, which the FBI used to read tens of millions of messages
sent by organized criminals. The confidential human source may testify
in court, too.</p>
<p><br></p>
<p><a
href="https://www.404media.co/government-to-name-key-witness-who-provided-fbi-with-backdoored-encrypted-chat-app-anom-2/"
class="uri">https://www.404media.co/government-to-name-key-witness-who-provided-fbi-with-backdoored-encrypted-chat-app-anom-2/</a></p>
<hr />
<h2 id="happy-holidays-from-the-national-archives">Happy Holidays from
the National Archives!</h2>
<p>date: 2024-12-23, from: National Archives, Pieces of History blog</p>
<p>If you visited the National Archives Building in late 1974, you could
purchase a specially designed holiday card with this design:¬† The card
showed Santa Claus and one of his reindeers looking at the Declaration
of Independence, Constitution, and Bill of Rights on display in the
National Archives Exhibition Hall. The design reflects what the ‚Ä¶
<a href="https://prologue.blogs.archives.gov/2024/12/23/happy-holidays-from-the-national-archives/" class="more-link">Continue
reading <span class="screen-reader-text">Happy Holidays from the
National Archives!</span></a></p>
<p><br></p>
<p><a
href="https://prologue.blogs.archives.gov/2024/12/23/happy-holidays-from-the-national-archives/"
class="uri">https://prologue.blogs.archives.gov/2024/12/23/happy-holidays-from-the-national-archives/</a></p>
<hr />
<h2 id="quoting-geoffrey-litt">Quoting Geoffrey Litt</h2>
<p>date: 2024-12-23, updated: 2024-12-23, from: Simon Willison‚Äôs
Weblog</p>
<blockquote cite="https://www.geoffreylitt.com/2024/12/22/making-programming-more-fun-with-an-ai-generated-debugger.html">
<p>
Whether you‚Äôre an AI-programming skeptic or an enthusiast, the reality
is that many programming tasks are beyond the reach of today‚Äôs models.
But many decent <em>dev tools</em> are actually quite easy for AI to
build, and can help the rest of the programming go smoother. In general,
these days any time I‚Äôm spending more than a minute staring at a JSON
blob, I consider whether it‚Äôs worth building a custom UI for it.
</p>
</blockquote>
<p class="cite">
‚Äî
<a href="https://www.geoffreylitt.com/2024/12/22/making-programming-more-fun-with-an-ai-generated-debugger.html">Geoffrey
Litt</a>
</p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/geoffrey-litt&quot;&gt;geoffrey-litt&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai-assisted-programming&quot;&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2024/Dec/23/geoffrey-litt/#atom-everything"
class="uri">https://simonwillison.net/2024/Dec/23/geoffrey-litt/#atom-everything</a></p>
<hr />
<h2 id="christmas-on-repeat">Christmas on Repeat</h2>
<p>date: 2024-12-23, from: Tedium site</p>
<p>Despite often being terrible, we watch the same holiday movies every
year. Why's that? Well, it's not often about the movies‚Äîit's about our
memories.</p>
<p><br></p>
<p><a
href="https://feed.tedium.co/link/15204/16926317/christmas-nostalgia-psychology"
class="uri">https://feed.tedium.co/link/15204/16926317/christmas-nostalgia-psychology</a></p>
<hr />
<h2 id="gsoc-2024-improve-clang-doc">GSoC 2024: Improve Clang Doc</h2>
<p>date: 2024-12-23, from: LLVM Blog</p>
<p>
Hi, my name is Peter, and this year I was involved in Google Summer of
Code 2024. I worked on
<a href="https://discourse.llvm.org/t/improve-Clang-Doc-usability/76996">improving
the Clang-Doc documenation generator</a>
</p>
<p>
Mentors: Petr Hosek and Paul Kirth
</p>
<h2 id="project-background">
Project Background
</h2>
<p>
Clang-Doc is a documentation generator developed on top of libtooling,
as analternative to Doxygen. Development started in 2018 and continued
through 2019,however, it has since stalled. Currently, the tool can
generate HTML, YAML, and markdown but the generated output has usability
issues. This GSOC project aimed to address the pain points regarding the
output of the HTML, by adding support for various C++ constructs and
reworking the CSS of the HTML output to be more user-friendly.
</p>
<h2 id="work-done">
Work Done
</h2>
<p>
The original scope of the project was to improve the output of
Clang-Doc‚Äôs generation. However during testing the tool was
significantly slower than expected which made developing features for
the tool impossible.Documentation generation for the LLVM codebase was
taking upwards of 10 hours on my local machine. Additionally, the tool
utilized a lot of memory and was prone to crashing with an out-of-memory
error. Similar tools such as Doxygen and Hdoc ran in comparatively less
time for the same codebase. This pointed to a significant bottleneck
within Clang-Doc‚Äôs code path when generating large-scale software
projects. Due to this the project scope quickly changed to improving the
runtime of Clang-Doc so that it could run much faster. It was only
during the latter half of the project did the scope changed back to
improving Clang-Doc‚Äôs generation.
</p>
<h3 id="added-more-test-cases-to-clang-doc-test-suite">
Added More Test Cases to Clang-Doc test suite
</h3>
<p>
Clang-Doc previously had tests which did not test the full scope of the
the HTML or Markdown output. I added more end-to-end tests to make sure
that in the process of optimizing documentation generation we were not
degrading the quality or functionality of the tool.
</p>
<p>
In summary, I added four comprehensive tests that covered all features
that we were not testing such as testing the generation for Enums,
Namespace, and Records for HTML and Markdown.
</p>
<h3 id="improve-clang-docs-performance-by-158-times">
Improve Clang-Doc‚Äôs performance by 1.58 times
</h3>
<p>
Internally, the way Clang-Doc works is by leveraging libtooling‚Äôs
ASTVisitor class to parse the source level declarations in each TU.
</p>
<p>
The tool is architected using a Map-Reduce pattern. Clang-Doc parses
each fragment of a declaration into an in-memory data format which is
serialized then into an internal format and stored as a key value
paired, identified by their
<a href="https://clang.llvm.org/doxygen/group__CINDEX__CURSOR__XREF.html#ga51679cb755bbd94cc5e9476c685f2df3">USR</a>.
After, Clang-Doc deserializes and combines each of the fragment
declarations back into the in-memory data format which is used by each
of the backend to generate the results.
</p>
<p>
Many experiments were conducted to identified the source of the
bottleneck. First I tried benchmarking the code with many different
codebases such JSON, and fmtlib to identify certain code patterns that
slowed the code path down. This didn‚Äôt really work since the
bottlenecking only showed up for large codebases like LLVM.Next I
leverage Windows prolifer (since I was coding on windows) however the
visualizations was not helpful and the my system was not capable of
profiling the 10 hour runtime required to compile LLVM documenation.
</p>
<p>
Eventually, we were able to identify a major bottleneck in Clang-Doc‚Äôs
by leveraging the TimeProfiler (similar to -ftime-trace in clang) code
to identify where the performance bottleneck was. Clang-Doc was
performing redundant work when it was processing each declaration. We
settled on a caching/memoization strategy to minimize the redundant
work.
</p>
<p>
For example, if we had the following project:
</p>
<div class="highlight">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">//File: Base.h</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Base</span> {}</span></span></code></pre>
</div>
<div class="highlight">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">//File: A.cpp</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&#34;Base.h&#34;</span><span style="color:#75715e"></span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span></span></span><span style="display:flex;"><span>...</span></span></code></pre>
</div>
<div class="highlight">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">//File: B.cpp</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&#34;Base.h&#34;</span><span style="color:#75715e"></span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span></span></span><span style="display:flex;"><span>...</span></span></code></pre>
</div>
<p>
In this case, the ASTVisitor invoked by Clang-Doc would visit the
serialized Base class three times, once when it is parsing Base.h,
another when its visiting A.cpp then B.cpp. The problem was that there
was no mechanism to identify declarations that we had already seen.
Using a simple dictionary which kept track of a list of declaration that
Clang-Doc had visited as a basic form of memoization ended up being a
surprisingly effective optimization.
</p>
<p>
Here is a plot of the benchmarking numbers:
</p>
<div style="margin:0 auto;">
<img src="https://blog.llvm.org/img/clang-doc-benchmark-numbers.png"><br/>
</div>
<p>
The benchmarking numbers were performed on a machine with a 6th gen
Intel(R) Xeon(R) CPU @ 2.00GHz w/ 96 cores, and 180GB of ram. Clang-doc
is able to run concurrently, however the benchmark here is with
concurrency set to 2. This is because anything higher crashes the slow
version of the tool with an out of memory error. It took around 6 hours
to complete a full generation of LLVM documentation in the previous
tool, where as current version took around 4 hours.
</p>
<p>
Here is a plot of the benchmark by number of threads:
</p>
<div style="margin:0 auto;">
<img src="https://blog.llvm.org/img/clang-doc-concurrency.png"><br/>
</div>
<p>
We notice a pretty dramatic dropoff as more and more threads are
utilize, the original time t 6 hours was cut down to 13 minutes at 64
threads. Considering the previous versions of the tool could not use the
higher thread count without crashing (even on a machine with 180GB of
ram), the performance gains are even more dramatic.
</p>
<h3 id="added-template-mustache-html-backend">
Added Template Mustache HTML Backend
</h3>
<p>
Clang-Doc originally used an ad-hoc method of generating HTML. I
introduced a templating language as a way of reducing project complexity
and reducing the ease of development. Two RFCs were made before arriving
at the idea of introducing Mustache as a library. Originally the idea
was to introduce a custom templating language, however, upon further
discussion, it was decided that the complexity of designing and
implementing a new templating language was too much.An LLVM community
member (<a href="https://discourse.llvm.org/u/cor3ntin/summary"><span
class="citation" data-cites="cor3ntin">@cor3ntin</span></a>) suggested
using Mustache as a templating language.Mustache was the ideal choice
since it was very simple to implement, and has a well defined spec that
fit what was needed for Clang-Doc‚Äôs use case. The feedback on the
<a href="https://discourse.llvm.org/t/rfc-add-template-mustache-language-to-the-support-library/82439/18">RFC</a>
was generally positive. While there was some resistance regarding the
inclusion of an HTML support library in LLVM, this concern stemmed
partly from a lack of awareness that HTML generation already occurs in
several parts of LLVM. Additionally, the introduction of Mustache has
the potential to simplify other HTML-related use cases.In terms of
engineering wins, this library was able to cut the direct down on the
HTML backend significantly dropping 500 lines of code compared to the
original Clang-Doc HTML backend. This library was also designed for
general-purpose use around LLVM since there are numerous places in LLVM
where various tools generate HTML in its way. Using the Mustache
templating library would be a nice way to standardize the codebase.
</p>
<h3 id="improve-clang-doc-html-output">
Improve Clang-Doc HTML Output
</h3>
<p>
The previous version of Clang-Doc‚Äôs HTML output was a pretty minimal,
bare bones implementation. It had a sidebar that contained every single
declaration within the project which created a large unnavigable UI.
Typedef documentation was missing, plus method documentation was missing
details such as whether or not the method was a const or virtual. There
was no linking between other declarations in the project and there was
no syntax highlighting on any language construct.
</p>
<p>
With the new Mustache changes an additional backend was added using the
specifier (‚Äìformat=mhtml). That addresses these issues.
</p>
<p>
Below is a comparison of the same output between the two backends
</p>
<div style="margin:0 auto;">
<img src="https://blog.llvm.org/img/Clang-Doc-old-html-output.png"><br/>
</div>
<div style="margin:0 auto;">
<img src="https://blog.llvm.org/img/Clang-Doc-new-output.png"><br/>
</div>
<p>
You can also visit the output project on my github.io page
link<a href="https://peterchou1.github.io/">here</a>.
</p>
<p>
Note: this output is still a work in progress.
</p>
<h2 id="learning-insight">
Learning Insight
</h2>
<p>
I‚Äôve learned a lot in the past few months, thanks to GSOC I now have a
much better idea of what it‚Äôs like to participate in a large open-source
project. I received a lot of feedback through PRs, making RFC, and
collaborating with other GSOC members. I learned a lot about how to
interact with the community and solicit feedback. I also learned a lot
about instrumentation/profiling code having conducted many experiments
to try to speed Clang-Doc up.
</p>
<h2 id="future-work">
Future Work
</h2>
<p>
As my work concluded I was named as one of the maintainers of the
project. In the future I plan to work on Clang-Doc until an MVP product
can be generated and evaluated for the LLVM project. My remaining tasks
include landing the Mustache support library and Clang-Doc‚Äôs Mustache
backend, as well as gathering feedback from the LLVM community regarding
Clang-Doc‚Äôs current output. Additionally, I intend to add test cases for
the Mustache HTML backend to ensure its robustness and functionality.
</p>
<h2 id="conclusion">
Conclusion
</h2>
<p>
Overall the current state of Clang-Doc is much healthier than it was
before. It now has much better test coverage across all its output,
markdown, html, yaml. Whereas previously there were no e2e test cases
that were not as comprehensive. The tool is significantly faster
especially for large scale projects like LLVM making documentation
generation and development a much better experience.The tool also has a
simplified HTML backend that will be much easier to work with compared
to before leading to a faster velocity for development.
</p>
<h2 id="acknowledgements">
Acknowledgements
</h2>
<p>
I‚Äôd like to thank my mentors, Paul and Petr for their invaluable input
when I encounter issues with the project. This year has been tough for
me mentally, and I‚Äôd like to thank my mentors for being accommodating
with me.
</p>
<p><br></p>
<p><a href="https://blog.llvm.org/posts/2024-12-04-improve-clang-doc/"
class="uri">https://blog.llvm.org/posts/2024-12-04-improve-clang-doc/</a></p>
</section>
<footer>Feed items based on the feeds identified in <a href="news.txt">news.txt</a> harvested
with <a href="https://github.com/rsdoiel/skimmer">skimmer</a></footer>
</body>
</html>
