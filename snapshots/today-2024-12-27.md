---
title: News gathered 2024-12-27
updated: 2024-12-27 07:10:04
---

# News gathered 2024-12-27

(date: 2024-12-27 07:10:04)

---

## Oh, No, No Need to Return That

date: 2024-12-27, updated: 2024-12-27, from: One Foot Tsunami

 

<br> 

<https://onefoottsunami.com/2024/12/27/oh-no-no-need-to-return-that/>

---

**@Dave Winer's linkblog** (date: 2024-12-27, from: Dave Winer's linkblog)

Top 500 Bluesky Accounts by Followers for 25th December 2024. 

<br> 

<https://sydesjokes.blogspot.com/2024/12/top-500-bluesky-accounts-by-followers_25.html#anamariecox.bsky.social>

---

**@Dave Winer's linkblog** (date: 2024-12-27, from: Dave Winer's linkblog)

2017: RSS-in-JSON is a feed format. 

<br> 

<https://github.com/scripting/Scripting-News/tree/master/rss-in-json>

---

## Wir wissen, wo dein Auto steht

date: 2024-12-27, updated: 2024-12-27, from: Chaos Computer Club Updates

Der Chaos Computer Club (CCC) deckt auf, dass der Volkswagen-Konzern Bewegungsdaten von hunderttausenden Fahrzeugen der Marken VW, Audi, Skoda und Seat systematisch erfasst und über lange Zeiträume speichert. Die Daten, einschließlich Informationen über Fahrzeughalter:innen, waren zudem ungeschützt im Internet zugänglich. 

<br> 

<https://www.ccc.de/de/updates/2024/wir-wissen-wo-dein-auto-steht>

---

## Open WebUI

date: 2024-12-27, updated: 2024-12-27, from: Simon Willison’s Weblog

<p><strong><a href="https://github.com/open-webui/open-webui">Open WebUI</a></strong></p>
I tried out this open source (MIT licensed, JavaScript and Python) localhost UI for accessing LLMs today for the first time. It's very nicely done.</p>
<p>I ran it with <a href="https://docs.astral.sh/uv/guides/tools/">uvx</a> like this:</p>
<pre><code>uvx --python 3.11 open-webui serve
</code></pre>
<p>On first launch it installed a bunch of dependencies and then downloaded 903MB to <code>~/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2</code> - a copy of the <a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2">all-MiniLM-L6-v2</a> embedding model, presumably for its <a href="https://docs.openwebui.com/features/rag">RAG feature</a>.</p>
<p>It then presented me with a working Llama 3.2:3b chat interface, which surprised me because I hadn't spotted it downloading that model. It turns out that was because I have <a href="https://ollama.com/">Ollama</a> running on my laptop already (with several models, including Llama 3.2:3b, already installed) - and Open WebUI automatically detected Ollama and gave me access to a list of available models.</p>
<p>I found a "knowledge" section and added all of the Datasette documentation (by dropping in the <code>.rst</code> files from the docs) - and now I can type <code>#</code> in chat to search for a file, add that to the context and then ask questions about it directly.</p>
<p>I selected the <code>spatialite.rst.txt</code> file, prompted it with "How do I use SpatiaLite with Datasette" and got back <a href="https://gist.github.com/simonw/3bf5ff0ed3b47aefbb94d3fd992f81f9#response">this</a>:</p>
<p><img alt="Chat UI. Prompt is How do I use SpatiaLite with Datasette? with an attached spatialite.rst.txt file. The response from llama3.2:3b reads: To use SpatiaLite with Datasette, you need to install the mod_spatialite dynamic library. This can then be loaded into Datasette using the --load-extension command-line option.   You can install it on OS X by running brew update and then brew install spatialite-tools. On Linux, SpatiaLite is packaged for most distributions, so you can typically install it with a package manager like apt.   When running Datasette, you can look for SpatiaLite in common installation locations or specify the full path to the extension if it's installed elsewhere.   For example, on OS X, you might run datasette --load-extension=spatialite after installing it with Homebrew. On Linux, you could use datasette --load-extension=/usr/lib/x86_64-linux-gnu/mod_spatialite.so.   It's also important to note that SpatiaLite adds a large number of additional SQL functions, some of which are not safe for untrusted users to execute. To secure your Datasette instance, consider disabling arbitrary SQL queries and defining canned queries with the SQL queries that use SpatiaLite functions you want people to be able to execute." src="https://static.simonwillison.net/static/2024/spatialite-webui.jpg" /></p>
<p>That's honestly a very solid answer, especially considering the Llama 3.2 3B model from Ollama is just a 1.9GB file! It's impressive how well that model can handle basic Q&amp;A and summarization against text provided to it - it somehow has a 128,000 token context size.</p>
<p>Open WebUI has a lot of other tricks up its sleeve: it can talk to API models such as OpenAI directly, has optional integrations with web search and custom tools and logs every interaction to a SQLite database. It also comes with <a href="https://docs.openwebui.com/">extensive documentation</a>.


    <p>Tags: <a href="https://simonwillison.net/tags/ollama">ollama</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llama">llama</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/rag">rag</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/uv">uv</a>, <a href="https://simonwillison.net/tags/sqlite">sqlite</a>, <a href="https://simonwillison.net/tags/python">python</a>, <a href="https://simonwillison.net/tags/edge-llms">edge-llms</a></p> 

<br> 

<https://simonwillison.net/2024/Dec/27/open-webui/#atom-everything>

---

**@Dave Winer's linkblog** (date: 2024-12-27, from: Dave Winer's linkblog)

Matt Mullenweg Declares Holiday Break for WordPress.org Services. 

<br> 

<https://wptavern.com/matt-mullenweg-declares-holiday-break-for-wordpress-org-services>

---

## A Boxing Day Reply to a Friendly Reader about Israel

date: 2024-12-26, from: Michael Moore's blog

He wrote, "F*** You!" so I wrote him back 

<br> 

<https://www.michaelmoore.com/p/a-boxing-day-reply-to-a-friendly>

---

**@Dave Winer's linkblog** (date: 2024-12-26, from: Dave Winer's linkblog)

Embracing change and new beginnings in Woodstock. 

<br> 

<https://hudsonvalleyone.com/2024/12/25/embracing-change-and-new-beginnings-in-woodstock/>

---

**@Dave Winer's linkblog** (date: 2024-12-26, from: Dave Winer's linkblog)

This is the kind of story that could be turned into a list people could subscribe to. <span style="letter-spacing: 0.01rem;">I love The Atlantic, long-time reader, and would try any podcast they recommend. </span> 

<br> 

<https://www.theatlantic.com/culture/archive/2024/12/20-best-podcasts-2024/680853/?gift=f35zZN0v_gDFE8xNwlQAHQS8e4ay1R8oZx1MhFbqJWI&utm_source=copy-link&utm_medium=social&utm_campaign=share>

---

## DeepSeek_V3.pdf

date: 2024-12-26, updated: 2024-12-26, from: Simon Willison’s Weblog

<p><strong><a href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf">DeepSeek_V3.pdf</a></strong></p>
The DeepSeek v3 paper (and <a href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/README.md">model card</a>) are out, after yesterday's mysterious release of <a href="https://simonwillison.net/2024/Dec/25/deepseek-v3/">the undocumented model weights</a>.</p>
<p>Plenty of interesting details in here. The model pre-trained on 14.8 trillion "high-quality and diverse tokens" (not otherwise documented).</p>
<blockquote>
<p>Following this, we conduct post-training, including Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on the base model of DeepSeek-V3, to align it with human preferences and further unlock its potential. During the post-training stage, we distill the reasoning capability from the DeepSeek-R1 series of models, and meanwhile carefully maintain the balance between model accuracy and generation length.</p>
</blockquote>
<p>By far the most interesting detail though is how much the training cost. DeepSeek v3 trained on 2,788,000 H800 GPU hours at an estimated cost of $5,576,000. For comparison, Meta AI's Llama 3.1 405B (smaller than DeepSeek v3's 685B parameters) <a href="https://huggingface.co/meta-llama/Llama-3.1-405B-Instruct#hardware-and-software">trained on 11x that</a> - 30,840,000 GPU hours, also on 15 trillion tokens.</p>
<p>DeepSeek v3 benchmarks comparably to Claude 3.5 Sonnet, indicating that it's now possible to train a frontier-class model (at least for the 2024 version of the frontier) for less than $6 million!</p>
<p><a href="https://twitter.com/karpathy/status/1872362712958906460">Andrej Karpathy</a>:</p>
<blockquote>
<p>For reference, this level of capability is supposed to require clusters of closer to 16K GPUs, the ones being brought up today are more around 100K GPUs. E.g. Llama 3 405B used 30.8M GPU-hours, while DeepSeek-V3 looks to be a stronger model at only 2.8M GPU-hours (~11X less compute). If the model also passes vibe checks (e.g. LLM arena rankings are ongoing, my few quick tests went well so far) it will be a highly impressive display of research and engineering under resource constraints.</p>
</blockquote>
<p>DeepSeek also <a href="https://twitter.com/deepseek_ai/status/1872242663489188088">announced their API pricing</a>. From February 8th onwards:</p>
<blockquote>
<p>Input: $0.27/million tokens ($0.07/million tokens with cache hits)<br>
Output: $1.10/million tokens</p>
</blockquote>
<p>Claude 3.5 Sonnet is currently $3/million for input and $15/million for output, so if the models are indeed of equivalent quality this is a dramatic new twist in the ongoing LLM pricing wars.

    <p><small></small>Via <a href="https://twitter.com/deepseek_ai/status/1872242657348710721">@deepseek_ai</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/deepseek">deepseek</a>, <a href="https://simonwillison.net/tags/training-data">training-data</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llm-pricing">llm-pricing</a>, <a href="https://simonwillison.net/tags/llama">llama</a>, <a href="https://simonwillison.net/tags/meta">meta</a>, <a href="https://simonwillison.net/tags/andrej-karpathy">andrej-karpathy</a></p> 

<br> 

<https://simonwillison.net/2024/Dec/26/deepseek-v3/#atom-everything>

---

**@Dave Winer's linkblog** (date: 2024-12-26, from: Dave Winer's linkblog)

Scott Knaster, a friend I know from the early Mac days, where he wrote a lot of the <em>excellent</em> developer docs we depended on, has written a series of stories of memories of his work at Apple, Google and elsewhere. 

<br> 

<https://docs.google.com/document/d/1RAYCCeZau426Cih_J4aFMc0-Qx3gMHCbph_KCgM2rIg/edit?tab=t.0#heading>

---

## Lilbits: Install Google Play on Amazon Fire tablets, postmarketOS update, and a new color ePaper display kit

date: 2024-12-26, from: Liliputing

<p>This week a lot of folks have been unwrapping Amazon Fire tablets, setting them up&#8230; and figuring out that some of the apps and games you want to run on them aren&#8217;t available out of the box. Fortunately there are a bunch of ways to make an Amazon tablet more useful. You can sideload applications [&#8230;]</p>
<p>The post <a href="https://liliputing.com/lilbits-install-google-play-on-amazon-fire-tablets-postmarketos-update-and-a-new-color-epaper-display-kit/">Lilbits: Install Google Play on Amazon Fire tablets, postmarketOS update, and a new color ePaper display kit</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/lilbits-install-google-play-on-amazon-fire-tablets-postmarketos-update-and-a-new-color-epaper-display-kit/>

---

**@Dave Winer's linkblog** (date: 2024-12-26, from: Dave Winer's linkblog)

Hospitals Give Doctors Minimal Guidance Under Abortion Bans, Report Finds. 

<br> 

<https://www.propublica.org/article/abortion-ban-deaths-report-ron-wyden>

---

## Quoting EU Artificial Intelligence Act

date: 2024-12-26, updated: 2024-12-26, from: Simon Willison’s Weblog

<blockquote cite="https://artificialintelligenceact.eu/article/4/"><p>Providers and deployers of AI systems shall take measures to ensure, to their best extent, a sufficient level of AI literacy of their staff and other persons dealing with the operation and use of AI systems on their behalf, taking into account their technical knowledge, experience, education and training and the context the AI systems are to be used in, and considering the persons or groups of persons on whom the AI systems are to be used.</p></blockquote>
<p class="cite">&mdash; <a href="https://artificialintelligenceact.eu/article/4/">EU Artificial Intelligence Act</a>, Article 4: AI literacy</p>

    <p>Tags: <a href="https://simonwillison.net/tags/eu">eu</a>, <a href="https://simonwillison.net/tags/ai">ai</a></p> 

<br> 

<https://simonwillison.net/2024/Dec/26/eu-artificial-intelligence-act/#atom-everything>

---

## Default Apps 2024

date: 2024-12-26, from: Chris Coyier blog

I wanted to update my list from my Default Apps 2023 list, but as I went through it&#8230; I haven&#8217;t really changed anything at all. What does that mean? I&#8217;m set in my ways? It doesn&#8217;t really feel like that, it feels more like I&#8217;m pretty happy with my choices and haven&#8217;t been sufficiently convinced [&#8230;] 

<br> 

<https://chriscoyier.net/2024/12/26/default-apps-2024/>

---

## Lenovo ThinkPad X9 leak points to a missing TrackPoint

date: 2024-12-26, from: Liliputing

<p>One of the key differences between Lenovo&#8217;s ThinkPad-branded laptops and&#8230; pretty much every other laptop on the market these days (including most Lenovo models) is that in addition to a touchpad below the keyboard, ThinkPads feature Lenovo&#8217;s TrackPoint system with a small pointing stick in the center of the keyboard. But leaked pictures of a [&#8230;]</p>
<p>The post <a href="https://liliputing.com/lenovo-thinkpad-x9-leak-points-to-a-missing-trackpoint/">Lenovo ThinkPad X9 leak points to a missing TrackPoint</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/lenovo-thinkpad-x9-leak-points-to-a-missing-trackpoint/>

---

## 2024 in reading: The Enlightened Economist Prize shortlist

date: 2024-12-26, from: Enlightenment Economics

There has been a long gap since my last post, which coincided with the start of Michaelmas Term &#8211; suggestive timing. Life was indeed very busy, and although I carried on reading, sitting tapping away at the laptop had diminished &#8230; <a href="http://www.enlightenmenteconomics.com/blog/index.php/2024/12/2024-in-reading-the-enlightened-economist-prize-shortlist/">Continue reading <span class="meta-nav">&#8594;</span></a> 

<br> 

<http://www.enlightenmenteconomics.com/blog/index.php/2024/12/2024-in-reading-the-enlightened-economist-prize-shortlist/>

---

## Lenovo ThinkBook Plus laptop with a rollable display could launch in 2025

date: 2024-12-26, from: Liliputing

<p>Lenovo has been showing off concept laptops with rollable OLED displays for the past few years. Now Lenovo is said to be preparing to turn that concept into a real device you can actually buy. Evan Blass has shared a set of pictures to Leakmail subscribers that give us a first look at a new Lenovo [&#8230;]</p>
<p>The post <a href="https://liliputing.com/lenovo-thinkbook-plus-laptop-with-a-rollable-display-could-launch-in-2025/">Lenovo ThinkBook Plus laptop with a rollable display could launch in 2025</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/lenovo-thinkbook-plus-laptop-with-a-rollable-display-could-launch-in-2025/>

---

## A Fun New Challenge

date: 2024-12-26, updated: 2024-12-26, from: One Foot Tsunami

 

<br> 

<https://onefoottsunami.com/2024/12/26/a-fun-new-challenge/>

---

**@Dave Winer's linkblog** (date: 2024-12-26, from: Dave Winer's linkblog)

You keep using that word. I do not think it means what you think it means. 

<br> 

<https://www.youtube.com/watch?v=dTRKCXC0JFg&t=8s>

---

## AI-Generated Book Grifters Threaten The Future of Lace-Making

date: 2024-12-26, from: 404 Media Group

“Unfortunately, for newcomers who might be excited to dive into this hobby, they could get burned by the inadequate books—and frankly the thievery—of the work of our cherished lacemakers and designers." 

<br> 

<https://www.404media.co/bobbin-tatting-lace-ai-generated-books/>

---

## Cognitive load is what matters

date: 2024-12-26, updated: 2024-12-26, from: Simon Willison’s Weblog

<p><strong><a href="https://minds.md/zakirullin/cognitive">Cognitive load is what matters</a></strong></p>
Excellent living document (the underlying repo has <a href="https://github.com/zakirullin/cognitive-load/commits/main/">625 commits</a> since being created in May 2023) maintained by Artem Zakirullin about minimizing the cognitive load needed to understand and maintain software.</p>
<p>This all rings very true to me. I judge the quality of a piece of code by how easy it is to change, and anything that causes me to take on more cognitive load - unraveling a class hierarchy, reading though dozens of tiny methods - reduces the quality of the code by that metric.</p>
<p>Lots of accumulated snippets of wisdom in this one.</p>
<blockquote>
<p>Mantras like "methods should be shorter than 15 lines of code" or "classes should be small" turned out to be somewhat wrong.</p>
</blockquote>

    <p><small></small>Via <a href="https://twitter.com/karpathy/status/1872038630405054853?s=46">@karpathy</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/programming">programming</a>, <a href="https://simonwillison.net/tags/software-engineering">software-engineering</a></p> 

<br> 

<https://simonwillison.net/2024/Dec/26/cognitive-load-is-what-matters/#atom-everything>

---

## In the Holy Land, Just a Couple of Dead Catholics

date: 2024-12-26, from: Michael Moore's blog

There is much to feel today &#8212; love, family, community, kindness, etc. 

<br> 

<https://www.michaelmoore.com/p/in-the-holy-land-just-a-couple-of>

---

## Merry Christmas 2024

date: 2024-12-26, from: Computer ads from the Past

and a Happy New Year 

<br> 

<https://computeradsfromthepast.substack.com/p/merry-christmas-2024>

---

## RSS Feeds and Real Time Crawling

date: 2024-12-26, from: Marginallia log

A while back an update went live that, with some caveats, changes the time it takes for an update on a website to reflect in the search engine index from up to 2 months to 1-2 days. Conditions being if the website has an RSS or Atom feed.
The big crawl job takes about two months, and is run partition by partition, meaning there&rsquo;s typically a slice of the index that is two months stale at any given point in time. 

<br> 

<https://www.marginalia.nu/log/a_113_rtc/>

