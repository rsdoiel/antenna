---
title: snapshots
updated: 2025-08-12 14:08:56
---

# snapshots

(date: 2025-08-12 14:08:56)

---

## KeyGo is a slim keyboard with an integrated 12.8 inch touchscreen display (crowdfunding)

date: 2025-08-12, from: Liliputing

<p>The KeyGo is a keyboard with low-profile scissor-switch, RGB backlit keys, a number pad on the right side, a CNC aluminum body and two USB Type-C ports. What makes it unusual though, is that there&#8217;s also a 12.8 inch, 1920 x 720 pixel IPS LCD touchscreen display atop the keyboard. Plug the KeyGo into a Windows, Mac, [&#8230;]</p>
<p>The post <a href="https://liliputing.com/keygo-is-a-slim-keyboard-with-an-integrated-12-8-inch-touchscreen-display-crowdfunding/">KeyGo is a slim keyboard with an integrated 12.8 inch touchscreen display (crowdfunding)</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/keygo-is-a-slim-keyboard-with-an-integrated-12-8-inch-touchscreen-display-crowdfunding/>

---

**@Robert's feed at BlueSky** (date: 2025-08-12, from: Robert's feed at BlueSky)

It days like this ... Said the protagonist as he reached for ...

[contains quote post or other embedded content] 

<br> 

<https://bsky.app/profile/rsdoiel.bsky.social/post/3lwa7aeobdc2p>

---

## Reddit Will Block the Internet Archive

date: 2025-08-12, from: Michael Tsai

Jay Peters: Reddit says that it has caught AI companies scraping its data from the Internet Archive&#8217;s Wayback Machine, so it&#8217;s going to start blocking the Internet Archive from indexing the vast majority of Reddit. The Wayback Machine will no longer be able to crawl post detail pages, comments, or profiles; instead, it will only [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/08/12/reddit-will-block-the-internet-archive/>

---

## GitHub CEO Resigns, Not Replaced

date: 2025-08-12, from: Michael Tsai

Thomas Dohmke (tweet): From building mobile developer tools, to running the acquisition of GitHub alongside Nat Friedman, to becoming GitHub&#8217;s CEO and guiding us into the age of Copilot and AI, it has been the ride of a lifetime. Still, after all this time, my startup roots have begun tugging on me and I&#8217;ve decided [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/08/12/github-ceo-resigns-not-replaced/>

---

## JSONSerialization Can Throw NSExceptions

date: 2025-08-12, from: Michael Tsai

Peter Steinberger (tweet): lol of the day: Apple&#8217;s JSONSerialization can throw NSExceptions. These cannot be captured in Swift. Gotta go back to ObjC and write a wrapper. The documentation suggests that to avoid this you can first call isValidJSONObject(). Of course, you have to remember to do this, and it adds overhead to the common [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/08/12/jsonserialization-can-throw-nsexceptions/>

---

## SwiftData Runtime

date: 2025-08-12, from: Michael Tsai

Richard Witherspoon: I&#8217;m working with SwiftData and trying to replicate behavior similar to what I used to do with CoreData, where I had an extension on NSManagedObjectContext that allowed me to fetch all stored objects, regardless of entity type.[&#8230;]I&#8217;m now using SwiftData with @Model types and the ModelContext, and I want to dynamically fetch all [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/08/12/swiftdata-runtime/>

---

## Daily Deals (8-12-2025)

date: 2025-08-12, from: Liliputing

<p>Handheld gaming PCs with Intel Meteor Lake processors never really took off in a big way, because they were sold in the same price range as AMD Ryzen-powered models that offered better graphics and efficiency. But if you&#8217;re looking to save a few bucks, Best Buy is running a sale on several handheld gaming PCs. [&#8230;]</p>
<p>The post <a href="https://liliputing.com/daily-deals-8-12-2025/">Daily Deals (8-12-2025)</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/daily-deals-8-12-2025/>

---

## He’s a 33-year-old Pro-Palestine Muslim Who’s Winning the Jewish Vote, a Democratic Socialist Whom Every Dem Party Leader in NY Has Refused to Endorse, and a U.S. Citizen for Only 7 Years!

date: 2025-08-12, from: Michael Moore's blog

Of Course He&#8217;s the Next Mayor! 

<br> 

<https://www.michaelmoore.com/p/hes-a-33-year-old-pro-palestine-muslim>

---

## Claude Sonnet 4 now supports 1M tokens of context

date: 2025-08-12, updated: 2025-08-12, from: Simon Willison’s Weblog

<p><strong><a href="https://www.anthropic.com/news/1m-context">Claude Sonnet 4 now supports 1M tokens of context</a></strong></p>
Gemini and OpenAI both have million token models, so it's good to see Anthropic catching up. This is 5x the previous 200,000 context length limit of the various Claude Sonnet models.</p>
<p>Anthropic have previously made 1 million tokens available to select customers. From <a href="https://www.anthropic.com/news/claude-3-family">the Claude 3 announcement</a> in March 2024:</p>
<blockquote>
<p>The Claude 3 family of models will initially offer a 200K context window upon launch. However, all three models are capable of accepting inputs exceeding 1 million tokens and we may make this available to select customers who need enhanced processing power.</p>
</blockquote>
<p>This is also the first time I've seen Anthropic use prices that vary depending on context length:</p>
<ul>
<li>Prompts ≤ 200K: $3/million input, $15/million output</li>
<li>Prompts &gt; 200K: $6/million input, $22.50/million output</li>
</ul>
<p>Gemini have been doing this for a while: Gemini 2.5 Pro is $1.25/$10 below 200,000 tokens and $2.50/$15 above 200,000.</p>
<p>Here's <a href="https://docs.anthropic.com/en/docs/build-with-claude/context-windows#1m-token-context-window">Anthropic's full documentation on the 1m token context window</a>. You need to send a <code>context-1m-2025-08-07</code> beta header in your request to enable it.</p>
<p>Note that this is currently restricted to "tier 4" users who have purchased at least $400 in API credits:</p>
<blockquote>
<p>Long context support for Sonnet 4 is now in public beta on the Anthropic API for customers with Tier 4 and custom rate limits, with broader availability rolling out over the coming weeks.</p>
</blockquote>

    <p><small></small>Via <a href="https://x.com/claudeai/status/1955299573620261343">@claudeai</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/anthropic">anthropic</a>, <a href="https://simonwillison.net/tags/claude">claude</a>, <a href="https://simonwillison.net/tags/llm-pricing">llm-pricing</a>, <a href="https://simonwillison.net/tags/long-context">long-context</a></p> 

<br> 

<https://simonwillison.net/2025/Aug/12/claude-sonnet-4-1m/#atom-everything>

---

## MINIX launches ER936-AI and ER937-AI AMD Strix Point mini PCs for $789 and up

date: 2025-08-12, from: Liliputing

<p>The MINIX ER936-AI and ER937-AI are a set of compact desktop computers with AMD Strix Point processors that combine Zen 5 CPU cores with RDNA 3.5 graphics and a 50 TOPS NPU. First unveiled during Computex in June, the mini PCs are now available for pre-order and they&#8217;re expected to begin shipping in early September. Prices start at [&#8230;]</p>
<p>The post <a href="https://liliputing.com/minix-launches-er936-ai-and-er937-ai-amd-strix-point-mini-pcs-for-789-and-up/">MINIX launches ER936-AI and ER937-AI AMD Strix Point mini PCs for $789 and up</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/minix-launches-er936-ai-and-er937-ai-amd-strix-point-mini-pcs-for-789-and-up/>

---

## This DIY handheld gaming PC has RTX 4090 graphics and a 12.5 inch, 4K display

date: 2025-08-12, from: Liliputing

<p>The upcoming GPD Win 5 and AYANEO Next 2 are going to be some of the first commercially-available handheld gaming PCs with discrete-class graphics thanks to their AMD Strix Halo processors with up to Radeon 8060S integrate graphics. But a Chinese modder decided to make a handheld that has an actual discrete GPU. A video posted to Bilbili [&#8230;]</p>
<p>The post <a href="https://liliputing.com/this-diy-handheld-gaming-pc-has-rtx-4090-graphics-and-a-12-5-inch-4k-display/">This DIY handheld gaming PC has RTX 4090 graphics and a 12.5 inch, 4K display</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/this-diy-handheld-gaming-pc-has-rtx-4090-graphics-and-a-12-5-inch-4k-display/>

---

## UK Asks People to Delete Emails In Order to Save Water During Drought

date: 2025-08-12, from: 404 Media Group

As Britain experiences one of its worst droughts in decades, its leaders suggest people get rid of old data to reduce stress on data centers. 

<br> 

<https://www.404media.co/uk-asks-people-to-delete-emails-in-order-to-save-water-during-drought/>

---

## On Moral Politics

date: 2025-08-12, from: Doc Searls on Medium

 

<br> 

<https://dsearls.medium.com/on-moral-politics-76098ad756ad?source=rss-c021b6737f47------2>

---

## Ancient Rome's Lessons on Leadership and Isolation

date: 2025-08-12, from: Guy Kawasaki blog

Kirk Freudenburg, Brooks and Suzanne Ragen Professor of Classics, Yale University. 

<br> 

<https://guykawasaki.substack.com/p/ancient-romes-lessons-on-leadership>

---

## PinePhone Pro Linux smartphone has been discontinued, but the original PinePhone is still available

date: 2025-08-12, from: Liliputing

<p>The PinePhone Pro is a Linux-friendly smartphone that launched in early 2022 as a higher-performance alternative to the original PinePhone. With a faster processor, more memory and storage, and a better camera, among other things, it was a significant upgrade&#8230; on paper, at least. But with a $400 price tag, it was also twice as expensive as [&#8230;]</p>
<p>The post <a href="https://liliputing.com/pinephone-pro-linux-smartphone-has-been-discontinued-but-the-original-pinephone-is-still-available/">PinePhone Pro Linux smartphone has been discontinued, but the original PinePhone is still available</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/pinephone-pro-linux-smartphone-has-been-discontinued-but-the-original-pinephone-is-still-available/>

---

## La noche de la desaparición: ¿alguien quiere pensar en los niños?

date: 2025-08-12, from: Iván Paredes Reséndiz blog, Mexico's cinema

<p>Dirección: Zach Cregger. Guion: Zach Cregger. Elenco: Julia Garner, Josh Brolin, Alden Ehrenheich, Austin Abrams, Benedict Wong, Cary Christopher, Amy Madigan. País: Estados Unidos.   Más información de la película: https://www.imdb.com/title/tt26581740 En lo que es una larga tradición, el género de terror suele proponer una perspectiva única sobre las infancias. Pasa por la mente la [&#8230;]</p>
<p>La entrada <a href="https://www.palomitademaiz.net/resenas-la-noche-de-la-desaparicion/">La noche de la desaparición: ¿alguien quiere pensar en los niños?</a> se publicó primero en <a href="https://www.palomitademaiz.net">Palomita de maíz</a>.</p>
 

<br> 

<https://www.palomitademaiz.net/resenas-la-noche-de-la-desaparicion/?utm_source=rss&utm_medium=rss&utm_campaign=resenas-la-noche-de-la-desaparicion>

---

## The Show Must Go On.  Take 2 At Cannes, 1946.

date: 2025-08-12, from: National Archives, Text Message blog

An earlier post discussed the collapse of the French attempt to initiate a film festival at Cannes in 1939, due to the outbreak of World War II.  Getting that festival off the ground was an early priority of the French government once the war ended in Europe in May 1945 and planning for resumption of &#8230; <a href="https://text-message.blogs.archives.gov/2025/08/12/the-show-must-go-on-take-2-at-cannes-1946/" class="more-link">Continue reading <span class="screen-reader-text">The Show Must Go On.  Take 2 At Cannes, 1946.</span></a> 

<br> 

<https://text-message.blogs.archives.gov/2025/08/12/the-show-must-go-on-take-2-at-cannes-1946/>

---

## Beelink launches GTR9 Pro Mac Studio lookalike with AMD Strix Halo (in China)

date: 2025-08-12, from: Liliputing

<p>The Beelink GTR 9 Pro is a 180 x 180 x 91mm (7.1&#8243; x 7.1&#8243; x 3.6&#8243;) desktop computer that bears a more than passing resemblance to a Mac Studio. But instead of Apple Silicon inside, this mini PC is powered by an AMD Ryzen AI Max+ 395 processor. First unveiled earlier this year, the GTR9 [&#8230;]</p>
<p>The post <a href="https://liliputing.com/beelink-launches-gtr9-pro-mac-studio-lookalike-with-amd-strix-halo-in-china/">Beelink launches GTR9 Pro Mac Studio lookalike with AMD Strix Halo (in China)</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/beelink-launches-gtr9-pro-mac-studio-lookalike-with-amd-strix-halo-in-china/>

---

## Feds Used Local Cop's Password to Do Immigration Surveillance With Flock Cameras

date: 2025-08-12, from: 404 Media Group

A DEA agent used a local cop's password "for federal investigations in late January 2025 without [the cop's] knowledge of said use." 

<br> 

<https://www.404media.co/feds-used-local-cops-password-to-do-immigration-surveillance-with-flock-cameras/>

---

## Back to School. Back to Work. Back to Being Remarkable. ✨ 

date: 2025-08-12, from: Guy Kawasaki blog

Think Remarkable &#8212; Now 50% Off for Back-to-School Season! 

<br> 

<https://guykawasaki.substack.com/p/back-to-school-back-to-work-back>

---

## You're Invited: 404 Media's Second Anniversary Party and LIVE PODCAST!

date: 2025-08-12, from: 404 Media Group

Come celebrate with us and catch a LIVE recording of the 404 Media podcast. 

<br> 

<https://www.404media.co/404-media-second-anniversary-party/>

---

## The Curious About Everything Newsletter #53

date: 2025-08-12, from: Curious about everything blog

The many interesting things I read in July 2025 

<br> 

<https://jodiettenberg.substack.com/p/fifty-three>

---

## Not a Booze Bag

date: 2025-08-12, updated: 2025-08-12, from: One Foot Tsunami

 

<br> 

<https://onefoottsunami.com/2025/08/12/no-booze-bag/>

---

## We caught companies making it harder to delete your personal data online

date: 2025-08-12, from: The Markup blog

Dozens of companies are hiding how you can delete your personal data, The Markup and CalMatters found. After our reporters reached out for comment, multiple companies have stopped the practice. 

<br> 

<https://themarkup.org/privacy/2025/08/12/we-caught-companies-making-it-harder-to-delete-your-data>

---

## Trump Plays the Carnage Card

date: 2025-08-12, from: Paul Krugman

Fake crime wave, real power grab 

<br> 

<https://paulkrugman.substack.com/p/trump-plays-the-carnage-card>

---

## Simplicity

date: 2025-08-12, from: Memo Garcia blog

The reason why newcomers try to do everything at once or add everything they can is to prove they can do anything with the new knowledge they acquire.
Veterans tend to make things simpler. 

<br> 

<https://memo.mx/posts/simplicity/>

---

## How Istio Handles Requests

date: 2025-08-12, from: Memo Garcia blog

Understanding how HTTP requests traverse an Istio service mesh is fundamental to effectively operating and troubleshooting microservices architectures. This technical analysis examines the complete request lifecycle, from external ingress through service-to-service communication, detailing the mechanisms that enable Istio&rsquo;s traffic management, security, and observability capabilities.
The Service Mesh Problem Statement Microservices need reliable communication, security, and observability. Without a service mesh:
Each service manually implements load balancing, retries, and circuit breakers Security and certificate management are inconsistent Service-to-service communication lacks visibility Debugging network issues is complex Code duplicates resilience patterns Istio provides standard networking, security, and observability across services without code changes. 

<br> 

<https://memo.mx/posts/how-istio-handles-requests/>

---

**@Robert's feed at BlueSky** (date: 2025-08-12, from: Robert's feed at BlueSky)

🙂

[contains quote post or other embedded content] 

<br> 

<https://bsky.app/profile/rsdoiel.bsky.social/post/3lw6glmatb22m>

---

## Quoting Nick Turley

date: 2025-08-12, updated: 2025-08-12, from: Simon Willison’s Weblog

<blockquote cite="https://www.youtube.com/watch?v=ixY2PvQJ0To&amp;t=2322s"><p>I think there's been a lot of decisions over time that proved pretty consequential, but we made them very quickly as we have to. [...]</p>
<p>[On pricing] I had this kind of panic attack because we really needed to launch subscriptions because at the time we were taking the product down all the time. [...]</p>
<p>So what I did do is ship a Google Form to Discord with <a href="https://en.wikipedia.org/wiki/Van_Westendorp%27s_Price_Sensitivity_Meter">the four questions you're supposed to ask</a> on how to price something.</p>
<p>But we got with the $20. We were debating something slightly higher at the time. I often wonder what would have happened because so many other companies ended up copying the $20 price point, so did we erase a bunch of market cap by pricing it this way?</p></blockquote>
<p class="cite">&mdash; <a href="https://www.youtube.com/watch?v=ixY2PvQJ0To&amp;t=2322s">Nick Turley</a>, Head of ChatGPT, interviewed by Lenny Rachitsky</p>

    <p>Tags: <a href="https://simonwillison.net/tags/chatgpt">chatgpt</a>, <a href="https://simonwillison.net/tags/discord">discord</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/openai">openai</a>, <a href="https://simonwillison.net/tags/llm-pricing">llm-pricing</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a></p> 

<br> 

<https://simonwillison.net/2025/Aug/12/nick-turley/#atom-everything>

---

## Far-Flung Modems

date: 2025-08-12, updated: 2025-08-12, from: Tedium site

AOL is ditching dial-up. They’re not required to continue running their dial-up service forever. But it would sure be nice. 

<br> 

<https://feed.tedium.co/link/15204/17118160/aol-dial-up-ending-retrospective>

---

## LLM 0.27, the annotated release notes: GPT-5 and improved tool calling

date: 2025-08-11, updated: 2025-08-11, from: Simon Willison’s Weblog

<p>I shipped <a href="https://llm.datasette.io/en/stable/changelog.html#v0-27">LLM 0.27</a> today (followed by a <a href="https://llm.datasette.io/en/stable/changelog.html#v0-27-1">0.27.1 with minor bug fixes</a>), adding support for the new GPT-5 family of models from OpenAI plus a flurry of improvements to the tool calling features <a href="https://simonwillison.net/2025/May/27/llm-tools/">introduced in LLM 0.26</a>. Here are the <a href="https://simonwillison.net/tags/annotated-release-notes/">annotated release notes</a>.</p>
<h4 id="gpt-5">GPT-5</h4>
<blockquote>
<ul>
<li>New models: <code>gpt-5</code>, <code>gpt-5-mini</code> and <code>gpt-5-nano</code>. <a href="https://github.com/simonw/llm/issues/1229">#1229</a>
</li>
</ul>
</blockquote>
<p>I would have liked to get these out sooner, but LLM had accumulated quite a lot of other changes since the last release and I wanted to use GPT-5 as an excuse to wrap all of those up and get them out there.</p>
<p>These models work much the same as other OpenAI models, but they have a new <code>reasoning_effort</code> option of <code>minimal</code>. You can try that out like this:</p>
<pre><code>llm -m gpt-5 'A letter advocating for cozy boxes for pelicans in Half Moon Bay harbor' -o reasoning_effort minimal
</code></pre>
<p>Setting "minimal" almost completely eliminates the "thinking" time for the model, causing it to behave more like GPT-4o.</p>
<p>Here's <a href="https://gist.github.com/simonw/49838dbca944d3f22dfe65ef11c5637d">the letter it wrote me</a> at a cost of 20 input, 706 output = <a href="https://www.llm-prices.com/#it=20&amp;ot=706&amp;ic=1.25&amp;oc=10">$0.007085 which is 0.7085 cents</a>.</p>
<p>You can set the default model to GPT-5-mini (since it's a bit cheaper) like this:</p>
<pre><code>llm models default gpt-5-mini
</code></pre>
<h4 id="tools-in-templates">Tools in templates</h4>
<blockquote>
<ul>
<li>LLM <a href="https://llm.datasette.io/en/stable/templates.html#prompt-templates">templates</a> can now include a list of tools. These can be named tools from plugins or arbitrary Python function blocks, see <a href="https://llm.datasette.io/en/stable/templates.html#prompt-templates-tools">Tools in templates</a>. <a href="https://github.com/simonw/llm/issues/1009">#1009</a>
</li>
</ul>
</blockquote>
<p>I think this is the most important feature in the new release.</p>
<p>I added LLM's <a href="https://simonwillison.net/2025/May/27/llm-tools/">tool calling features</a> in LLM 0.26. You can call them from the Python API but you can also call them from the command-line like this:</p>
<pre><code>llm -T llm_version -T llm_time 'Tell the time, then show the version'
</code></pre>
<p>Here's <a href="https://gist.github.com/simonw/65d830f8cb38cdeb78093d6ac890ce2c#response-1">the output</a> of <code>llm logs -c</code> after running that command.</p>
<p>This example shows that you have to explicitly list all of the tools you would like to expose to the model, using the <code>-T/--tool</code> option one or more times.</p>
<p>In LLM 0.27 you can now save these tool collections to <a href="https://llm.datasette.io/en/stable/templates.html">a template</a>. Let's try that now:</p>
<pre><code>llm -T llm_version -T llm_time -m gpt-5 --save mytools
</code></pre>
<p>Now <code>mytools</code> is a template that bundles those two tools and sets the default model to GPT-5. We can run it like this:</p>
<pre><code>llm -t mytools 'Time then version'
</code></pre>
<p>Let's do something more fun. My blog has a <a href="https://datasette.simonwillison.net/">Datasette mirror</a> which I can run queries against. I'm going to use the <a href="https://github.com/simonw/llm-tools-datasette">llm-tools-datasette</a> plugin to turn that into a tool-driven template. This plugin uses a "toolbox", which looks a bit like a class. Those are <a href="https://llm.datasette.io/en/stable/python-api.html#toolbox-classes">described here</a>.</p>
<pre><code>llm install llm-tools-datasette

# Now create that template
llm --tool 'Datasette("https://datasette.simonwillison.net/simonwillisonblog")' \
  -m gpt-5 -s 'Use Datasette tools to answer questions' --save blog
</code></pre>
<p>Now I can ask questions of my database like this:</p>
<pre><code>llm -t blog 'top ten tags by number of entries'</code></pre>
<p>The <code>--td</code> option there stands for <code>--tools-debug</code> - it means we can see all tool calls as they are run.</p>
<p>Here's the output of the above:</p>
<pre><code>Top 10 tags by number of entries (excluding drafts):
- quora — 1003
- projects — 265
- datasette — 238
- python — 213
- ai — 200
- llms — 200
- generative-ai — 197
- weeknotes — 193
- web-development — 166
- startups — 157
</code></pre>
<p><a href="https://gist.github.com/simonw/7b2d0d327afc32ad6c90179fa76290ad">Full transcript with tool traces here</a>.</p>
<p>I'm really excited about the ability to store configured tools</p>
<blockquote>
<ul>
<li>Tools <a href="https://llm.datasette.io/en/stable/python-api.html#python-api-tools-attachments">can now return attachments</a>, for models that support features such as image input. <a href="https://github.com/simonw/llm/issues/1014">#1014</a>
</li>
</ul>
</blockquote>
<p>I want to build a tool that can render SVG to an image, then return that image so the model can see what it has drawn. For reasons.</p>
<blockquote>
<ul>
<li>New methods on the <code>Toolbox</code> class: <code>.add_tool()</code>, <code>.prepare()</code> and <code>.prepare_async()</code>, described in <a href="https://llm.datasette.io/en/stable/python-api.html#python-api-tools-dynamic">Dynamic toolboxes</a>. <a href="https://github.com/simonw/llm/issues/1111">#1111</a>
</li>
</ul>
</blockquote>
<p>I added these because there's a lot of interest in an MCP plugin for Datasette. Part of the challenge with MCP is that the user provides the URL to a server but we then need to introspect that server and dynamically add the tools we have discovered there. The new <code>.add_tool()</code> method can do that, and the <code>.prepare()</code> and <code>.prepare_async()</code> methods give us a reliable way to run some discovery code outside of the class constructor, allowing it to make asynchronous calls if necessary.</p>
<blockquote>
<ul>
<li>New <code>model.conversation(before_call=x, after_call=y)</code> attributes for registering callback functions to run before and after tool calls. See <a href="https://llm.datasette.io/en/stable/python-api.html#python-api-tools-debug-hooks">tool debugging hooks</a> for details. <a href="https://github.com/simonw/llm/issues/1088">#1088</a>
</li>
<li>Raising <code>llm.CancelToolCall</code> now only cancels the current tool call, passing an error back to the model and allowing it to continue. <a href="https://github.com/simonw/llm/issues/1148">#1148</a>
</li>
</ul>
</blockquote>
<p>These hooks are useful for implementing more complex tool calling at the Python API layer. In addition to debugging and logging they allow Python code to intercept tool calls and cancel or delay them based on what they are trying to do.</p>
<blockquote>
<ul>
<li>Some model providers can serve different models from the same configured URL - <a href="https://github.com/simonw/llm-llama-server">llm-llama-server</a> for example. Plugins for these providers can now record the resolved model ID of the model that was used to the LLM logs using the <code>response.set_resolved_model(model_id)</code> method. <a href="https://github.com/simonw/llm/issues/1117">#1117</a>
</li>
</ul>
</blockquote>
<p>This solves a frustration I've had for a while where some of my plugins log the same model ID for requests that were processed by a bunch of different models under the hood - making my logs less valuable. The new mechanism now allows plugins to record a more accurate model ID for a prompt, should it differ from the model ID that was requsted.</p>
<blockquote>
<ul>
<li>New <code>-l/--latest</code> option for <code>llm logs -q searchterm</code> for searching logs ordered by date (most recent first) instead of the default relevance search. <a href="https://github.com/simonw/llm/issues/1177">#1177</a>
</li>
</ul>
</blockquote>
<p>My personal <a href="https://llm.datasette.io/en/stable/logging.html">log database</a> has grown to over 8,000 entries now, and running full-text search queries against it often returned results from last year that were no longer relevant to me. Being able to find the <em>latest</em> prompt matching "pelican svg" is much more useful.</p>
<p>Everything else was bug fixes and documentation improvements:</p>
<blockquote>
<h3 id="bug-fixes-and-documentation">Bug fixes and documentation</h3>
<ul>
<li>The <code>register_embedding_models</code> hook is <a href="https://llm.datasette.io/en/stable/plugins/plugin-hooks.html#register-embedding-models-register">now documented</a>. <a href="https://github.com/simonw/llm/issues/1049">#1049</a>
</li>
<li>Show visible stack trace for <code>llm templates show invalid-template-name</code>. <a href="https://github.com/simonw/llm/issues/1053">#1053</a>
</li>
<li>Handle invalid tool names more gracefully in <code>llm chat</code>. <a href="https://github.com/simonw/llm/issues/1104">#1104</a>
</li>
<li>Add a <a href="https://llm.datasette.io/en/stable/plugins/directory.html#plugin-directory-tools">Tool plugins</a> section to the plugin directory. <a href="https://github.com/simonw/llm/issues/1110">#1110</a>
</li>
<li>Error on <code>register(Klass)</code> if the passed class is not a subclass of <code>Toolbox</code>. <a href="https://github.com/simonw/llm/issues/1114">#1114</a>
</li>
<li>Add <code>-h</code> for <code>--help</code> for all <code>llm</code> CLI commands. <a href="https://github.com/simonw/llm/issues/1134">#1134</a>
</li>
<li>Add missing <code>dataclasses</code> to advanced model plugins docs. <a href="https://github.com/simonw/llm/issues/1137">#1137</a>
</li>
<li>Fixed a bug where <code>llm logs -T llm_version "version" --async</code> incorrectly recorded just one single log entry when it should have recorded two. <a href="https://github.com/simonw/llm/issues/1150">#1150</a>
</li>
<li>All extra OpenAI model keys in <code>extra-openai-models.yaml</code> are <a href="https://llm.datasette.io/en/stable/other-models.html#openai-compatible-models">now documented</a>. <a href="https://github.com/simonw/llm/issues/1228">#1228</a>
</li>
</ul>
</blockquote>
    
        <p>Tags: <a href="https://simonwillison.net/tags/projects">projects</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/datasette">datasette</a>, <a href="https://simonwillison.net/tags/annotated-release-notes">annotated-release-notes</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/llm">llm</a>, <a href="https://simonwillison.net/tags/llm-tool-use">llm-tool-use</a>, <a href="https://simonwillison.net/tags/gpt-5">gpt-5</a></p> 

<br> 

<https://simonwillison.net/2025/Aug/11/llm-027/#atom-everything>

---

**@Robert's feed at BlueSky** (date: 2025-08-11, from: Robert's feed at BlueSky)

Nice.

[contains quote post or other embedded content] 

<br> 

<https://bsky.app/profile/rsdoiel.bsky.social/post/3lw5t2e56o22a>

---

**@Tomosino's Mastodon feed** (date: 2025-08-11, from: Tomosino's Mastodon feed)

<p>If you were transformed into a loaf of bread, what type would it be?</p> 

<br> 

<https://tilde.zone/@tomasino/115012336650081880>

---

## iOS 26 Developer Beta 6

date: 2025-08-11, from: Michael Tsai

Juli Clover: Apple today provided developers with the sixth betas of iOS 26 and iPadOS 26 for testing purposes, with the updates coming a week after Apple seeded the fifth betas. The release notes don&#8217;t call out any changes in beta 6. Juli Clover: The Lock Screen clock has been updated with additional transparency, allowing [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/08/11/ios-26-developer-beta-6/>

---

## macOS Tahoe 26 Developer Beta 6

date: 2025-08-11, from: Michael Tsai

Juli Clover: Apple today provided developers with the sixth beta of macOS Tahoe 26 for testing purposes, with the update coming a week after the fifth beta. The release notes don&#8217;t call out any changes in beta 6. Previously: macOS Tahoe 26 Developer Beta 5 Update (2025-08-12): BasicAppleGuy: Apple recently added several new aerial wallpapers [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/08/11/macos-tahoe-26-developer-beta-6/>

---

## History of Apple’s Developer Relations

date: 2025-08-11, from: Michael Tsai

David Barnard (John Gruber): On the podcast I talk with John about the fascinating 40-year history of Apple&#8217;s developer relations, how almost going bankrupt in the 1990s shaped today&#8217;s control-focused approach, and why we might need an &#8216;App Store 3.0&#8217; reset. [&#8230;] As the App Store became a services giant, the partnership vibe faded. Developers [&#8230;] 

<br> 

<https://mjtsai.com/blog/2025/08/11/history-of-apples-developer-relations/>

---

## Ploopy TrackPad review: USB touchpad with open source firmware and multitouch support

date: 2025-08-11, from: Liliputing

<p>Most desktop computers are designed for keyboard and mouse input. Most laptops have a built-in touchpad. But it&#8217;s surprisingly difficult to find a good touchpad that&#8217;s designed for use in a desktop setup. Mac users have Apple&#8217;s Magic Trackpad. But if you&#8217;re using Windows or Linux you&#8217;ll either need to fight with unofficial drivers to [&#8230;]</p>
<p>The post <a href="https://liliputing.com/ploopy-trackpad-review-usb-touchpad-with-open-source-firmware-and-multitouch-support/">Ploopy TrackPad review: USB touchpad with open source firmware and multitouch support</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/ploopy-trackpad-review-usb-touchpad-with-open-source-firmware-and-multitouch-support/>

---

**@Robert's feed at BlueSky** (date: 2025-08-11, from: Robert's feed at BlueSky)

This is important.  https://laist.com/news/politics/tuesday-august-14-boycott-operation-trojan-horse 

<br> 

<https://bsky.app/profile/rsdoiel.bsky.social/post/3lw5i4dn56s23>

---

## New TestFlight Build Uploaded, Waiting for Review

date: 2025-08-11, from: NetNewsWire

<p>We know some folks are waiting on a new TestFlight build for iOS, and we have good news — we’ve just uploaded 6.1.10 (6198), and it’s waiting on Apple review. Once reviewed it will be available on TestFlight.</p>

<p><i>Update a few hours later…</i> The build is now available via TestFlight.</p> 

<br> 

<https://netnewswire.blog/2025/08/11/new-testflight-build-uploaded-waiting.html>

---

## Reddit will block the Internet Archive

date: 2025-08-11, updated: 2025-08-11, from: Simon Willison’s Weblog

<p><strong><a href="https://www.theverge.com/news/757538/reddit-internet-archive-wayback-machine-block-limit">Reddit will block the Internet Archive</a></strong></p>
Well this <em>sucks</em>. Jay Peters for the Verge:</p>
<blockquote>
<p>Reddit says that it has caught AI companies scraping its data from the Internet Archive’s Wayback Machine, so it’s going to start blocking the Internet Archive from indexing the vast majority of Reddit. The Wayback Machine will no longer be able to crawl post detail pages, comments, or profiles; instead, it will only be able to index the Reddit.com homepage, which effectively means Internet Archive will only be able to archive insights into which news headlines and posts were most popular on a given day.</p>
</blockquote>


    <p>Tags: <a href="https://simonwillison.net/tags/internet-archive">internet-archive</a>, <a href="https://simonwillison.net/tags/reddit">reddit</a>, <a href="https://simonwillison.net/tags/scraping">scraping</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/training-data">training-data</a>, <a href="https://simonwillison.net/tags/ai-ethics">ai-ethics</a></p> 

<br> 

<https://simonwillison.net/2025/Aug/11/reddit-will-block-the-internet-archive/#atom-everything>

---

## Witch Hunts to Misinformation Campaigns

date: 2025-08-11, from: Guy Kawasaki blog

Julie Walsh, Whitehead Associate Professor of Critical Thought and Associate Professor of Philosophy, Wellesley College. 

<br> 

<https://guykawasaki.substack.com/p/witch-hunts-to-misinformation-campaigns>

---

## Overcompensating (temporada 1): superficial paseo por la dicha y la pena del autodescubrimiento

date: 2025-08-11, from: Iván Paredes Reséndiz blog, Mexico's cinema

<p>Disponible en: Prime Video. Creador: Benito Skinner. Dirección: Daniel Gray Longino, Desiree Akhavan. Guion: Benito Skinner, Scott King, Mitra Jouhari, Jordan Mendoza. Elenco: Benito Skinner, Wally Baram, Mary Beth Barone, Adam DiMarco, Rish Shah, Connie Britton, Kyle MacLachlan, Corteon Moore, Owen Thiele, Lukas Gage. País: Estados Unidos. Duración: ocho episodios de 30 minutos cada uno. [&#8230;]</p>
<p>La entrada <a href="https://www.palomitademaiz.net/resenas-overcompensating-temporada-1/">Overcompensating (temporada 1): superficial paseo por la dicha y la pena del autodescubrimiento</a> se publicó primero en <a href="https://www.palomitademaiz.net">Palomita de maíz</a>.</p>
 

<br> 

<https://www.palomitademaiz.net/resenas-overcompensating-temporada-1/?utm_source=rss&utm_medium=rss&utm_campaign=resenas-overcompensating-temporada-1>

---

## Codex upgrade

date: 2025-08-11, updated: 2025-08-11, from: Simon Willison’s Weblog

<p>If you've been experimenting with OpenAI's <a href="https://github.com/openai/codex">Codex CLI</a> and have been frustrated that it's not possible to select text and copy it to the clipboard, at least when running in the Mac terminal (I genuinely didn't know it was possible to build a terminal app that disabled copy and paste) you should know that they fixed that in <a href="https://github.com/openai/codex/issues/1247">this issue</a> last week.</p>
<p>The new <a href="https://github.com/openai/codex/releases/tag/rust-v0.20.0">0.20.0 version</a> from three days ago also completely removes the old TypeScript codebase in favor of Rust. Even installations via NPM now get the Rust version.</p>
<p>I originally installed Codex via Homebrew, so I had to run this command to get the updated version:</p>
<pre><code>brew upgrade codex
</code></pre>
<p>Another Codex tip: to use GPT-5 (or any other specific OpenAI model) you can run it like this:</p>
<pre><code>export OPENAI_DEFAULT_MODEL="gpt-5"
codex
</code></pre>
<p><em>This no longer works, see update below.</em></p>
<p>I've been using a <code>codex-5</code> script on my PATH containing this, because sometimes I like to live dangerously!</p>
<pre><code>#!/usr/bin/env zsh
# Usage: codex-5 [additional args passed to `codex`]
export OPENAI_DEFAULT_MODEL="gpt-5"
exec codex --dangerously-bypass-approvals-and-sandbox "$@"
</code></pre>
<p><strong>Update</strong>: It looks like GPT-5 is <a href="https://github.com/openai/codex/blob/c61911524d839f5d56842faee0c46f6ef52d4387/codex-rs/core/src/config.rs#L28">the default model</a> in v0.20.0 already.</p>
<p>Also the environment variable I was using no longer does anything, it was <a href="https://github.com/openai/codex/commit/107d2ce4e74618968b2eb7016777121d9529a204#diff-b012ea51eb2b6d23db97b930526379af9c4c119a3e057e55ea29d056326242e0L6">removed in this commit</a> (I used Codex Web to <a href="https://chatgpt.com/s/cd_689a252794b081919099d5ade205b41d">help figure that out</a>). You can use the <code>-m model_id</code> command-line option instead.</p>

    <p>Tags: <a href="https://simonwillison.net/tags/openai">openai</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/gpt-5">gpt-5</a>, <a href="https://simonwillison.net/tags/rust">rust</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a></p> 

<br> 

<https://simonwillison.net/2025/Aug/11/codex-upgrade/#atom-everything>

---

## Zavala Will Always Be Free

date: 2025-08-11, from: Maurice Parker

<h2 id="my-promise-to-you">My promise to you.</h2>

<p>I have every intention of maintaining and updating Zavala for as long as I am able. I’m also committed to keeping it free. I have no intention of getting you hooked on using it and then starting to charge a subscription.</p>

<p>To show I am serious about this, Zavala is Open Source software released under the MIT license. This means that any other developer can take the years of work that I have in Zavala and make a competing outliner from it should I start charging for it. Given how small and competitive the outliner market is, I don’t stand much of a chance of making any money by going commercial. After all, I could be competing with my own past work.</p>

<h2 id="what-if-i-get-ran-over-by-a-bus">What if I get ran over by a bus?</h2>

<p>Since Zavala is Open Source someone could pick up the project and continue to update it. Worst case scenario, some enterprising independent developer could try to make a commercial product out of it. I don’t see much money in the endeavor, but others may see it differently.</p>

<h2 id="why-don-t-i-charge-for-zavala-or-accept-donations">Why don’t I charge for Zavala or accept donations?</h2>

<p>Funny story. I fully intended to when I started writing it. After doing some competitive analysis on the Mac-only, outliner market, I realized there wasn’t much money there. There was so little in fact, that it isn’t enough for me to be motivated enough to do the business side when I’d rather be coding.</p>

<p>Let me break it down. Up front payments are a dead-end these days. I would have to add a free tier, in-app purchases, and maybe a subscription option to the app. That means more coding. Then I need to incorporate a business of some kind and do all the regular bookkeeping associated with it. That would be payroll taxes, quarterly and annual tax filings, etc… I used to own my own software consulting business and really don’t want to do that stuff again.</p>

<p>But if I thought I could make it up on volume, that might make it worth while, right? The simple truth is most computer users don’t know what an outliner is, much less how useful they are. Even those that do, rarely need to use one on a daily basis. Zavala is free and has been all the years that it has been available in the App Store and I couldn’t make it on the number of users I have now. That number would probably drop to about zero if I were to start charging. Could I get more volume by marketing Zavala? Sure, but that is another business thing that costs time and money, that I don’t want to do.</p>

<p>There is an upside to not having money involved when you write software. I don’t have to add features just to drive an upgrade cycle. With commercial software, you constantly have to deliver upgrades to keep a steady income regardless of if you are subscription based or charging up front. I don’t want Zavala to become bloatware. I don’t want to add features that I don’t believe add core value, just to keep the money coming in.</p>

<p>Same goes for donations. I don’t accept donations because I don’t want to feel obligated to implement a feature that a donor may want, but that I don’t think belongs in Zavala. I would rather accept feature requests on an equal basis from all users and decide which to implement on the merit of the idea, rather than who gave me money.</p>

<h2 id="why-write-zavala-at-all">Why write Zavala at all?</h2>

<p>I retired early after a successful career as a software consultant. I really liked writing software, I just didn’t always like the work I had to do. Now I have the freedom to craft software how I see fit and only work on projects that I am interested in.</p>

<p>The way I usually explain it is like this. Imagine you made furniture your whole life, but your employer only gave you pallet wood to use and half the time needed to make a piece. You were good at it and loved furniture, but were unfulfilled at your job until you retired. Now you can make furniture using walnut and take the time needed to make something you are proud of.</p>

<h2 id="how-can-you-help-you-ask">How can you help, you ask?</h2>

<p>Please, please email me with bug reports using the Provide Feedback option under Help (in Settings on iOS). I take them seriously and fix them as fast as I can. I do test Zavala as rigorously as I can. Unfortunately it is the nature of software that a developer will never be able to predict every way that users will use an app. Production bugs do happen. The best we can do is squash them as fast as possible.</p> 

<br> 

<https://vincode.io/2025/08/11/zavala-will-always-be-free.html>

---

## This DIY eReader has dual E Ink displays for a more book-like reading experience

date: 2025-08-11, from: Liliputing

<p>E Ink devices like the Amazon Kindle, Kobo, and B&#38;N Nook line of products promise a book-like reading experience thanks to displays that mimic some of the properties of ink on paper. But one big difference? For the most part they&#8217;re about the size of a single page in a paperback book. Pick up an [&#8230;]</p>
<p>The post <a href="https://liliputing.com/this-diy-ereader-has-dual-e-ink-displays-for-a-more-book-like-reading-experience/">This DIY eReader has dual E Ink displays for a more book-like reading experience</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/this-diy-ereader-has-dual-e-ink-displays-for-a-more-book-like-reading-experience/>

---

## How our dog increased my appreciation for accessibility

date: 2025-08-11, from: Cloud Four

Our dog headbutted me, gave me a concussion and a new appreciation of accessibility features. 

<br> 

<https://cloudfour.com/thinks/how-our-dog-increased-my-appreciation-for-accessibility/>

---

## Voiceover Artists Weigh the 'Faustian Bargain' of Lending Their Talents to AI

date: 2025-08-11, from: 404 Media Group

The human voiceover artists behind AI voices are grappling with the choice to embrace the gigs and earn a living, or pass on potentially life-changing opportunities from Big Tech. 

<br> 

<https://www.404media.co/voiceover-artists-ai-voice-acting-jobs-microsoft-openai-chatgpt/>

---

## The U.S. Army Is Testing AI Controlled Ground Drones Near a Border with Russia

date: 2025-08-11, from: 404 Media Group

The OverDrive is made to let ground vehicles navigate tough terrain with minimal input from humans. 

<br> 

<https://www.404media.co/the-u-s-army-is-testing-ai-controlled-ground-drones-near-a-border-with-russia/>

---

## Insignificant Figures

date: 2025-08-11, updated: 2025-08-11, from: One Foot Tsunami

 

<br> 

<https://onefoottsunami.com/2025/08/11/insignificant-figures/>

---

## Did the Old Robber Barons Get a Bad Rap?

date: 2025-08-11, from: Tina Brown

I&#8217;m gutted that the third season of Julian Fellowes&#8217;s The Gilded Age on HBO ended last night. 

<br> 

<https://tinabrown.substack.com/p/did-the-old-robber-barons-get-a-bad>

---

## The Political Economy of Incompetence

date: 2025-08-11, from: Paul Krugman

How Hannah Arendt predicted Stephen Moore 

<br> 

<https://paulkrugman.substack.com/p/the-political-economy-of-incompetence>

---

## Happy Maker Monday — show us your Raspberry Pi builds!

date: 2025-08-11, from: Raspberry Pi News (.com)

<p>Another Maker Monday is upon us! </p>
<p>The post <a href="https://www.raspberrypi.com/news/happy-maker-monday-show-us-your-raspberry-pi-builds/">Happy Maker Monday — show us your Raspberry Pi builds!</a> appeared first on <a href="https://www.raspberrypi.com">Raspberry Pi</a>.</p>
 

<br> 

<https://www.raspberrypi.com/news/happy-maker-monday-show-us-your-raspberry-pi-builds/>

---

## One man in his time plays many parts…

date: 2025-08-11, from: Status-Q blog

I did like this article: 27 Notes on Growing Old(er), by the author Ian Leslie. Excerpt: Wisdom is meant to be the great compensation for growing older. Though your your knees sound like they’re unlocking a safe when you bend down, and you can’t straighten up without an “oof”, you can at least revel in <a class="more-link excerpt-link" href="https://statusq.org/archives/2025/08/11/13259/">Continue Reading<span class="glyphicon glyphicon-chevron-right"></span></a> 

<br> 

<https://statusq.org/archives/2025/08/11/13259/>

---

## qwen-image-mps

date: 2025-08-11, updated: 2025-08-11, from: Simon Willison’s Weblog

<p><strong><a href="https://github.com/ivanfioravanti/qwen-image-mps">qwen-image-mps</a></strong></p>
Ivan Fioravanti built this Python CLI script for running the <a href="https://huggingface.co/Qwen/Qwen-Image">Qwen/Qwen-Image</a> image generation model on an Apple silicon Mac, optionally using the <a href="https://github.com/ModelTC/Qwen-Image-Lightning">Qwen-Image-Lightning</a> LoRA to dramatically speed up generation.</p>
<p>Ivan has tested it this on 512GB and 128GB machines and it ran <a href="https://x.com/ivanfioravanti/status/1954646355458269562">really fast</a> - 42 seconds on his M3 Ultra. I've run it on my 64GB M2 MacBook Pro - after quitting almost everything else - and it just about manages to output images after pegging my GPU (fans whirring, keyboard heating up) and occupying 60GB of my available RAM. With the LoRA option running the script to generate an image took 9m7s on my machine.</p>
<p>Ivan merged <a href="https://github.com/ivanfioravanti/qwen-image-mps/pull/3">my PR</a> adding inline script dependencies for <a href="https://github.com/astral-sh/uv">uv</a> which means you can now run it like this:</p>
<pre><code>uv run https://raw.githubusercontent.com/ivanfioravanti/qwen-image-mps/refs/heads/main/qwen-image-mps.py \
-p 'A vintage coffee shop full of raccoons, in a neon cyberpunk city' -f
</code></pre>
<p>The first time I ran this it downloaded the 57.7GB model from Hugging Face and stored it in my <code>~/.cache/huggingface/hub/models--Qwen--Qwen-Image</code> directory. The <code>-f</code> option fetched an extra 1.7GB <code>Qwen-Image-Lightning-8steps-V1.0.safetensors</code> file to my working directory that sped up the generation.</p>
<p>Here's the resulting image:</p>
<p><img alt="Digital artwork of a cyberpunk-style coffee shop populated entirely by raccoons as customers, with illegible neon signs visible in the windows, pendant lighting over the counter, menu boards on the wall, bottles on shelves behind the bar, and raccoons sitting at tables and the counter with coffee cups" src="https://static.simonwillison.net/static/2025/racoon-cyberpunk-coffee.jpg" />

    <p><small></small>Via <a href="https://x.com/ivanfioravanti/status/1954284146064576966">@ivanfioravanti</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/macos">macos</a>, <a href="https://simonwillison.net/tags/python">python</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/uv">uv</a>, <a href="https://simonwillison.net/tags/qwen">qwen</a>, <a href="https://simonwillison.net/tags/text-to-image">text-to-image</a>, <a href="https://simonwillison.net/tags/ai-in-china">ai-in-china</a>, <a href="https://simonwillison.net/tags/ivan-fioravanti">ivan-fioravanti</a></p> 

<br> 

<https://simonwillison.net/2025/Aug/11/qwen-image-mps/#atom-everything>

---

## AI for data engineers with Simon Willison

date: 2025-08-11, updated: 2025-08-11, from: Simon Willison’s Weblog

<p><strong><a href="https://talkingpostgres.com/episodes/ai-for-data-engineers-with-simon-willison">AI for data engineers with Simon Willison</a></strong></p>
I recorded an episode last week with Claire Giordano for the Talking Postgres podcast. The topic was "AI for data engineers" but we ended up covering an enjoyable range of different topics.</p>
<ul>
<li>How I got started programming with a Commodore 64 - the tape drive for which inspired the name <a href="https://datasette.io/">Datasette</a></li>
<li>Selfish motivations for <a href="https://til.simonwillison.net/">TILs</a> (force me to write up my notes) and open source (help me never have to solve the same problem twice)</li>
<li>LLMs have been good at SQL for a couple of years now. Here's how I used them <a href="https://simonwillison.net/2025/Apr/28/dashboard-alt-text/">for a complex PostgreSQL query</a> that extracted alt text from my blog's images using regular expressions</li>
<li>Structured data extraction as the most economically valuable application of LLMs for data work</li>
<li>2025 has been the year of tool calling a loop ("agentic" if you like)</li>
<li>Thoughts on running MCPs securely - read-only database access, think about sandboxes, use PostgreSQL permissions, watch out for the <a href="https://simonwillison.net/tags/lethal-trifecta/">lethal trifecta</a></li>
<li>Jargon guide: Agents, MCP, RAG, Tokens</li>
<li>How to get started learning to prompt: play with the models and "bring AI to the table" even for tasks that you don't think it can handle</li>
<li>"It's always a good day if you see a pelican"</li>
</ul>


    <p>Tags: <a href="https://simonwillison.net/tags/postgresql">postgresql</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/podcast-appearances">podcast-appearances</a></p> 

<br> 

<https://simonwillison.net/2025/Aug/11/ai-for-data-engineers/#atom-everything>

---

## Chromium Docs: The Rule Of 2

date: 2025-08-11, updated: 2025-08-11, from: Simon Willison’s Weblog

<p><strong><a href="https://chromium.googlesource.com/chromium/src/+/main/docs/security/rule-of-2.md">Chromium Docs: The Rule Of 2</a></strong></p>
Alex Russell <a href="https://toot.cafe/@slightlyoff/114999510361121718">pointed me</a> to this principle in the Chromium security documentation as similar to my description of <a href="https://simonwillison.net/2025/Aug/9/bay-area-ai/">the lethal trifecta</a>. First added <a href="https://github.com/chromium/chromium/commit/aef94dd0e444605a16be26cba96aa477bc7fc3f5">in 2019</a>, the Chromium guideline states:</p>
<blockquote>
<p>When you write code to parse, evaluate, or otherwise handle untrustworthy inputs from the Internet — which is almost everything we do in a web browser! — we like to follow a simple rule to make sure it's safe enough to do so. The Rule Of 2 is: Pick no more than 2 of</p>
<ul>
<li>untrustworthy inputs;</li>
<li>unsafe implementation language; and</li>
<li>high privilege.</li>
</ul>
<p><img alt="Venn diagram showing you should always use
a safe language, a sandbox, or not be processing untrustworthy inputs in the first
place." src="https://static.simonwillison.net/static/2025/rule-of-2.png" /></p>
</blockquote>
<p>Chromium uses this design pattern to help try to avoid the high severity memory safety bugs that come when untrustworthy inputs are handled by code running at high privilege.</p>
<blockquote>
<p>Chrome Security Team will generally not approve landing a CL or new feature that involves all 3 of untrustworthy inputs, unsafe language, and high privilege. To solve this problem, you need to get rid of at least 1 of those 3 things.</p>
</blockquote>


    <p>Tags: <a href="https://simonwillison.net/tags/alex-russell">alex-russell</a>, <a href="https://simonwillison.net/tags/browsers">browsers</a>, <a href="https://simonwillison.net/tags/chrome">chrome</a>, <a href="https://simonwillison.net/tags/security">security</a>, <a href="https://simonwillison.net/tags/lethal-trifecta">lethal-trifecta</a></p> 

<br> 

<https://simonwillison.net/2025/Aug/11/the-rule-of-2/#atom-everything>

---

## What Interviews Should I Look For?

date: 2025-08-11, from: Computer ads from the Past

Help point me in the right direction. 

<br> 

<https://computeradsfromthepast.substack.com/p/what-interviews-should-i-look-for>

---

## How Do Committees Fail To Invent?

date: 2025-08-11, updated: 2025-08-11, from: Alex Russel's blog

 

<br> 

<https://infrequently.org/2025/08/how-do-committees-fail-to-invent/>

---

## Browsertrix 1.18: Large URL Lists and Beautiful Emails

date: 2025-08-11, from: Web Recorder

Browsertrix 1.18 brings support for large URL lists, new email templates, and UX improvements for crawling and curating. 

<br> 

<https://webrecorder.net/blog/2025-08-11-browsertrix-1-18/>

---

## Qwen3-4B-Thinking: "This is art - pelicans don't ride bikes!"

date: 2025-08-10, updated: 2025-08-10, from: Simon Willison’s Weblog

<p>I've fallen a few days behind keeping up with Qwen. They released two new 4B models last week:  <a href="https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507">Qwen3-4B-Instruct-2507</a> and its thinking equivalent <a href="https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507">Qwen3-4B-Thinking-2507</a>.</p>
<p>These are relatively tiny models that punch <em>way</em> above their weight. I’ve been running the 8bit GGUF varieties via LM Studio (here's <a href="https://huggingface.co/lmstudio-community/Qwen3-4B-Instruct-2507-GGUF">Instruct</a>, here's <a href="https://huggingface.co/lmstudio-community/Qwen3-4B-Thinking-2507-GGUF">Thinking</a>) - both of them are 4GB downloads that use around 4.3GB of my M2 MacBook Pro’s system RAM while running. Both are way more capable than I would expect from such small files.</p>
<p>Qwen3-4B-Thinking is the first model I've tried which called out the absurdity of being asked to draw <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">a pelican riding a bicycle</a>!</p>
<p>Here's <a href="https://gist.github.com/simonw/cd41769de4791b98ba43a17c6ff32ee1">the full transcript</a> - some highlights from the thinking trace:</p>
<blockquote>
<p>Okay, the user asked for an SVG of a pelican riding a bicycle. That's... oddly specific and completely unrealistic.</p>
<p>First reaction: Pelicans don't ride bicycles. They're birds that fly or swim, not human-like vehicles. This feels like a mix-up - maybe they meant "a cyclist" but typed "pelican"? Or perhaps it's a joke?</p>
<p>Hmm, user might be:</p>
<ul>
<li>A kid playing with words (pelican + bicycle = silly combo)</li>
<li>Someone testing if I'll generate impossible images</li>
<li>Actually wanting a pelican <em>on</em> a bike for art project? But that still doesn't make sense biologically</li>
</ul>
<p><em>Checks SVG capabilities</em>
SVG is for vector graphics, but this request violates physics and biology. If I tried to draw it literally:</p>
<ul>
<li>Pelican would be too big for a bike frame</li>
<li>Bike wheels would be tiny compared to bird wings</li>
<li>No realistic way to show "riding" since pelicans don't have legs for pedaling</li>
</ul>
<p>[…]</p>
<p><em>Self-check</em>: Am I being too pedantic? Nah - if someone asks for impossible things, it's better to gently correct than make fake art that could confuse them. […]</p>
<p>I appreciate your creative request! 🦅🚴‍♂️ However, <strong>pelicans don't ride bicycles</strong> (they're birds that fly/swim, not humans with bike skills). Generating this as a literal SVG would be biologically impossible and visually confusing.</p>
</blockquote>
<p>"This request violates physics and biology" - Qwen3-4B-Thinking saying what no other model ever thought to express.</p>
<p>I also really enjoyed the "Am I being too pedantic? Nah" line. This model is sassy!</p>
<p>It continued on to spit out two SVGS: the first titled "Most Likely: A Human Cyclist" and the second "Artistic Interpretation: Pelican <em>On</em> a Bicycle (For Fun!)".</p>
<p>They were both terrible. Here's the human one:</p>
<p><img src="https://static.simonwillison.net/static/2025/qwen3-4b-thinking-human.png" alt="It's a green horizontal line, three abstract black shapes, a brown circle and the word Person" style="max-width: 100%;" /></p>
<p>And here's the supposed pelican:</p>
<p><img src="https://static.simonwillison.net/static/2025/qwen3-4b-thinking-pelican.png" alt="A blue circle, with a small black shape that might be a wing and a black shape that could maybe be the head? It's awful. Red text overlaps it that says This is art - pelicans don't ride bikes! - there is no attempt at a bicycle." style="max-width: 100%;" /></p>
<p>I like Qwen's decision to include the clarifying annotation "This is art - pelicans don't ride bikes!":</p>
<p>I tried the Qwen3-4B-Instruct non-thinking model too. It <a href="https://gist.github.com/simonw/ad927a3849d0aece043afc97559be4bf">answered much faster</a> (no time spent questioning my choice of task with its thinking tokens) and gave me this:</p>
<p><img src="https://static.simonwillison.net/static/2025/qwen3-4b-instruct-2507-pelican.png" alt="A bunch of shaps. Pelican Riding a Bike! transposed on top. The yellow and orange bits might be a pelican I guess. The bicycle has two wheels overlapping too close and a single bar in the wrong direction." style="max-width: 100%;" /></p>
<p>4B is such an interesting model size. These models should run on almost anything and, at least on my M2 MacBook, they run <em>fast</em>. I'm getting 50+ tokens per second and they're using just less than 4.5GB of RAM while running.</p>
<p>The question is always how useful such a tiny model can be. Clearly it's not great for SVG pelican illustrations!</p>

<p>I did get a useful result out of the <code>-Thinking</code> variant for a <code>jq</code> expression I needed. I prompted:</p>

<blockquote><p>queries[0].rows is an array of objects each with a markdown key - write a jq bash one liner to output a raw string if that markdown concatenated together with double newlines between each</p></blockquote>

<p>It thought <a href="https://gist.github.com/simonw/3f76749aa710f4a2d6405ebcf5b00ac4">for 3 minutes 13 seconds</a> before spitting out a recipe that did roughly what I wanted:</p>

<pre><code>jq -r '.queries[0].rows[] | .markdown' | tr '\n' '\n\n'</code></pre>

<p>I'm not sure that was worth waiting three minutes for though!</p>

<p>These models have a 262,144 token context - wildly impressive, <em>if it works</em>.</p>
<p>So I tried another experiment: I used the Instruct model to summarize <a href="https://news.ycombinator.com/item?id=44851557">this Hacker News conversation about GPT-5</a>.</p>
<p>I did this with the <a href="https://github.com/agustif/llm-lmstudio">llm-lmstudio</a> plugin for LLM combined with my <a href="https://til.simonwillison.net/llms/claude-hacker-news-themes">hn-summary.sh script</a>, which meant I could run the experiment like this:</p>
<pre><code>hn-summary.sh 44851557 -m qwen3-4b-instruct-2507
</code></pre>
<p>I believe this is 15,785 tokens - so nothing close to the 262,144 maximum but still an interesting test of a 4GB local model.</p>
<p>The good news is Qwen spat out a genuinely useful summary of the conversation! You can <a href="https://gist.github.com/simonw/4c5a1912f73e0d68b456b18000a76f0d#response">read that here</a> - it's the best I've seen yet from a model running on my laptop, though honestly I've not tried many other recent models in this way.</p>
<p>The bad news... it took almost five minutes to process and return the result!</p>
<p>As a loose calculation, if the model can output 50 tokens/second maybe there's a similar speed for processing incoming input.. in which case 15785 / 50 = 315 seconds which is 5m15s.</p>
<p>Hosted models can crunch through 15,000 tokens of input in just a few seconds. I guess this is one of the more material limitations of running models on Apple silicon as opposed to dedicated GPUs.</p>
<p>I think I'm going to spend some more time with these models. They're fun, they have personality and I'm confident there are classes of useful problems they will prove capable at despite their small size. Their ability at summarization should make them a good fit for local RAG, and I've not started exploring their tool calling abilities yet.</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/local-llms">local-llms</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/qwen">qwen</a>, <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle">pelican-riding-a-bicycle</a>, <a href="https://simonwillison.net/tags/llm-release">llm-release</a>, <a href="https://simonwillison.net/tags/lm-studio">lm-studio</a>, <a href="https://simonwillison.net/tags/ai-in-china">ai-in-china</a></p> 

<br> 

<https://simonwillison.net/2025/Aug/10/qwen3-4b/#atom-everything>

---

## Episode 162 - CSIRAC, Australia's First Computer

date: 2025-08-10, from: Advent of Computing

<p>In 1949 CSIRAC sprung to life in a lab in Sydney, Australia. It was a very early stored program computer. All machines of the era were unique. But CSIRAC, well, it was <em>very</em> unique indeed.</p> <p>Selected Sources:</p> <p> <a href= "https://cis.unimelb.edu.au/about/csirac/music/reconstruction" rel= "noopener noreferrer nofollow" data-link-auto= ""><u>https://cis.unimelb.edu.au/about/csirac/music/reconstruction</u></a> - The Music of CSIRAC</p> <p><a href="https://sci-hub.se/10.1109/MAHC.1984.10014" rel= "noopener noreferrer nofollow" data-link-auto= "">https://sci-hub.se/10.1109/MAHC.1984.10014</a> - Pearcy and Beard on CSIRAC</p> 

<audio crossorigin="anonymous" controls="controls">
<source type="audio/mpeg" src="https://traffic.libsyn.com/secure/adventofcomputing/ep162_csirac.mp3?dest-id=1206722"></source>
</audio> <a href="https://traffic.libsyn.com/secure/adventofcomputing/ep162_csirac.mp3?dest-id=1206722" target="_blank">download audio/mpeg</a><br> 

<https://adventofcomputing.libsyn.com/episode-162-csirac-australias-first-computer>

---

## Quoting Sam Altman

date: 2025-08-10, updated: 2025-08-10, from: Simon Willison’s Weblog

<blockquote cite="https://x.com/sama/status/1954603417252532479"><p>the percentage of users using reasoning models each day is significantly increasing; for example, for free users we went from &lt;1% to 7%, and for plus users from 7% to 24%.</p></blockquote>
<p class="cite">&mdash; <a href="https://x.com/sama/status/1954603417252532479">Sam Altman</a>, revealing quite how few people used the old model picker to upgrade from GPT-4o</p>

    <p>Tags: <a href="https://simonwillison.net/tags/openai">openai</a>, <a href="https://simonwillison.net/tags/llm-reasoning">llm-reasoning</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/gpt-5">gpt-5</a>, <a href="https://simonwillison.net/tags/sam-altman">sam-altman</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/chatgpt">chatgpt</a></p> 

<br> 

<https://simonwillison.net/2025/Aug/10/sam-altman/#atom-everything>

---

## Focus

date: 2025-08-10, from: Memo Garcia blog

Just say no. 

<br> 

<https://memo.mx/posts/focus/>

---

**@Robert's feed at BlueSky** (date: 2025-08-10, from: Robert's feed at BlueSky)

Wrote up a short post on using Flat Lake, flatelake.app, and Deno+TypeScript to generate RSS 2.0 feeds. https://rsdoiel.github.io/blog/2025/08/10/generating_rss_with_flatlake.html
https://flatelake.app 

<br> 

<https://bsky.app/profile/rsdoiel.bsky.social/post/3lw3cri7t5c2l>

---

## Lilbits: AOL frees up your phone line by ending dial-up access

date: 2025-08-10, from: Liliputing

<p>AOL is ending dial-up access next month, 34 years after launching the service that provided many Americans with their first (somewhat limited) taste of the internet. The surprising news here is that it hadn&#8217;t already happened&#8230; who uses dial-up or AOL in 2025? But it&#8217;s still an interesting footnote in the history of the internet. Here&#8217;s [&#8230;]</p>
<p>The post <a href="https://liliputing.com/lilbits-2/">Lilbits: AOL frees up your phone line by ending dial-up access</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/lilbits-2/>

---

**@Robert's feed at BlueSky** (date: 2025-08-10, from: Robert's feed at BlueSky)

😆👇

[contains quote post or other embedded content] 

<br> 

<https://bsky.app/profile/rsdoiel.bsky.social/post/3lw2nz5raws2q>

---

## Debian 13 “trixie” release brings RISC-V support plus to the popular GNU/Linux distro, plus thousands of other updates

date: 2025-08-10, from: Liliputing

<p>Debian is a free and open source, Linux-based operating system that&#8217;s bee around for more than three decades. And computers have changed a lot in that time. So while Debian has a reputation for releasing updates on a slow, steady, and stable basis rather than pushing bleeding edge features, the operating system has made some major changes [&#8230;]</p>
<p>The post <a href="https://liliputing.com/debian-13-trixie-release-brings-risc-v-support-plus-to-the-popular-gnu-linux-distro-plus-thousands-of-other-updates/">Debian 13 &#8220;trixie&#8221; release brings RISC-V support plus to the popular GNU/Linux distro, plus thousands of other updates</a> appeared first on <a href="https://liliputing.com">Liliputing</a>.</p>
 

<br> 

<https://liliputing.com/debian-13-trixie-release-brings-risc-v-support-plus-to-the-popular-gnu-linux-distro-plus-thousands-of-other-updates/>

---

## The Economics of Smoot Hawley 2.0, Part II

date: 2025-08-10, from: Paul Krugman

This trade war is really a class war 

<br> 

<https://paulkrugman.substack.com/p/the-economics-of-smoot-hawley-20-cf7>

---

## Generating RSS with FlatLake

date: 2025-08-10, from: Robert's Ramblings

A show post describing a prototype in Deno+TypeScript for generating RSS 2.0 feeds from a FlatLake generated JSON API.
 

<br> 

<https://rsdoiel.github.io/blog/2025/08/10/generating_rss_with_flatlake.html>

