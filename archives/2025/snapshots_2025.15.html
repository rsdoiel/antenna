<!doctype html>
<html lang="en-US">
<head>
  <meta charset="utf-8" >
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" >
  <title>snapshots</title>
<!--  <link rel="stylesheet" type="text/css"  href="../webfonts/fonts.css" media="screen" > -->
  <link rel="stylesheet" type="text/css"  href="../css/site.css" media="screen" >
</head>
<body>
<header>
	<img class="logo" 
	src="https://upload.wikimedia.org/wikipedia/commons/9/9c/Antenna_1_-_The_Noun_Project.svg"
	alt="line art showing an antenna"
	height="80" width="60" >
	<h1>The Antenna</h1> 
	<h2>finding signal in the noise</h2>
</header>
<nav>
<ul>
	<li><a href="../../">The Antenna</a></li>
	<li><a href="../">Archives</a></li>
	<li><a href="../../about.html">About</a></li>
</ul>
</nav>
<section>
<div class="description-for-items">
<h2>snapshots</h2>
An experiment in personal news aggregation.
</div>
<h1 id="snapshots">snapshots</h1>
<p>(date: 2025-04-14 14:07:50)</p>
<hr />
<h2
id="my-video-chat-with-the-brilliant-writer-and-zeitgeist-predictor-michael-lewis">My
video chat with the brilliant writer and zeitgeist predictor Michael
Lewis</h2>
<p>date: 2025-04-14, from: Tina Brown</p>
<p>Our chat roamed from his new book Who is Government?</p>
<audio crossorigin="anonymous" controls="controls">
<source type="audio/mpeg" src="https://api.substack.com/feed/podcast/161331615/7b2308cd8292adfbd4295bb8f9117e8c.mp3">
</source>
</audio>
<p><a href="https://api.substack.com/feed/podcast/161331615/7b2308cd8292adfbd4295bb8f9117e8c.mp3" target="_blank">download
audio/mpeg</a><br></p>
<p><a
href="https://tinabrown.substack.com/p/my-video-chat-with-the-brilliant"
class="uri">https://tinabrown.substack.com/p/my-video-chat-with-the-brilliant</a></p>
<hr />
<h2
id="bigme-b13-is-a-portable-monitor-with-a-13.3-inch-e-ink-color-display">Bigme
B13 is a portable monitor with a 13.3 inch E Ink color display</h2>
<p>date: 2025-04-14, from: Liliputing</p>
<p>
The Bigme B13 is a portable monitor with a 13.3 inch, 3200 x 2400 pixel
display featuring a 30 Hz refresh rate. There’s nothing unusual about
that, but what makes this little screen stand out is the type of display
technology it uses. Rather than LCD or OLED, the Bigme B13 has an E Ink
color […]
</p>
<p>
The post
<a href="https://liliputing.com/bigme-b13-is-a-portable-monitor-with-a-13-3-inch-e-ink-color-display/">Bigme
B13 is a portable monitor with a 13.3 inch E Ink color display</a>
appeared first on <a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/bigme-b13-is-a-portable-monitor-with-a-13-3-inch-e-ink-color-display/"
class="uri">https://liliputing.com/bigme-b13-is-a-portable-monitor-with-a-13-3-inch-e-ink-color-display/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Robert">@Robert</span>’s
feed at BlueSky</strong> (date: 2025-04-14, from: Robert’s feed at
BlueSky)</p>
<p>This is how easy it should be. I think it is possible even in
“static” websites when the tool(s) we use are thought of as read and
write.</p>
<p>[contains quote post or other embedded content]</p>
<p><br></p>
<p><a
href="https://bsky.app/profile/rsdoiel.bsky.social/post/3lmsga72gsk2o"
class="uri">https://bsky.app/profile/rsdoiel.bsky.social/post/3lmsga72gsk2o</a></p>
<hr />
<h2
id="pine64-starpro64-single-board-pc-with-a-risc-v-processor-and-20-tops-npu-arrives-this-month">Pine64
StarPro64 single-board PC with a RISC-V processor and 20 TOPS NPU
arrives this month</h2>
<p>date: 2025-04-14, from: Liliputing</p>
<p>
The StarPro64 is a single-board computer with a quad-core RISC-V
processor, hardware-accelerated graphics and support for 8K video
playback, and an NPU that delivers nearly 20 TOPS of AI performance.
First unveiled last fall, Pine64 now says StarPro64 should be available
for purchase before the end of April. The board measures 133 x 80 x 19mm
[…]
</p>
<p>
The post
<a href="https://liliputing.com/pine64-starpro64-single-board-pc-with-a-risc-v-processor-and-20-tops-npu-arrives-this-month/">Pine64
StarPro64 single-board PC with a RISC-V processor and 20 TOPS NPU
arrives this month</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/pine64-starpro64-single-board-pc-with-a-risc-v-processor-and-20-tops-npu-arrives-this-month/"
class="uri">https://liliputing.com/pine64-starpro64-single-board-pc-with-a-risc-v-processor-and-20-tops-npu-arrives-this-month/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
linkblog</strong> (date: 2025-04-14, from: Dave Winer’s linkblog)</p>
<p>Harvard’s response.</p>
<p><br></p>
<p><a
href="https://www.harvard.edu/president/news/2025/the-promise-of-american-higher-education/"
class="uri">https://www.harvard.edu/president/news/2025/the-promise-of-american-higher-education/</a></p>
<hr />
<h2
id="github-actions-now-supports-windows-on-arm-runners-for-all-public-repos">GitHub
Actions now supports Windows on Arm runners for all public repos</h2>
<p>date: 2025-04-14, from: Windows Developer Blog</p>
<p>
We are continuously investing in improving the Windows on Arm developer
experience by providing and improving the tools needed by developers
targeting Arm powered Copilot+ PCs.
</p>
<p>
Today we are thrilled to announce Windows on Arm runner availability has
</p>
<p>
The post
<a href="https://blogs.windows.com/windowsdeveloper/2025/04/14/github-actions-now-supports-windows-on-arm-runners-for-all-public-repos/">GitHub
Actions now supports Windows on Arm runners for all public repos</a>
appeared first on
<a href="https://blogs.windows.com/windowsdeveloper">Windows Developer
Blog</a>.
</p>
<p><br></p>
<p><a
href="https://blogs.windows.com/windowsdeveloper/2025/04/14/github-actions-now-supports-windows-on-arm-runners-for-all-public-repos/"
class="uri">https://blogs.windows.com/windowsdeveloper/2025/04/14/github-actions-now-supports-windows-on-arm-runners-for-all-public-repos/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
linkblog</strong> (date: 2025-04-14, from: Dave Winer’s linkblog)</p>
<p>Bukele’s Offense Against the American People.</p>
<p><br></p>
<p><a
href="https://talkingpointsmemo.com/edblog/bukeles-offense-against-the-american-people"
class="uri">https://talkingpointsmemo.com/edblog/bukeles-offense-against-the-american-people</a></p>
<hr />
<h2
id="gpt-4.1-three-new-million-token-input-models-from-openai-including-their-cheapest-model-yet">GPT-4.1:
Three new million token input models from OpenAI, including their
cheapest model yet</h2>
<p>date: 2025-04-14, updated: 2025-04-14, from: Simon Willison’s
Weblog</p>
<p>
OpenAI <a href="https://openai.com/index/gpt-4-1/">introduced</a> three
new models this morning: GPT-4.1, GPT-4.1 mini and GPT-4.1 nano. These
are API-only models right now, not available through the ChatGPT
interface (though you can try them out in OpenAI’s
<a href="https://platform.openai.com/playground">API playground</a>).
All three models can handle 1,047,576 tokens of input and 32,768 tokens
of output, and all three have a May 31, 2024 cut-off date (their
previous models were mostly September 2023).
</p>
<p>
The models score higher than GPT-4o <em>and</em> GPT-4.5 on coding
benchmarks, and do very well on long context benchmarks as well. They
also claim improvements in instruction following - following requested
formats, obeying negative instructions, sorting output and obeying
instructions to say “I don’t know”.
</p>
<p>
I released a new version of my
<a href="https://github.com/simonw/llm-openai-plugin">llm-openai</a>
plugin supporting the new models. This is a new thing for the
<a href="https://llm.datasette.io/">LLM</a> ecosystem: previously OpenAI
models were only supported in core, which meant I had to ship a full LLM
release to add support for them.
</p>
<p>
You can run the new models like this:
</p>
<div class="highlight highlight-source-shell">
<pre>llm install llm-openai-plugin -U
llm -m openai/gpt-4.1 <span class="pl-s"><span class="pl-pds">"</span>Generate an SVG of a pelican riding a bicycle<span class="pl-pds">"</span></span></pre>
</div>
<p>
The other model IDs are <code>openai/gpt-4.1-mini</code> and
<code>openai/gpt-4.1-nano</code>.
</p>
<p>
Here’s the
<a href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">pelican
riding a bicycle</a> I got from full sized GPT-4.1:
</p>
<p>
<img src="https://static.simonwillison.net/static/2025/gpt-4.1-pelican.jpg" alt="Not a terrible pelican on a bicycle. The frame is blue, though misshapen. The pelican's legs are detached from its body. It has a nice but square beak." style="max-width: 100%;" />
</p>
<p>
I’m particularly excited by
<a href="https://platform.openai.com/docs/models/gpt-4.1-nano">GPT-4.1
nano</a>, which handles image and text input up to a million tokens and
is priced lower than any other previous OpenAI model: $0.10/million for
input and $0.40/million for output, less than previous cheapest OpenAI
model GPT-4o-mini ($0.15/$0.60). I’ve updated my
<a href="https://tools.simonwillison.net/llm-prices">LLM pricing
table</a> to include the new models.
</p>
<p>
They’re not the cheapest overall though: Gemini 2.0 Flash Lite and,
Gemini 1.5 Flash 8B, Amazon Nova Lite and Nova Micro and Mistral’s 3B,
8B and Small 3.1 hosted models remain less expensive.
</p>
<p>
<img src="https://static.simonwillison.net/static/2025/model-prices-april-14.jpg" alt="Screenshot of the table from that LLM pricing table link above. Amazon Nova Micro is cheapest at $0.035/million input tokens." style="max-width: 100%;" />
</p>
<p>
As a demonstration of just how cheap GPT-4.1 nano is, consider this
photograph I took of some pelicans:
</p>
<p>
<img src="https://static.simonwillison.net/static/2025/two-pelicans.jpg" alt="Description to follow" style="max-width: 100%" />
</p>
<p>
I ran that through GPT-4.1 nano like this:
</p>
<pre>llm -m openai/gpt-4.1-nano describe \
  -a https://static.simonwillison.net/static/2025/two-pelicans.jpg</pre>
<p>
And got back this response:
</p>
<blockquote>
<p>
The image shows two pelicans flying against a clear blue sky. They are
positioned in flight, with their wings extended, showcasing their large
wingspan and feather patterns. The pelican on the right appears slightly
higher and facing slightly to the left, while the pelican on the left is
oriented more horizontally with its beak pointing forward. Both birds
display a combination of brown, tan, and white plumage, characteristic
of pelicans, with their long beaks prominently visible.
</p>
</blockquote>
<p>
Running <code>llm logs -c –usage</code> revealed that this used 1,933
input tokens and 96 output tokens. Passing those through
<a href="https://tools.simonwillison.net/llm-prices">the pricing
calculator</a> returns a total cost of $0.000232, or 0.0232 cents.
</p>
<p>
That means I could use GPT-4.1 nano to generate descriptions of 4,310
images like this one for just shy of a dollar.
</p>
<p>
A few closing thoughts on these new models:
</p>
<ul>
<li>
<p>
The 1 million input token context thing is a <em>really big deal</em>.
The huge token context has been a major competitive advantage for the
Google Gemini models for a full year at this point - it’s reassuring to
see other vendors start to catch up. I’d like to see the same from
Anthropic - Claude was the first model to hit 200,000 but hasn’t shipped
more than that yet (aside from a 500,000 token model that was restricted
to their big enterprise partners).
</p>
</li>
<li>
<p>
When I added
<a href="https://simonwillison.net/2025/Apr/7/long-context-llm/">fragments
support</a> to LLM last week the feature was mainly designed to help
take advantage of longer context models. It’s pleasing to see another
one show up so shortly after that release.
</p>
</li>
<li>
<p>
OpenAI really emphasized code performance for this model. They called
out the <a href="https://aider.chat/docs/leaderboards/">Aider
benchmark</a> in their announcement post.
</p>
</li>
<li>
<p>
<a href="https://simonwillison.net/2025/Feb/27/introducing-gpt-45/#confidence">As
expected</a>, GPT-4.5 turned out to be not long for this world:
</p>
<blockquote>
<p>
We will also begin deprecating GPT‑4.5 Preview in the API, as GPT‑4.1
offers improved or similar performance on many key capabilities at much
lower cost and latency. GPT‑4.5 Preview will be turned off in three
months, on July 14, 2025, to allow time for developers to transition
</p>
</blockquote>
</li>
<li>
<p>
In <a href="https://www.youtube.com/watch?v=kA-P9ood-cE">the livestream
announcement</a> Michelle Pokrass
<a href="https://www.youtube.com/live/kA-P9ood-cE?t=641s">let slip</a>
that the codename for the model was Quasar - that’s the name of the
stealth model that’s
<a href="https://openrouter.ai/announcements/stealth-model-quasar-alpha">been
previewing on OpenRouter</a> for the past two weeks. That has
<a href="https://twitter.com/openrouterai/status/1911833662464864452">now
been confirmed</a> by OpenRouter.
</p>
</li>
<li>
<p>
OpenAI shared a
<a href="https://cookbook.openai.com/examples/gpt4-1_prompting_guide">GPT
4.1 Prompting Guide</a>, which includes this tip about long context
prompting:
</p>
<blockquote>
<p>
Especially in long context usage, placement of instructions and context
can impact performance. If you have long context in your prompt, ideally
place your instructions at both the beginning and end of the provided
context, as we found this to perform better than only above or below. If
you’d prefer to only have your instructions once, then above the
provided context works better than below.
</p>
</blockquote>
<p>
Adding instructions before the content is incompatible with
<a href="https://platform.openai.com/docs/guides/prompt-caching">prompt
caching</a> - I always keep user instructions at the end since doing so
means multiple prompts can benefit from OpenAI’s prefix cache.
</p>
<p>
They also recommend XML-style delimiters over JSON for long context,
suggesting this format (complete with the XML-invalid unquoted
attribute) that’s similar to the format
<a href="https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags">recommended
by Anthropic</a> for Claude:
</p>
<div class="highlight highlight-text-xml">
<pre>&lt;<span class="pl-ent">doc</span> <span class="pl-e">id</span>=1 <span class="pl-e">title</span>=<span class="pl-s"><span class="pl-pds">"</span>The Fox<span class="pl-pds">"</span></span>&gt;The quick brown fox jumps over the lazy dog&lt;/<span class="pl-ent">doc</span>&gt;</pre>
</div>
<p>
There’s an extensive section at the end
<a href="https://cookbook.openai.com/examples/gpt4-1_prompting_guide#appendix-generating-and-applying-file-diffs">describing
their recommended approach to applying file diffs</a>: “we open-source
here one recommended diff format, on which the model has been
extensively trained”.
</p>
</li>
<li>
<p>
One thing notably absent from the GPT-4.1 announcement is any mention of
audio support. The “o” in GPT-4o stood for “omni”, because it was a
multi-modal model with image and audio input and output. The 4.1 models
appear to be text and image input and text output only.
</p>
</li>
</ul>
<pre><code>    &lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/openai&quot;&gt;openai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llm&quot;&gt;llm&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/vision-llms&quot;&gt;vision-llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llm-pricing&quot;&gt;llm-pricing&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/pelican-riding-a-bicycle&quot;&gt;pelican-riding-a-bicycle&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/long-context&quot;&gt;long-context&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llm-release&quot;&gt;llm-release&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Apr/14/gpt-4-1/#atom-everything"
class="uri">https://simonwillison.net/2025/Apr/14/gpt-4-1/#atom-everything</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
linkblog</strong> (date: 2025-04-14, from: Dave Winer’s linkblog)</p>
<p>How Donald Trump Rolled Bill Maher.</p>
<p><br></p>
<p><a
href="https://www.theframelab.org/how-donald-trump-rolled-bill-maher/?ref=lakoff-and-duran-framelab-newsletter"
class="uri">https://www.theframelab.org/how-donald-trump-rolled-bill-maher/?ref=lakoff-and-duran-framelab-newsletter</a></p>
<hr />
<h2
id="world-quantum-day-embracing-post-quantum-encryption-for-a-secure-future">World
Quantum Day: Embracing Post-Quantum Encryption for a Secure Future</h2>
<p>date: 2025-04-14, from: Purism News and Events</p>
<p>
Today, on World Quantum Day, we celebrate the incredible advancements in
quantum computing—a technology poised to revolutionize industries from
healthcare to telecommunications. But as we marvel at its potential, we
must also confront the challenges it brings, particularly the
existential threat it poses to current encryption systems. At Purism, we
are not just preparing for this future; we are actively shaping it by
integrating post-quantum cryptography (PQC) into our devices and
solutions.
</p>
<p>
The post
<a rel="nofollow" href="https://puri.sm/posts/world-quantum-day-embracing-post-quantum-encryption-for-a-secure-future/">World
Quantum Day: Embracing Post-Quantum Encryption for a Secure Future</a>
appeared first on <a rel="nofollow" href="https://puri.sm/">Purism</a>.
</p>
<p><br></p>
<p><a
href="https://puri.sm/posts/world-quantum-day-embracing-post-quantum-encryption-for-a-secure-future/"
class="uri">https://puri.sm/posts/world-quantum-day-embracing-post-quantum-encryption-for-a-secure-future/</a></p>
<hr />
<h2
id="lenovo-thinkpad-p14s-mobile-workstation-with-amd-strix-point-coming-soon">Lenovo
ThinkPad P14s mobile workstation with AMD Strix Point coming soon</h2>
<p>date: 2025-04-14, from: Liliputing</p>
<p>
The Lenovo ThinkPad P14s is a mobile workstation-class laptop that
combines powerful hardware with a relatively compact design. Last year
Lenovo introduced 5th-gen models with Intel and AMD processor options,
and now it looks like the company is getting ready to bring a big
performance boost with the new ThinkPad P14s Gen 6 series. While Lenovo
hasn’t […]
</p>
<p>
The post
<a href="https://liliputing.com/lenovo-thinkpad-p14s-mobile-workstation-with-amd-strix-point-coming-soon/">Lenovo
ThinkPad P14s mobile workstation with AMD Strix Point coming soon</a>
appeared first on <a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br></p>
<p><a
href="https://liliputing.com/lenovo-thinkpad-p14s-mobile-workstation-with-amd-strix-point-coming-soon/"
class="uri">https://liliputing.com/lenovo-thinkpad-p14s-mobile-workstation-with-amd-strix-point-coming-soon/</a></p>
<hr />
<h2 id="obituary-for-cyc">Obituary for Cyc</h2>
<p>date: 2025-04-14, from: Michael Tsai</p>
<p>Yuxi Liu (via Hacker News): The legendary Cyc project, Douglas
Lenat’s 40-year quest to build artificial general intelligence by
scaling symbolic logic, has failed. Based on extensive archival
research, this essay brings to light its secret history so that it may
be widely known. […] In 1984, he launched Cyc to manually encode
millions of […]</p>
<p><br></p>
<p><a href="https://mjtsai.com/blog/2025/04/14/obituary-for-cyc/"
class="uri">https://mjtsai.com/blog/2025/04/14/obituary-for-cyc/</a></p>
<hr />
<h2 id="google-is-winning-on-every-ai-front">Google Is Winning on Every
AI Front</h2>
<p>date: 2025-04-14, from: Michael Tsai</p>
<p>Alberto Romero (via Hacker News): I’d been holding off on writing
about Gemini 2.5. Focusing on the AI model didn’t feel like enough to
tell the full story of Google’s comeback. Gemini 2.5 is only a
piece—albeit a big one—of something much larger. Back in December 2024,
I said they would come out on top […]</p>
<p><br></p>
<p><a
href="https://mjtsai.com/blog/2025/04/14/google-is-winning-on-every-ai-front/"
class="uri">https://mjtsai.com/blog/2025/04/14/google-is-winning-on-every-ai-front/</a></p>
<hr />
<h2 id="claude-for-mac">Claude for Mac</h2>
<p>date: 2025-04-14, from: Michael Tsai</p>
<p>Jordan Novet (2024, via Hacker News): OpenAI co-founder John Schulman
said in a Monday X post that he would leave the Microsoft-backed company
and join Anthropic, an artificial intelligence startup with funding from
Amazon.The move comes less than three months after OpenAI disbanded a
superalignment team that focused on trying to ensure that people can
[…]</p>
<p><br></p>
<p><a href="https://mjtsai.com/blog/2025/04/14/claude-for-mac/"
class="uri">https://mjtsai.com/blog/2025/04/14/claude-for-mac/</a></p>
<hr />
<h2 id="llama-gaming-ai-benchmarks">LLaMA Gaming AI Benchmarks</h2>
<p>date: 2025-04-14, from: Michael Tsai</p>
<p>Kylie Robison (via Hacker News, Slashdot): Over the weekend, Meta
dropped two new Llama 4 models: a smaller model named Scout, and
Maverick, a mid-size model that the company claims can beat GPT-4o and
Gemini 2.0 Flash “across a broad range of widely reported
benchmarks.”[…]The achievement seemed to position Meta’s open-weight
Llama 4 as a […]</p>
<p><br></p>
<p><a
href="https://mjtsai.com/blog/2025/04/14/llama-gaming-ai-benchmarks/"
class="uri">https://mjtsai.com/blog/2025/04/14/llama-gaming-ai-benchmarks/</a></p>
<hr />
<h2 id="note-on-14th-april-2025">Note on 14th April 2025</h2>
<p>date: 2025-04-14, updated: 2025-04-14, from: Simon Willison’s
Weblog</p>
<p>
Believing AI vendors who promise you that they won’t train on your data
is a <em>huge</em> competitive advantage these days.
</p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Apr/14/believe/#atom-everything"
class="uri">https://simonwillison.net/2025/Apr/14/believe/#atom-everything</a></p>
<hr />
<h2
id="why-tattoos-are-such-an-unreliable-marker-of-gang-membership">Why
tattoos are such an unreliable marker of gang membership</h2>
<p>date: 2025-04-14, from: Guy Kawasaki blog</p>
<p>Beth C. Caldwell, Professor of Law, Southwestern Law School.</p>
<p><br></p>
<p><a
href="https://guykawasaki.substack.com/p/why-tattoos-are-such-an-unreliable"
class="uri">https://guykawasaki.substack.com/p/why-tattoos-are-such-an-unreliable</a></p>
<hr />
<h2
id="the-outdoor-socket-and-the-monster-that-is-the-skoda-mode-2-cable">The
outdoor socket and the monster that is the Skoda Mode 2 cable</h2>
<p>date: 2025-04-14, updated: 2025-04-14, from: Peter Molnar blog</p>
<p>We got a new (to us) car because a truck liberated us from the one we
bought a year ago. Since this one is a plug-in hybrid, I wanted to
charge it from an outdoor socket using the official 3 pin cable.
Apparently it’s not this simple.</p>
<p><br></p>
<p><a
href="https://petermolnar.net/article/skoda-ev-3-pin-outdoor-socket-size/"
class="uri">https://petermolnar.net/article/skoda-ev-3-pin-outdoor-socket-size/</a></p>
<hr />
<h2 id="sqlite-file-format-viewer">SQLite File Format Viewer</h2>
<p>date: 2025-04-14, updated: 2025-04-14, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://sqlite-internal.pages.dev/">SQLite File Format
Viewer</a></strong>
</p>
<p>Neat browser-based visual interface for exploring the structure of a
SQLite database file, built by Visal In using React and a custom parser
<a href="https://github.com/invisal/sqlite-internal/tree/main/src/parser">implemented
in TypeScript</a>.</p>
<pre><code>&lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href=&quot;https://twitter.com/invisal89/status/1911692246182928753&quot;&gt;@invisal89&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/typescript&quot;&gt;typescript&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/react&quot;&gt;react&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/sqlite&quot;&gt;sqlite&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Apr/14/sqlite-file-format-viewer/#atom-everything"
class="uri">https://simonwillison.net/2025/Apr/14/sqlite-file-format-viewer/#atom-everything</a></p>
<hr />
<h2
id="i-tested-the-ai-that-calls-your-elderly-parents-if-you-cant-be-bothered">I
Tested The AI That Calls Your Elderly Parents If You Can’t Be
Bothered</h2>
<p>date: 2025-04-14, from: 404 Media Group</p>
<p>inTouch says on its website “Busy life? You can’t call your parent
every day—but we can.” My own mum said she would feel terrible if her
child used it.</p>
<p><br></p>
<p><a
href="https://www.404media.co/i-tested-the-ai-that-calls-your-elderly-parents-if-you-cant-bothered/"
class="uri">https://www.404media.co/i-tested-the-ai-that-calls-your-elderly-parents-if-you-cant-bothered/</a></p>
<hr />
<h2 id="an-unacceptable-level-of-care">An Unacceptable Level of
Care</h2>
<p>date: 2025-04-14, updated: 2025-04-14, from: One Foot Tsunami</p>
<p><br></p>
<p><a
href="https://onefoottsunami.com/2025/04/14/an-unacceptable-level-of-care/"
class="uri">https://onefoottsunami.com/2025/04/14/an-unacceptable-level-of-care/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
linkblog</strong> (date: 2025-04-14, from: Dave Winer’s linkblog)</p>
<p>Scripting News: What is Inbound RSS?</p>
<p><br></p>
<p><a href="http://scripting.com/2025/04/14/121946.html"
class="uri">http://scripting.com/2025/04/14/121946.html</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
linkblog</strong> (date: 2025-04-14, from: Dave Winer’s linkblog)</p>
<p>Christian immigrants helped elect Trump, now some are at risk of
being deported.</p>
<p><br></p>
<p><a
href="https://www.npr.org/2025/04/11/nx-s1-5345876/christian-immigrants-helped-elect-trump-now-some-are-at-risk-of-being-deported"
class="uri">https://www.npr.org/2025/04/11/nx-s1-5345876/christian-immigrants-helped-elect-trump-now-some-are-at-risk-of-being-deported</a></p>
<hr />
<h2 id="update-to-my-tech-writing-gear-and-tools">Update to my tech
writing gear and tools</h2>
<p>date: 2025-04-14, from: Blog by Fabrizio Ferri-Benedetti</p>
<p>
I’ve recently upgraded some of the hardware I use for work and leisure,
so it’s a good time to refresh my list of
<a href="https://passo.uno/technical-writing-equipment/">tech writing
gear</a>. At the same time, after working as a documentation engineer, I
also picked up new
<a href="https://passo.uno/favorite-tech-writing-tools/">favorite
tools</a>, especially AI-powered ones. Some I already use at work, while
others I keep for personal projects. Let me tell you of some of the
recent additions to my personal inventory and why I think they’re making
me more productive.
</p>
<p><br></p>
<p><a href="https://passo.uno/tech-writing-ai-tools-gear/"
class="uri">https://passo.uno/tech-writing-ai-tools-gear/</a></p>
<hr />
<h2 id="democrats-shouldnt-support-tariffs">Democrats Shouldn’t Support
Tariffs</h2>
<p>date: 2025-04-14, from: Paul Krugman</p>
<p>Don’t get sucked in by Trump’s revenge mania</p>
<p><br></p>
<p><a
href="https://paulkrugman.substack.com/p/democrats-shouldnt-support-tariffs"
class="uri">https://paulkrugman.substack.com/p/democrats-shouldnt-support-tariffs</a></p>
<hr />
<h2 id="on-the-history-of-valve-and-linux">On the history of Valve and
Linux</h2>
<p>date: 2025-04-14, from: Libre News</p>
<p>Valve and Linux have a symbiotic relationship today, but they go way
back, and their story is a long and interesting one.</p>
<p><br></p>
<p><a href="https://thelibre.news/on-the-history-of-valve-and-linux/"
class="uri">https://thelibre.news/on-the-history-of-valve-and-linux/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
linkblog</strong> (date: 2025-04-14, from: Dave Winer’s linkblog)</p>
<p>ChatGPT is to Google what Google was to library card catalogs.</p>
<p><br></p>
<p><a href="https://en.m.wikipedia.org/wiki/Library_catalog"
class="uri">https://en.m.wikipedia.org/wiki/Library_catalog</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
linkblog</strong> (date: 2025-04-14, from: Dave Winer’s linkblog)</p>
<p>I was looking forward to hearing why it was somehow wrong to use
ChatGPT to formulate a housing plan for New York, I would be surprised
if he didn’t (it’s a useful tool!) but I couldn’t because well I’ll
never find out because the author used some other random tool to put up
a paywall.</p>
<p><br></p>
<p><a href="https://hellgatenyc.com/andrew-cuomo-chatgpt-housing-plan/"
class="uri">https://hellgatenyc.com/andrew-cuomo-chatgpt-housing-plan/</a></p>
<hr />
<h2 id="repost-the-fraudulence-of-waste-fraud-and-abuse">Repost: The
Fraudulence of “Waste, Fraud and Abuse”</h2>
<p>date: 2025-04-14, from: Paul Krugman</p>
<p>History repeats itself, the first time as farce, the second as clown
show</p>
<p><br></p>
<p><a
href="https://paulkrugman.substack.com/p/repost-the-fraudulence-of-waste-fraud"
class="uri">https://paulkrugman.substack.com/p/repost-the-fraudulence-of-waste-fraud</a></p>
<hr />
<h2 id="using-llms-as-the-first-line-of-support-in-open-source">Using
LLMs as the first line of support in Open Source</h2>
<p>date: 2025-04-14, updated: 2025-04-14, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://noumenal.es/posts/llms-for-user-support/WZb/">Using
LLMs as the first line of support in Open Source</a></strong>
</p>
From reading the title I was nervous that this might involve automating
the initial response to a user support query in an issue tracker with an
LLM, but Carlton Gibson has better taste than that.
</p>
<blockquote>
<p>
The <strong>open contribution</strong> model engendered by GitHub —
where anonymous (to the project) users can create issues, and comments,
which are almost always extractive support requests — results in an
effective <strong>denial-of-service attack against maintainers</strong>.
[…]
</p>
<p>
For anonymous users, who really just want help almost all the time, the
pattern I’m settling on is to facilitate them getting their answer from
their LLM of choice. […] we can generate a file that we offer users to
download, then we tell the user to pass this to (say) Claude with a
simple prompt for their question.
</p>
</blockquote>
<p>
This resonates with the concept proposed by
<a href="https://llmstxt.org/">llms.txt</a> - making LLM-friendly
context files available for different projects.
</p>
<p>
My
<a href="https://github.com/simonw/docs-for-llms">simonw/docs-for-llms</a>
contains my own early experiment with this: I’m running a build script
to create LLM-friendly concatenated documentation for several of my
projects, and my
<a href="https://github.com/simonw/llm-docs">llm-docs</a> plugin
(<a href="https://simonwillison.net/2025/Apr/7/long-context-llm/#asking-questions-of-llm-s-documentation">described
here</a>) can then be used to ask questions of that documentation.
</p>
<p>
It’s possible to pre-populate the Claude UI with a prompt by linking to
<code>https://claude.ai/new?q={PLACE_HOLDER}</code>, but it looks like
there’s quite a short length limit on how much text can be passed that
way. It would be neat if you could pass a URL to a larger document
instead.
</p>
<p>
<p>ChatGPT also supports
<code>https://chatgpt.com/?q=your-prompt-here</code> (again with a short
length limit) and directly executes the prompt rather than waiting for
you to edit it first(!)</p>
<pre><code>&lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href=&quot;https://fosstodon.org/@carlton/114329734119743735&quot;&gt;@carlton&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;


&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/open-source&quot;&gt;open-source&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/carlton-gibson&quot;&gt;carlton-gibson&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/chatgpt&quot;&gt;chatgpt&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/claude&quot;&gt;claude&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Apr/14/llms-as-the-first-line-of-support/#atom-everything"
class="uri">https://simonwillison.net/2025/Apr/14/llms-as-the-first-line-of-support/#atom-everything</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
linkblog</strong> (date: 2025-04-14, from: Dave Winer’s linkblog)</p>
<p>Musk and minions are still quietly at work, away from the
spotlight.</p>
<p><br></p>
<p><a
href="https://daveverse.wordpress.com/2025/04/13/musk-and-minions-are-still-quietly-at-work-away-from-the-spotlight/"
class="uri">https://daveverse.wordpress.com/2025/04/13/musk-and-minions-are-still-quietly-at-work-away-from-the-spotlight/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Feed">@Feed</span> for Alt
USDS</strong> (date: 2025-04-13, from: Feed for Alt USDS)</p>
<p>🚨Big Announcement🚨 We the Builders is launching a Substack
newsletter tomorrow! Sign up here: https://altusds.substack.com/</p>
<p><br></p>
<p><a
href="https://bsky.app/profile/altusds.bsky.social/post/3lmq7ga6b6q2w"
class="uri">https://bsky.app/profile/altusds.bsky.social/post/3lmq7ga6b6q2w</a></p>
<hr />
<h2 id="the-battle-of-hastings-part-3">556. 1066: The Battle of Hastings
(Part 3)</h2>
<p>date: 2025-04-13, from: This is history podcast</p>
<p>
Following King Harold Godwinson’s climactic victory at the Battle of
Stanford Bridge, and the death of Harald Hardrada, what did he do when
news reached him that William of Normandy’s army had landed further
south? How did the two armies finally come together for one of the most
totemic clashes of all time, on the […]
</p>
<p>
The post
<a href="https://therestishistory.com/556-1066-the-battle-of-hastings-part-3/">556.
1066: The Battle of Hastings (Part 3)</a> appeared first on
<a href="https://therestishistory.com">The Rest is History</a>.
</p>
<p><br></p>
<p><a
href="https://therestishistory.com/556-1066-the-battle-of-hastings-part-3/"
class="uri">https://therestishistory.com/556-1066-the-battle-of-hastings-part-3/</a></p>
<hr />
<h2 id="episode-155---linc">Episode 155 - LINC</h2>
<p>date: 2025-04-13, from: Advent of Computing</p>
<p data-pm-slice="0 0 []">
In the early 1960s a neat little machine came out of MIT. Well, kind of
MIT. The machine was called LINC. It was small, flexible, and designed
to live in laboratories. Some have called it the first personal
computer. But, is that true? Does it have some secret that will unseat
my beloved LGP-30? And how does DEC fit into the picture?
</p>
<audio crossorigin="anonymous" controls="controls">
<source type="audio/mpeg" src="https://traffic.libsyn.com/secure/adventofcomputing/ep155_LINC.mp3?dest-id=1206722">
</source>
</audio>
<p><a href="https://traffic.libsyn.com/secure/adventofcomputing/ep155_LINC.mp3?dest-id=1206722" target="_blank">download
audio/mpeg</a><br></p>
<p><a href="https://adventofcomputing.libsyn.com/episode-155-linc"
class="uri">https://adventofcomputing.libsyn.com/episode-155-linc</a></p>
<hr />
<h2
id="join-me-monday-at-4pet-for-my-live-video-chat-with-the-non-fiction-master-michael-lewis">Join
me Monday at 4pET for my live video chat with the non-fiction master
Michael Lewis</h2>
<p>date: 2025-04-13, from: Tina Brown</p>
<p><br></p>
<p><a
href="https://tinabrown.substack.com/p/join-me-monday-at-4pet-for-my-live"
class="uri">https://tinabrown.substack.com/p/join-me-monday-at-4pet-for-my-live</a></p>
<hr />
<h2 id="our-coming-cyberpunk-dictatorship-snow-crash">Our Coming
Cyberpunk Dictatorship (Snow Crash)</h2>
<p>date: 2025-04-13, from: Literate Machine</p>
YouTube Version | Audio Version There’s a worst case scenario looming
here, right? On January 20th, Trump asked the Department of Defense and
the Department of Homeland Security to submit a joint report, within 90
days, recommending whether or not to invoke the Insurrection Act over
the non-existent “invasion” on our Southern Border. This would allow
Trump to
<p>
<a href="https://literatemachine.com/2025/04/13/our-coming-cyberpunk-dictatorship-snow-crash/" class="more-link themebutton">Read
More</a>
</p>
<p><br></p>
<p><a
href="https://literatemachine.com/2025/04/13/our-coming-cyberpunk-dictatorship-snow-crash/"
class="uri">https://literatemachine.com/2025/04/13/our-coming-cyberpunk-dictatorship-snow-crash/</a></p>
<hr />
<h2 id="sanitizer-fun">sanitizer-fun</h2>
<p>date: 2025-04-13, from: Keith P’s blog</p>
<h2>
Fun with -fsanitize=undefined and Picolibc
</h2>
<p>
Both GCC and Clang support the -fsanitize=undefined flag which
instruments the generated code to detect places where the program
wanders into parts of the C language specification which are either
undefined or implementation defined. Many of these are also common
programming errors. It would be great if there were sanitizers for other
easily detected bugs, but for now, at least the undefined sanitizer does
catch several useful problems.
</p>
<h2>
Supporting the sanitizer
</h2>
<p>
The sanitizer can be built to either trap on any error or call handlers.
In both modes, the same problems are identified, but when trap mode is
enabled, the compiler inserts a trap instruction and doesn’t expect the
program to continue running. When handlers are in use, each identified
issue is tagged with a bunch of useful data and then a specific
sanitizer handling function is called.
</p>
<p>
The specific functions are not all that well documented, nor are the
parameters they receive. Maybe this is because both compilers provide an
implementation of all of the functions they use and don’t really expect
external implementations to exist? However, to make these useful in an
embedded environment, picolibc needs to provide a complete set of
handlers that support all versions both gcc and clang as the
compiler-provided versions depend upon specific C (and C++) libraries.
</p>
<p>
Of course, programs can be built in trap-on-error mode, but that makes
it much more difficult to figure out what went wrong.
</p>
<h2>
Fixing Sanitizer Issues
</h2>
<p>
Once the sanitizer handlers were implemented, picolibc could be built
with them enabled and all of the picolibc tests run to uncover issues
within the library.
</p>
<p>
As with the static analyzer adventure from last year, the vast bulk of
sanitizer complaints came from invoking undefined or
implementation-defined behavior in harmless ways:
</p>
<ul>
<li>
<p>
Computing pointers past &amp;array[size+1]. I found no cases where the
resulting pointers were actually used, but the mere computation is still
undefined behavior. These were fixed by adjusting the code to avoid
computing pointers like this. The result was clearer code, which is
good.
</p>
</li>
<li>
<p>
Signed arithmetic overflow in PRNG code. There are several linear
congruential PRNGs in the library which used signed integer arithmetic.
The rand48 generator carefully used unsigned short values. Of course, in
C, the arithmetic performed on them is done with signed ints if int is
wider than short. C specifies signed overflow as undefined, but both gcc
and clang generate the expected code anyways. The fixes here were
simple; just switch the computations to unsigned arithmetic, adjusting
types and inserting casts as required.
</p>
</li>
<li>
<p>
Passing pointers to the middle of a data structure. For example, free
takes a pointer to the start of an allocation. The management structure
appears just before that in memory; computing the address of which
appears to be undefined behavior to the compiler. The only fix I could
do here was to disable the sanitizer in functions doing these
computations – the sanitizer was mis-detecting correct code and it
doesn’t provide a way to skip checks on a per-operator basis.
</p>
</li>
<li>
<p>
Null pointer plus or minus zero. C says that any arithmetic with the
NULL pointer is undefined, even when the value being added or subtracted
is zero. The fix here was to create a macro, enabled only when the
sanitizer is enabled, which checks for this case and skips the
arithmetic.
</p>
</li>
<li>
<p>
Discarded computations which overflow. A couple of places computed a
value, then checked if that would have overflowed and discard the
result. Even though the program doesn’t depend upon the computation, its
mere presence is undefined behavior. These were fixed by moving the
computation into an <code>else</code> clause in the overflow check. This
inserts an extra branch instruction, which is annoying.
</p>
</li>
<li>
<p>
Signed integer overflow in math code. There’s a common pattern in
various functions that want to compare against 1.0. Instead of using the
floating point equality operator, they do the computation using the two
32-bit halves with ((hi - 0x3ff00000) | lo) == 0. It’s efficient, but
because most of these functions store the ‘hi’ piece in a signed integer
(to make checking the sign bit fast), the result is undefined when hi is
a large negative value. These were fixed by inserting casts to unsigned
types as the results were always tested for equality.
</p>
</li>
</ul>
<h3>
Signed integer shifts
</h3>
<p>
This is one area where the C language spec is just wrong.
</p>
<p>
For left shift, before C99, it worked on signed integers as a bit-wise
operator, equivalent to the operator on unsigned integers. After that,
left shift of negative integers became undefined. Fortunately, it’s
straightforward (if tedious) to work around this issue by just casting
the operand to unsigned, performing the shift and casting it back to the
original type. Picolibc now has an internal macro, <code>lsl</code>,
which does this:
</p>
<pre><code>    #define lsl(__x,__s) ((sizeof(__x) == sizeof(char)) ?                   \
                          (__typeof(__x)) ((unsigned char) (__x) &lt;&lt; (__s)) :  \
                          (sizeof(__x) == sizeof(short)) ?                  \
                          (__typeof(__x)) ((unsigned short) (__x) &lt;&lt; (__s)) : \
                          (sizeof(__x) == sizeof(int)) ?                    \
                          (__typeof(__x)) ((unsigned int) (__x) &lt;&lt; (__s)) :   \
                          (sizeof(__x) == sizeof(long)) ?                   \
                          (__typeof(__x)) ((unsigned long) (__x) &lt;&lt; (__s)) :  \
                          (sizeof(__x) == sizeof(long long)) ?              \
                          (__typeof(__x)) ((unsigned long long) (__x) &lt;&lt; (__s)) : \
                          __undefined_shift_size(__x, __s))
</code></pre>
<p>
Right shift is significantly more complicated to implement. What we want
is an arithmetic shift with the sign bit being replicated as the value
is shifted rightwards. C defines no such operator. Instead, right shift
of negative integers is implementation defined. Fortunately, both gcc
and clang define the <code>&gt;&gt;</code> operator on signed integers
as arithmetic shift. Also fortunately, C hasn’t made this undefined, so
the program itself doesn’t end up undefined.
</p>
<p>
The trouble with arithmetic right shift is that it is <em>not</em>
equivalent to right shift of unsigned values. Here’s what I came up with
using standard C operators:
</p>
<pre><code>    int
    __asr_int(int x, int s) {
        return (int) ((unsigned int) x &gt;&gt; s) |
            -(((unsigned int) x &amp; ((unsigned int) 1 &lt;&lt; (8 * sizeof(int) - 1))) &gt;&gt; s);
    }
</code></pre>
<p>
The sign bit is replicated separately and then or’d into the result.
This function is replicated for each of the five standard integer types
and then the set of them wrapped in another sizeof-selecting macro:
</p>
<pre><code>    #define asr(__x,__s) ((sizeof(__x) == sizeof(char)) ?           \
                          (__typeof(__x))__asr_char(__x, __s) :       \
                          (sizeof(__x) == sizeof(short)) ?          \
                          (__typeof(__x))__asr_short(__x, __s) :      \
                          (sizeof(__x) == sizeof(int)) ?            \
                          (__typeof(__x))__asr_int(__x, __s) :        \
                          (sizeof(__x) == sizeof(long)) ?           \
                          (__typeof(__x))__asr_long(__x, __s) :       \
                          (sizeof(__x) == sizeof(long long)) ?      \
                          (__typeof(__x))__asr_long_long(__x, __s):   \
                          __undefined_shift_size(__x, __s))
</code></pre>
<p>
The lsl and asr macros use sizeof instead of the type-generic mechanism
to remain compatible with compilers that lack type-generic support.
</p>
<p>
Once these macros were written, they needed to be applied where
required. To preserve the benefits of detecting programming errors, they
were only applied where required, not blindly across the whole codebase.
</p>
<p>
There are a couple of common patterns in the math code using shift
operators. One is when computing the exponent value for subnormal
numbers.
</p>
<pre><code>for (ix = -1022, i = hx &lt;&lt; 11; i &gt; 0; i &lt;&lt;= 1)
    ix -= 1;
</code></pre>
<p>
This code computes the exponent by shifting the significand left by 11
bits (the width of the exponent field) and then incrementally shifting
it one bit at a time until the sign flips, which indicates that the
most-significant bit is set. Use of the pre-C99 definition of the left
shift operator is intentional here; so both shifts are replaced with our
lsl operator.
</p>
<p>
In the implementation of pow, the final exponent is computed as the sum
of the two exponents, both of which are in the allowed range. The
resulting sum is then tested to see if it is zero or negative to see if
the final value is sub-normal:
</p>
<pre><code>hx += n &lt;&lt; 20;
if (hx &gt;&gt; 20 &lt;= 0)
    /* do sub-normal things */
</code></pre>
<p>
In this case, the exponent adjustment, <code>n</code>, is a signed value
and so that shift is replaced with the <code>lsl</code> macro. The test
value needs to compute the correct the sign bit, so we replace this with
the <code>asr</code> macro.
</p>
<p>
Because the right shift operation is not undefined, we only use our
fancy macro above when the undefined behavior sanitizer is enabled. On
the other hand, the lsl macro should have zero cost and covers undefined
behavior, so it is always used.
</p>
<h2>
Actual Bugs Found!
</h2>
<p>
The goal of this little adventure was both to make using the undefined
behavior sanitizer with picolibc possible as well as to use the
sanitizer to identify bugs in the library code. I fully expected that
most of the effort would be spent masking harmless undefined behavior
instances, but was hopeful that the effort would also uncover real bugs
in the code. I was not disappointed. Through this work, I found (and
fixed) eight bugs in the code:
</p>
<ol>
<li>
<p>
setlocale/newlocale didn’t check for NULL locale names
</p>
</li>
<li>
<p>
qsort was using uintptr_t to swap data around. On MSP430 in ‘large’
mode, that’s a 20-bit type inside a 32-bit representation.
</p>
</li>
<li>
<p>
random() was returning values in <code>int</code> range rather than
<code>long</code>.
</p>
</li>
<li>
<p>
m68k assembly for memcpy was broken for sizes &gt; 64kB.
</p>
</li>
<li>
<p>
freopen returned NULL, even on success
</p>
</li>
<li>
<p>
The optimized version of memrchr was <em>always</em> performing
unaligned accesses.
</p>
</li>
<li>
<p>
String to float conversion had a table missing four values. This caused
an array access overflow which resulted in imprecise values in some
cases.
</p>
</li>
<li>
<p>
vfwscanf mis-parsed floating point values by assuming that
<code>wchar_t</code> was unsigned.
</p>
</li>
</ol>
<h2>
Sanitizer Wishes
</h2>
<p>
While it’s great to have a way to detect places in your C code which
evoke undefined and implementation defined behaviors, it seems like this
tooling could easily be extended to detect other common programming
mistakes, even where the code is well defined according to the language
spec. An obvious example is in unsigned arithmetic. How many bugs come
from this seemingly innocuous line of code?
</p>
<pre><code>    p = malloc(sizeof(*p) * c);
</code></pre>
<p>
Because sizeof returns an unsigned value, the resulting computation
never results in undefined behavior, even when the multiplication wraps
around, so even with the undefined behavior sanitizer enabled, this bug
will not be caught. Clang seems to have an unsigned integer overflow
sanitizer which should do this, but I couldn’t find anything like this
in gcc.
</p>
<h2>
Summary
</h2>
<p>
The undefined behavior sanitizers present in clang and gcc both provide
useful diagnostics which uncover some common programming errors. In most
cases, replacing undefined behavior with defined behavior is
straightforward, although the lack of an arithmetic right shift operator
in standard C is irksome. I recommend anyone using C to give it a try.
</p>
<p><br></p>
<p><a href="http://keithp.com/blogs/sanitizer-fun/"
class="uri">http://keithp.com/blogs/sanitizer-fun/</a></p>
<hr />
<p><strong><span class="citation"
data-cites="Tomosino">@Tomosino</span>’s Mastodon feed</strong> (date:
2025-04-13, from: Tomosino’s Mastodon feed)</p>
<p>
What I’m saying is… new Ernest movie? 🍿
</p>
<p><br></p>
<p><a href="https://tilde.zone/@tomasino/114332697163690210"
class="uri">https://tilde.zone/@tomasino/114332697163690210</a></p>
<hr />
<p><strong><span class="citation"
data-cites="Tomosino">@Tomosino</span>’s Mastodon feed</strong> (date:
2025-04-13, from: Tomosino’s Mastodon feed)</p>
<p>
Jason Isaacs looks just like Jim Varney
</p>
<p><br></p>
<p><a href="https://tilde.zone/@tomasino/114332693860556798"
class="uri">https://tilde.zone/@tomasino/114332693860556798</a></p>
<hr />
<h2
id="stevens-a-hackable-ai-assistant-using-a-single-sqlite-table-and-a-handful-of-cron-jobs">Stevens:
a hackable AI assistant using a single SQLite table and a handful of
cron jobs</h2>
<p>date: 2025-04-13, updated: 2025-04-13, from: Simon Willison’s
Weblog</p>
<p>
<strong><a href="https://www.geoffreylitt.com/2025/04/12/how-i-made-a-useful-ai-assistant-with-one-sqlite-table-and-a-handful-of-cron-jobs">Stevens:
a hackable AI assistant using a single SQLite table and a handful of
cron jobs</a></strong>
</p>
Geoffrey Litt reports on Stevens, a shared digital assistant he put
together for his family using SQLite and scheduled tasks running on Val
Town.
</p>
<p>
The design is refreshingly simple considering how much it can do.
Everything works around a single <code>memories</code> table. A memory
has text, tags, creation metadata and an optional <code>date</code> for
things like calendar entries and weather reports.
</p>
<p>
Everything else is handled by scheduled jobs to popular weather
information and events from Google Calendar, a Telegram integration
offering a chat UI and a neat system where USPS postal email delivery
notifications are run through Val’s own email handling mechanism to
trigger a Claude prompt to add those as memories too.
</p>
<p>
<p>Here’s <a href="https://www.val.town/x/geoffreylitt/stevensDemo">the
full code on Val Town</a>, including
<a href="https://www.val.town/x/geoffreylitt/stevensDemo/code/dailyBriefing/sendDailyBrief.ts">the
daily briefing prompt</a> that incorporates most of the personality of
the bot.</p>
<pre><code>&lt;p&gt;Tags: &lt;a href=&quot;https://simonwillison.net/tags/geoffrey-litt&quot;&gt;geoffrey-litt&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/sqlite&quot;&gt;sqlite&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/generative-ai&quot;&gt;generative-ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/val-town&quot;&gt;val-town&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/ai&quot;&gt;ai&lt;/a&gt;, &lt;a href=&quot;https://simonwillison.net/tags/llms&quot;&gt;llms&lt;/a&gt;&lt;/p&gt; </code></pre>
<p><br></p>
<p><a
href="https://simonwillison.net/2025/Apr/13/stevens/#atom-everything"
class="uri">https://simonwillison.net/2025/Apr/13/stevens/#atom-everything</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
linkblog</strong> (date: 2025-04-13, from: Dave Winer’s linkblog)</p>
<p>This Is Your Social Safety Net on DOGE.</p>
<p><br></p>
<p><a
href="https://www.emptywheel.net/2025/04/13/this-is-your-social-safety-net-on-doge/"
class="uri">https://www.emptywheel.net/2025/04/13/this-is-your-social-safety-net-on-doge/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
linkblog</strong> (date: 2025-04-13, from: Dave Winer’s linkblog)</p>
<p>Openvibe is an interesting product, a social network browser for
people using Bluesky, Threads, Mastodon and Nostr. An approach to the
problem of too many incompatible twitter-like products.</p>
<p><br></p>
<p><a href="https://openvibe.social/"
class="uri">https://openvibe.social/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Robert">@Robert</span>’s
feed at BlueSky</strong> (date: 2025-04-13, from: Robert’s feed at
BlueSky)</p>
<p>I thought this was a good article on the things to consider in using
or building large language models.
https://americanlibrariesmagazine.org/2025/03/03/assessing-ai/</p>
<p><br></p>
<p><a
href="https://bsky.app/profile/rsdoiel.bsky.social/post/3lmpfsnorbs2j"
class="uri">https://bsky.app/profile/rsdoiel.bsky.social/post/3lmpfsnorbs2j</a></p>
<hr />
<h2
id="onexplayer-x1-pro-handheld-gaming-pc-now-available-with-intel-arrow-lake-for-a-steep-price">ONEXPLAYER
X1 Pro handheld gaming PC now available with Intel Arrow Lake (for a
steep price)</h2>
<p>date: 2025-04-13, from: Liliputing</p>
<p>
The ONEXPLAYER X1 Pro is a handheld gaming PC with a large 10.95 inch
display and a pair of detachable controllers that let you use the system
like a tablet, console, or laptop (with an optional keyboard). When the
ONEXPLAYER X1 Pro first launched late last year it shipped with an AMD
Ryzen AI 9 HX […]
</p>
<p>
The post
<a href="https://liliputing.com/onexplayer-x1-pro-handheld-gaming-pc-now-available-with-intel-arrow-lake-for-a-steep-price/">ONEXPLAYER
X1 Pro handheld gaming PC now available with Intel Arrow Lake (for a
steep price)</a> appeared first on
<a href="https://liliputing.com">Liliputing</a>.
</p>
<p><br><video crossorigin="anonymous" controls="controls" width="250">
<source type="video/mp4" src="https://liliputing.com/wp-content/uploads/2025/04/OXP_EVA.mp4"></source>
</video>
<a href="https://liliputing.com/wp-content/uploads/2025/04/OXP_EVA.mp4" target="_blank">download
video/mp4</a></p>
<p><a
href="https://liliputing.com/onexplayer-x1-pro-handheld-gaming-pc-now-available-with-intel-arrow-lake-for-a-steep-price/"
class="uri">https://liliputing.com/onexplayer-x1-pro-handheld-gaming-pc-now-available-with-intel-arrow-lake-for-a-steep-price/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
linkblog</strong> (date: 2025-04-13, from: Dave Winer’s linkblog)</p>
<p>Developers: This is the WordPress API. Compare it to AT Proto and
ActivityPub. It's got a lot of advantages. It does the basics of social
media. It scales, is mature and stable, and well-managed. A better
foundation imho to build on than the others.</p>
<p><br></p>
<p><a href="https://developer.wordpress.com/docs/api/"
class="uri">https://developer.wordpress.com/docs/api/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
linkblog</strong> (date: 2025-04-13, from: Dave Winer’s linkblog)</p>
<p>Homeland Security Email Tells a US Citizen to 'Immediately'
Self-Deport.</p>
<p><br></p>
<p><a
href="https://www.wired.com/story/homeland-security-email-tells-a-us-citizen-to-immediately-self-deport/"
class="uri">https://www.wired.com/story/homeland-security-email-tells-a-us-citizen-to-immediately-self-deport/</a></p>
<hr />
<h2 id="a-financial-crisis-primer-part-i">A Financial Crisis Primer,
Part I</h2>
<p>date: 2025-04-13, from: Paul Krugman</p>
<p>How things can go catastrophically wrong</p>
<p><br></p>
<p><a
href="https://paulkrugman.substack.com/p/a-financial-crisis-primer-part-i"
class="uri">https://paulkrugman.substack.com/p/a-financial-crisis-primer-part-i</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
linkblog</strong> (date: 2025-04-13, from: Dave Winer’s linkblog)</p>
<p>“If the Europeans decide to issue a ‘sanity bond,’ the world might
jump at it.”</p>
<p><br></p>
<p><a
href="https://www.nytimes.com/2025/04/13/business/trump-risk-us-bonds.html"
class="uri">https://www.nytimes.com/2025/04/13/business/trump-risk-us-bonds.html</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
linkblog</strong> (date: 2025-04-13, from: Dave Winer’s linkblog)</p>
<p>Investing in plant and equipment looks like a bad idea given the
uncertainty, but investing in bribes for the ruling family clearly
yields excellent returns.</p>
<p><br></p>
<p><a
href="https://paulkrugman.substack.com/p/the-trump-tariffs-just-got-even-worse?publication_id=277517&amp;post_id=161220956&amp;isFreemail=true&amp;r=w33x&amp;triedRedirect=true"
class="uri">https://paulkrugman.substack.com/p/the-trump-tariffs-just-got-even-worse?publication_id=277517&amp;post_id=161220956&amp;isFreemail=true&amp;r=w33x&amp;triedRedirect=true</a></p>
<hr />
<h2 id="the-trump-tariffs-just-got-even-worse">The Trump Tariffs Just
Got Even Worse</h2>
<p>date: 2025-04-13, from: Paul Krugman</p>
<p>Higher costs, uncertainty and crony capitalism, oh my</p>
<p><br></p>
<p><a
href="https://paulkrugman.substack.com/p/the-trump-tariffs-just-got-even-worse"
class="uri">https://paulkrugman.substack.com/p/the-trump-tariffs-just-got-even-worse</a></p>
<hr />
<h2 id="i-dream-about-ai-subagents-they-whisper-to-me-while-im-asleep">I
dream about AI subagents; they whisper to me while I’m asleep</h2>
<p>date: 2025-04-13, from: Geoffrey Hunntley’s blog</p>
<p>
In a <a href="https://ghuntley.com/redlining/" rel="noreferrer">previous
post</a>, I shared about "real context window" sizes and "advertised
context window sizes"
</p>
<blockquote>
Claude 3.7’s advertised context window is 200k, but I've noticed that
the quality of output clips at the 147k-152k mark. Regardless of which
agent is
</blockquote>
<p><br></p>
<p><a href="https://ghuntley.com/subagents/"
class="uri">https://ghuntley.com/subagents/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
linkblog</strong> (date: 2025-04-13, from: Dave Winer’s linkblog)</p>
<p>Amazon Is Going Nuts Ahead of the Tariff Hike, this 4TB Seagate Hard
Drive Is Almost Free.</p>
<p><br></p>
<p><a
href="https://gizmodo.com/amazon-is-going-nuts-ahead-of-the-tariff-hike-this-4tb-seagate-hard-drive-is-almost-free-2000588664"
class="uri">https://gizmodo.com/amazon-is-going-nuts-ahead-of-the-tariff-hike-this-4tb-seagate-hard-drive-is-almost-free-2000588664</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
linkblog</strong> (date: 2025-04-13, from: Dave Winer’s linkblog)</p>
<p>I test-drove 2025 Kia EV6 today.</p>
<p><br></p>
<p><a
href="https://daveverse.wordpress.com/2025/04/12/test-drove-2025-kia-ev6/"
class="uri">https://daveverse.wordpress.com/2025/04/12/test-drove-2025-kia-ev6/</a></p>
</section>
<footer>
Antenna is a personal aggregation of items found around the web.
Curated with <a href="https://rsdoiel.github.io/skimmer">skimmer</a> and <a href="https://sqlite.org">sqlite</a> then rendered with <a href="https://pandoc.org">Pandoc</a>.
</footer>
</body>
</html>
