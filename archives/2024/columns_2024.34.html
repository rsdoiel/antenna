<!doctype html>
<html lang="en-US">
<head>
  <meta charset="utf-8" >
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" >
  <title>columns 2024.34</title>
<!--  <link rel="stylesheet" type="text/css"  href="../webfonts/fonts.css" media="screen" > -->
  <link rel="stylesheet" type="text/css"  href="../css/site.css" media="screen" >
</head>
<body>
<header>
	<img class="logo" 
	src="https://upload.wikimedia.org/wikipedia/commons/9/9c/Antenna_1_-_The_Noun_Project.svg"
	alt="line art showing an antenna"
	height="80" width="60" >
	<h1>The Antenna</h1> 
	<h2>finding signal in the noise</h2>
</header>
<nav>
<ul>
	<li><a href="../../">The Antenna</a></li>
	<li><a href="../../../socal_north.html" title="news from the Northern side of Southern California" >SoCal North!</a></li>
	<li><a href="../../../pacific.html" title="News from Micronesia and Pacific">Pacific</a></li>
	<li><a href="../../../mid_central.html" title="news from Mid Central California">Mid Central</a></li>
	<li><a href="../../columns.html" title="blogs I read like columnists">Columns</a></li>
	<li><a href="../../weather.html" title="U.S. National Weather">Weather</a></li>
	<li><a href="../../snapshots/" title="Somedays daily">Snapshots</a></li>
	<li><a href="../">Archives</a></li>
	<li><a href="../../search.html">Search</a></li>
	<li><a href="../../about.html">About</a></li>
</ul>
</nav>
<section>
<div class="description-for-items">
<h2>columns 2024.34</h2>
An experiment in personal news aggregation.
</div>
<h1 id="columns-2024.34">columns 2024.34</h1>
<p>(date: 2024-08-19 08:54:37)</p>
<hr />
<h2
id="costco-in-canc√∫n-a-piece-about-costcos-travel-service-and-how-the">Costco
in Canc√∫n, a piece about Costco‚Äôs travel service and how the‚Ä¶</h2>
<p>date: 2024-08-19, updated: 2024-08-19, from: Jason Kittke‚Äôs blog</p>
<p><a href="https://kottke.org/24/08/0045151-costco-in-cancun-a-piece"
class="uri">https://kottke.org/24/08/0045151-costco-in-cancun-a-piece</a></p>
<hr />
<h2
id="livestreams-of-watering-holes-in-the-namibian-desert">Livestreams of
Watering Holes in the Namibian Desert</h2>
<p>date: 2024-08-19, updated: 2024-08-19, from: Jason Kittke‚Äôs blog</p>
<p><a
href="https://kottke.org/24/08/livestreams-of-watering-holes-in-the-namibian-desert-1"
class="uri">https://kottke.org/24/08/livestreams-of-watering-holes-in-the-namibian-desert-1</a></p>
<hr />
<h2
id="a-disturbing-report-from-propublica-on-the-armed-domestic-terror-cells-that">A
disturbing report from ProPublica on the armed domestic terror cells
that‚Ä¶</h2>
<p>date: 2024-08-19, updated: 2024-08-19, from: Jason Kittke‚Äôs blog</p>
<p><a href="https://kottke.org/24/08/0045150-a-disturbing-report-from-"
class="uri">https://kottke.org/24/08/0045150-a-disturbing-report-from-</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer‚Äôs
Scripting News</strong> (date: 2024-08-19, from: Dave Winer‚Äôs Scripting
News)</p>
<p>BTW, it‚Äôs nice to see the DNC
<a href="https://www.yahoo.com/news/the-democratic-national-convention-is-giving-influencers-media-credentials-for-the-first-time-why-both-campaigns-are-pivoting-to-social-first-strategies-110059052.html">including
influencers</a> this year. I hear them say this is the first time, but I
beg to disagree. A few dozen bloggers were
<a href="http://scripting.com/2004/07/07.html">at the DNC in 2004</a>,
and were treated well, in many ways. I think the word influencer and
blogger have fairly similar meanings. Blogger is a broader term, because
it‚Äôs possible to have a very small readership for a blog, thus not be
influencing very much, but still have a lot of value. And you always can
influence your mom and little sister, right? <span
class="spOldSchoolEmoji">üòÑ</span></p>
<p><a href="http://scripting.com/2024/08/19.html#a142623"
class="uri">http://scripting.com/2024/08/19.html#a142623</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer‚Äôs
Scripting News</strong> (date: 2024-08-19, from: Dave Winer‚Äôs Scripting
News)</p>
<p><img class="imgRightMargin" src="https://imgs.scripting.com/2024/05/03/shootThisDog.png" border="0" style="float: right; padding-left: 25px; padding-bottom: 10px; padding-top: 10px; padding-right: 15px;"><b>Respect
the reader</b>. This isn‚Äôt exactly a new
<a href="https://this.how/rulesForJournalism/">rule for journalism</a>,
but it‚Äôs worth mentioning anyway. If you wouldn‚Äôt want to read the piece
yourself, don‚Äôt let them put your name on it. Example. A
<a href="https://www.nytimes.com/2024/08/18/us/politics/kamala-harris-2010-debate.html?unlocked_article_code=1.EE4.7g6L.aTYQ0sm2Xwz6&smid=url-share">story</a>
promises to tell you about 47 seconds that saved Kamala Harris‚Äôs career.
They do eventually tell you the words, but you have to wade through a
lot of pointless bullshit to get to it. If I were writing it, the first
words of the piece would have to be the words, and then explain it.
You‚Äôve seen this over and over and it gets worse all the time. I still
don‚Äôt understand why they do it, if I‚Äôm reading the piece, I‚Äôm a paying
subscriber, right? Another example of disrespect, quit trying to upsell
paying customers. Once a month maybe, but not every 8th time I visit
your site. Most businesses have no regard for their customers‚Äô time, but
the ones that do, really make an impression.</p>
<p><a href="http://scripting.com/2024/08/19.html#a140827"
class="uri">http://scripting.com/2024/08/19.html#a140827</a></p>
<hr />
<h2 id="reliable-app-storage-over-time-is-not-here-yet">Reliable app
storage over time is not here yet</h2>
<p>date: 2024-08-19, from: Dave Winer‚Äôs Scripting News</p>
<p>
I‚Äôm working on a project which may or may not ship, but it presents an
interesting design challenge either way.
</p>
<p>
The idea is I want to write lots of little bits, less than 5000
characters each, they have titles, use styling, links, include images,
etc.
</p>
<p>
Or it could also be as small as a single emoji.
</p>
<p>
This is what we‚Äôve settled on in 2024 as the basic unit of writing. From
a tweet to a long blog post.
</p>
<p>
I want to make an editor and storage system that fits this model
perfectly based on all we know about this stuff, and the latest server
and network technologies.
</p>
<p>
It should have the best simplest API we know how to make in 2024.
</p>
<p>
In every way it‚Äôll be the nicest, fastest and most flexible way to
create structures of writing over time.
</p>
<p>
In that last sentence is the gotcha ‚Äì <i>over time. </i>It‚Äôs the
frontier, the leading edge. Because in 2024 there‚Äôs no way for me, as an
individual developer to create a structure that lasts over time.
</p>
<p>
I can create a structure that has a high probability of lasting a month.
A pretty good chance of lasting a few years, but beyond that, it gets
less likely probably at a pretty good clip and eventually goes over a
cliff.
</p>
<p>
The way I have answered that in the past was with GitHub.
</p>
<p>
In 2017, I started an
<a href="https://github.com/scripting/Scripting-News/tree/master/blog">archive</a>
of my <a href="http://scripting.com/">Scripting News</a> writing on
GitHub. It‚Äôs still just a fraction of my writing, I‚Äôm not doing anything
like that for all my other sites and services. But at least I‚Äôve managed
to set up a system that only requires me to do something once a month,
which is something I like to do because it gives me some assurance the
other mechanisms are still working. Archive systems have bugs too.
</p>
<p>
So I guess for the project I‚Äôm doing I will again use GitHub to mirror
the content in the database until and unless GitHub proves unusable for
this purpose, or something much better comes along.
</p>
<p>
Note that GitHub has made no promise about the continued availability of
their service, all we have to go on is that they have been reliable for
enough time to present the <i>illusion</i> of persistence. <span
class="spOldSchoolEmoji">üòÑ</span>
</p>
<p><a
href="http://scripting.com/2024/08/19/134815.html?title=reliableAppStorageOverTimeIsNotHereYet"
class="uri">http://scripting.com/2024/08/19/134815.html?title=reliableAppStorageOverTimeIsNotHereYet</a></p>
<hr />
<h2 id="feeds-for-threads">Feeds for Threads</h2>
<p>date: 2024-08-19, from: Dave Winer‚Äôs Scripting News</p>
<p>
I was
<a href="https://www.merriam-webster.com/dictionary/kvell">kvelling</a>
the other day
<a href="https://www.threads.net/@davew/post/C-wOWuDJUU6">about
rss.app</a> and how they have feeds for
<a href="https://www.threads.net/">Threads</a> accounts. They do. But
there are two caveats.
</p>
<ol>
<li>
It <a href="https://rss.app/pricing">costs</a> $9.99 per month for 15
feeds. Could be a bit expensive for some people‚Äôs budgets.
</li>
<li>
<img class="imgRightMargin" src="http://scripting.com/images/2023/07/02/validRss.png" border="0" style="float: right; padding-left: 25px; padding-bottom: 10px; padding-top: 10px; padding-right: 15px;">The
second concern is more serious. It doesn‚Äôt handle titleless items
properly. It repeats the contents of the tweet in the title and
description of the feeds it generates. An
<a href="https://feeder.scripting.com/returnjson?feedurl=https://rss.app/feeds/3A2qGRnWMHFk5DvE.xml">example</a>.
This is not right, and it‚Äôs not the way Mastodon and Bluesky do it.
There‚Äôs nothing wrong with items that have no titles. When an item has
no title you do the common sense thing ‚Äì omit the title. I‚Äôm happy to
help with this. I wrote the
<a href="https://cyber.harvard.edu/rss/rss.html">RSS 2.0 spec</a>, and
am something of an authority on this. It‚Äôs important to get this right.
</li>
</ol>
<p><a
href="http://scripting.com/2024/08/19/125603.html?title=feedsForThreads"
class="uri">http://scripting.com/2024/08/19/125603.html?title=feedsForThreads</a></p>
<hr />
<h2 id="the-state-of-ransomware">The State of Ransomware</h2>
<p>date: 2024-08-19, updated: 2024-08-15, from: Bruce Schneier blog</p>
<p>
Palo Alto Networks published its
<a href="https://unit42.paloaltonetworks.com/unit-42-ransomware-leak-site-data-analysis/">semi-annual
report</a> on ransomware. From the Executive Summary:
</p>
<blockquote>
<p>
Unit 42 monitors ransomware and extortion leak sites closely to keep
tabs on threat activity. We reviewed compromise announcements from 53
dedicated leak sites in the first half of 2024 and found 1,762 new
posts. This averages to approximately 294 posts a month and almost 68
posts a week. Of the 53 ransomware groups whose leak sites we monitored,
six of the groups accounted for more than half of the compromises
observed.
</p>
<p>
In February, we reported a 49% increase year-over-year in alleged
victims posted on ransomware leak sites. So far, in 2024, comparing the
first half of 2023 to the first half of 2024, we see an even further
increase of 4.3%. The higher level of activity observed in 2023 was no
fluke‚Ä¶
</p>
</blockquote>
<p><a
href="https://www.schneier.com/blog/archives/2024/08/the-state-of-ransomware.html"
class="uri">https://www.schneier.com/blog/archives/2024/08/the-state-of-ransomware.html</a></p>
<hr />
<h2 id="indie-search-for-oddmu">2024-08-18 Indie search for Oddmu</h2>
<p>date: 2024-08-19, from: Alex Schroeder‚Äôs Blog</p>
<h1 id="2024-08-18-indie-search-for-oddmu">
2024-08-18 Indie search for Oddmu
</h1>
<p>
This is a follow-up for
<a href="2024-08-16-json-feed-for-indexes">2024-08-16 JSON feed for
indexing</a> where I linked to
<a href="https://www.byjp.me/posts/indiesearch/">IndieSearch, byJP</a>.
I want to see what‚Äôs required for this to work.
</p>
<p>
First, I need to install Pagefind. Lucky me, I already have a Rust build
environment installed.
</p>
<pre><code>cargo install pagefind
</code></pre>
<p>
Next, I need a static HTML copy of my site:
</p>
<pre><code>env ODDMU_LANGUAGES=de,en  oddmu static -jobs 3 /tmp/alex
</code></pre>
<p>
Create the index:
</p>
<pre><code>pagefind --site /tmp/alex
</code></pre>
<p>
Upload:
</p>
<pre><code>mv /tmp/alex/pagefind .
make upload
</code></pre>
<p>
It‚Äôs now available at
<code>https://alexschroeder.ch/wiki/pagefind</code>.
</p>
<p>
Adding the info to the page header:
</p>
<pre><code>&lt;link rel=&quot;search&quot; type=&quot;application/pagefind&quot; href=&quot;/wiki/pagefind&quot; title=&quot;Alex Schroeder‚Äôs Diary&quot;&gt;
&lt;link href=&quot;/wiki/pagefind/pagefind-ui.css&quot; rel=&quot;stylesheet&quot;&gt;
&lt;script src=&quot;/wiki/pagefind/pagefind-ui.js&quot;&gt;&lt;/script&gt;
&lt;script&gt;
window.addEventListener('DOMContentLoaded', (event) =&gt; {
  new PagefindUI({ element: &quot;#pagefind&quot;, showSubResults: true });
});
&lt;/script&gt;
</code></pre>
<p>
And a div to the page body:
</p>
<pre><code>&lt;div id=&quot;pagefind&quot;&gt;&lt;/div&gt;
</code></pre>
<p>
And I had to add <code>‚Äòunsafe-eval‚Äô</code> to the
<code>script-src</code> Content-Security-Policy header.
</p>
<p>
Too bad the search result links all end in <code>.html</code> ‚Ä¶ that
requires an extra rewrite rule, to get rid of. On the other hand, it
also allowed me to get rid of <code>baseUrl: "/view/"</code>.
</p>
<p>
Since there are still rough edges, this search is only available via
<a href="pagefind.html">Pagefind</a>. I‚Äôm also not promising any updates
to the index.
</p>
<p>
<a class="tag" href="/search/?q=%23Search">#Search</a>
<a class="tag" href="/search/?q=%23Odd¬µ">#Odd¬µ</a>
</p>
<p>
<strong>2024-08-19</strong>. While I was experimenting with this all, I
asked
<a class="account" href="https://hachyderm.io/@byjp" title="@byjp@hachyderm.io"><span
class="citation" data-cites="byjp">@byjp</span></a> some questions.
</p>
<p>
<em>Sites provide local indexes in the Pagefind format, as a static
file?</em>
</p>
<p>
Correct ‚Äî except it‚Äôs many files, organised so as to allow minimal
transfer for a single search query ‚Äî but all can be retrieved to have a
full local index
</p>
<p>
<em>Clients register one or more of these files and allow searching
them?</em>
</p>
<p>
Correct ‚Äî they can be retrieved/cached to query locally, or queried
efficiently remotely.
</p>
<p>
<em>Users can install a large number of them, locally? Like I have 23
local dictionaries installed for my dictd and I can query them,
locally.</em>
</p>
<p>
Yes. Many can be kept locally or remotely. The sites you ‚Äúregister‚Äù/add
become your search index.
</p>
<p>
<em>Is it possible for a website to offer just a Pagefind installation
with a number of URLs to Pagefind indexes without hosting pages and
indexes? Clients visiting this Pagefind installation would download all
the indexes pointed to in the list and search them locally?</em>
</p>
<p>
Yes (with minor hackery). Each Pagefind instance <em>is</em> the index,
a small bootstrapping JS/WASM blob, and ~5 lines of init JS. Those 5
lines can include locations of multiple indexes for the (exclusively
client-side) JS to query when searching; by default the only one
configured is the ‚Äúlocal‚Äù index that created with the Pagefind JS/WASM
blob, but you could strip away an empty index and have what you describe
‚Äî in fact, that‚Äôs what my
<a href="https://www.byjp.me/posts/indiesearch/">IndieSearch</a> demo
does!
</p>
<p>
<em>If instead of visiting a site with a Pagefind installation one
installs a Pagefind browser extensions, is it possible to point it to a
URL that hosts a list of indexes?</em>
</p>
<p>
I haven‚Äôt built that (yet), but yeah ‚Äî I‚Äôd want to build an mf2/IndieWeb
compatible ‚Äúnew user experience‚Äù that‚Äôd guide folks to finding a
good-for-them set of defaults. My demo automatically (provisionally)
adds any site you visit that supports IndieSearch, so you‚Äôd get better
coverage fast. I‚Äôd also consider default-importing from blogrolls and
the like. (Management &amp; performance gets tricky with 1000s of
indexes. Probs an ‚Äúif we get there‚Äù problem. üòÖ)
</p>
<p>
<em>Is it possible to ‚Äúmerge‚Äù Pagefind indexes and pass those aggregates
on? I‚Äôm afraid that having local copies of the indexes means that
clients will have to at least query thousands of sites for updates to
their page indexes.</em>
</p>
<p>
Not yet, but I asked exactly this question of the Pagefind devs and they
offered that it‚Äôs currently too hard, but that there is a potential
route they‚Äôd consider, see
<a href="https://github.com/CloudCannon/pagefind/discussions/564#discussioncomment-8702059">#564</a>.
</p>
<p>
<em>Thank you so much for answering the questions!</em>
</p>
<p>
I‚Äôm still thinking about the situation where I‚Äôm part of a community and
we want to all share search, like using
<a href="https://lieu.cblgh.org/">Lieu</a> for a webring ‚Äì except I‚Äôd
like a solution where I don‚Äôt have to do the crawling.
</p>
<p>
Sadly, the communities I‚Äôm part of are planets such as
<a href="https://campaignwiki.org/rpg/">RPG Planet</a> or
<a href="https://planet.emacslife.com/">Planet Emacslife</a>, each with
hundreds of blogs. I suppose most of them don‚Äôt offer a Pagefind index,
being hosted on Blogspot and Wordpress, but what I‚Äôm considering is
ingesting their feed and indexing it. This could be a service I could
perform for people. Luckily, it‚Äôs often possible to get all the blog
pages via the feed. This is how I‚Äôve made
<a href="2010-05-31_Blognapping">local backups of other people‚Äôs
blogs</a>. I guess that each site would be a separate index, however?
</p>
<p>
I‚Äôd like to find a way that doesn‚Äôt require me to always download all
the pages. I‚Äôd like to find a way to update the index as it‚Äôs being
used.
</p>
<p>
I‚Äôd need a way to figure out how to configure it such that the results
link back to the original pages, of course.
</p>
<p>
Another thing I‚Äôm considering is that my own site is rendered live, from
Markdown files‚Ä¶ it‚Äôs not a static site. So ideally I‚Äôd be able to ingest
Markdown files directly. Or I can go the route of exporting it all into
a big feed and ingesting that, once I‚Äôve solved the problem above, I
guess. But the problem above might also be easier to solve by extracting
HTML pages from the feed. It‚Äôs what I‚Äôve done in the past. Create
something that works, first, then improve it later?
</p>
<p>
Anyway, ideas are swirling around.
</p>
<p>
<strong>2024-08-19</strong>. I notice more things that aren‚Äôt quite
working the way I like them to work.
</p>
<p>
The sort order of the results is less than ideal, for example. I like to
emphasize more recent blog posts. Pagefind, however, returns them in
some sort of scoring order so that I‚Äôve seen quite a few results with
pages around 20 years old.
</p>
<p>
Image previews seem to rarely work. I suspect the problem is pages in
subfolders linking to images in that same subfolder. Such relative links
don‚Äôt need a path ‚Äì but they do if Pagefind is not in the same
directory.
</p>
<p>
Here‚Äôs another thing to consider: The index takes up more space than the
full HTML of the entire site, compressed!
</p>
<pre><code>alex@sibirocobombus ~&gt; du -sh alexschroeder.ch/wiki/pagefind alexschroeder.ch/wiki/feed.json.gz 
 43M    alexschroeder.ch/wiki/pagefind
9.7M    alexschroeder.ch/wiki/feed.json.gz
</code></pre>
<p>
So the Pagefind index takes about 4√ó more space than the full HTML, for
this site. This matches my experience with better indexing for my own
site where I experimented with full text indexes and trigram indexes.
Back then:
</p>
<blockquote>
<p>
the 15 MiB of markdown files seem to have generated an index of 70 MiB ‚Äì
<a href="2023-09-11-oddmu">2023-09-11 Odd¬µ memory consumption</a>
</p>
</blockquote>
<p>
Of course, in terms of copyright incentives, handing off the entire site
like that is tricky. Doing it with a feed feels OK. Doing it for a
search engine seems like handing the keys to Google. This provides an
incentive to use a pre-computed index.
</p>
<p>
It also reminds me that the idea I had of building a search engine out
of feed slurping without consent is probably a bad idea ‚Äì like all ideas
based on non-consensual acts.
</p>
<p>
Whether self-indexing is a good thing in terms of avoiding an
English-first focus I don‚Äôt know. I suspect that most people will be
using free software and therefore there‚Äôs no reason to suspect that a
search engine doesn‚Äôt have the means to process the languages. Then
again, that‚Äôs a lock-in where in order to support a new language, you
have to support the software your favourite search-engine supports. So
people indexing our own pages might have long term benefits.
</p>
<p>
I‚Äôm still wondering about the comparison of Pagefind and Lunr, to be
honest. How many such static search solutions are there? Is there a
benefit of one implementation over another?
</p>
<p>
I guess now I should look into Pagefind some more? Indexing non-HTML
pages, handling image previews for pages not in the root directory and
relative image source URLs, the sort order of results, the use of the
.html extension in results‚Ä¶ there are still rough edges as far as I am
concerned ‚Äì and per discussion above the onus is on me to fix my
indexing. üò≠
</p>
<p><a href="https://alexschroeder.ch/view/2024-08-18-indie-search"
class="uri">https://alexschroeder.ch/view/2024-08-18-indie-search</a></p>
<hr />
<h2 id="json-feed-for-indexing">2024-08-16 JSON feed for indexing</h2>
<p>date: 2024-08-19, from: Alex Schroeder‚Äôs Blog</p>
<h1 id="2024-08-16-json-feed-for-indexing">
2024-08-16 JSON feed for indexing
</h1>
<p>
Recently,
<a class="account" href="https://toot.cat/@dredmorbius" title="@dredmorbius@toot.cat"><span
class="citation" data-cites="dredmorbius">@dredmorbius</span></a> wrote
about Google and search and posed the question:
</p>
<blockquote>
<p>
What if websites indexed their own content, and published a permuted
index in a standard format, in a cache-and-forward model similar to how
DNS works?
</p>
</blockquote>
<p>
A while ago I wondered about
<a href="2023-03-07_A_vision_for_search">self-published indexes</a>. We
have software to generate feeds. Why not software to generate indexes?
Back then I proposed a JSON format. Today I finally took a look at
<a href="https://www.jsonfeed.org/version/1.1/">JSON Feed</a>. I think
it has everything we need.
</p>
<p>
Take a look at the example for this site:
<a href="/.well-known/search-feed.json.gz">.well-known/search-feed.json.gz</a>.
This file has about 9.7MiB. The source material is 6740 Markdown pages,
a total of about 21.5MiB, or 8.4MiB compressed.
</p>
<p>
Using the <code>next_url</code> attribute, it would be possible to split
this file up into chunks of 100 pages each, or a chunk per year, if the
platform promises that older pages never change. This wouldn‚Äôt work for
my wiki, but perhaps it would for certain platforms.
</p>
<p>
Somebody will have write up a best-practice on how to use HTTP headers
to avoid downloading the whole file when nothing has changed. Sadly,
<a href="https://datatracker.ietf.org/doc/html/rfc2616#section-13">section
13 of RFC 2616</a> is pretty convoluted. Basically something about the
use of If-Modified-Since and ETags headers.
</p>
<p>
We also need to agree on how to use some of the JSON Feed attributes.
</p>
<p>
<code>content_text</code>: If used, all markup should be ignored by the
server (no guessing whether the text is Markdown or not). It would be
fine if this contained just the text nodes of the HTML, separated by
spaces. This can be useful to see whether words occur in the text, how
frequent they are, etc.
</p>
<p>
<code>content_html</code>: This is the preferred way to include pages in
the index. It is up to the search engine provider to extract useful
information from the HTML, including summaries, extracts, scoring, etc.
It is up to index providers to provide the kind of HTML they think
serves search engines best. This includes using the semantic HTML tags
and dropping style, scripts, footers and other elements that might be
used by search engines to reduce the relevance of the item.
</p>
<p>
I also find <a href="https://datatracker.ietf.org/doc/html/rfc5005">RFC
5005</a> to be very instructive in how to think about feeds for
archiving.
</p>
<p>
<a class="account" href="https://neuromatch.social/@jonny" title="@jonny@neuromatch.social"><span
class="citation" data-cites="jonny">@jonny</span></a> commented, saying
that it was important to think about how search indexes were going to be
used:
</p>
<blockquote>
<p>
so given that no single machine would or should store a whole index of
the internet or even all your local internet, you can go a few ways with
that, take the global quorum sensing path and you get a bigass global
dht-like thing like ipfs. if instead you think there should be some
structure, then you need proximity. is that social proximity where we
swap indexes between people we know? or webring like proximity dependent
on pages linking to each other and mutually indexing their neighborhood?
</p>
</blockquote>
<p>
It‚Äôs an interesting question but I think I want incremental improvements
to the current situation. So if a person has a website right now, on
server, what‚Äôs the simplest thing they can do so that they aren‚Äôt
drowned in crawlers and can still be found via search? That would be
publishing an index, analogous to publishing a feed. Having more search
engines (even if using legacy centralized architecture) would be better
than what we have now. Not depending on crawlers would be better what we
have now.
</p>
<p>
In terms of decentralisation, I think I like community search engines
like lieu. The idea is great: a community lists a bunch of sites. Lieu
generates a web ring and crawls them to build an index of all the member
sites. Instead of crawling, it could fetch the indexes. This would be
much better than what it does right now, because right now, lieu uses
colly for crawling and colly ignores robots.txt. This means that
<a href="2024-06-22-lieu">lieu instantly bans itself when it visits my
site</a> because it‚Äôs not rate limited. It‚Äôs just an implementation
detail, but sadly I am biased. I‚Äôve been on a Butlerian Jihad since 2009
when I discover that <a href="2009-10-15_Network_Traffic">over 30% of
all requests I serve from my sites are for machines, not humans</a>.
</p>
<p>
It makes me want to raise my keyboard and scream ‚ÄúCO‚ÇÇ for the CO‚ÇÇ god!!‚Äù
</p>
<p>
Somebody should draw a Hacker Elric doing that, standing on a mountain
of electro-trash with the burnt and dead landscape of the
post-apocalypse in the background.
</p>
<p>
But back to the problem of indexing. Right now, search engine operators
and their parasites, the search engine optimisation enterprises, crawl
every single page including page histories, page diffs, and more, on my
wikis. If every wanna-be search engine downloaded my index once a day, I
would be saving resources. Whether that‚Äôs a step in the right direction,
I don‚Äôt know.
</p>
<p>
<a class="account" href="https://neuromatch.social/@jonny" title="@jonny@neuromatch.social"><span
class="citation" data-cites="jonny">@jonny</span></a> also said:
</p>
<blockquote>
<p>
i just think that the ability to fundamentally depart from the
commercial structure of the web and all its brokenness doesn‚Äôt happen
gradually and esp.¬†not with the server/client stack we have now
</p>
</blockquote>
<p>
Indeed, there must be another way. I just don‚Äôt see it, right now. It‚Äôs
always hard to imagine a new world while you‚Äôre still living in the old
one. I‚Äôm sure the solution will seem obvious to the next generation,
looking back.
</p>
<p>
<a class="tag" href="/search/?q=%23Search">#Search</a>
<a class="tag" href="/search/?q=%23Feeds">#Feeds</a>
<a class="tag" href="/search/?q=%23Butlerian_Jihad">#Butlerian Jihad</a>
</p>
<p>
<strong>2024-08-17</strong>.
<a class="account" href="https://octodon.social/@splitbrain" title="@splitbrain@octodon.social"><span
class="citation" data-cites="splitbrain">@splitbrain</span></a>
suggested that this was the same as the sitemaps.org concept, but I
think the sitemap lists the URLs available and you still have to crawl
the site. At least now you never miss a page.
</p>
<p>
Would having such an index generate too much traffic? I think it would
worm if all other crawling would stop. That‚Äôs the necessary trade-off,
of course. No stupid crawlers lost in my wiki admin links (history
pages, diffs) wasting resources ‚Äì that is my goal. Also, since I ask for
a crawl delay, crawling has to reconnect all the time, negotiate TLS all
the time, start up CGI scripts all the time‚Ä¶ having basically a static
snapshot for download would obviate that (in a world where crawlers are
smart enough to understand that the don‚Äôt need to crawl).
</p>
<p>
<strong>2024-08-18</strong>.
<a class="account" href="https://merveilles.town/@zens" title="@zens@merveilles.town"><span
class="citation" data-cites="zens">@zens</span></a> mentioned Lunr but
then suggested that
<a class="account" href="https://hachyderm.io/@byjp" title="@byjp@hachyderm.io"><span
class="citation" data-cites="byjp">@byjp</span></a>‚Äôs solution to the
problem is even better: the server provides indexes that are used
client-side and a browser extension allows querying multiple such
indexes, locally.
</p>
<blockquote>
<p>
Lunr.js is a small, full-text search library for use in the browser. It
indexes JSON documents and provides a simple search interface for
retrieving documents that best match text queries.
</p>
<p>
After indexing, Pagefind adds a static search bundle to your built
files, which exposes a JavaScript search API that can be used anywhere
on your site. Pagefind also provides a prebuilt UI that can be used with
no configuration. ‚Äì <a href="https://pagefind.app/">Pagefind</a>
</p>
<p>
Any time they visit the IndieSearch homepage (a page served from their
browser extension) they can now search all the sites supporting
IndieSearch they‚Äôve visited and/or included. ‚Äì
<a href="https://www.byjp.me/posts/indiesearch/">IndieSearch, byJP</a>
</p>
</blockquote>
<p><a
href="https://alexschroeder.ch/view/2024-08-16-json-feed-for-indexes"
class="uri">https://alexschroeder.ch/view/2024-08-16-json-feed-for-indexes</a></p>
<hr />
<h2 id="a-filename-when-none-exists">a filename when none exists</h2>
<p>date: 2024-08-19, from: Daniel Stenberg Blog</p>
<p>This is episode four in my mini-series about shiny new features in
the upcoming curl 8.10.0 release. One of the most commonly used curl
command line options is the dash capital O (-O) which also is known as
dash dash remote-name (‚Äìremote-name) in its long form. This option tells
curl to create a local file ‚Ä¶
<a href="https://daniel.haxx.se/blog/2024/08/19/a-filename-when-none-exists/" class="more-link">Continue
reading <span class="screen-reader-text">a filename when none
exists</span> <span class="meta-nav">‚Üí</span></a></p>
<p><a
href="https://daniel.haxx.se/blog/2024/08/19/a-filename-when-none-exists/"
class="uri">https://daniel.haxx.se/blog/2024/08/19/a-filename-when-none-exists/</a></p>
<hr />
<h2 id="we-thank-you-joe">We thank you, Joe</h2>
<p>date: 2024-08-19, from: Robert Reich‚Äôs blog</p>
<p>Tonight is for you</p>
<p><a href="https://robertreich.substack.com/p/thank-you-joe-c33"
class="uri">https://robertreich.substack.com/p/thank-you-joe-c33</a></p>
<hr />
<h2 id="august-18-2024">August 18, 2024</h2>
<p>date: 2024-08-19, from: Heather Cox Richardson blog</p>
<p>On August 18, 1920, the Tennessee legislature ratified the Nineteenth
Amendment to the U.S.</p>
<p><a href="https://heathercoxrichardson.substack.com/p/august-18-2024"
class="uri">https://heathercoxrichardson.substack.com/p/august-18-2024</a></p>
<hr />
<h2 id="on-a-mac">On a Mac</h2>
<p>date: 2024-08-19, from: Jirka‚Äôs blog</p>
<p>SDon‚Äôt worry. I only have turned on my Apple PowerBook G4 (a machine
which was made when that company was named the ‚ÄúApple Computers‚Äù) and
I‚Äôm now writing (and reading the gopherspace) on it. I think I didn‚Äôt
booted it for 6or so months!</p>
<p><a href="http://jirka.1-2-8.net/20240819-0442_On_a_Mac"
class="uri">http://jirka.1-2-8.net/20240819-0442_On_a_Mac</a></p>
<hr />
<h2 id="monday-19-august-2024">Monday 19 August, 2024</h2>
<p>date: 2024-08-18, from: John Naughton‚Äôs online diary</p>
<p>The silence of the grave A photograph taken on Saturday afternoon in
the beautiful old churchyard where my beloved Sue lies buried. Her death
from cancer in August 2002 left me and our two young children
devastated. We‚Äôve recovered as ‚Ä¶
<a href="https://memex.naughtons.org/monday-19-august-2024/39759/">Continue
reading <span class="meta-nav">‚Üí</span></a></p>
<p><a href="https://memex.naughtons.org/monday-19-august-2024/39759/"
class="uri">https://memex.naughtons.org/monday-19-august-2024/39759/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer‚Äôs
Scripting News</strong> (date: 2024-08-18, from: Dave Winer‚Äôs Scripting
News)</p>
<p>BTW,
<a href="https://www.oliverexplains.com/p/time-for-a-break-democrats-dont-need">Olliver
Willis is right</a>, the Dems don‚Äôt need the journos.</p>
<p><a href="http://scripting.com/2024/08/18.html#a230630"
class="uri">http://scripting.com/2024/08/18.html#a230630</a></p>
<hr />
<h2 id="twitter-isnt-over">Twitter isn‚Äôt over</h2>
<p>date: 2024-08-18, from: Dave Winer‚Äôs Scripting News</p>
<p>
I was surprised that Donald Trump was so famous because I didn‚Äôt watch
reality TV. I come from NY and he was a pretty small thing in NY, even
though I guess the rest of the world thinks he‚Äôs big in NY.
</p>
<ul>
<li>
I come from Queens, actually, so I know the Trump character pretty well
too. Self-important narcissists who inside feel worthless, lashing out
at everything they come in contact with. Not the ordinary Scotch/German
in Queens, but not that rare either.
</li>
</ul>
<p>
The same thing is probably happening now with Elon Musk, because
attention of people like me has wandered away from Twitter, but the
audience is huge, and probably every bit as movable as it was for Trump
in 2016, and Musk owns it? Seems so.
</p>
<p>
People who think this is over are fooled, imho.
</p>
<p>
Read this
<a href="https://www.theguardian.com/commentisfree/article/2024/aug/18/inciting-rioters-in-britain-was-a-test-run-for-elon-musk-just-see-what-he-plans-for-america">piece</a>
in today‚Äôs Guardian for another perspective.
</p>
<p><a
href="http://scripting.com/2024/08/18/230346.html?title=twitterIsntOver"
class="uri">http://scripting.com/2024/08/18/230346.html?title=twitterIsntOver</a></p>
<hr />
<h2
id="james-milner-38-starts-record-23rd-season-in-the-premier-league.-hes">James
Milner, 38, starts record 23rd season in the Premier League. He‚Äôs‚Ä¶</h2>
<p>date: 2024-08-18, updated: 2024-08-18, from: Jason Kittke‚Äôs blog</p>
<p><a href="https://kottke.org/24/08/0045149-james-milner-38-starts-re"
class="uri">https://kottke.org/24/08/0045149-james-milner-38-starts-re</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer‚Äôs
Scripting News</strong> (date: 2024-08-18, from: Dave Winer‚Äôs Scripting
News)</p>
<p><img class="imgRightMargin" src="https://imgs.scripting.com/2019/10/10/sorryClosed.png" border="0" style="float: right; padding-left: 25px; padding-bottom: 10px; padding-top: 10px; padding-right: 15px;">Another
possible <a href="https://this.how/rulesForJournalism/">rule for
journalism</a>. Employ non-journalist op-ed writers. Appointed to a
two-year residence, columns published alongside other op-eds.¬†They
expose flaws in stories that have appeared in the publication, either
news or editorial. They have expertise in areas the publication covers.
They have never been employed as a journalist. They are not part of your
organization, never meet with other writers, have no personal
relationships to preserve. They write from the perspective of a reader.
By giving them equal weight as news or op-ed pieces, it‚Äôs more likely
the professional journalists and opinion writers will pay attention.
Maybe they‚Äôll even respond. This is the beginning of accountability. The
‚Äúpublic editors‚Äù the news orgs employed briefly were jokes. They never
addressed the serious issues, likely because they lacked the perspective
of a reader, or they had relationships to preserve, or just saw it from
the perspective of an insider. There is an obvious and real problem with
news, and it can never be solved until the people whose work is the
problem see it. Is there a more important area of power that gets so
little outside scrutiny? They say democracy dies in darkness, so does
journalism.</p>
<p><a href="http://scripting.com/2024/08/18.html#a144235"
class="uri">http://scripting.com/2024/08/18.html#a144235</a></p>
<hr />
<h2 id="photos-of-huaweis-triple-screen-folding-phone-leak">Photos of
Huawei‚Äôs Triple-Screen Folding Phone Leak</h2>
<p>date: 2024-08-18, updated: 2024-08-18, from: Daring Fireball</p>
<p><a
href="https://www.theverge.com/2024/8/16/24221720/huawei-triple-screen-foldable-leak-rumor"
class="uri">https://www.theverge.com/2024/8/16/24221720/huawei-triple-screen-foldable-leak-rumor</a></p>
<hr />
<h2 id="jackass-of-the-week-thierry-breton">Jackass of the Week: Thierry
Breton</h2>
<p>date: 2024-08-18, updated: 2024-08-18, from: Daring Fireball</p>
<p><a
href="https://www.politico.eu/article/eu-elon-musk-donald-trump-interview-thierry-breton-letter-social-media/"
class="uri">https://www.politico.eu/article/eu-elon-musk-donald-trump-interview-thierry-breton-letter-social-media/</a></p>
<hr />
<h2 id="all-that-jazz">‚ÄôAll That Jazz‚Äô</h2>
<p>date: 2024-08-18, from: Dan Rather‚Äôs Steady</p>
<p>A Reason To Smile</p>
<p><a href="https://steady.substack.com/p/all-that-jazz"
class="uri">https://steady.substack.com/p/all-that-jazz</a></p>
<hr />
<h2 id="sunday-caption-contest-history">Sunday caption contest:
History</h2>
<p>date: 2024-08-18, from: Robert Reich‚Äôs blog</p>
<p>And last week‚Äôs winner</p>
<p><a
href="https://robertreich.substack.com/p/sunday-caption-contest-history"
class="uri">https://robertreich.substack.com/p/sunday-caption-contest-history</a></p>
<hr />
<h2 id="august-17-2024">August 17, 2024</h2>
<p>date: 2024-08-18, from: Heather Cox Richardson blog</p>
<p>I am in Chicago for the Democratic National Convention, and don‚Äôt
think it‚Äôs possible for anyone who has written as much as I have about
political conventions not to want to dive into some past history of them
even as modern history is being made.</p>
<p><a href="https://heathercoxrichardson.substack.com/p/august-17-2024"
class="uri">https://heathercoxrichardson.substack.com/p/august-17-2024</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer‚Äôs
Scripting News</strong> (date: 2024-08-18, from: Dave Winer‚Äôs Scripting
News)</p>
<p>Journalism is very important part of how our country works yet there
is no accountability, no checks and balances, no requirement of
transparency. There isn‚Äôt even a mechanism to disagree with them. most
of the time they have the only voice. We don‚Äôt even know what they‚Äôre
trying to do, what their goals are.</p>
<p><a href="http://scripting.com/2024/08/17.html#a011636"
class="uri">http://scripting.com/2024/08/17.html#a011636</a></p>
</section>
<footer>
Antenna is a personal aggregation of items found around the web.
Curated with <a href="https://rsdoiel.github.io/skimmer">skimmer</a> and <a href="https://sqlite.org">sqlite</a> then rendered with <a href="https://pandoc.org">Pandoc</a> with search provided by <a href="https://pagefind.app">PageFind</a>.
</footer>
<script type="module">
    await import('/pagefind/pagefind-highlight.js');
    new PagefindHighlight({ highlightParam: "highlight" });
</script>
</body>
</html>
