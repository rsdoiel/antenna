<!doctype html>
<html lang="en-US">
<head>
  <meta charset="utf-8" >
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" >
  <title>columns 2024.34</title>
<!--  <link rel="stylesheet" type="text/css"  href="../webfonts/fonts.css" media="screen" > -->
  <link rel="stylesheet" type="text/css"  href="../css/site.css" media="screen" >
</head>
<body>
<header>
	<img class="logo" 
	src="https://upload.wikimedia.org/wikipedia/commons/9/9c/Antenna_1_-_The_Noun_Project.svg"
	alt="line art showing an antenna"
	height="80" width="60" >
	<h1>The Antenna</h1> 
	<h2>finding signal in the noise</h2>
</header>
<nav>
<ul>
	<li><a href="../../">The Antenna</a></li>
	<li><a href="../../../socal_north.html" title="news from the Northern side of Southern California" >SoCal North!</a></li>
	<li><a href="../../../pacific.html" title="News from Micronesia and Pacific">Pacific</a></li>
	<li><a href="../../../mid_central.html" title="news from Mid Central California">Mid Central</a></li>
	<li><a href="../../columns.html" title="blogs I read like columnists">Columns</a></li>
	<li><a href="../../weather.html" title="U.S. National Weather">Weather</a></li>
	<li><a href="../../snapshots/" title="Somedays daily">Snapshots</a></li>
	<li><a href="../">Archives</a></li>
	<li><a href="../../search.html">Search</a></li>
	<li><a href="../../about.html">About</a></li>
</ul>
</nav>
<section>
<div class="description-for-items">
<h2>columns 2024.34</h2>
An experiment in personal news aggregation.
</div>
<h1 id="columns-2024.34">columns 2024.34</h1>
<p>(date: 2024-08-19 08:54:37)</p>
<hr />
<h2
id="costco-in-cancún-a-piece-about-costcos-travel-service-and-how-the">Costco
in Cancún, a piece about Costco’s travel service and how the…</h2>
<p>date: 2024-08-19, updated: 2024-08-19, from: Jason Kittke’s blog</p>
<p><a href="https://kottke.org/24/08/0045151-costco-in-cancun-a-piece"
class="uri">https://kottke.org/24/08/0045151-costco-in-cancun-a-piece</a></p>
<hr />
<h2
id="livestreams-of-watering-holes-in-the-namibian-desert">Livestreams of
Watering Holes in the Namibian Desert</h2>
<p>date: 2024-08-19, updated: 2024-08-19, from: Jason Kittke’s blog</p>
<p><a
href="https://kottke.org/24/08/livestreams-of-watering-holes-in-the-namibian-desert-1"
class="uri">https://kottke.org/24/08/livestreams-of-watering-holes-in-the-namibian-desert-1</a></p>
<hr />
<h2
id="a-disturbing-report-from-propublica-on-the-armed-domestic-terror-cells-that">A
disturbing report from ProPublica on the armed domestic terror cells
that…</h2>
<p>date: 2024-08-19, updated: 2024-08-19, from: Jason Kittke’s blog</p>
<p><a href="https://kottke.org/24/08/0045150-a-disturbing-report-from-"
class="uri">https://kottke.org/24/08/0045150-a-disturbing-report-from-</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
Scripting News</strong> (date: 2024-08-19, from: Dave Winer’s Scripting
News)</p>
<p>BTW, it’s nice to see the DNC
<a href="https://www.yahoo.com/news/the-democratic-national-convention-is-giving-influencers-media-credentials-for-the-first-time-why-both-campaigns-are-pivoting-to-social-first-strategies-110059052.html">including
influencers</a> this year. I hear them say this is the first time, but I
beg to disagree. A few dozen bloggers were
<a href="http://scripting.com/2004/07/07.html">at the DNC in 2004</a>,
and were treated well, in many ways. I think the word influencer and
blogger have fairly similar meanings. Blogger is a broader term, because
it’s possible to have a very small readership for a blog, thus not be
influencing very much, but still have a lot of value. And you always can
influence your mom and little sister, right? <span
class="spOldSchoolEmoji">😄</span></p>
<p><a href="http://scripting.com/2024/08/19.html#a142623"
class="uri">http://scripting.com/2024/08/19.html#a142623</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
Scripting News</strong> (date: 2024-08-19, from: Dave Winer’s Scripting
News)</p>
<p><img class="imgRightMargin" src="https://imgs.scripting.com/2024/05/03/shootThisDog.png" border="0" style="float: right; padding-left: 25px; padding-bottom: 10px; padding-top: 10px; padding-right: 15px;"><b>Respect
the reader</b>. This isn’t exactly a new
<a href="https://this.how/rulesForJournalism/">rule for journalism</a>,
but it’s worth mentioning anyway. If you wouldn’t want to read the piece
yourself, don’t let them put your name on it. Example. A
<a href="https://www.nytimes.com/2024/08/18/us/politics/kamala-harris-2010-debate.html?unlocked_article_code=1.EE4.7g6L.aTYQ0sm2Xwz6&smid=url-share">story</a>
promises to tell you about 47 seconds that saved Kamala Harris’s career.
They do eventually tell you the words, but you have to wade through a
lot of pointless bullshit to get to it. If I were writing it, the first
words of the piece would have to be the words, and then explain it.
You’ve seen this over and over and it gets worse all the time. I still
don’t understand why they do it, if I’m reading the piece, I’m a paying
subscriber, right? Another example of disrespect, quit trying to upsell
paying customers. Once a month maybe, but not every 8th time I visit
your site. Most businesses have no regard for their customers’ time, but
the ones that do, really make an impression.</p>
<p><a href="http://scripting.com/2024/08/19.html#a140827"
class="uri">http://scripting.com/2024/08/19.html#a140827</a></p>
<hr />
<h2 id="reliable-app-storage-over-time-is-not-here-yet">Reliable app
storage over time is not here yet</h2>
<p>date: 2024-08-19, from: Dave Winer’s Scripting News</p>
<p>
I’m working on a project which may or may not ship, but it presents an
interesting design challenge either way.
</p>
<p>
The idea is I want to write lots of little bits, less than 5000
characters each, they have titles, use styling, links, include images,
etc.
</p>
<p>
Or it could also be as small as a single emoji.
</p>
<p>
This is what we’ve settled on in 2024 as the basic unit of writing. From
a tweet to a long blog post.
</p>
<p>
I want to make an editor and storage system that fits this model
perfectly based on all we know about this stuff, and the latest server
and network technologies.
</p>
<p>
It should have the best simplest API we know how to make in 2024.
</p>
<p>
In every way it’ll be the nicest, fastest and most flexible way to
create structures of writing over time.
</p>
<p>
In that last sentence is the gotcha – <i>over time. </i>It’s the
frontier, the leading edge. Because in 2024 there’s no way for me, as an
individual developer to create a structure that lasts over time.
</p>
<p>
I can create a structure that has a high probability of lasting a month.
A pretty good chance of lasting a few years, but beyond that, it gets
less likely probably at a pretty good clip and eventually goes over a
cliff.
</p>
<p>
The way I have answered that in the past was with GitHub.
</p>
<p>
In 2017, I started an
<a href="https://github.com/scripting/Scripting-News/tree/master/blog">archive</a>
of my <a href="http://scripting.com/">Scripting News</a> writing on
GitHub. It’s still just a fraction of my writing, I’m not doing anything
like that for all my other sites and services. But at least I’ve managed
to set up a system that only requires me to do something once a month,
which is something I like to do because it gives me some assurance the
other mechanisms are still working. Archive systems have bugs too.
</p>
<p>
So I guess for the project I’m doing I will again use GitHub to mirror
the content in the database until and unless GitHub proves unusable for
this purpose, or something much better comes along.
</p>
<p>
Note that GitHub has made no promise about the continued availability of
their service, all we have to go on is that they have been reliable for
enough time to present the <i>illusion</i> of persistence. <span
class="spOldSchoolEmoji">😄</span>
</p>
<p><a
href="http://scripting.com/2024/08/19/134815.html?title=reliableAppStorageOverTimeIsNotHereYet"
class="uri">http://scripting.com/2024/08/19/134815.html?title=reliableAppStorageOverTimeIsNotHereYet</a></p>
<hr />
<h2 id="feeds-for-threads">Feeds for Threads</h2>
<p>date: 2024-08-19, from: Dave Winer’s Scripting News</p>
<p>
I was
<a href="https://www.merriam-webster.com/dictionary/kvell">kvelling</a>
the other day
<a href="https://www.threads.net/@davew/post/C-wOWuDJUU6">about
rss.app</a> and how they have feeds for
<a href="https://www.threads.net/">Threads</a> accounts. They do. But
there are two caveats.
</p>
<ol>
<li>
It <a href="https://rss.app/pricing">costs</a> $9.99 per month for 15
feeds. Could be a bit expensive for some people’s budgets.
</li>
<li>
<img class="imgRightMargin" src="http://scripting.com/images/2023/07/02/validRss.png" border="0" style="float: right; padding-left: 25px; padding-bottom: 10px; padding-top: 10px; padding-right: 15px;">The
second concern is more serious. It doesn’t handle titleless items
properly. It repeats the contents of the tweet in the title and
description of the feeds it generates. An
<a href="https://feeder.scripting.com/returnjson?feedurl=https://rss.app/feeds/3A2qGRnWMHFk5DvE.xml">example</a>.
This is not right, and it’s not the way Mastodon and Bluesky do it.
There’s nothing wrong with items that have no titles. When an item has
no title you do the common sense thing – omit the title. I’m happy to
help with this. I wrote the
<a href="https://cyber.harvard.edu/rss/rss.html">RSS 2.0 spec</a>, and
am something of an authority on this. It’s important to get this right.
</li>
</ol>
<p><a
href="http://scripting.com/2024/08/19/125603.html?title=feedsForThreads"
class="uri">http://scripting.com/2024/08/19/125603.html?title=feedsForThreads</a></p>
<hr />
<h2 id="the-state-of-ransomware">The State of Ransomware</h2>
<p>date: 2024-08-19, updated: 2024-08-15, from: Bruce Schneier blog</p>
<p>
Palo Alto Networks published its
<a href="https://unit42.paloaltonetworks.com/unit-42-ransomware-leak-site-data-analysis/">semi-annual
report</a> on ransomware. From the Executive Summary:
</p>
<blockquote>
<p>
Unit 42 monitors ransomware and extortion leak sites closely to keep
tabs on threat activity. We reviewed compromise announcements from 53
dedicated leak sites in the first half of 2024 and found 1,762 new
posts. This averages to approximately 294 posts a month and almost 68
posts a week. Of the 53 ransomware groups whose leak sites we monitored,
six of the groups accounted for more than half of the compromises
observed.
</p>
<p>
In February, we reported a 49% increase year-over-year in alleged
victims posted on ransomware leak sites. So far, in 2024, comparing the
first half of 2023 to the first half of 2024, we see an even further
increase of 4.3%. The higher level of activity observed in 2023 was no
fluke…
</p>
</blockquote>
<p><a
href="https://www.schneier.com/blog/archives/2024/08/the-state-of-ransomware.html"
class="uri">https://www.schneier.com/blog/archives/2024/08/the-state-of-ransomware.html</a></p>
<hr />
<h2 id="indie-search-for-oddmu">2024-08-18 Indie search for Oddmu</h2>
<p>date: 2024-08-19, from: Alex Schroeder’s Blog</p>
<h1 id="2024-08-18-indie-search-for-oddmu">
2024-08-18 Indie search for Oddmu
</h1>
<p>
This is a follow-up for
<a href="2024-08-16-json-feed-for-indexes">2024-08-16 JSON feed for
indexing</a> where I linked to
<a href="https://www.byjp.me/posts/indiesearch/">IndieSearch, byJP</a>.
I want to see what’s required for this to work.
</p>
<p>
First, I need to install Pagefind. Lucky me, I already have a Rust build
environment installed.
</p>
<pre><code>cargo install pagefind
</code></pre>
<p>
Next, I need a static HTML copy of my site:
</p>
<pre><code>env ODDMU_LANGUAGES=de,en  oddmu static -jobs 3 /tmp/alex
</code></pre>
<p>
Create the index:
</p>
<pre><code>pagefind --site /tmp/alex
</code></pre>
<p>
Upload:
</p>
<pre><code>mv /tmp/alex/pagefind .
make upload
</code></pre>
<p>
It’s now available at
<code>https://alexschroeder.ch/wiki/pagefind</code>.
</p>
<p>
Adding the info to the page header:
</p>
<pre><code>&lt;link rel=&quot;search&quot; type=&quot;application/pagefind&quot; href=&quot;/wiki/pagefind&quot; title=&quot;Alex Schroeder’s Diary&quot;&gt;
&lt;link href=&quot;/wiki/pagefind/pagefind-ui.css&quot; rel=&quot;stylesheet&quot;&gt;
&lt;script src=&quot;/wiki/pagefind/pagefind-ui.js&quot;&gt;&lt;/script&gt;
&lt;script&gt;
window.addEventListener('DOMContentLoaded', (event) =&gt; {
  new PagefindUI({ element: &quot;#pagefind&quot;, showSubResults: true });
});
&lt;/script&gt;
</code></pre>
<p>
And a div to the page body:
</p>
<pre><code>&lt;div id=&quot;pagefind&quot;&gt;&lt;/div&gt;
</code></pre>
<p>
And I had to add <code>‘unsafe-eval’</code> to the
<code>script-src</code> Content-Security-Policy header.
</p>
<p>
Too bad the search result links all end in <code>.html</code> … that
requires an extra rewrite rule, to get rid of. On the other hand, it
also allowed me to get rid of <code>baseUrl: "/view/"</code>.
</p>
<p>
Since there are still rough edges, this search is only available via
<a href="pagefind.html">Pagefind</a>. I’m also not promising any updates
to the index.
</p>
<p>
<a class="tag" href="/search/?q=%23Search">#Search</a>
<a class="tag" href="/search/?q=%23Oddµ">#Oddµ</a>
</p>
<p>
<strong>2024-08-19</strong>. While I was experimenting with this all, I
asked
<a class="account" href="https://hachyderm.io/@byjp" title="@byjp@hachyderm.io"><span
class="citation" data-cites="byjp">@byjp</span></a> some questions.
</p>
<p>
<em>Sites provide local indexes in the Pagefind format, as a static
file?</em>
</p>
<p>
Correct — except it’s many files, organised so as to allow minimal
transfer for a single search query — but all can be retrieved to have a
full local index
</p>
<p>
<em>Clients register one or more of these files and allow searching
them?</em>
</p>
<p>
Correct — they can be retrieved/cached to query locally, or queried
efficiently remotely.
</p>
<p>
<em>Users can install a large number of them, locally? Like I have 23
local dictionaries installed for my dictd and I can query them,
locally.</em>
</p>
<p>
Yes. Many can be kept locally or remotely. The sites you “register”/add
become your search index.
</p>
<p>
<em>Is it possible for a website to offer just a Pagefind installation
with a number of URLs to Pagefind indexes without hosting pages and
indexes? Clients visiting this Pagefind installation would download all
the indexes pointed to in the list and search them locally?</em>
</p>
<p>
Yes (with minor hackery). Each Pagefind instance <em>is</em> the index,
a small bootstrapping JS/WASM blob, and ~5 lines of init JS. Those 5
lines can include locations of multiple indexes for the (exclusively
client-side) JS to query when searching; by default the only one
configured is the “local” index that created with the Pagefind JS/WASM
blob, but you could strip away an empty index and have what you describe
— in fact, that’s what my
<a href="https://www.byjp.me/posts/indiesearch/">IndieSearch</a> demo
does!
</p>
<p>
<em>If instead of visiting a site with a Pagefind installation one
installs a Pagefind browser extensions, is it possible to point it to a
URL that hosts a list of indexes?</em>
</p>
<p>
I haven’t built that (yet), but yeah — I’d want to build an mf2/IndieWeb
compatible “new user experience” that’d guide folks to finding a
good-for-them set of defaults. My demo automatically (provisionally)
adds any site you visit that supports IndieSearch, so you’d get better
coverage fast. I’d also consider default-importing from blogrolls and
the like. (Management &amp; performance gets tricky with 1000s of
indexes. Probs an “if we get there” problem. 😅)
</p>
<p>
<em>Is it possible to “merge” Pagefind indexes and pass those aggregates
on? I’m afraid that having local copies of the indexes means that
clients will have to at least query thousands of sites for updates to
their page indexes.</em>
</p>
<p>
Not yet, but I asked exactly this question of the Pagefind devs and they
offered that it’s currently too hard, but that there is a potential
route they’d consider, see
<a href="https://github.com/CloudCannon/pagefind/discussions/564#discussioncomment-8702059">#564</a>.
</p>
<p>
<em>Thank you so much for answering the questions!</em>
</p>
<p>
I’m still thinking about the situation where I’m part of a community and
we want to all share search, like using
<a href="https://lieu.cblgh.org/">Lieu</a> for a webring – except I’d
like a solution where I don’t have to do the crawling.
</p>
<p>
Sadly, the communities I’m part of are planets such as
<a href="https://campaignwiki.org/rpg/">RPG Planet</a> or
<a href="https://planet.emacslife.com/">Planet Emacslife</a>, each with
hundreds of blogs. I suppose most of them don’t offer a Pagefind index,
being hosted on Blogspot and Wordpress, but what I’m considering is
ingesting their feed and indexing it. This could be a service I could
perform for people. Luckily, it’s often possible to get all the blog
pages via the feed. This is how I’ve made
<a href="2010-05-31_Blognapping">local backups of other people’s
blogs</a>. I guess that each site would be a separate index, however?
</p>
<p>
I’d like to find a way that doesn’t require me to always download all
the pages. I’d like to find a way to update the index as it’s being
used.
</p>
<p>
I’d need a way to figure out how to configure it such that the results
link back to the original pages, of course.
</p>
<p>
Another thing I’m considering is that my own site is rendered live, from
Markdown files… it’s not a static site. So ideally I’d be able to ingest
Markdown files directly. Or I can go the route of exporting it all into
a big feed and ingesting that, once I’ve solved the problem above, I
guess. But the problem above might also be easier to solve by extracting
HTML pages from the feed. It’s what I’ve done in the past. Create
something that works, first, then improve it later?
</p>
<p>
Anyway, ideas are swirling around.
</p>
<p>
<strong>2024-08-19</strong>. I notice more things that aren’t quite
working the way I like them to work.
</p>
<p>
The sort order of the results is less than ideal, for example. I like to
emphasize more recent blog posts. Pagefind, however, returns them in
some sort of scoring order so that I’ve seen quite a few results with
pages around 20 years old.
</p>
<p>
Image previews seem to rarely work. I suspect the problem is pages in
subfolders linking to images in that same subfolder. Such relative links
don’t need a path – but they do if Pagefind is not in the same
directory.
</p>
<p>
Here’s another thing to consider: The index takes up more space than the
full HTML of the entire site, compressed!
</p>
<pre><code>alex@sibirocobombus ~&gt; du -sh alexschroeder.ch/wiki/pagefind alexschroeder.ch/wiki/feed.json.gz 
 43M    alexschroeder.ch/wiki/pagefind
9.7M    alexschroeder.ch/wiki/feed.json.gz
</code></pre>
<p>
So the Pagefind index takes about 4× more space than the full HTML, for
this site. This matches my experience with better indexing for my own
site where I experimented with full text indexes and trigram indexes.
Back then:
</p>
<blockquote>
<p>
the 15 MiB of markdown files seem to have generated an index of 70 MiB –
<a href="2023-09-11-oddmu">2023-09-11 Oddµ memory consumption</a>
</p>
</blockquote>
<p>
Of course, in terms of copyright incentives, handing off the entire site
like that is tricky. Doing it with a feed feels OK. Doing it for a
search engine seems like handing the keys to Google. This provides an
incentive to use a pre-computed index.
</p>
<p>
It also reminds me that the idea I had of building a search engine out
of feed slurping without consent is probably a bad idea – like all ideas
based on non-consensual acts.
</p>
<p>
Whether self-indexing is a good thing in terms of avoiding an
English-first focus I don’t know. I suspect that most people will be
using free software and therefore there’s no reason to suspect that a
search engine doesn’t have the means to process the languages. Then
again, that’s a lock-in where in order to support a new language, you
have to support the software your favourite search-engine supports. So
people indexing our own pages might have long term benefits.
</p>
<p>
I’m still wondering about the comparison of Pagefind and Lunr, to be
honest. How many such static search solutions are there? Is there a
benefit of one implementation over another?
</p>
<p>
I guess now I should look into Pagefind some more? Indexing non-HTML
pages, handling image previews for pages not in the root directory and
relative image source URLs, the sort order of results, the use of the
.html extension in results… there are still rough edges as far as I am
concerned – and per discussion above the onus is on me to fix my
indexing. 😭
</p>
<p><a href="https://alexschroeder.ch/view/2024-08-18-indie-search"
class="uri">https://alexschroeder.ch/view/2024-08-18-indie-search</a></p>
<hr />
<h2 id="json-feed-for-indexing">2024-08-16 JSON feed for indexing</h2>
<p>date: 2024-08-19, from: Alex Schroeder’s Blog</p>
<h1 id="2024-08-16-json-feed-for-indexing">
2024-08-16 JSON feed for indexing
</h1>
<p>
Recently,
<a class="account" href="https://toot.cat/@dredmorbius" title="@dredmorbius@toot.cat"><span
class="citation" data-cites="dredmorbius">@dredmorbius</span></a> wrote
about Google and search and posed the question:
</p>
<blockquote>
<p>
What if websites indexed their own content, and published a permuted
index in a standard format, in a cache-and-forward model similar to how
DNS works?
</p>
</blockquote>
<p>
A while ago I wondered about
<a href="2023-03-07_A_vision_for_search">self-published indexes</a>. We
have software to generate feeds. Why not software to generate indexes?
Back then I proposed a JSON format. Today I finally took a look at
<a href="https://www.jsonfeed.org/version/1.1/">JSON Feed</a>. I think
it has everything we need.
</p>
<p>
Take a look at the example for this site:
<a href="/.well-known/search-feed.json.gz">.well-known/search-feed.json.gz</a>.
This file has about 9.7MiB. The source material is 6740 Markdown pages,
a total of about 21.5MiB, or 8.4MiB compressed.
</p>
<p>
Using the <code>next_url</code> attribute, it would be possible to split
this file up into chunks of 100 pages each, or a chunk per year, if the
platform promises that older pages never change. This wouldn’t work for
my wiki, but perhaps it would for certain platforms.
</p>
<p>
Somebody will have write up a best-practice on how to use HTTP headers
to avoid downloading the whole file when nothing has changed. Sadly,
<a href="https://datatracker.ietf.org/doc/html/rfc2616#section-13">section
13 of RFC 2616</a> is pretty convoluted. Basically something about the
use of If-Modified-Since and ETags headers.
</p>
<p>
We also need to agree on how to use some of the JSON Feed attributes.
</p>
<p>
<code>content_text</code>: If used, all markup should be ignored by the
server (no guessing whether the text is Markdown or not). It would be
fine if this contained just the text nodes of the HTML, separated by
spaces. This can be useful to see whether words occur in the text, how
frequent they are, etc.
</p>
<p>
<code>content_html</code>: This is the preferred way to include pages in
the index. It is up to the search engine provider to extract useful
information from the HTML, including summaries, extracts, scoring, etc.
It is up to index providers to provide the kind of HTML they think
serves search engines best. This includes using the semantic HTML tags
and dropping style, scripts, footers and other elements that might be
used by search engines to reduce the relevance of the item.
</p>
<p>
I also find <a href="https://datatracker.ietf.org/doc/html/rfc5005">RFC
5005</a> to be very instructive in how to think about feeds for
archiving.
</p>
<p>
<a class="account" href="https://neuromatch.social/@jonny" title="@jonny@neuromatch.social"><span
class="citation" data-cites="jonny">@jonny</span></a> commented, saying
that it was important to think about how search indexes were going to be
used:
</p>
<blockquote>
<p>
so given that no single machine would or should store a whole index of
the internet or even all your local internet, you can go a few ways with
that, take the global quorum sensing path and you get a bigass global
dht-like thing like ipfs. if instead you think there should be some
structure, then you need proximity. is that social proximity where we
swap indexes between people we know? or webring like proximity dependent
on pages linking to each other and mutually indexing their neighborhood?
</p>
</blockquote>
<p>
It’s an interesting question but I think I want incremental improvements
to the current situation. So if a person has a website right now, on
server, what’s the simplest thing they can do so that they aren’t
drowned in crawlers and can still be found via search? That would be
publishing an index, analogous to publishing a feed. Having more search
engines (even if using legacy centralized architecture) would be better
than what we have now. Not depending on crawlers would be better what we
have now.
</p>
<p>
In terms of decentralisation, I think I like community search engines
like lieu. The idea is great: a community lists a bunch of sites. Lieu
generates a web ring and crawls them to build an index of all the member
sites. Instead of crawling, it could fetch the indexes. This would be
much better than what it does right now, because right now, lieu uses
colly for crawling and colly ignores robots.txt. This means that
<a href="2024-06-22-lieu">lieu instantly bans itself when it visits my
site</a> because it’s not rate limited. It’s just an implementation
detail, but sadly I am biased. I’ve been on a Butlerian Jihad since 2009
when I discover that <a href="2009-10-15_Network_Traffic">over 30% of
all requests I serve from my sites are for machines, not humans</a>.
</p>
<p>
It makes me want to raise my keyboard and scream “CO₂ for the CO₂ god!!”
</p>
<p>
Somebody should draw a Hacker Elric doing that, standing on a mountain
of electro-trash with the burnt and dead landscape of the
post-apocalypse in the background.
</p>
<p>
But back to the problem of indexing. Right now, search engine operators
and their parasites, the search engine optimisation enterprises, crawl
every single page including page histories, page diffs, and more, on my
wikis. If every wanna-be search engine downloaded my index once a day, I
would be saving resources. Whether that’s a step in the right direction,
I don’t know.
</p>
<p>
<a class="account" href="https://neuromatch.social/@jonny" title="@jonny@neuromatch.social"><span
class="citation" data-cites="jonny">@jonny</span></a> also said:
</p>
<blockquote>
<p>
i just think that the ability to fundamentally depart from the
commercial structure of the web and all its brokenness doesn’t happen
gradually and esp. not with the server/client stack we have now
</p>
</blockquote>
<p>
Indeed, there must be another way. I just don’t see it, right now. It’s
always hard to imagine a new world while you’re still living in the old
one. I’m sure the solution will seem obvious to the next generation,
looking back.
</p>
<p>
<a class="tag" href="/search/?q=%23Search">#Search</a>
<a class="tag" href="/search/?q=%23Feeds">#Feeds</a>
<a class="tag" href="/search/?q=%23Butlerian_Jihad">#Butlerian Jihad</a>
</p>
<p>
<strong>2024-08-17</strong>.
<a class="account" href="https://octodon.social/@splitbrain" title="@splitbrain@octodon.social"><span
class="citation" data-cites="splitbrain">@splitbrain</span></a>
suggested that this was the same as the sitemaps.org concept, but I
think the sitemap lists the URLs available and you still have to crawl
the site. At least now you never miss a page.
</p>
<p>
Would having such an index generate too much traffic? I think it would
worm if all other crawling would stop. That’s the necessary trade-off,
of course. No stupid crawlers lost in my wiki admin links (history
pages, diffs) wasting resources – that is my goal. Also, since I ask for
a crawl delay, crawling has to reconnect all the time, negotiate TLS all
the time, start up CGI scripts all the time… having basically a static
snapshot for download would obviate that (in a world where crawlers are
smart enough to understand that the don’t need to crawl).
</p>
<p>
<strong>2024-08-18</strong>.
<a class="account" href="https://merveilles.town/@zens" title="@zens@merveilles.town"><span
class="citation" data-cites="zens">@zens</span></a> mentioned Lunr but
then suggested that
<a class="account" href="https://hachyderm.io/@byjp" title="@byjp@hachyderm.io"><span
class="citation" data-cites="byjp">@byjp</span></a>’s solution to the
problem is even better: the server provides indexes that are used
client-side and a browser extension allows querying multiple such
indexes, locally.
</p>
<blockquote>
<p>
Lunr.js is a small, full-text search library for use in the browser. It
indexes JSON documents and provides a simple search interface for
retrieving documents that best match text queries.
</p>
<p>
After indexing, Pagefind adds a static search bundle to your built
files, which exposes a JavaScript search API that can be used anywhere
on your site. Pagefind also provides a prebuilt UI that can be used with
no configuration. – <a href="https://pagefind.app/">Pagefind</a>
</p>
<p>
Any time they visit the IndieSearch homepage (a page served from their
browser extension) they can now search all the sites supporting
IndieSearch they’ve visited and/or included. –
<a href="https://www.byjp.me/posts/indiesearch/">IndieSearch, byJP</a>
</p>
</blockquote>
<p><a
href="https://alexschroeder.ch/view/2024-08-16-json-feed-for-indexes"
class="uri">https://alexschroeder.ch/view/2024-08-16-json-feed-for-indexes</a></p>
<hr />
<h2 id="a-filename-when-none-exists">a filename when none exists</h2>
<p>date: 2024-08-19, from: Daniel Stenberg Blog</p>
<p>This is episode four in my mini-series about shiny new features in
the upcoming curl 8.10.0 release. One of the most commonly used curl
command line options is the dash capital O (-O) which also is known as
dash dash remote-name (–remote-name) in its long form. This option tells
curl to create a local file …
<a href="https://daniel.haxx.se/blog/2024/08/19/a-filename-when-none-exists/" class="more-link">Continue
reading <span class="screen-reader-text">a filename when none
exists</span> <span class="meta-nav">→</span></a></p>
<p><a
href="https://daniel.haxx.se/blog/2024/08/19/a-filename-when-none-exists/"
class="uri">https://daniel.haxx.se/blog/2024/08/19/a-filename-when-none-exists/</a></p>
<hr />
<h2 id="we-thank-you-joe">We thank you, Joe</h2>
<p>date: 2024-08-19, from: Robert Reich’s blog</p>
<p>Tonight is for you</p>
<p><a href="https://robertreich.substack.com/p/thank-you-joe-c33"
class="uri">https://robertreich.substack.com/p/thank-you-joe-c33</a></p>
<hr />
<h2 id="august-18-2024">August 18, 2024</h2>
<p>date: 2024-08-19, from: Heather Cox Richardson blog</p>
<p>On August 18, 1920, the Tennessee legislature ratified the Nineteenth
Amendment to the U.S.</p>
<p><a href="https://heathercoxrichardson.substack.com/p/august-18-2024"
class="uri">https://heathercoxrichardson.substack.com/p/august-18-2024</a></p>
<hr />
<h2 id="on-a-mac">On a Mac</h2>
<p>date: 2024-08-19, from: Jirka’s blog</p>
<p>SDon’t worry. I only have turned on my Apple PowerBook G4 (a machine
which was made when that company was named the “Apple Computers”) and
I’m now writing (and reading the gopherspace) on it. I think I didn’t
booted it for 6or so months!</p>
<p><a href="http://jirka.1-2-8.net/20240819-0442_On_a_Mac"
class="uri">http://jirka.1-2-8.net/20240819-0442_On_a_Mac</a></p>
<hr />
<h2 id="monday-19-august-2024">Monday 19 August, 2024</h2>
<p>date: 2024-08-18, from: John Naughton’s online diary</p>
<p>The silence of the grave A photograph taken on Saturday afternoon in
the beautiful old churchyard where my beloved Sue lies buried. Her death
from cancer in August 2002 left me and our two young children
devastated. We’ve recovered as …
<a href="https://memex.naughtons.org/monday-19-august-2024/39759/">Continue
reading <span class="meta-nav">→</span></a></p>
<p><a href="https://memex.naughtons.org/monday-19-august-2024/39759/"
class="uri">https://memex.naughtons.org/monday-19-august-2024/39759/</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
Scripting News</strong> (date: 2024-08-18, from: Dave Winer’s Scripting
News)</p>
<p>BTW,
<a href="https://www.oliverexplains.com/p/time-for-a-break-democrats-dont-need">Olliver
Willis is right</a>, the Dems don’t need the journos.</p>
<p><a href="http://scripting.com/2024/08/18.html#a230630"
class="uri">http://scripting.com/2024/08/18.html#a230630</a></p>
<hr />
<h2 id="twitter-isnt-over">Twitter isn’t over</h2>
<p>date: 2024-08-18, from: Dave Winer’s Scripting News</p>
<p>
I was surprised that Donald Trump was so famous because I didn’t watch
reality TV. I come from NY and he was a pretty small thing in NY, even
though I guess the rest of the world thinks he’s big in NY.
</p>
<ul>
<li>
I come from Queens, actually, so I know the Trump character pretty well
too. Self-important narcissists who inside feel worthless, lashing out
at everything they come in contact with. Not the ordinary Scotch/German
in Queens, but not that rare either.
</li>
</ul>
<p>
The same thing is probably happening now with Elon Musk, because
attention of people like me has wandered away from Twitter, but the
audience is huge, and probably every bit as movable as it was for Trump
in 2016, and Musk owns it? Seems so.
</p>
<p>
People who think this is over are fooled, imho.
</p>
<p>
Read this
<a href="https://www.theguardian.com/commentisfree/article/2024/aug/18/inciting-rioters-in-britain-was-a-test-run-for-elon-musk-just-see-what-he-plans-for-america">piece</a>
in today’s Guardian for another perspective.
</p>
<p><a
href="http://scripting.com/2024/08/18/230346.html?title=twitterIsntOver"
class="uri">http://scripting.com/2024/08/18/230346.html?title=twitterIsntOver</a></p>
<hr />
<h2
id="james-milner-38-starts-record-23rd-season-in-the-premier-league.-hes">James
Milner, 38, starts record 23rd season in the Premier League. He’s…</h2>
<p>date: 2024-08-18, updated: 2024-08-18, from: Jason Kittke’s blog</p>
<p><a href="https://kottke.org/24/08/0045149-james-milner-38-starts-re"
class="uri">https://kottke.org/24/08/0045149-james-milner-38-starts-re</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
Scripting News</strong> (date: 2024-08-18, from: Dave Winer’s Scripting
News)</p>
<p><img class="imgRightMargin" src="https://imgs.scripting.com/2019/10/10/sorryClosed.png" border="0" style="float: right; padding-left: 25px; padding-bottom: 10px; padding-top: 10px; padding-right: 15px;">Another
possible <a href="https://this.how/rulesForJournalism/">rule for
journalism</a>. Employ non-journalist op-ed writers. Appointed to a
two-year residence, columns published alongside other op-eds. They
expose flaws in stories that have appeared in the publication, either
news or editorial. They have expertise in areas the publication covers.
They have never been employed as a journalist. They are not part of your
organization, never meet with other writers, have no personal
relationships to preserve. They write from the perspective of a reader.
By giving them equal weight as news or op-ed pieces, it’s more likely
the professional journalists and opinion writers will pay attention.
Maybe they’ll even respond. This is the beginning of accountability. The
“public editors” the news orgs employed briefly were jokes. They never
addressed the serious issues, likely because they lacked the perspective
of a reader, or they had relationships to preserve, or just saw it from
the perspective of an insider. There is an obvious and real problem with
news, and it can never be solved until the people whose work is the
problem see it. Is there a more important area of power that gets so
little outside scrutiny? They say democracy dies in darkness, so does
journalism.</p>
<p><a href="http://scripting.com/2024/08/18.html#a144235"
class="uri">http://scripting.com/2024/08/18.html#a144235</a></p>
<hr />
<h2 id="photos-of-huaweis-triple-screen-folding-phone-leak">Photos of
Huawei’s Triple-Screen Folding Phone Leak</h2>
<p>date: 2024-08-18, updated: 2024-08-18, from: Daring Fireball</p>
<p><a
href="https://www.theverge.com/2024/8/16/24221720/huawei-triple-screen-foldable-leak-rumor"
class="uri">https://www.theverge.com/2024/8/16/24221720/huawei-triple-screen-foldable-leak-rumor</a></p>
<hr />
<h2 id="jackass-of-the-week-thierry-breton">Jackass of the Week: Thierry
Breton</h2>
<p>date: 2024-08-18, updated: 2024-08-18, from: Daring Fireball</p>
<p><a
href="https://www.politico.eu/article/eu-elon-musk-donald-trump-interview-thierry-breton-letter-social-media/"
class="uri">https://www.politico.eu/article/eu-elon-musk-donald-trump-interview-thierry-breton-letter-social-media/</a></p>
<hr />
<h2 id="all-that-jazz">’All That Jazz’</h2>
<p>date: 2024-08-18, from: Dan Rather’s Steady</p>
<p>A Reason To Smile</p>
<p><a href="https://steady.substack.com/p/all-that-jazz"
class="uri">https://steady.substack.com/p/all-that-jazz</a></p>
<hr />
<h2 id="sunday-caption-contest-history">Sunday caption contest:
History</h2>
<p>date: 2024-08-18, from: Robert Reich’s blog</p>
<p>And last week’s winner</p>
<p><a
href="https://robertreich.substack.com/p/sunday-caption-contest-history"
class="uri">https://robertreich.substack.com/p/sunday-caption-contest-history</a></p>
<hr />
<h2 id="august-17-2024">August 17, 2024</h2>
<p>date: 2024-08-18, from: Heather Cox Richardson blog</p>
<p>I am in Chicago for the Democratic National Convention, and don’t
think it’s possible for anyone who has written as much as I have about
political conventions not to want to dive into some past history of them
even as modern history is being made.</p>
<p><a href="https://heathercoxrichardson.substack.com/p/august-17-2024"
class="uri">https://heathercoxrichardson.substack.com/p/august-17-2024</a></p>
<hr />
<p><strong><span class="citation" data-cites="Dave">@Dave</span> Winer’s
Scripting News</strong> (date: 2024-08-18, from: Dave Winer’s Scripting
News)</p>
<p>Journalism is very important part of how our country works yet there
is no accountability, no checks and balances, no requirement of
transparency. There isn’t even a mechanism to disagree with them. most
of the time they have the only voice. We don’t even know what they’re
trying to do, what their goals are.</p>
<p><a href="http://scripting.com/2024/08/17.html#a011636"
class="uri">http://scripting.com/2024/08/17.html#a011636</a></p>
</section>
<footer>
Antenna is a personal aggregation of items found around the web.
Curated with <a href="https://rsdoiel.github.io/skimmer">skimmer</a> and <a href="https://sqlite.org">sqlite</a> then rendered with <a href="https://pandoc.org">Pandoc</a> with search provided by <a href="https://pagefind.app">PageFind</a>.
</footer>
<script type="module">
    await import('/pagefind/pagefind-highlight.js');
    new PagefindHighlight({ highlightParam: "highlight" });
</script>
</body>
</html>
